Unnamed: 0,Research Area,Professor Name,Publication Date,Publication Title,Publication Link,Citation,Publication Summary,doc_id
0,Algorithms and Theory,Soheil Behnezhad,"January 12th, 2025",Massively Parallel Minimum Spanning Tree in General Metric Spaces,https://doi.org/10.1137/1.9781611978322.5," Amir Azarmehr, Soheil Behnezhad, Rajesh Jayaram, Jakub Lacki, Vahab Mirrokni, Peilin Zhong. (2025). Massively Parallel Minimum Spanning Tree in General Metric Spaces SODA, 143-174. https://doi.org/10.1137/1.9781611978322.5","We study the minimum spanning tree (MST) problem in the massively parallel computation (MPC) model. The MST problem admits a simple and folklore O (log n )-round algorithm in the MPC model. This matches a conditional lower bound of Œ©(log n ), which follows from a well-known 1vs2 -C ycle conjecture.",86
1,Algorithms and Theory,Soheil Behnezhad,"January 12th, 2025",Settling the Pass Complexity of Approximate Matchings in Dynamic Graph Streams,https://doi.org/10.1137/1.9781611978322.25," Sepehr Assadi, Soheil Behnezhad, Christian Konrad , Kheeran K. Naidu, Janani Sundaresan. (2025). Settling the Pass Complexity of Approximate Matchings in Dynamic Graph Streams SODA, 864-904. https://doi.org/10.1137/1.9781611978322.25","A semi-streaming algorithm in dynamic graph streams processes any n -vertex graph by making one or multiple passes over a stream of insertions and deletions to edges of the graph and using O ( n ¬∑ polylog( n )) space. Semi-streaming algorithms for dynamic streams were first obtained in the seminal work of Ahn, Guha, and McGregor in 2012, alongside the introduction of the graph sketching technique, which remains the de facto way of designing algorithms in this model and a highly popular technique for designing graph algorithms in general. We settle the pass complexity of approximating maximum matchings in dynamic streams via semistreaming algorithms by improving the state-of-the-art in both upper and lower bounds: ‚Ä¢ We present a randomized sketching based semi-streaming algorithm for O (1)-approximation of maximum matching in dynamic streams using O (log log n ) passes. The approximation ratio of this algorithm can be improved to (1 + Œµ ) for any fixed Œµ > 0 even on weighted graphs using standard techniques. This exponentially improves upon several O (log n ) pass algorithms developed for this problem since the introduction of the dynamic graph streaming model. ‚Ä¢ We prove that any semi-streaming algorithm (not only sketching based) for O (1)-approximation of maximum matching in dynamic streams requires Œ© (log log n ) passes. This presents the first multi-pass lower bound for this problem, which is already also optimal, settling a longstanding open question in this area.",87
2,Algorithms and Theory,Soheil Behnezhad,"January 1st, 2025",Fully Dynamic (Œî + 1)-Coloring Against Adaptive Adversaries,https://doi.org/10.1137/1.9781611978322.169," Soheil Behnezhad, Rajmohan Rajaraman, Omer Wasim. (2025). Fully Dynamic (Œî + 1)-Coloring Against Adaptive Adversaries SODA, 4983-5026. https://doi.org/10.1137/1.9781611978322.169","There are randomized algorithms that maintain a valid solution after each edge insertion or deletion to the n -vertex graph by spending polylog n time. None of these algorithms work against adaptive adversaries whose updates may depend on the output of the algorithm. Our algorithm is randomized, and maintains a valid (Œì + 2) coloring after each update by spending √ï ( n 8/9 ) time with high probability.",88
3,Algorithms and Theory,Soheil Behnezhad,"November 29th, 2024",Fully Dynamic Matching and Ordered Ruzsa-Szemer√©di Graphs,https://doi.org/10.1109/FOCS61266.2024.00027," Soheil Behnezhad, Alma Ghafari. (2024). Fully Dynamic Matching and Ordered Ruzsa-Szemer√©di Graphs FOCS, 314-327. https://doi.org/10.1109/FOCS61266.2024.00027","The goal is to efficiently maintain an approximate maximum matching of a graph that is subject to edge insertions and deletions. Until recently, the fastest known algorithm for this problem required Œò ( n ) time per update where n is the number of vertices. In this paper, we introduce Ordered Ruzsa-Szemer√©di (ORS) graphs and show that the complexity of dynamic matching is closely tied to them. We show that there is a randomized algorithm that maintains a ( 1 ‚àí Œµ ) -approximate maximum matching. of a fully dynamic graph in amortized update-time. We present our algorithm at the IEEE 65th Annual Symposium on Foundations of Computer Science (FOCS) in Chicago, IL, USA.",89
4,Algorithms and Theory,Soheil Behnezhad,"June 11th, 2024",Approximating Maximum Matching Requires Almost Quadratic Time,https://doi.org/10.1145/3618260.3649785," Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein. (2024). Approximating Maximum Matching Requires Almost Quadratic Time STOC, 444-454. https://doi.org/10.1145/3618260.3649785","We study algorithms for estimating the size of maximum matching. This problem has been subject to extensive research. For n -vertex graphs, Bhattacharya, Kiss, and Saranurak [FOCS‚Äô23] (BKS) showed that an estimate that is within —î n of the optimal solution can be achieved in n 2‚àíŒ© —î (1) time, where n is the number of vertices. While this is subquadratic in n for any fixed —î > 0, it gets closer and closer to the trivial Œò( n 2 ) time algorithm that reads the entire input as —î is made smaller and smaller. In this work, we close this gap and show that the algorithm of BKS is close to optimal. In particular, we prove that for any fixed Œ¥ > 0, there is another fixed —î = —î(Œ¥) > 0 such that estimating the size of maximum matching within an additive error of —î n requires Œ©( n 2‚àíŒ¥ ) time in the adjacency list model.",90
5,Algorithms and Theory,Soheil Behnezhad,"May 1st, 2024",Bipartite Matching in Massive Graphs: A Tight Analysis of EDCS,https://openreview.net/forum?id=EDEISRmi6X," Amir Azarmehr, Soheil Behnezhad, Mohammad Roghani. (2024). Bipartite Matching in Massive Graphs: A Tight Analysis of EDCS ICML. https://openreview.net/forum?id=EDEISRmi6X","Graph sparsification has been an extremely powerful tool to alleviate this problem. We study a highly successful and versatile sparsifier for the matching problem: the edge-degree constrained subgraph (EDCS) In this paper, we propose a new approach for analyzing the approximation ratio of EDCS. We gratefully acknowledge the support of the OpenReview Sponsors.",91
6,Algorithms and Theory,Soheil Behnezhad,"January 1st, 2024",Fully Dynamic Matching: -Approximation in Polylog Update Time,https://doi.org/10.1137/1.9781611977912.109," Amir Azarmehr, Soheil Behnezhad, Mohammad Roghani. (2024). Fully Dynamic Matching: -Approximation in Polylog Update Time SODA, 3040-3061. https://doi.org/10.1137/1.9781611977912.109","We study maximum matchings in fully dynamic graphs, which are graphs that undergo both edge insertions and deletions. Our focus is on algorithms that estimate the size of maximum matching after each update while spending a small time. An important question studied extensively is the best approximation achievable via algorithms that only spend poly(log n ) time per update, where n is the number of vertices. The current best bound is a (1/2 + …õ 0 )- approximation for a small constant …õ 0 > 0, due to recent works of Behnezhad [SODA‚Äô23] (…õ 0 ~ 0.001) and Bhattacharya, Kiss, Saranurak, Wajc [SODA‚Äô23] (…õ 0 ~ 0.006) who broke the long-standing 1/2-approximation barrier. These works also showed that for any fixed …õ > 0, the approximation can be further improved to (2 ‚Äî ‚Äî …õ) ~ .585 for bipartite graphs, leaving a huge gap between general and bipartite graphs. In this work, we close this gap. We show that for any fixed …õ > 0, a (2 ‚Äî ‚Äî …õ) approximation can be maintained in poly(log n ) time per update even in general graphs. Our techniques also lead to the same approximation for general graphs in two passes of the semi-streaming setting, removing a similar gap in that setting.",92
7,Algorithms and Theory,Soheil Behnezhad,"December 22nd, 2023",Local Computation Algorithms for Maximum Matching: New Lower Bounds,https://doi.org/10.1109/FOCS57990.2023.00143," Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein. (2023). Local Computation Algorithms for Maximum Matching: New Lower Bounds FOCS, 2322-2335. https://doi.org/10.1109/FOCS57990.2023.00143","We study local computation algorithms (LCA) for maximum matching. An LCA does not return its output entirely, but reveals parts of it upon query. For matchings, each query is a vertices v; the LCA should return whether v is matched‚Äîand if so to which neighbor. We prove that any LCA that computes a matching that is at most an additive of œµ n smaller than the maximum matching in n-vertex graphs of maximum degree Œî must take at least 1 / œµ. This negatively resolves a decade old open problem of the area (see Open Problem 39 of sublinear.info)",93
8,Algorithms and Theory,Soheil Behnezhad,"June 2nd, 2023",On Regularity Lemma and Barriers in Streaming and Dynamic Matching,https://doi.org/10.1145/3564246.3585110," Sepehr Assadi, Soheil Behnezhad, Sanjeev Khanna, Huan Li. (2023). On Regularity Lemma and Barriers in Streaming and Dynamic Matching STOC, 131-144. https://doi.org/10.1145/3564246.3585110","We present a new approach for finding matchings in dense graphs by building on Szemer√©di‚Äôs celebrated Regularity Lemma. This allows us to obtain non-trivial albeit slight improvements over longstanding bounds for matchings in streaming and dynamic graphs. In particular, we establish the following results for n -vertex graphs: A deterministic single-pass streaming algorithm that finds a (1‚àí o (1))-approximate matching in o ( n 2 ) bits of space. This constitutes the first single-pass algorithm for this problem in sublinear space that improves over the 1/2-approximation of the greedy algorithm. A randomized fully dynamic algorithm that with high probability maintains a (1‚àí o (1))-approximate matching in o ( n ) worst-case update time per each edge insertion or deletion. The algorithm works even against an adaptive adversary. This is the first o ( n ) update-time dynamic algorithm with approximation guarantee arbitrarily close to one. Given the use of regularity lemma, the improvement obtained by our algorithms over trivial bounds is only by some (log * n ) Œò(1) factor. Nevertheless, in each case, they show that the ‚Äúright‚Äù answer to the problem is not what is dictated by the previous bounds. Finally, in the streaming model, we also present a randomized (1‚àí o (1))-approximation algorithm whose space can be upper bounded by the density of certain Ruzsa-Szemer√©di (RS) graphs. While RS graphs by now have been used extensively to prove streaming lower bounds, ours is the first to use them as an upper bound tool for desigining improved streaming algorithms.",94
9,Algorithms and Theory,Soheil Behnezhad,"January 16th, 2023",Single-Pass Streaming Algorithms for Correlation Clustering,https://doi.org/10.1137/1.9781611977554.ch33," Soheil Behnezhad, Moses Charikar, Weiyun Ma, Li-Yang Tan. (2023). Single-Pass Streaming Algorithms for Correlation Clustering SODA, 819-849. https://doi.org/10.1137/1.9781611977554.ch33","We study correlation clustering in the streaming setting. This problem has been studied extensively and numerous algorithms have been developed, most requiring multiple passes over the stream. For the important case of single-pass algorithms, recent work of Assadi and Wang [8] obtains a c -approximation using √ï( n ) space where c > 10 5 is a constant and n is the number of vertices to be clustered. We present a single-pass algorithm that obtains a 5-approximation using O(n) space. The algorithm itself is extremely simple and has implications beyond the streaming setting (such as for dynamic and local computation algorithms). The approximation analysis, on the other hand, is delicate and in fact tight.",95
10,Algorithms and Theory,Soheil Behnezhad,"January 16th, 2023",Dynamic Algorithms for Maximum Matching Size,https://doi.org/10.1137/1.9781611977554.ch6," Soheil Behnezhad. (2023). Dynamic Algorithms for Maximum Matching Size SODA, 129-162. https://doi.org/10.1137/1.9781611977554.ch6","We study fully dynamic algorithms for maximum matching. This is a well-studied problem, known to admit several update-time/approximation trade-offs. For instance, it is known how to maintain a 1/2-approximate matching in (poly log n) update time or a 2/3-approximate match¬≠ing in update time, where n is the number of vertices. It has been a long-standing open problem to determine whether either of these bounds can be improved. In this paper, we show that when the goal is to maintain just the size of the matching (and not its edge-set), then these bounds can indeed be improved. First, we give an algorithm that takes (polylog n ) update-time and maintains a .501-approximation (.585-approximation if the graph is bipartite). Second, we give an algorithm that maintains a (2/3 + Œ©(1))-approximation in time for bipartite graphs. Our results build on new connections to sublinear time algorithms. In particular, a key tool for both is an algorithm of the author for estimating the size of maximal matchings in √ï ( n ) time [Behnezhad; FOCS 2021]. Our second result also builds on the edge-degree constrained subgraph (EDCS) of Bernstein and Stein [ICALP'15, SODA'16]. In particular, while it has been known that EDCS may not include a better than 2/3-approximation, we give a new characterization of such tight instances which allows us to break it. We believe this characterization might be of independent interest.",96
11,Algorithms and Theory,Soheil Behnezhad,"January 16th, 2023",Beating Greedy Matching in Sublinear Time,https://doi.org/10.1137/1.9781611977554.ch151," Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein, Amin Saberi. (2023). Beating Greedy Matching in Sublinear Time SODA, 3900-3945. https://doi.org/10.1137/1.9781611977554.ch151","We study sublinear time algorithms for estimating the size of maximum matching in graphs. Our main result is a (¬Ω + Œ©(1))-approximation algorithm which can be implemented in O ( n 1+Œµ ) time, where n is the number of vertices and the constant Œµ > 0 can be made arbitrarily small. The best known lower bound for the problem is Œ©( n ), which holds for any constant approximation. Existing algorithms either obtain the greedy bound of ¬Ω-approximation [Behnezhad FOCS'21], or require some assumption on the maximum degree to run in o ( n 2 )-time [Yoshida, Yamamoto, and Ito STOC'09]. We improve over these by designing a less ‚Äúadaptive‚Äù augmentation algorithm for maximum matching that might be of independent interest.",97
12,Algorithms and Theory,Soheil Behnezhad,"December 28th, 2022",Almost 3-Approximate Correlation Clustering in Constant Rounds,https://doi.org/10.1109/FOCS54457.2022.00074," Soheil Behnezhad, Moses Charikar, Weiyun Ma, Li-Yang Tan. (2022). Almost 3-Approximate Correlation Clustering in Constant Rounds FOCS, 720-731. https://doi.org/10.1109/FOCS54457.2022.00074","We study parallel algorithms for correlation clustering. Each pair among n objects is labeled as either ‚Äúsimilar‚Äù or ‚Äúdissimilar‚Äù The goal is to partition the objects into arbitrarily many clusters while minimizing the number of disagreements with the labels. Our main result is an algorithm that for any. Œµ > 0 obtains a (3 + Œµ )-approximation in O ( 1. /   rounds) This is a culminating point for the rich literature on parallel correlation. clustering and draws on the work of Yoshida, Yamamoto, and Ito.",98
13,Algorithms and Theory,Soheil Behnezhad,"January 5th, 2022",New Trade-Offs for Fully Dynamic Matching via Hierarchical EDCS,https://doi.org/10.1137/1.9781611977073.140," Soheil Behnezhad, Sanjeev Khanna. (2022). New Trade-Offs for Fully Dynamic Matching via Hierarchical EDCS SODA, 3529-3566. https://doi.org/10.1137/1.9781611977073.140","We study the maximum matching problem in fully dynamic graphs: a graph is undergoing both edge insertions and deletions, and the goal is to efficiently maintain a large matching after each edge update. This problem has received considerable attention in recent years. The known algorithms naturally exhibit a trade-off between the quality of the matching maintained (i.e., the approximation ratio) and the time needed per update. While several interesting results have been obtained, the optimal behavior of this trade-off remains largely unclear. Our main contribution is a new approach to designing fully dynamic approximate matching algorithms that in a unified manner not only (essentially) recovers all previously known trade-offs that were achieved via very different techniques, but reveals some new ones as well. Specifically, we introduce a generalization of the edge-degree constrained subgraph (EDCS) of Bernstein and Stein (2015) that we call the hierarchical EDCS (HEDCS). We also present a randomized algorithm for efficiently maintaining an HEDCS. In an m -edge graph with maximum degree Œî, for any integer k ‚â• 0 that is essentially the number of levels of the hierarchy in HEDCS, our algorithm takes √ï (min{Œî 1/( k + 1) , m 1/(2 k +2) }) worst-case update-time and maintains an (almost) Œ± ( k )-approximate matching where we show: These bounds recover all previous trade-offs known for dynamic matching in the literature up to logarithmic factors in the update-time. Œ± (2) > .612 for bipartite graphs, and Œ± (2) > .609 for general graphs. Note that these approximations are obtained in √ï (min{Œî 1/3 , m 1/6 }) update-time. Œ± (3) > .563 for bipartite graphs, and Œ± (3) > .532 for general graphs. Note that these approximations are obtained in √ï (min{Œî 1/4 , m 1/8 }) update-time.",99
14,Algorithms and Theory,Soheil Behnezhad,"January 5th, 2022",Stochastic Vertex Cover with Few Queries,https://doi.org/10.1137/1.9781611977073.73," Soheil Behnezhad, Avrim Blum, Mahsa Derakhshan. (2022). Stochastic Vertex Cover with Few Queries SODA, 1808-1846. https://doi.org/10.1137/1.9781611977073.73","We study the minimum vertex cover problem in the following stochastic setting. Let G be an arbitrary given graph, p ‚àä (0, 1] a parameter of the problem, and let G p be a random subgraph that includes each edge of G independently with probability p . We are unaware of the realization G p , but can learn if an edge e exists in G p by querying it. The goal is to find an approximate minimum vertex cover (MVC) of G p by querying few edges of G non-adaptively. This stochastic setting has been studied extensively for various problems such as minimum spanning trees, matroids, shortest paths, and matchings. To our knowledge, however, no non-trivial bound was known for MVC prior to our work. In this work, we present a: (2 + ‚àä )-approximation for general graphs which queries edges per vertex, and a 1.367-approximation for bipartite graphs which queries poly(1/ p ) edges per vertex. Additionally, we show that at the expense of a triple-exponential dependence on p ‚Äì1 in the number of queries, the approximation ratio can be improved down to (1 + ‚àä ) for bipartite graphs. Our techniques also lead to improved bounds for bipartite stochastic matching. We obtain a 0.731-approximation with nearly-linear in 1/ p per-vertex queries. This is the first result to break the prevalent (2/3‚àº 0.66)-approximation barrier in the poly(1/ p ) query regime, improving algorithms of [Behnezhad et al ., SODA'19] and [Assadi and Bernstein, SOSA'19].",100
15,Algorithms and Theory,Soheil Behnezhad,"March 4th, 2021",Time-Optimal Sublinear Algorithms for Matching and Vertex Cover,https://doi.org/10.1109/FOCS52979.2021.00089," Soheil Behnezhad. (2021). Time-Optimal Sublinear Algorithms for Matching and Vertex Cover FOCS, 873-884. https://doi.org/10.1109/FOCS52979.2021.00089","We study the problem of estimating the size of maximum matching and minimum vertices cover in sub linear time. We obtain the following results for both problems which are all provably time-optimal up to polylogarithmic factors. Our main contribution and the key ingredient of the bounds above is a near-tight analysis of the average query complexity of randomized greedy maximal matching. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details.",101
16,Algorithms and Theory,Mahsa Derakhshan,"January 12th, 2025","New Philosopher Inequalities for Online Bayesian Matching, via Pivotal Sampling",https://doi.org/10.1137/1.9781611978322.98," Mark Braverman, Mahsa Derakhshan, Tristan Pollner, Amin Saberi, David Wajc. (2025). New Philosopher Inequalities for Online Bayesian Matching, via Pivotal Sampling SODA, 3029-3068. https://doi.org/10.1137/1.9781611978322.98","We study the polynomial-time approximability of the optimal online stochastic bipartite matching algorithm, initiated by Papadimitriou et al. (EC‚Äô21). Here, nodes on one side of the graph are given upfront, while at each time t, an online node and its edge weights are drawn from a time-dependent distribution. The optimal algorithm is PSPACE-hard to approximate within some universal constant. We refer to this optimal algorithm, which requires time to think (compute), as a philosopher, and refer to polynomial-time online approximations of the above as philosopher inequalities. The best known philosopher inequality for online matching yields a 0.652-approximation. In contrast, the best possible prophet inequality, or approximation of the optimum offline solution, is 0.5. Our main results are a 0.678-approximate algorithm and a 0.685-approximation for a vertex-weighted special case. Notably, both bounds exceed the 0.666-approximation of the offline optimum obtained by Tang, Wu, and Wu (STOC‚Äô22) for the vertex-weighted problem. Building on our algorithms and the recent black-box reduction of Banihashem et al. (SODA‚Äô24), we provide polytime (pricing-based) truthful mechanisms which 0.678-approximate the social welfare of the optimal online allocation for bipartite matching markets. Our online allocation algorithm relies on the classic pivotal sampling algorithm (Srinivasan FOCS‚Äô01, Gandhi et al. J.ACM‚Äô06), along with careful discarding to obtain strong negative correlations between offline nodes, while matching using the highest-value edges. Consequently, the analysis boils down to examining the distribution of a weighted sum X of negatively correlated Bernoulli variables, specifically lower bounding its mass below a threshold, ùîº[min(1, X )], of possible independent interest. Interestingly, our bound relies on an imaginary invocation of pivotal sampling.",102
17,Algorithms and Theory,Mahsa Derakhshan,"June 2nd, 2023",Stochastic Minimum Vertex Cover in General Graphs: A 3/2-Approximation,https://doi.org/10.1145/3564246.3585230," Mahsa Derakhshan, Naveen Durvasula, Nika Haghtalab. (2023). Stochastic Minimum Vertex Cover in General Graphs: A 3/2-Approximation STOC, 242-253. https://doi.org/10.1145/3564246.3585230","We study the stochastic vertex cover problem. In this problem, G = ( V , E ) is an arbitrary known graph, and G ‚ãÜ is an unknown random subgraph of G where each edge e is realized independently with probability p . Edges of G ‚ãÜ can only be verified using edge queries. The goal in this problem is to find a minimum vertex cover of G ‚ãÜ using a small number of queries. Our main result is designing an algorithm that returns a vertex cover of G ‚ãÜ with size at most (3/2+—î) times the expected size of the minimum vertex cover, using only O ( n /—î p ) non-adaptive queries. This improves over the best-known 2-approximation algorithm by Behnezhad, Blum and Derakhshan [SODA‚Äô22] who also show that Œ©( n / p ) queries are necessary to achieve any constant approximation. Our guarantees also extend to instances where edge realizations are not fully independent. We complement this upperbound with a tight 3/2-approximation lower bound for stochastic graphs whose edges realizations demonstrate mild correlations.",103
18,Algorithms and Theory,Mahsa Derakhshan,"May 27th, 2023",Learning and Collusion in Multi-unit Auctions,http://papers.nips.cc/paper_files/paper/2023/hash/4661b55200c03a8c4bb9c2974b4fb12d-Abstract-Conference.html," Simina Br√¢nzei, Mahsa Derakhshan, Negin Golrezaei, Yanjun Han. (2023). Learning and Collusion in Multi-unit Auctions NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/4661b55200c03a8c4bb9c2974b4fb12d-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Main Conference Track Simina Branzei, Mahsa Derakhshan, Negin Golrezaei, Yanjun Han In a carbon auction, licenses for CO2 emissions are allocated among multiple interested players. Inspired by this setting, we consider repeated multi-unit auctions with uniform pricing, which are widely used in practice. Our contribution is to analyze these auctions in both the offline and online settings, by designing efficient bidding algorithms with low regret and giving regret lower bounds. We also analyze the quality of the equilibria in two main variants of the auction, finding that one variant is susceptible to collusion among the bidders while the other is not.",104
19,Algorithms and Theory,Mahsa Derakhshan,"January 16th, 2023",Beating (1 ‚Äì 1/e)-Approximation for Weighted Stochastic Matching,https://doi.org/10.1137/1.9781611977554.ch74," Mahsa Derakhshan, Alireza Farhadi . (2023). Beating (1 - 1/e)-Approximation for Weighted Stochastic Matching SODA, 1931-1961. https://doi.org/10.1137/1.9781611977554.ch74","In the stochastic weighted matching problem, the goal is to find a large-weight matching of a graph when we are uncertain about the existence of its edges. In particular, each edge e has a known weight w e but is realized independently with some probability p e . The algorithm may query an edge to see whether it is realized. We consider the well-studied query commit version of the problem, in which any queried edge that happens to be realized must be included in the solution. Gamlath, Kale, and Svensson [SODA'19] showed that when the input graph is bipartite, the problem admits a (1 ‚Äî 1/ e )-approximation. In this paper, we give an algorithm that obtains a (1 ‚Äî 1/ e + Œ¥)-approximation for an absolute constant Œ¥ > 0.0014, therefore breaking this prevalent bound.",105
20,Algorithms and Theory,Mahsa Derakhshan,"July 13th, 2022",Max-Weight Online Stochastic Matching: Improved Approximations Against the Online Benchmark,https://doi.org/10.1145/3490486.3538315," Mark Braverman, Mahsa Derakhshan, Antonio Molina Lovett. (2022). Max-Weight Online Stochastic Matching: Improved Approximations Against the Online Benchmark EC, 967-985. https://doi.org/10.1145/3490486.3538315","In this paper, we study max-weight stochastic matchings on online bipartite graphs under both vertex and edge arrivals. We focus on designing polynomial time approximation algorithms with respect to the online benchmark, which was first considered by Papadimitriou, Pollner, Saberi, and Wajc [EC'21]. In the vertex arrival version of the problem, the goal is to find an approximate max-weight matching of a given bipartite graph when the vertices in one part of the graph arrive online in a fixed order with independent chances of failure. Whenever a vertex arrives we should decide, irrevocably, whether to match it with one of its unmatched neighbors or leave it unmatched forever.¬†There has been a long line of work designing approximation algorithms for different variants of this problem with respect to the offline benchmark (prophet). Papadimitriou et al., however, propose the alternative online benchmark and show that considering this new benchmark allows them to improve the 0.5 approximation ratio, which is the best ratio achievable with respect to the offline benchmark. They provide a 0.51-approximation algorithm which was later improved to 0.526 by Saberi and Wajc [ICALP'21]. The main contribution of this paper is designing a simple algorithm with a significantly improved approximation ratio of (1-1/e) for this problem. We also consider the edge arrival version in which, instead of vertices, edges of the graph arrive in an online fashion with independent chances of failure. Designing approximation algorithms for this problem has also been studied extensively with the best approximation ratio being 0.337 with respect to the offline benchmark. This paper, however, is the first to consider the online benchmark for the edge arrival version of the problem. For this problem, we provide a simple algorithm with an approximation ratio of 0.5 with respect to the online benchmark.",106
21,Algorithms and Theory,Mahsa Derakhshan,"January 5th, 2022",Stochastic Vertex Cover with Few Queries,https://doi.org/10.1137/1.9781611977073.73," Soheil Behnezhad, Avrim Blum, Mahsa Derakhshan. (2022). Stochastic Vertex Cover with Few Queries SODA, 1808-1846. https://doi.org/10.1137/1.9781611977073.73","We study the minimum vertex cover problem in the following stochastic setting. Let G be an arbitrary given graph, p ‚àä (0, 1] a parameter of the problem, and let G p be a random subgraph that includes each edge of G independently with probability p . We are unaware of the realization G p , but can learn if an edge e exists in G p by querying it. The goal is to find an approximate minimum vertex cover (MVC) of G p by querying few edges of G non-adaptively. This stochastic setting has been studied extensively for various problems such as minimum spanning trees, matroids, shortest paths, and matchings. To our knowledge, however, no non-trivial bound was known for MVC prior to our work. In this work, we present a: (2 + ‚àä )-approximation for general graphs which queries edges per vertex, and a 1.367-approximation for bipartite graphs which queries poly(1/ p ) edges per vertex. Additionally, we show that at the expense of a triple-exponential dependence on p ‚Äì1 in the number of queries, the approximation ratio can be improved down to (1 + ‚àä ) for bipartite graphs. Our techniques also lead to improved bounds for bipartite stochastic matching. We obtain a 0.731-approximation with nearly-linear in 1/ p per-vertex queries. This is the first result to break the prevalent (2/3‚àº 0.66)-approximation barrier in the poly(1/ p ) query regime, improving algorithms of [Behnezhad et al ., SODA'19] and [Assadi and Bernstein, SOSA'19].",107
22,Algorithms and Theory,Mahsa Derakhshan,"January 19th, 2021",Stochastic Weighted Matching: (Stochastic Weighted Matching: (1-Œµ) Approximation -\varepsilon$) Approximation,https://doi.org/10.1109/FOCS46700.2020.00131," Soheil Behnezhad, Mahsa Derakhshan. (2020). Stochastic Weighted Matching: (Stochastic Weighted Matching: (1-Œµ) Approximation -varepsilon$) Approximation FOCS, 1392-1403. https://doi.org/10.1109/FOCS46700.2020.00131","We study a stochastic matching problem where the goal is to non-adaptively pick a sparse subgraph Q of G without knowing the realization G. For every graph G, every sub graph Q has a maximum degree only O Œµ , p ( 1 ) and guarantees a ( 1 ‚àí Œµ ) -approximation. That is, the maximum degree of Q depends only on Œµ and p (both of which are known to be necessary) and not for example on the number of nodes in G , the edge-weights, etc. Our result substantially improves over these works and matches the state-of-the-art for unweighted graphs.",108
23,Algorithms and Theory,Mahsa Derakhshan,"January 7th, 2021",Beating Greedy For Approximating Reserve Prices in Multi-Unit VCG Auctions,https://doi.org/10.1137/1.9781611976465.68," Mahsa Derakhshan, David M. Pennock, Aleksandrs Slivkins. (2021). Beating Greedy For Approximating Reserve Prices in Multi-Unit VCG Auctions SODA, 1099-1118. https://doi.org/10.1137/1.9781611976465.68","We study the problem of finding personalized reserve prices for unit-demand buyers in multi-unit eager VCG auctions with correlated buyers. The input to this problem is a dataset of submitted bids of n buyers in a set of auctions. The goal is to find a vector of reserve prices, one for each buyer, that maximizes the total revenue across all auctions. Roughgarden and Wang (2016) showed that this problem is APX-hard but admits a greedy ¬Ω-approximation algorithm. Later, Derakhshan, Golrezai, and Paes Leme (2019) gave an LP-based algorithm achieving a 0.68-approximation for the (important) special case of the problem with a single-item, thereby beating greedy. We show in this paper that the algorithm of Derakhshan et al . in fact does not beat greedy for the general multi-item problem. This raises the question of whether or not the general problem admits a better-than-¬Ω approximation. In this paper, we answer this question in the affirmative and provide a polynomial-time algorithm with a significantly better approximation-factor of 0.63. Our solution is based on a novel linear programming formulation, for which we propose two different rounding schemes. We prove that the best of these two and the no-reserve case (all-zero vector) is a 0.63-approximation. Full version. Due to the page limit, this version of the paper does not include all the proofs. The full version of the paper is available at [11].",109
24,Algorithms and Theory,Paul Hand,"January 23rd, 2024",The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting ‚Äì An Analytical Model,https://doi.org/10.48550/arXiv.2401.12617," Daniel Goldfarb, Itay Evron, Nir Weinberger, Daniel Soudry, Paul Hand. (2024). The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting - An Analytical Model CoRR, abs/2401.12617. https://doi.org/10.48550/arXiv.2401.12617","In continual learning, catastrophic forgetting is affected by multiple aspects of the tasks. Previous works have analyzed separately how forgetting is affected by either task similarity or overparameterization. In contrast, our paper examines how task similarity and overparameterization jointly affect forgetting in an analyzable model. Specifically, we focus on two-task continual linear regression, where the second task is a random orthogonal transformation of an arbitrary first task (an abstraction of random permutation tasks). We derive an exact analytical expression for the expected forgetting - and uncover a nuanced pattern. In highly overparameterized models, intermediate task similarity causes the most forgetting. However, near the interpolation threshold, forgetting decreases monotonically with the expected task similarity. We validate our findings with linear regression on synthetic data, and with neural networks on established permutation task benchmarks.",110
25,Algorithms and Theory,Paul Hand,"March 20th, 2023",Guest Editorial,https://doi.org/10.1109/JSAIT.2023.3242517," Paul Hand, Reinhard Heckel, Jonathan Scarlett. (2022). Guest Editorial IEEE J. Sel. Areas Inf. Theory, 3, 432. https://doi.org/10.1109/JSAIT.2023.3242517","Abstract: Welcome to the eleventh issue of the Journal on Selected Areas in Information Theory (JSAIT), dedicated to ‚ÄúDeep Learning Methods for Inverse Problems‚Äù. Metadata Abstract: Welcome to the eleventh issue of the Journal on Selected Areas in Information Theory (JSAIT), dedicated to ‚ÄúDeep Learning Methods for Inverse Problems‚Äù. Published in: IEEE Journal on Selected Areas in Information Theory ( Volume: 3 , Issue: 3 , September 2022 ) Page(s): 432 - 432 Date of Publication: 20 March 2023 Electronic ISSN: 2641-8770 DOI: 10.1109/JSAIT.2023.3242517 Publisher: IEEE Abstract: Welcome to the eleventh issue of the Journal on Selected Areas in Information Theory (JSAIT), dedicated to ‚ÄúDeep Learning Methods for Inverse Problems‚Äù. Metadata Abstract: Welcome to the eleventh issue of the Journal on Selected Areas in Information Theory (JSAIT), dedicated to ‚ÄúDeep Learning Methods for Inverse Problems‚Äù. Published in: IEEE Journal on Selected Areas in Information Theory ( Volume: 3 , Issue: 3 , September 2022 ) Page(s): 432 - 432 Date of Publication: 20 March 2023 Electronic ISSN: 2641-8770 DOI: 10.1109/JSAIT.2023.3242517 Publisher: IEEE Abstract: Welcome to the eleventh issue of the Journal on Selected Areas in Information Theory (JSAIT), dedicated to ‚ÄúDeep Learning Methods for Inverse Problems‚Äù. Published in: IEEE Journal on Selected Areas in Information Theory ( Volume: 3 , Issue: 3 , September 2022 ) Date of Publication: 20 March 2023 DOI: 10.1109/JSAIT.2023.3242517 Publisher: IEEE",111
26,Algorithms and Theory,Paul Hand,"June 29th, 2022",Theoretical Perspectives on Deep Learning Methods in Inverse Problems,https://doi.org/10.48550/arXiv.2206.14373," Jonathan Scarlett, Reinhard Heckel, Miguel R. D. Rodrigues, Paul Hand, Yonina C. Eldar. (2022). Theoretical Perspectives on Deep Learning Methods in Inverse Problems CoRR, abs/2206.14373. https://doi.org/10.48550/arXiv.2206.14373","In recent years, there have been significant advances in the use of deep learning methods in inverse problems such as denoising, compressive sensing, inpainting, and super-resolution. While this line of works has predominantly been driven by practical algorithms and experiments, it has also given rise to a variety of intriguing theoretical problems. In this paper, we survey some of the prominent theoretical developments in this line of works, focusing in particular on generative priors, untrained neural network priors, and unfolding algorithms. In addition to summarizing existing results in these topics, we highlight several ongoing challenges and open problems.",112
27,Algorithms and Theory,Zhengzhong Jin,"June 11th, 2024",SNARGs under LWE via Propositional Proofs,https://doi.org/10.1145/3618260.3649770," Zhengzhong Jin, Yael Kalai, Alex Lombardi, Vinod Vaikuntanathan. (2024). SNARGs under LWE via Propositional Proofs STOC, 1750-1757. https://doi.org/10.1145/3618260.3649770",We construct a succinct non-interactive argument (SNARG) system for every NP language L that has a propositional proof of non-membership. The soundness of our SNARG system relies on the hardness of the learning with errors (LWE) problem. We additionally show that propositional proofs of unsatisfiability generically imply the existence of locally unsatisfiable extensions.,113
28,Algorithms and Theory,Zhengzhong Jin,"November 21st, 2023",Scalable Multiparty Garbling,https://doi.org/10.1145/3576915.3623132," Gabrielle Beck, Aarushi Goel, Aditya Hegde , Abhishek Jain , Zhengzhong Jin, Gabriel Kaptchuk. (2023). Scalable Multiparty Garbling CCS, 2158-2172. https://doi.org/10.1145/3576915.3623132","Multiparty garbling is the most popular approach for constant-round secure multiparty computation (MPC). Despite being the focus of significant research effort, instantiating prior approaches to multiparty garbling results in constant-round MPC that can not realistically accommodate large numbers of parties. In this work we present the first global-scale multiparty garbling protocol. The per-party communication complexity of our protocol decreases as the number of parties participating in the protocol increases - for the first time matching the asymptotic communication complexity of non-constant round MPC protocols. Our protocol achieves malicious security in the honest-majority setting and relies on the hardness of the Learning Party with Noise assumption.",114
29,Algorithms and Theory,Zhengzhong Jin,"August 9th, 2023",A Note on Non-interactive Zero-Knowledge from CDH,https://doi.org/10.1007/978-3-031-38551-3_23," Geoffroy Couteau, Abhishek Jain , Zhengzhong Jin, Willy Quach. (2023). A Note on Non-interactive Zero-Knowledge from CDH CRYPTO (4), 731-764. https://doi.org/10.1007/978-3-031-38551-3_23","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",115
30,Algorithms and Theory,Zhengzhong Jin,"August 9th, 2023",Correlation Intractability and SNARGs from Sub-exponential DDH,https://doi.org/10.1007/978-3-031-38551-3_20," Arka Rai Choudhuri, Sanjam Garg, Abhishek Jain , Zhengzhong Jin, Jiaheng Zhang. (2023). Correlation Intractability and SNARGs from Sub-exponential DDH CRYPTO (4), 635-668. https://doi.org/10.1007/978-3-031-38551-3_20","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",116
31,Algorithms and Theory,Huy L√™ Nguyen,"May 1st, 2024",Private Vector Mean Estimation in the Shuffle Model: Optimal Rates Require Many Messages,https://openreview.net/forum?id=PTGJOUlQ68," Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar, Samson Zhou. (2024). Private Vector Mean Estimation in the Shuffle Model: Optimal Rates Require Many Messages ICML. https://openreview.net/forum?id=PTGJOUlQ68","We study the problem of private vector mean estimation in the shuffle model of privacy where $n$ users each have a unit vector $v^{(i)} \in \mathbb{R}^d$. We propose a new multi-message protocol that achieves the optimal error using $O(\min(n\varepsilon^2,d))$ messages per user. Moreover, we show that any (unbiased) protocol that achieves optimal error must require each user to send $\Omega(\min(n\varepsilon^2,d)/\log(n))$ messages, demonstrating the optimality of our message complexity up to logarithmic factors. Additionally, we study the single-message setting and design a protocol that achieves mean squared error $O(dn^{d/(d+2)}\varepsilon^{-4/(d+2)})$. Moreover, we show that any single-message protocol must incur mean squared error $\Omega(dn^{d/(d+2)})$, showing that our protocol is optimal in the standard setting where $\varepsilon = \Theta(1)$. Finally, we study robustness to malicious users and show that malicious users can incur large additive error with a single shuffler. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",117
32,Algorithms and Theory,Huy L√™ Nguyen,"June 26th, 2023",An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret,https://ojs.aaai.org/index.php/AAAI/article/view/25985," Matthew Jones, Huy L. Nguyen, Thy Dinh Nguyen. (2023). An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret AAAI, 8159-8167. https://ojs.aaai.org/index.php/AAAI/article/view/25985","Abstract Recently a multi-agent variant of the classical multi-armed bandit was proposed to tackle fairness issues in online learning. Inspired by a long line of work in social choice and economics, the goal is to optimize the Nash social welfare instead of the total utility. Unfortunately previous algorithms either are not efficient or achieve sub-optimal regret in terms of the number of rounds. We propose a new efficient algorithm with lower regret than even previous inefficient ones. We also complement our efficient algorithm with an inefficient approach with regret that matches the lower bound for one agent. The experimental findings confirm the effectiveness of our efficient algorithm compared to the previous approaches.",118
33,Algorithms and Theory,Huy L√™ Nguyen,"June 7th, 2023",Fast Optimal Locally Private Mean Estimation via Random Projections,http://papers.nips.cc/paper_files/paper/2023/hash/34822dab66c13f0100017b8ea373038a-Abstract-Conference.html," Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar. (2023). Fast Optimal Locally Private Mean Estimation via Random Projections NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/34822dab66c13f0100017b8ea373038a-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Main Conference Track Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy Nguyen, Kunal Talwar We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, namely ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a 1 + o ( 1 ) 1 + o ( 1 ) -factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace and then runs an optimal algorithm such a PrivUnitG in the lower dimensional space. We analyze the error of the algorithm in terms of properties of the random projection ensemble, and study two instantiations. We conduct several experiments for private mean estimation and private federated learning which demonstrate that our algorithms obtain nearly the same utility as optimal algorithms while having significantly lower communication and computational cost. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",119
34,Algorithms and Theory,Huy L√™ Nguyen,"October 25th, 2022",Streaming Submodular Maximization with Differential Privacy,https://proceedings.mlr.press/v202/chaturvedi23a.html," Anamay Chaturvedi, Huy L. Nguyen, Thy Dinh Nguyen. (2023). Streaming Submodular Maximization with Differential Privacy ICML, 4116-4143. https://proceedings.mlr.press/v202/chaturvedi23a.html","In this work, we study the problem of privately maximizing a submodular function in the streaming setting. Extensive work has been done on privately maximizing submodular functions in the general case when the function depends upon the private data of individuals. However, when the size of the data stream drawn from the domain of the objective function is large or arrives very fast, one must privately optimize the objective within the constraints of the streaming setting. We establish fundamental differentially private baselines for this problem and then derive better trade-offs between privacy and utility for the special case of decomposable submodular functions. A submodular function is decomposable when it can be written as a sum of submodular functions; this structure arises naturally when each summand function models the utility of an individual and the goal is to study the total utility of the whole population as in the well-known Combinatorial Public Projects Problem. Finally, we complement our theoretical analysis with experimental corroboration.",120
35,Algorithms and Theory,Huy L√™ Nguyen,"June 28th, 2022",Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence,https://ojs.aaai.org/index.php/AAAI/article/view/20609," Alina Ene, Huy Le Nguyen. (2022). Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence AAAI, 6559-6567. https://ojs.aaai.org/index.php/AAAI/article/view/20609","Abstract We develop new adaptive algorithms for variational inequalities with monotone operators, which capture many problems of interest, notably convex optimization and convex-concave saddle point problems. Our algorithms automatically adapt to unknown problem parameters such as the smoothness and the norm of the operator, and the variance of the stochastic evaluation oracle. We show that our algorithms are universal and simultaneously achieve the optimal convergence rates in the non-smooth, smooth, and stochastic settings. The convergence guarantees of our algorithms improve over existing adaptive methods and match the optimal non-adaptive algorithms. Additionally, prior works require that the optimization domain is bounded. In this work, we remove this restriction and give algorithms for unbounded domains that are adaptive and universal. Our general proof techniques can be used for many variants of the algorithm using one or two operator evaluations per iteration. The classical methods based on the ExtraGradient/MirrorProx algorithm require two operator evaluations per iteration, which is the dominant factor in the running time in many settings.",121
36,Algorithms and Theory,Huy L√™ Nguyen,"January 1st, 2022",Streaming Algorithm for Monotone k-Submodular Maximization with Cardinality Constraints,https://proceedings.mlr.press/v162/ene22a.html," Alina Ene, Huy L. Nguyen. (2022). Streaming Algorithm for Monotone k-Submodular Maximization with Cardinality Constraints ICML, 5944-5967. https://proceedings.mlr.press/v162/ene22a.html","Maximizing a monotone k-submodular function subject to cardinality constraints is a general model for several applications ranging from influence maximization with multiple products to sensor placement with multiple sensor types and online ad allocation. Due to the large problem scale in many applications and the online nature of ad allocation, a need arises for algorithms that process elements in a streaming fashion and possibly make online decisions. In this work, we develop a new streaming algorithm for maximizing a monotone k-submodular function subject to a per-coordinate cardinality constraint attaining an approximation guarantee close to the state of the art guarantee in the offline setting. Though not typical for streaming algorithms, our streaming algorithm also readily applies to the online setting with free disposal. Our algorithm is combinatorial and enjoys fast running time and small number of function evaluations. Furthermore, its guarantee improves as the cardinality constraints get larger, which is especially suited for the large scale applications. For the special case of maximizing a submodular function with large budgets, our combinatorial algorithm matches the guarantee of the state-of-the-art continuous algorithm, which requires significantly more time and function evaluations.",122
37,Algorithms and Theory,Huy L√™ Nguyen,"January 1st, 2022",Private frequency estimation via projective geometry,https://proceedings.mlr.press/v162/feldman22a.html," Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar. (2022). Private frequency estimation via projective geometry ICML, 6418-6433. https://proceedings.mlr.press/v162/feldman22a.html","In this work, we propose a new algorithm ProjectiveGeometryResponse (PGR) for locally differentially private (LDP) frequency estimation. For universe size of k and with n users, our eps-LDP algorithm has communication cost ceil(log_2 k) and computation cost O(n + k\exp(eps) log k) for the server to approximately reconstruct the frequency histogram, while achieve optimal privacy-utility tradeoff. In many practical settings this is a significant improvement over the O¬†(n+k^2) computation cost that is achieved by the recent PI-RAPPOR algorithm (Feldman and Talwar; 2021). Our empirical evaluation shows a speedup of over 50x over PI-RAPPOR while using approximately 75x less memory. In addition, the running time of our algorithm is comparable to that of HadamardResponse (Acharya, Sun, and Zhang; 2019) and RecursiveHadamardResponse (Chen, Kairouz, and Ozgur; 2020) which have significantly worse reconstruction error. The error of our algorithm essentially matches that of the communication- and time-inefficient but utility-optimal SubsetSelection (SS) algorithm (Ye and Barg; 2017). Our new algorithm is based on using Projective Planes over a finite field to define a small collection of sets that are close to being pairwise independent and a dynamic programming algorithm for approximate histogram reconstruction for the server.",123
38,Algorithms and Theory,Huy L√™ Nguyen,"May 31st, 2021",Locally Private k-Means Clustering with Constant Multiplicative Approximation and Near-Optimal Additive Error,https://arxiv.org/abs/2105.15007," Locally Private k-Means Clustering with Constant Multiplicative Approximation and Near-Optimal Additive Error. CoRR abs/2105.15007 (2021), Anamay Chaturvedi, Matthew Jones, Huy L. Nguyen.","Given a data set of sizenind‚Ä≤-dimensional Euclidean space, thek-means problem asks for a set ofkpoints (called centers) so that the sum of the‚Ñì22-distances between points of a given data set of sizenand the set ofkcenters is minimized. Recent work on this problem in the locally private setting achieves constant multiplicative approximation with additive errorO~(n1/2+a‚ãÖk‚ãÖmax{d‚àí‚àí‚àö,k‚àí‚àí‚àö})and proves a lower bound ofŒ©(n‚àí‚àí‚àö)on the additive error for any solution with a constant number of rounds. In this work we bridge the gap between the exponents ofnin the upper and lower bounds on the additive error with two new algorithms. Given anyŒ±>0, our first algorithm achieves a multiplicative approximation guarantee which is at most a(1+Œ±)factor greater than that of any non-privatek-means clustering algorithm withkO~(1/Œ±2)d‚Ä≤n‚àí‚àí‚àí‚àöpolylognadditive error. Given anyc>2‚Äì‚àö, our second algorithm achievesO(k1+O~(1/(2c2‚àí1))d‚Ä≤n‚àí‚àí‚àí‚àöpolylogn)additive error with constant multiplicative approximation. Both algorithms go beyond theŒ©(n1/2+a)factor that occurs in the additive error for arbitrarily small parametersain previous work, and the second algorithm in particular shows for the first time that it is possible to solve the locally privatek-means problem in a constant number of rounds with constant factor multiplicative approximation and polynomial dependence onkin the additive error arbitrarily close to linear.",124
39,Algorithms and Theory,Huy L√™ Nguyen,"December 8th, 2018",Improved Algorithms for Collaborative PAC Learning,https://papers.nips.cc/paper/7990-improved-algorithms-for-collaborative-pac-learning," Huy L√™ Nguy·ªÖn and Lydia Zakynthinou. ""Improved Algorithms for Collaborative PAC Learning.""  Advances in Neural Information Processing Systems 31 (NeurIPS‚Äô18), 2018.","Part of Advances in Neural Information Processing Systems 31 (NeurIPS 2018) Huy Nguyen, Lydia Zakynthinou We study a recent model of collaborative PAC learning where k k players with k k different tasks collaborate to learn a single classifier that works for all tasks. Previous work showed that when there is a classifier that has very small error on all tasks, there is a collaborative algorithm that finds a single classifier for all tasks and has O ( ( ln ( k ) ) 2 ) O ( ( ln ‚Å° ( k ) ) 2 ) times the worst-case sample complexity for learning a single task. In this work, we design new algorithms for both the realizable and the non-realizable setting, having sample complexity only O ( ln ( k ) ) O ( ln ‚Å° ( k ) ) times the worst-case sample complexity for learning a single task. The sample complexity upper bounds of our algorithms match previous lower bounds and in some range of parameters are even better than previous algorithms that are allowed to output different classifiers for different tasks. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",125
40,Algorithms and Theory,Huy L√™ Nguyen,"June 14th, 2015",Time Lower Bounds for Nonadaptive Turnstile Streaming Algorithms,https://dl.acm.org/citation.cfm?id=2746542," Kasper Green Larsen, Jelani Nelson, Huy L. Nguyen. Time Lower Bounds for Nonadaptive Turnstile Streaming Algorithms. STOC 2015: 803-812","We say a turnstile streaming algorithm is {\em non-adaptive} if, during updates, the memory cells written and read depend only on the index being updated and random coins tossed at the beginning of the stream (and not on the memory contents of the algorithm). Memory cells read during queries may be decided upon adaptively. All known turnstile streaming algorithms in the literature, except a single recent example for a particular promise problem [7], are non-adaptive. In fact, even more specifically, they are all linear sketches. We prove the first non-trivial update time lower bounds for both randomized and deterministic turnstile streaming algorithms, which hold when the algorithms are non-adaptive. While there has been abundant success in proving space lower bounds, there have been no non-trivial turnstile update time lower bounds. Our lower bounds hold against classically studied problems such as heavy hitters, point query, entropy estimation, and moment estimation. In some cases of deterministic algorithms, our lower bounds nearly match known upper bounds.",126
41,Algorithms and Theory,Rajmohan Rajaraman,"January 1st, 2025",Fully Dynamic (Œî + 1)-Coloring Against Adaptive Adversaries,https://doi.org/10.1137/1.9781611978322.169," Soheil Behnezhad, Rajmohan Rajaraman, Omer Wasim. (2025). Fully Dynamic (Œî + 1)-Coloring Against Adaptive Adversaries SODA, 4983-5026. https://doi.org/10.1137/1.9781611978322.169","There are randomized algorithms that maintain a valid solution after each edge insertion or deletion to the n -vertex graph by spending polylog n time. None of these algorithms work against adaptive adversaries whose updates may depend on the output of the algorithm. Our algorithm is randomized, and maintains a valid (Œì + 2) coloring after each update by spending √ï ( n 8/9 ) time with high probability.",127
42,Algorithms and Theory,Rajmohan Rajaraman,"September 16th, 2024",Scheduling Splittable Jobs on Configurable Machines,https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22," Matthew Casey, Rajmohan Rajaraman, David Stalfa, Cheng Tan . (2024). Scheduling Splittable Jobs on Configurable Machines APPROX/RANDOM, 22:1-22:20. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22","Abstract Motivated by modern architectures allowing for the partitioning of a GPU into hardware separated instances, we initiate the study of scheduling splittable jobs on configurable machines. We consider machines that can be configured into smaller instances, which we call blocks, in multiple ways, each of which is referred to as a configuration. We introduce the Configurable Machine Scheduling (cms) problem, where we are given n jobs and a set C of configurations. A schedule consists of a set of machines, each assigned some configuration in C with each block in the configuration assigned to process one job. The amount of a job‚Äôs demand that is satisfied by a block is given by an arbitrary function of the job and block. The objective is to construct a schedule using as few machines as possible. We provide a tight logarithmic factor approximation algorithm for this problem in the general setting, a factor (3 + Œµ) approximation algorithm for arbitrary Œµ > 0 when there are O(1) input configurations, and a polynomial time approximation scheme when both the number and size of configurations are O(1). Finally, we utilize a technique for finding conic integer combinations in fixed dimension to develop an optimal polynomial time algorithm in the case with O(1) jobs, O(1) blocks, and every configuration up to a given size.",128
43,Algorithms and Theory,Rajmohan Rajaraman,"December 22nd, 2023",One Tree to Rule Them All: Poly-Logarithmic Universal Steiner Tree,https://doi.org/10.1109/FOCS57990.2023.00012," Costas Busch, Da Qi Chen, Arnold Filtser, Daniel Hathcock, D. Ellis Hershkowitz, Rajmohan Rajaraman. (2023). One Tree to Rule Them All: Poly-Logarithmic Universal Steiner Tree FOCS, 60-76. https://doi.org/10.1109/FOCS57990.2023.00012",We reduce the existence of these objects to the previously studied cluster aggregation problem and a class of well-separated point sets which we call dangling nets. For graphs with constant doubling dimension or constant pathwidth we obtain improved bounds by deriving O ( log n ) -approximate USTs and O ( 1 ) strong sparse partition hierarchies. For more information about the IEEE 64th Annual Symposium on Foundations of Computer Science (FOCS) please visit: http://www.iife.org/focs/symposium/2023/index.php?title=IEEE64thAnnualSymposiumOnFoundationsOfComputerScience.html.,129
44,Algorithms and Theory,Rajmohan Rajaraman,"July 5th, 2023",Scheduling Under Non-Uniform Job and Machine Delays,https://doi.org/10.4230/LIPIcs.ICALP.2023.98," Rajmohan Rajaraman, David Stalfa, Sheng Yang. (2023). Scheduling Under Non-Uniform Job and Machine Delays ICALP, 98:1-98:20. https://doi.org/10.4230/LIPIcs.ICALP.2023.98","We study the problem of scheduling precedence-constrained jobs on heterogenous machines. The objective is to construct a schedule that minimizes makespan, which is the maximum completion time over all jobs. For schedules with no duplication, we obtain an asymptotic polylog(n)-approximation for the above model.",130
45,Algorithms and Theory,Rajmohan Rajaraman,"October 1st, 2022",Improved Algorithms for Scheduling Unsplittable Flows on Paths,https://doi.org/10.1007/s00453-022-01043-6," Hamidreza Jahanjou, Erez Kantor, Rajmohan Rajaraman. (2023). Improved Algorithms for Scheduling Unsplittable Flows on Paths Algorithmica, 85, 563-583. https://doi.org/10.1007/s00453-022-01043-6","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 235 Accesses",131
46,Algorithms and Theory,Rajmohan Rajaraman,"January 4th, 2022",Improved Bounds for Scheduling Flows under Endpoint Capacity Constraints,https://doi.org/10.1137/1.9781611977059.1," Searidang Pa, Rajmohan Rajaraman, David Stalfa. (2022). Improved Bounds for Scheduling Flows under Endpoint Capacity Constraints APOCS, 1-14. https://doi.org/10.1137/1.9781611977059.1","The response time (or flow time) of a request is the difference between the time the request is completed and its release time. Previous work has shown that it is impossible to achieve bounded competitive ratio for average response time without resource augmentation. For the maximum response time objective, the best known result is a 2-competitive algorithm with aResource augmentation at least 4.",132
47,Algorithms and Theory,Rajmohan Rajaraman,"January 19th, 2021",Scheduling Precedence-Constrained Jobs on Related Machines with Communication Delay,https://doi.org/10.1109/FOCS46700.2020.00082," Biswaroop Maiti, Rajmohan Rajaraman, David Stalfa, Zoya Svitkina, Aravindan Vijayaraghavan. (2020). Scheduling Precedence-Constrained Jobs on Related Machines with Communication Delay FOCS, 834-845. https://doi.org/10.1109/FOCS46700.2020.00082","Communication delay is the amount of time that must pass between the completion of a job on one machine and the start of any successor of that job on a different machine. We consider a model that allows job duplication, i.e. processing of the same job on multiple machines, which, as we show, can reduce the length of a schedule (i.e., its makespan) by a logarithmic factor. We show that the best schedule without duplication can have a larger makespan than the optimal with duplication. We present a polynomial time algorithm to transform this into an approximation algorithm for makespan with approximation ratio polylogarithmmic in the number of machines and the communication delay, assuming the minimum makespan is at least the delay.",133
48,Algorithms and Theory,Rajmohan Rajaraman,"January 1st, 2021",Competitive Data-Structure Dynamization,https://doi.org/10.1137/1.9781611976465.135," Claire Mathieu, Rajmohan Rajaraman, Neal E. Young, Arman Yousefi. (2021). Competitive Data-Structure Dynamization SODA, 2269-2287. https://doi.org/10.1137/1.9781611976465.135","Data-structure dynamization is a general approach for making static data structures dynamic. It is used extensively in geometric settings and in the guise of so-called merge (or compaction) policies in big-data databases such as Google Bigtable and LevelDB (our focus). Previous theoretical work is based on worst-case analyses for uniform inputs ‚Äî insertions of one item at a time and constant read rate. In practice, merge policies must not only handle batch insertions and varying read/write ratios, they can take advantage of such non-uniformity to reduce cost on a per-input basis. To model this, we initiate the study of data-structure dynamization through the lens of competitive analysis, via two new online set-cover problems. For each, the input is a sequence of disjoint sets of weighted items. The sets are revealed one at a time. The algorithm must respond to each with a set cover that covers all items revealed so far. It obtains the cover incrementally from the previous cover by adding one or more sets and optionally removing existing sets. For each new set the algorithm incurs build cost equal to the weight of the items in the set. In the first problem the objective is to minimize total build cost plus total query cost , where the algorithm incurs a query cost at each time t equal to the current cover size. In the second problem, the objective is to minimize the build cost while keeping the query cost from exceeding k (a given parameter) at any time. We give deterministic online algorithms for both variants, with competitive ratios of Œò(log‚àó n ) and k , respectively. The latter ratio is optimal for the second variant.",134
49,Algorithms and Theory,Rajmohan Rajaraman,"October 15th, 2018",A better method to analyze blockchain consistency,https://dl.acm.org/doi/10.1145/3243734.3243814," Kiffer, Lucianna, Rajmohan Rajaraman, and Abhi Shelat. ""A better method to analyze blockchain consistency."" Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 2018.","The celebrated Nakamoto consensus protocol [16] ushered in several new consensus applications including cryptocurrencies. A few recent works [7, 17] have analyzed important properties of blockchains, including most significantly, consistency, which is a guarantee that all honest parties output the same sequence of blocks throughout the execution of the protocol. To establish consistency, the prior analysis of Pass, Seeman and Shelat [17] required a careful counting of certain combinatorial events that was difficult to apply to variations of Nakamoto. The work of Garay, Kiayas, and Leonardas [7] provides another method of analyzing the blockchain under the simplifying assumption that the network was synchronous. The contribution of this paper is the development of a simple Markov-chain based method for analyzing consistency properties of blockchain protocols. The method includes a formal way of stating strong concentration bounds as well as easy ways to concretely compute the bounds. We use our new method to answer a number of basic questions about consistency of blockchains: Our new analysis provides a tighter guarantee on the consistency property of Nakamoto's protocol, including for parameter regimes which [17] could not consider; We analyze a family of delaying attacks first presented in [17], and extend them to other protocols; We analyze how long a participant should wait before considering a high-value transaction ""confirmed""; We analyze the consistency of CliqueChain, a variation of the Chainweb [14] system; We provide the first rigorous consistency analysis of GHOST [20] and also analyze a folklore ""balancing""-attack. In each case, we use our framework to experimentally analyze the consensus bounds for various network delay parameters and adversarial computing percentages. We hope our techniques enable authors of future blockchain proposals to provide a more rigorous analysis of their schemes.",135
50,Algorithms and Theory,Rajmohan Rajaraman,"July 19th, 2016",Information Spreading in Dynamic Networks under Oblivious Adversaries,https://arxiv.org/abs/1607.05645," Information Spreading in Dynamic Networks under Oblivious Adversaries with J. Augustine, C. Avin, M. Liaee, and G. Pandurangan International Conference on Distributed Computing, October 2016","We study the problem of gossip in dynamic networks controlled by an adversary that can modify the network arbitrarily from one round to another, provided that the network is always connected. In the gossip problem,ntokens are arbitrarily distributed among thennetwork nodes, and the goal is to disseminate all thentokens to every node. Our focus is on token-forwarding algorithms, which do not manipulate tokens in any way other than storing, copying, and forwarding them. Gossip can be completed in linear time in any static network, but a basic open question for dynamic networks is the existence of a distributed protocol that can do significantly better than an easily achievable bound ofO(n2)rounds.In previous work, it has been shown that under adaptive adversaries, every token forwarding algorithm requiresŒ©(n2/logn)rounds. In this paper, we study oblivious adversaries, which differ from adaptive adversaries in one crucial aspect--- they are oblivious to random choices made by the protocol. We present anŒ©~(n3/2)lower bound under an oblivious adversary for RANDDIFF, a natural algorithm in which neighbors exchange a token chosen uniformly at random from the difference of their token sets. We also present anŒ©~(n4/3)bound under a stronger notion of oblivious adversary for symmetric knowledge-based algorithms. On the positive side, we present a centralized algorithm that completes gossip inO~(n3/2)rounds. We also show anO~(n5/3)upper bound for RANDDIFF in a restricted class of oblivious adversaries, which we call paths-respecting.",136
51,Algorithms and Theory,Abhi Shelat,"August 16th, 2024",Secure Multiparty Computation with Identifiable Abort via Vindicating Release,https://doi.org/10.1007/978-3-031-68397-8_2," Ran Cohen, Jack Doerner, Yashvanth Kondi, Abhi Shelat. (2024). Secure Multiparty Computation with Identifiable Abort via Vindicating Release CRYPTO (8), 36-73. https://doi.org/10.1007/978-3-031-68397-8_2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",137
52,Algorithms and Theory,Abhi Shelat,"May 25th, 2022",Guaranteed Output in $O(\sqrt{n})$ Rounds for Round-Robin Sampling Protocols,https://doi.org/10.1007/978-3-031-06944-4_9," Ran Cohen, Jack Doerner, Yashvanth Kondi, Abhi Shelat. (2022). Guaranteed Output in $O(sqrt{n})$ Rounds for Round-Robin Sampling Protocols EUROCRYPT (1), 241-271. https://doi.org/10.1007/978-3-031-06944-4_9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",138
53,Algorithms and Theory,Abhi Shelat,"August 10th, 2020",Multiparty Generation of an RSA Modulus,https://doi.org/10.1007/978-3-030-56877-1_3," Megan Chen, Ran Cohen, Jack Doerner, Yashvanth Kondi, Eysa Lee, Schuyler Rosefield, Abhi Shelat. (2020). Multiparty Generation of an RSA Modulus CRYPTO (3), 64-93. https://doi.org/10.1007/978-3-030-56877-1_3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",139
54,Algorithms and Theory,Abhi Shelat,"November 6th, 2019",Securely Sampling Biased Coins with Applications to Differential Privacy,https://doi.org/10.1145/3319535.3354256," Jeffrey Champion, Abhi Shelat, Jonathan R. Ullman. (2019). Securely Sampling Biased Coins with Applications to Differential Privacy CCS, 603-614. https://doi.org/10.1145/3319535.3354256","We design an efficient method for sampling a large batch of d independent coins with a given bias p ‚àà [0,1]. The folklore secure computation method for doing so requires O(lambda + log d) communication and computation per coin to achieve total statistical difference 2-lambda. We present an exponential improvement over the folklore method that uses just O(log(lambda+log d)) gates per coin when sampling d coins with total statistical difference 2-lambda. We present a variant of our work that also concretely beats the folklore method for lambda ‚â• 60 which are parameters that are often used in practice. Our new technique relies on using specially designed oblivious data structures to achieve biased coin samples that take an expected 2 random bits to sample. Using our new sampling technique, we present an implementation of the differentially private report-noisy-max mechanism (a more practical implementation of the celebrated exponential mechanism) as a secure multi-party computation. Our benchmarks show that one can run this mechanism on a domain of size d=212 in 6 seconds and up to d=219 in 14 minutes. As far as we know, this is the first complete distributed implementation of either of these mechanisms.",140
55,Algorithms and Theory,Abhi Shelat,"August 1st, 2019",Adaptively Secure MPC with Sublinear Communication Complexity,https://doi.org/10.1007/978-3-030-26951-7_2," Ran Cohen, Abhi Shelat, Daniel Wichs. (2019). Adaptively Secure MPC with Sublinear Communication Complexity CRYPTO (2), 30-60. https://doi.org/10.1007/978-3-030-26951-7_2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",141
56,Algorithms and Theory,Abhi Shelat,"October 15th, 2018",A better method to analyze blockchain consistency,https://dl.acm.org/doi/10.1145/3243734.3243814," Kiffer, Lucianna, Rajmohan Rajaraman, and Abhi Shelat. ""A better method to analyze blockchain consistency."" Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 2018.","The celebrated Nakamoto consensus protocol [16] ushered in several new consensus applications including cryptocurrencies. A few recent works [7, 17] have analyzed important properties of blockchains, including most significantly, consistency, which is a guarantee that all honest parties output the same sequence of blocks throughout the execution of the protocol. To establish consistency, the prior analysis of Pass, Seeman and Shelat [17] required a careful counting of certain combinatorial events that was difficult to apply to variations of Nakamoto. The work of Garay, Kiayas, and Leonardas [7] provides another method of analyzing the blockchain under the simplifying assumption that the network was synchronous. The contribution of this paper is the development of a simple Markov-chain based method for analyzing consistency properties of blockchain protocols. The method includes a formal way of stating strong concentration bounds as well as easy ways to concretely compute the bounds. We use our new method to answer a number of basic questions about consistency of blockchains: Our new analysis provides a tighter guarantee on the consistency property of Nakamoto's protocol, including for parameter regimes which [17] could not consider; We analyze a family of delaying attacks first presented in [17], and extend them to other protocols; We analyze how long a participant should wait before considering a high-value transaction ""confirmed""; We analyze the consistency of CliqueChain, a variation of the Chainweb [14] system; We provide the first rigorous consistency analysis of GHOST [20] and also analyze a folklore ""balancing""-attack. In each case, we use our framework to experimentally analyze the consensus bounds for various network delay parameters and adversarial computing percentages. We hope our techniques enable authors of future blockchain proposals to provide a more rigorous analysis of their schemes.",142
57,Algorithms and Theory,Abhi Shelat,"July 25th, 2018","Multi-Key Searchable Encryption, Revisited",https://eprint.iacr.org/2018/018," Ariel Hamlin, Abhi Shelat, Mor Weiss, Daniel Wichs: Multi-Key Searchable Encryption, Revisited. Public Key Cryptography (1) 2018: 95-124","Ariel Hamlin, abhi shelat, Mor Weiss, and Daniel Wichs We consider a setting where users store their encrypted documents on a remote server and can selectively share documents with each other. A user should be able to perform keyword searches over all the documents she has access to, including the ones that others shared with her. The contents of the documents, and the search queries, should remain private from the server. This setting was considered by Popa et al. (NSDI '14) who developed a new cryptographic primitive called Multi-Key Searchable Encryption (MKSE), together with an instantiation and an implementation within a system called Mylar, to address this goal. Unfortunately, Grubbs et al. (CCS '16) showed that the proposed MKSE definition fails to provide basic security guarantees, and that the Mylar system is susceptible to simple attacks. Most notably, if a malicious Alice colludes with the server and shares a document with an honest Bob then the privacy of all of Bob's search queries is lost. In this work we revisit the notion of MKSE and propose a new strengthened definition that rules out the above attacks. We then construct MKSE schemes meeting our definition. We first give a simple and efficient construction using only pseudorandom functions. This construction achieves our strong security definition at the cost of increasing the server storage overhead relative to Mylar, essentially replicating the document each time it is shared. We also show that high server storage overhead is not inherent, by giving an alternate (albeit impractical) construction that manages to avoid it using obfuscation. BibTeX Copy to clipboard",143
58,Algorithms and Theory,Ravi Sundaram,"June 11th, 2022",Online Paging with Heterogeneous Cache Slots,https://doi.org/10.48550/arXiv.2206.05579," Marek Chrobak, Samuel Haney, Mehraneh Liaee, Debmalya Panigrahi, Rajmohan Rajaraman, Ravi Sundaram, Neal E. Young. (2022). Online Paging with Heterogeneous Cache Slots CoRR, abs/2206.05579. https://doi.org/10.48550/arXiv.2206.05579","It is natural to generalize the onlinek-Server problem by allowing each request to specify not only a pointp, but also a subsetSof servers that may serve it. For uniform metrics, the problem is equivalent to a generalization of Paging in which each request specifies not only a pagep, but also a subsetSof cache slots, and is satisfied by having a copy ofpin some slot inS. We call this problem Slot-Heterogenous Paging.We parameterize the problem by specifying a familyS‚äÜ2[k]of requestable slot sets, and we establish bounds on the competitive ratio as a function of the cache sizekand familyS:- If all request sets are allowed (S=2[k]‚àñ{‚àÖ}), the optimal deterministic and randomized competitive ratios are exponentially worse than for standard \Paging (S={[k]}).- As a function of|S|andk, the optimal deterministic ratio is polynomial: at mostO(k2|S|)and at leastŒ©(|S|‚àí‚àí‚àí‚àö).- For any laminar familySof heighth, the optimal ratios areO(hk)(deterministic) andO(h2logk)(randomized).- The special case of laminarSthat we call All-or-One Paging extends standard Paging by allowing each request to specify a specific slot to put the requested page in. The optimal deterministic ratio for weighted All-or-One Paging isŒò(k). Offline All-or-One Paging is NP-hard.Some results for the laminar case are shown via a reduction to the generalization of Paging in which each request specifies a setPofpages,andissatisfiedbyfetchinganypagefrom\mathcal P into the cache. The optimal ratios for the latter problem (with laminar family of heighth) are at mosthk(deterministic) andhHk(randomized).",144
59,Algorithms and Theory,Ravi Sundaram,"June 11th, 2021",PAC-Learning for Strategic Classification,http://proceedings.mlr.press/v139/sundaram21a.html," Ravi Sundaram, Anil Vullikanti, Haifeng Xu, Fan Yao. (2021). PAC-Learning for Strategic Classification ICML, 9978-9988. http://proceedings.mlr.press/v139/sundaram21a.html","The study of strategic or adversarial manipulation of testing data to fool a classifier has attracted much recent attention. Most previous works have focused on two extreme situations where any testing data point either is completely adversarial or always equally prefers the positive label. In this paper, we generalize both of these through a unified framework for strategic classification and introduce the notion of strategic VC-dimension (SVC) to capture the PAC-learnability in our general strategic setup. SVC provably generalizes the recent concept of adversarial VC-dimension (AVC) introduced by Cullina et al. (2018). We instantiate our framework for the fundamental strategic linear classification problem. We fully characterize: (1) the statistical learnability of linear classifiers by pinning down its SVC; (2) it‚Äôs computational tractability by pinning down the complexity of the empirical risk minimization problem. Interestingly, the SVC of linear classifiers is always upper bounded by its standard VC-dimension. This characterization also strictly generalizes the AVC bound for linear classifiers in (Cullina et al., 2018).",145
60,Algorithms and Theory,Ravi Sundaram,"March 24th, 2021",Realization problems on reachability sequences,https://doi.org/10.1016/j.tcs.2021.02.034," Matthew Dippel, Ravi Sundaram, Akshar Varma. (2021). Realization problems on reachability sequences Theor. Comput. Sci., 866, 1-13. https://doi.org/10.1016/j.tcs.2021.02.034","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",146
61,Algorithms and Theory,Ravi Sundaram,"June 11th, 2020",Attention improves concentration when learning node embeddings,https://arxiv.org/abs/2006.06834," Matthew Dippel, Adam Kiezun, Tanay Mehta, Ravi Sundaram, Srikanth Thirumalai, Akshar Varma. (2020). Attention improves concentration when learning node embeddings CoRR, abs/2006.06834. https://arxiv.org/abs/2006.06834","We consider the problem of predicting edges in a graph from node attributes in an e-commerce setting. Specifically, given nodes labelled with search query text, we want to predict links to related queries that share products. Experiments with a range of deep neural architectures show that simple feedforward networks with an attention mechanism perform best for learning embeddings. The simplicity of these models allows us to explain the performance of attention.We propose an analytically tractable model of query generation, AttEST, that views both products and the query text as vectors embedded in a latent space. We prove (and empirically validate) that the point-wise mutual information (PMI) matrix of the AttEST query text embeddings displays a low-rank behavior analogous to that observed in word embeddings. This low-rank property allows us to derive a loss function that maximizes the mutual information between related queries which is used to train an attention network to learn query embeddings. This AttEST network beats traditional memory-based LSTM architectures by over 20% on F-1 score. We justify this out-performance by showing that the weights from the attention mechanism correlate strongly with the weights of the best linear unbiased estimator (BLUE) for the product vectors, and conclude that attention plays an important role in variance reduction.",147
62,Algorithms and Theory,Ravi Sundaram,"October 27th, 2019",Nexus: a GPU cluster engine for accelerating DNN-based video analysis,https://doi.org/10.1145/3341301.3359658," Haichen Shen, Lequn Chen, Yuchen Jin, Liangyu Zhao, Bingyu Kong, Matthai Philipose, Arvind Krishnamurthy, Ravi Sundaram. (2019). Nexus: a GPU cluster engine for accelerating DNN-based video analysis SOSP, 322-337. https://doi.org/10.1145/3341301.3359658","We address the problem of serving Deep Neural Networks (DNNs) efficiently from a cluster of GPUs. In order to realize the promise of very low-cost processing made by accelerators such as GPUs, it is essential to run them at sustained high utilization. Doing so requires cluster-scale resource management that performs detailed scheduling of GPUs, reasoning about groups of DNN invocations that need to be co-scheduled, and moving from the conventional whole-DNN execution model to executing fragments of DNNs. Nexus is a fully implemented system that includes these innovations. In large-scale case studies on 16 GPUs, when required to stay within latency constraints at least 99% of the time, Nexus can process requests at rates 1.8-12.7X higher than state of the art systems can. A long-running multi-application deployment stays within 84% of optimal utilization and, on a 100-GPU cluster, violates latency SLOs on 0.27% of requests.",148
63,Algorithms and Theory,Ravi Sundaram,"January 1st, 2013",Maygh: building a CDN from client web browsers,http://dl.acm.org/citation.cfm?id=2465379," Liang Zhang, Fangfei Zhou, Alan Mislove, and Ravi Sundaram. 2013. Maygh: building a CDN from client web browsers. In Proceedings of the 8th ACM European Conference on Computer Systems (EuroSys '13). ACM, New York, NY, USA, 281-294. DOI=http://dx.doi.org/10.1145/2465351.2465379","Over the past two decades, the web has provided dramatic improvements in the ease of sharing content. Unfortunately, the costs of distributing this content are largely incurred by web site operators; popular web sites are required to make substantial monetary investments in serving infrastructure or cloud computing resources---or must pay other organizations (e.g., content distribution networks)---to help serve content. Previous approaches to offloading some of the distribution costs onto end users have relied on client-side software or web browser plug-ins, providing poor user incentives and dramatically limiting their scope in practice. In this paper, we present Maygh, a system that builds a content distribution network from client web browsers, without the need for additional plug-ins or client-side software. The result is an organically scalable system that distributes the cost of serving web content across the users of a web site. Through simulations based on real-world access logs from Etsy (a large e-commerce web site that is the 50th most popular web site in the U.S.), microbenchmarks, and a small-scale deployment, we demonstrate that Maygh provides substantial savings to site operators, imposes only modest costs on clients, and can be deployed on the web sites and browsers of today. In fact, if Maygh was deployed to Etsy, it would reduce network bandwidth due to static content by 75% and require only a single coordinating server.",149
64,Algorithms and Theory,Jonathan Ullman,"January 1st, 2025",Private Mean Estimation with Person-Level Differential Privacy,https://doi.org/10.1137/1.9781611978322.92," Sushant Agarwal, Gautam Kamath , Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan R. Ullman. (2025). Private Mean Estimation with Person-Level Differential Privacy SODA, 2819-2880. https://doi.org/10.1137/1.9781611978322.92","We study person-level differentially private (DP) mean estimation in the case where each person holds multiple samples. DP here requires the usual notion of distributional stability when all of a person‚Äôs datapoints can be modified. Informally, if n people each have m samples from an unknown d -dimensional distribution with bounded k -th moments, we show that people are necessary and sufficient to estimate the mean up to distance Œ± in ‚Ñì 2 -norm under Œµ -differential privacy (and its common relaxations). In the multivariate setting, we give computationally efficient algorithms under approximate DP and computationally inefficient algorithms under pure DP, and our nearly matching lower bounds hold for the most permissive case of approximate DP. Our computationally efficient estimators are based on the standard clip-and-noise framework, but the analysis for our setting requires both new algorithmic techniques and new analyses. In particular, our new bounds on the tails of sums of independent, vector-valued, bounded-moments random variables may be of interest. * Authors are listed in alphabetical order.",150
65,Algorithms and Theory,Jonathan Ullman,"June 20th, 2024",Program Analysis for Adaptive Data Analysis,https://doi.org/10.1145/3656414," Jiawen Liu, Weihao Qu, Marco Gaboardi, Deepak Garg , Jonathan R. Ullman. (2024). Program Analysis for Adaptive Data Analysis Proc. ACM Program. Lang., 8, 914-938. https://doi.org/10.1145/3656414","An adaptive data analysis can be seen as a process composed by multiple queries interrogating some data. The choice of which query to run next may rely on the results of previous queries. The generalization error of each individual query/analysis can be controlled by using an array of well-established statistical techniques. In this work, we consider adaptive data analyses implemented as while-like programs and we design a program analysis which can help with identifying which technique to use.",151
66,Algorithms and Theory,Jonathan Ullman,"May 1st, 2024",How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization,https://openreview.net/forum?id=XoSF46Pc2e," Andrew Lowy, Jonathan R. Ullman, Stephen J. Wright . (2024). How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization ICML. https://openreview.net/forum?id=XoSF46Pc2e","We provide a simple and flexible framework for designing differentially private algorithms to find approximate stationary points of non-convex loss functions. Our framework is based on using a private approximate risk minimizer to ""warm start"" another private algorithm for finding stationary points. We use this framework to obtain improved, and sometimes optimal, rates for several classes of non-convex loss functions. First, we obtain improved rates for finding stationary points of smooth non-convex empirical loss functions. Second, we specialize to quasar-convex functions, which generalize star-convex functions and arise in learning dynamical systems and training some neural nets. We achieve the optimal rate for this class. Third, we give an optimal algorithm for finding stationary points of functions satisfying the Kurdyka-Lojasiewicz (KL) condition. For example, over-parameterized neural networks often satisfy this condition. Fourth, we provide new state-of-the-art rates for stationary points of non-convex population loss functions. Fifth, we obtain improved rates for non-convex generalized linear models. A modification of our algorithm achieves nearly the same rates for second-order stationary points of functions with Lipschitz Hessian, improving over the previous state-of-the-art for each of the above problems. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",152
67,Algorithms and Theory,Jonathan Ullman,"January 16th, 2024",Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning,https://openreview.net/forum?id=4DoSULcfG6," Harsh Chaudhari, Giorgio Severi, Alina Oprea, Jonathan R. Ullman. (2024). Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning ICLR. https://openreview.net/forum?id=4DoSULcfG6","The integration of Machine Learning in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for ML training purposes. One such privacy risk is Membership Inference (MI), in which an adversary seeks to determine whether a particular data point was included in the training dataset of a model. Current state-of-the-art MI approaches capitalize on access to the model‚Äôs predicted confidence scores to successfully perform membership inference.",153
68,Algorithms and Theory,Jonathan Ullman,"July 5th, 2023",Investigating the Visual Utility of Differentially Private Scatterplots,https://doi.org/10.1109/TVCG.2023.3292391," Liudas Panavas, Tarik Crnovrsanin, Jane Lydia Adams, Jonathan R. Ullman, Ali Sarvghad, Melanie Tory, Cody Dunne. (2024). Investigating the Visual Utility of Differentially Private Scatterplots IEEE Trans. Vis. Comput. Graph., 30, 5370-5385. https://doi.org/10.1109/TVCG.2023.3292391","Increasingly, visualization practitioners are working with, using, and studying private data. Differential privacy algorithms do this by aggregating data statistics with noise. This now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.",154
69,Algorithms and Theory,Jonathan Ullman,"June 22nd, 2020",The power of factorization mechanisms in local and central differential privacy,https://doi.org/10.1145/3357713.3384297," Alexander Edmonds, Aleksandar Nikolov, Jonathan R. Ullman. (2020). The power of factorization mechanisms in local and central differential privacy STOC, 425-438. https://doi.org/10.1145/3357713.3384297","We give new characterizations of the sample complexity of answering linear queries (statistical queries) in the local and central models of differential privacy: (1) In the non-interactive local model, we give the first approximate characterization of the sample complexity. Informally our bounds are tight to within polylogarithmic factors in the number of queries and desired accuracy. Our characterization extends to agnostic learning in the local model. (2) In the central model, we give a characterization of the sample complexity in the high-accuracy regime that is analogous to that of Nikolov, Talwar, and Zhang (STOC 2013), but is both quantitatively tighter and has a dramatically simpler proof. Our lower bounds apply equally to the empirical and population estimation problems. In both cases, our characterizations show that a particular factorization mechanism is approximately optimal, and the optimal sample complexity is bounded from above and below by well studied factorization norms of a matrix associated with the queries.",155
70,Algorithms and Theory,Jonathan Ullman,"January 1st, 2020",Private Query Release Assisted by Public Data,http://proceedings.mlr.press/v119/bassily20a.html," Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan R. Ullman, Zhiwei Steven Wu. (2020). Private Query Release Assisted by Public Data ICML, 695-703. http://proceedings.mlr.press/v119/bassily20a.html","We study the problem of differentially private query release assisted by access to public data. In this problem, the goal is to answer a large class H H of statistical queries with error no more than Œ± Œ± using a combination of public and private samples. The algorithm is required to satisfy differential privacy only with respect to the private samples. We study the limits of this task in terms of the private and public sample complexities. Our upper and lower bounds on the private sample complexity have matching dependence on the dual VC-dimension of H H . For a large category of query classes, our bounds on the public sample complexity have matching dependence on Œ± Œ± .",156
71,Algorithms and Theory,Jonathan Ullman,"December 6th, 2018",Differentially Private Fair Learning,https://arxiv.org/abs/1812.02696," Jagielski, Matthew, Kearns, Michael, Mao, Jieming, Oprea, Alina, Roth, Aaron, Sharifi, Saeed, & Ullman, Jonathan. (2019). Differentially Private Fair Learning. Proceedings of the 36 Th International Conference on Machine Learning.","Motivated by settings in which predictive models may be required to be non-discriminatory with respect to certain attributes (such as race), but even collecting the sensitive attribute may be forbidden or restricted, we initiate the study of fair learning under the constraint of differential privacy. We design two learning algorithms that simultaneously promise differential privacy and equalized odds, a 'fairness' condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a private implementation of the equalized odds post-processing approach of [Hardt et al., 2016]. This algorithm is appealingly simple, but must be able to use protected group membership explicitly at test time, which can be viewed as a form of 'disparate treatment'. Our second algorithm is a differentially private version of the oracle-efficient in-processing approach of [Agarwal et al., 2018] that can be used to find the optimal fair classifier, given access to a subroutine that can solve the original (not necessarily fair) learning problem. This algorithm is more complex but need not have access to protected group membership at test time. We identify new tradeoffs between fairness, accuracy, and privacy that emerge only when requiring all three properties, and show that these tradeoffs can be milder if group membership may be used at test time. We conclude with a brief experimental evaluation.",157
72,Algorithms and Theory,Jonathan Ullman,"November 27th, 2018",The Structure of Optimal Private Tests for Simple Hypotheses,https://arxiv.org/abs/1811.11148," Canonne, C.L., Kamath, G., McMillan, A., Smith, A.D., & Ullman, J. (2018). The structure of optimal private tests for simple hypotheses. ArXiv, abs/1811.11148.","Hypothesis testing plays a central role in statistical inference, and is used in many settings where privacy concerns are paramount. This work answers a basic question about privately testing simple hypotheses: given two distributionsPandQ, and a privacy levelŒµ, how many i.i.d. samples are needed to distinguishPfromQsubject toŒµ-differential privacy, and what sort of tests have optimal sample complexity? Specifically, we characterize this sample complexity up to constant factors in terms of the structure ofPandQand the privacy levelŒµ, and show that this sample complexity is achieved by a certain randomized and clamped variant of the log-likelihood ratio test. Our result is an analogue of the classical Neyman-Pearson lemma in the setting of private hypothesis testing. We also give an application of our result to the private change-point detection. Our characterization applies more generally to hypothesis tests satisfying essentially any notion of algorithmic stability, which is known to imply strong generalization bounds in adaptive data analysis, and thus our results have applications even when privacy is not a primary concern.",158
73,Algorithms and Theory,Jonathan Ullman,"August 4th, 2018",Distributed Differential Privacy via Shuffling,https://arxiv.org/abs/1808.01394," Cheu A., Smith A., Ullman J., Zeber D., Zhilyaev M. (2019) Distributed Differential Privacy via Shuffling. In: Ishai Y., Rijmen V. (eds) Advances in Cryptology ‚Äì EUROCRYPT 2019. EUROCRYPT 2019. Lecture Notes in Computer Science, vol 11476. Springer, Cham","We consider the problem of designing scalable, robust protocols for computing statistics about sensitive data. Specifically, we look at how best to design differentially private protocols in a distributed setting, where each user holds a private datum. The literature has mostly considered two models: the ""central"" model, in which a trusted server collects users' data in the clear, which allows greater accuracy; and the ""local"" model, in which users individually randomize their data, and need not trust the server, but accuracy is limited. Attempts to achieve the accuracy of the central model without a trusted server have so far focused on variants of cryptographic MPC, which limits scalability.In this paper, we initiate the analytic study of a shuffled model for distributed differentially private algorithms, which lies between the local and central models. This simple-to-implement model, a special case of the ESA framework of [Bittau et al., '17], augments the local model with an anonymous channel that randomly permutes a set of user-supplied messages. For sum queries, we show that this model provides the power of the central model while avoiding the need to trust a central server and the complexity of cryptographic secure function evaluation. More generally, we give evidence that the power of the shuffled model lies strictly between those of the central and local models: for a natural restriction of the model, we show that shuffled protocols for a widely studied selection problem require exponentially higher sample complexity than do central-model protocols.",159
74,Algorithms and Theory,Jonathan Ullman,"May 1st, 2018",Privately Learning High-Dimensional Distributions,https://arxiv.org/abs/1805.00216," Kamath, G., Li, J., Singhal, V., & Ullman, J. (2018). Privately Learning High-Dimensional Distributions. COLT.","We present novel, computationally efficient, and differentially private algorithms for two fundamental high-dimensional learning problems: learning a multivariate Gaussian and learning a product distribution over the Boolean hypercube in total variation distance. The sample complexity of our algorithms nearly matches the sample complexity of the optimal non-private learners for these tasks in a wide range of parameters, showing that privacy comes essentially for free for these problems. In particular, in contrast to previous approaches, our algorithm for learning Gaussians does not require strong a priori bounds on the range of the parameters. Our algorithms introduce a novel technical approach to reducing the sensitivity of the estimation procedure that we call recursive private preconditioning.",160
75,Algorithms and Theory,Jonathan Ullman,"April 10th, 2017",Tight lower bounds for differentially private selection,https://arxiv.org/abs/1704.03024," Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. In IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS‚Äô17), 2017.","A pervasive task in the differential privacy literature is to select thekitems of ""highest quality"" out of a set ofditems, where the quality of each item depends on a sensitive dataset that must be protected. Variants of this task arise naturally in fundamental problems like feature selection and hypothesis testing, and also as subroutines for many sophisticated differentially private algorithms.The standard approaches to these tasks---repeated use of the exponential mechanism or the sparse vector technique---approximately solve this problem given a dataset ofn=O(k‚àí‚àí‚àölogd)samples. We provide a tight lower bound for some very simple variants of the private selection problem. Our lower bound shows that a sample of sizen=Œ©(k‚àí‚àí‚àölogd)is required even to achieve a very minimal accuracy guarantee.Our results are based on an extension of the fingerprinting method to sparse selection problems. Previously, the fingerprinting method has been used to provide tight lower bounds for answering an entire set ofdqueries, but often only some much smaller set ofkqueries are relevant. Our extension allows us to prove lower bounds that depend on both the number of relevant queries and the total number of queries.",161
76,Algorithms and Theory,Jonathan Ullman,"June 19th, 2016",Algorithmic stability for adaptive data analysis,https://dl.acm.org/citation.cfm?id=2897566," Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Symposium on Theory of Computing (STOC‚Äô16), 2016","We prove the first upper bounds on the number of samples required to answer more general families of queries. We also show that weaker stability guarantees such as bounded KL divergence and total variation distance lead to correspondingly weaker generalization guarantees. The bounds improve and simplify the work of Dwork et al. (STOC, 2015) and have been applied in subsequent work by those authors.",162
77,Algorithms and Theory,Jonathan Ullman,"October 20th, 2015",Interactive fingerprinting codes and the hardness of preventing false discovery,https://arxiv.org/abs/1410.1228," Thomas Steinke and Jonathan Ullman. Interactive fingerprinting codes and the hardness of preventing false discovery. In Proceedings of The 28th Conference on Learning Theory (COLT‚Äô15), 2015","We show an essentially tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately givennsamples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is ""close"" to the correct expectation over the distribution. This question was recently studied by Dwork et al., who showed how to answerŒ©~(n2)queries efficiently, and also by Hardt and Ullman, who showed that answeringO~(n3)queries is hard. We close the gap between the two bounds and show that, under a standard hardness assumption, there is no computationally efficient algorithm that, givennsamples from an unknown distribution, can give valid answers toO(n2)adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private.We obtain our results using a new connection between the problem of answering adaptively chosen statistical queries and a combinatorial object called an interactive fingerprinting code. In order to optimize our hardness result, we give a new Fourier-analytic approach to analyzing fingerprinting codes that is simpler, more flexible, and yields better parameters than previous constructions.",163
78,Algorithms and Theory,Jonathan Ullman,"October 17th, 2015",Robust traceability from trace amounts,http://ieeexplore.ieee.org/document/7354420/," Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. In IEEE 56th Annual Symposium on Foundations of Computer Science (FOCS‚Äô15), 2015.","The privacy risks inherent in the release of a large number of summary statistics were illustrated by Homer et al. (PLoS Genetics, 2008) In this work we describe and analyze a simple attack that succeeds even if the summary statistics are significantly distorted. The attack only requires that the vector of distorted summary statistics is close to the vector. of true marginals in ‚Ñì 1 norm. The new attack, which is not specific to genomics and which handles Gaussian as well as Bernouilli data, significantly generalizes recent lower bounds on the noise needed to ensure differential privacy (Bun, Ullman, and Vadhan, STOC 2014, Steinke and Ullmann, 2015)",164
79,Algorithms and Theory,Emanuele Viola,"November 19th, 2024",Boosting Uniformity in Quasirandom Groups: Fast and Simple,https://doi.org/10.1109/FOCS61266.2024.00091," Harm Derksen, Chin Ho Lee, Emanuele Viola. (2024). Boosting Uniformity in Quasirandom Groups: Fast and Simple FOCS, 1425-1430. https://doi.org/10.1109/FOCS61266.2024.00091","We study the communication complexity of multiplying k √ó t elements from the group H = SL ( 2 , q ) in the number-on-forehead model with k parties. We prove a lower bound of ( t log H ) / c k . This is an exponential improvement over previous work, and matches the state-of-the-art in the area. We also show that for any group L I , any distribution over H m whose weight-k Fourier coefficients are small is close to a k-uniform distribution.",165
80,Algorithms and Theory,Emanuele Viola,"May 21st, 2024","Pseudorandomness, symmetry, smoothing: I",https://doi.org/10.48550/arXiv.2405.13143," Harm Derksen, Peter Ivanov, Chin Ho Lee, Emanuele Viola. (2024). Pseudorandomness, symmetry, smoothing: I CoRR, abs/2405.13143. https://doi.org/10.48550/arXiv.2405.13143","We prove several new results about bounded uniform and small-bias distributions. A main message is that, small-bias, even perturbed with noise, does not fool several classes of tests better than bounded uniformity. We prove this for threshold tests, small-space algorithms, and small-depth circuits. In particular, we obtain small-bias distributions that1) achieve an optimal lower bound on their statistical distance to any bounded-uniform distribution. This closes a line of research initiated by Alon, Goldreich, and Mansour in 2003, and improves on a result by O'Donnell and Zhao.2) have heavier tail mass than the uniform distribution. This answers a question posed by several researchers including Bun and Steinke.3) rule out a popular paradigm for constructing pseudorandom generators, originating in a 1989 work by Ajtai and Wigderson. This again answers a question raised by several researchers. For branching programs, our result matches a bound by Forbes and Kelley.Our small-bias distributions above are symmetric. We show that the xor of any two symmetric small-bias distributions fools any bounded function. Hence our examples cannot be extended to the xor of two small-bias distributions, another popular paradigm whose power remains unknown. We also generalize and simplify the proof of a result of Bazzi.",166
81,Algorithms and Theory,Emanuele Viola,"July 2nd, 2021","Fourier Conjectures, Correlation Bounds, and Majority",https://doi.org/10.4230/LIPIcs.ICALP.2021.111," Viola, Emanuele. ""Fourier conjectures, correlation bounds, and majority."" 48th International Colloquium on Automata, Languages, and Programming (ICALP 2021). Schloss Dagstuhl-Leibniz-Zentrum f√ºr Informatik, 2021.","Abstract Recently several conjectures were made regarding the Fourier spectrum of low-degree polynomials. We show that these conjectures imply new correlation bounds for functions related to Majority. Then we prove several new results on correlation bounds which aim to, but don't, resolve the conjectures. In particular, we prove several new results on Majority which are of independent interest and complement Smolensky‚Äôs classic result.",167
82,Algorithms and Theory,Emanuele Viola,"June 17th, 2021",Average-case rigidity lower bounds,https://doi.org/10.1007/978-3-030-79416-3_11," Huang, Xuangui, and Emanuele Viola. ""Average-case rigidity lower bounds."" In International Computer Science Symposium in Russia (CSR 2021), pp. 186-205. Springer, Cham, 2021","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",168
83,Algorithms and Theory,Emanuele Viola,"January 13th, 2020","Approximate Degree, Weight, and Indistinguishability",https://eccc.weizmann.ac.il/report/2019/085/," Huang, Xuangui, and Emanuele Viola. ""Approximate Degree, Weight, and Indistinguishability."" To appear in ACM Transactions on Computation Theory.","The OR function on n bits can be point-wise approximated with error by a polynomial of degree O ( k ) and weight 2 O ( n log (1 \eps ) k ) , for any k n log 1 \eps . This result is tight for all k . In general we obtain an approximation result for any symmetric function, also tight.",169
84,Algorithms and Theory,Emanuele Viola,"January 1st, 2020",How to Store a Random Walk,https://doi.org/10.1137/1.9781611975994.26," Emanuele Viola, Omri Weinstein, Huacheng Yu. (2020). How to Store a Random Walk SODA, 426-445. https://doi.org/10.1137/1.9781611975994.26",We study the following data structure problem: an encoder wishes to store a collection of jointly-distributed files which are correlated. We show that it is possible to store using just a constant number of extra bits beyond the information-theoretic minimum space. We present a data structure with O (1) extra bits at the price of O (lg n ) decoding time.,170
85,Algorithms and Theory,Emanuele Viola,"December 18th, 2019",Lower bounds for data structures with space close to maximum imply circuit lower bounds,http://doi.org/10.4086/toc.2019.v015a018," Viola, Emanuele. ""Lower bounds for data structures with space close to maximum imply circuit lower bounds."" Theory of Computing 15.1 (2019): 1-9. DOI: 10.4086/toc.2019.v015a018","Abstract: [Plain Text Version] Let f : { 0 , 1 } n ‚Üí { 0 , 1 } m f : { 0 , 1 } n ‚Üí { 0 , 1 } m be a function computable by a circuit with unbounded fan-in, arbitrary gates, w w wires and depth d d . With a very simple argument we show that the m m -query problem corresponding to f f has data structures with space s = n + r s = n + r and time ( w / r ) d ( w / r ) d , for any r r . As a consequence, in the setting where s s is close to m m a slight improvement on the state of existing data-structure lower bounds would solve long-standing problems in circuit complexity. We also use this connection to obtain a data structure for error-correcting codes which nearly matches the 2007 lower bound by G√°l and Miltersen. This data structure can also be made dynamic. Finally we give a problem that requires at least 3 3 bit probes for m = n O ( 1 ) m = n O ( 1 ) and even s = m / 2 ‚àí 1 s = m / 2 ‚àí 1 . Independent work by Dvir, Golovnev, and Weinstein (2018) and by Corrigan-Gibbs and Kogan (2018) give incomparable connections between data-structure and other types of lower bounds.",171
86,Algorithms and Theory,Emanuele Viola,"October 7th, 2018","Indistinguishability by Adaptive Procedures with Advice, and Lower Bounds on Hardness Amplification Proofs",https://doi.org/10.1109/FOCS.2018.00094," A. Grinberg, R. Shaltiel and E. Viola, ""Indistinguishability by Adaptive Procedures with Advice, and Lower Bounds on Hardness Amplification Proofs,"" 2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS), 2018, pp. 956-966, doi: 10.1109/FOCS.2018.00094.","We study how well can q- query decision trees distinguish between the following two distributions. We prove two lemmas: ¬∑ Forbidden-set lemma: There exists B ‚äÜ [N] of size poly(a, q, 1/Œ∑) such that q-query trees that do not query variables in B cannot distinguish X from R with advantage Œ∑. We use the second lemma to prove lower bounds on black-box proofs for hardness amplification. These results prove 15-year-old conjectures by Viola, and improve on three incomparable previous works.",172
87,Algorithms and Theory,Emanuele Viola,"October 11th, 2016",The multiparty communication complexity of interleaved group products,http://ieeexplore.ieee.org/document/7782942/, W.T. Gowers and Emanuele Viola,"We establish the security of the leakage-resilient circuits studied by Miles and Viola (STOC 2013) in the ""only computation leaks"" model. We conclude that for a given fixed k, the communication between parties A i and A k is tight enough to be considered secure. We are the authors of the 2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS) (IEEE Xplore: 15 December 2016 ISBN Information: Print ISSN: 0272-5428 DOI: 10.1109/FocS.2016.39 Publisher: IEEE Conference Location: New Brunswick, NJ, USA",173
88,Algorithms and Theory,Emanuele Viola,"February 24th, 2016",From RAM to SAT,http://eccc.hpi-web.de/report/2012/125/," Zahra Jafargholi, Hamidreza Jahanjou, Eric Miles, Jaideep Ramachandran, Emanuele Viola. From RAM to SAT. Electronic Colloquium on Computational Complexity (ECCC) 19: 125 (2012)","Under the auspices of the Computational Complexity Foundation (CCF) Common presentations of the NP-completeness of SAT suffer from two drawbacks which hinder the scope of this flagship result. First, they do not apply to machines equipped with random-access memory, also known as direct-access memory, even though this feature is critical in basic algorithms. Second, they incur a quadratic blow-up in parameters, even though the distinction between, say, linear and quadratic time is often as critical as the one between polynomial and exponential. But the landmark result of a sequence of works overcomes both these drawbacks simultaneously! \cite{HennieS66,Schnorr78,PippengerF79,Cook88,GurevichS89,Robson91} The proof of this result is simplified by Van Melkebeek in \cite[\S 2.3.1]{Melkebeek06}. Compared to previous proofs, this proof more directly reduces random-access machines to SAT, bypassing sequential Turing machines, and using a simple, well-known sorting algorithm: Odd-Even Merge sort \cite{Batcher68}. In this work we give a self-contained rendering of this simpler proof.",174
89,Algorithms and Theory,Emanuele Viola,"October 28th, 2014","3sum, 3xor, triangles",http://link.springer.com/article/10.1007%2Fs00453-014-9946-9," Jafargholi, Z. and Viola, E., 2013. 3sum, 3xor, triangles. Algorithmica, January 2016","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 425 Accesses",175
90,Algorithms and Theory,Daniel Wichs,"November 29th, 2024",How to Simulate Random Oracles with Auxiliary Input,https://doi.org/10.1109/FOCS61266.2024.00080," Yevgeniy Dodis, Aayush Jain, Huijia Lin, Ji Luo , Daniel Wichs. (2024). How to Simulate Random Oracles with Auxiliary Input FOCS, 1207-1230. https://doi.org/10.1109/FOCS61266.2024.00080","The random oracle model (ROM) allows us to opti-mistically reason about security properties of cryptographic hash functions. It is overly optimistic against non-uniform adversaries, and often suggests security levels unachievable by any real hash function. This work shows how to efficiently simulate the AI-ROM. The simulation has low concrete overhead, leading to small losses in exact security. We present our results at the IEEE 65th Annual Symposium on Foundations of Computer Science (FOCS) in Chicago, IL, on 27-30 October 2024.",176
91,Algorithms and Theory,Daniel Wichs,"August 16th, 2024",Laconic Function Evaluation and ABE for RAMs from (Ring-)LWE,https://doi.org/10.1007/978-3-031-68382-4_4," Fangqi Dong, Zihan Hao, Ethan Mook, Hoeteck Wee, Daniel Wichs. (2024). Laconic Function Evaluation and ABE for RAMs from (Ring-)LWE CRYPTO (3), 107-142. https://doi.org/10.1007/978-3-031-68382-4_4","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",177
92,Algorithms and Theory,Daniel Wichs,"May 8th, 2024","Laconic Function Evaluation, Functional Encryption and Obfuscation for RAMs with Sublinear Computation",https://doi.org/10.1007/978-3-031-58723-8_7," Fangqi Dong, Zihan Hao, Ethan Mook, Daniel Wichs. (2024). Laconic Function Evaluation, Functional Encryption and Obfuscation for RAMs with Sublinear Computation EUROCRYPT (2), 190-218. https://doi.org/10.1007/978-3-031-58723-8_7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",178
93,Algorithms and Theory,Daniel Wichs,"August 9th, 2023",Universal Amplification of KDM Security: From 1-Key Circular to Multi-Key KDM,https://doi.org/10.1007/978-3-031-38545-2_22," Brent Waters, Daniel Wichs. (2023). Universal Amplification of KDM Security: From 1-Key Circular to Multi-Key KDM CRYPTO (2), 674-693. https://doi.org/10.1007/978-3-031-38545-2_22","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",179
94,Algorithms and Theory,Daniel Wichs,"August 9th, 2023",The Pseudorandom Oracle Model and Ideal Obfuscation,https://doi.org/10.1007/978-3-031-38551-3_8," Aayush Jain, Huijia Lin, Ji Luo , Daniel Wichs. (2023). The Pseudorandom Oracle Model and Ideal Obfuscation CRYPTO (4), 233-262. https://doi.org/10.1007/978-3-031-38551-3_8","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",180
95,Algorithms and Theory,Daniel Wichs,"June 2nd, 2023",Doubly Efficient Private Information Retrieval and Fully Homomorphic RAM Computation from Ring LWE,https://doi.org/10.1145/3564246.3585175," Wei-Kai Lin, Ethan Mook, Daniel Wichs. (2023). Doubly Efficient Private Information Retrieval and Fully Homomorphic RAM Computation from Ring LWE STOC, 595-608. https://doi.org/10.1145/3564246.3585175","A (single server) private information retrieval (PIR) allows a client to read data from a public database held on a remote server. In a doubly efficient PIR (DEPIR) the database is first preprocessed, but the server can subsequently answer any client‚Äôs query in time that is sub-linear in the database size. Building on top of our DEPIR, we construct general fully homomorphic encryption for random-access machines (RAM-FHE) This allows a server to homomorphically evaluate an arbitrary RAM program P over a",181
96,Algorithms and Theory,Daniel Wichs,"June 2nd, 2023",Boosting Batch Arguments and RAM Delegation,https://doi.org/10.1145/3564246.3585200," Yael Kalai, Alex Lombardi, Vinod Vaikuntanathan, Daniel Wichs. (2023). Boosting Batch Arguments and RAM Delegation STOC, 1545-1552. https://doi.org/10.1145/3564246.3585200","We show how to generically improve the succinctness of non-interactive publicly verifiable batch argument ( BARG ) systems. In particular, we show (under a mild additional assumption) how to convert a BARG that generates proofs of length poly ( m )¬∑ k 1‚àí—î , where m is the length of a single instance and k is the number of instances being batched, into one that generates proofs of length poly ( m , log k ), which is the gold standard for succinctness of BARG s. By prior work, such BARG s imply the existence of SNARG s for deterministic time T computation with succinctness poly (log T ). Our result reduces the long-standing challenge of building publicly-verifiable delegation schemes to a much easier problem: building a batch argument system that beats the trivial construction. It also immediately implies new constructions of BARG s and SNARG s with polylogarithmic succinctness based on either bilinear maps or a combination of the DDH and QR assumptions. Along the way, we prove an equivalence between BARG s and a new notion of SNARG s for (deterministic) RAM computations that we call ‚Äú flexible RAM SNARG s with partial input soundness .‚Äù This is the first demonstration that SNARG s for deterministic computation (of any kind) imply BARG s. Our RAM SNARG notion is of independent interest and has already been used in a recent work on constructing rate-1 BARG s (Devadas et.‚ÄÑ‚Äçal. FOCS 2022).",182
97,Algorithms and Theory,Daniel Wichs,"April 16th, 2023","Speak Much, Remember Little: Cryptography in the Bounded Storage Model, Revisited",https://doi.org/10.1007/978-3-031-30545-0_4," Yevgeniy Dodis, Willy Quach, Daniel Wichs. (2023). Speak Much, Remember Little: Cryptography in the Bounded Storage Model, Revisited EUROCRYPT (1), 86-116. https://doi.org/10.1007/978-3-031-30545-0_4","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",183
98,Algorithms and Theory,Daniel Wichs,"October 12th, 2022",Nearly Optimal Property Preserving Hashing,https://doi.org/10.1007/978-3-031-15982-4_16," Justin Holmgren, Minghao Liu , LaKyah Tyner, Daniel Wichs. (2022). Nearly Optimal Property Preserving Hashing CRYPTO (3), 473-502. https://doi.org/10.1007/978-3-031-15982-4_16","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",184
99,Algorithms and Theory,Daniel Wichs,"August 11th, 2021",Limits on the Adaptive Security of Yao‚Äôs Garbling,https://doi.org/10.1007/978-3-030-84245-1_17," Chethan Kamath, Karen Klein, Krzysztof Pietrzak, Daniel Wichs. (2021). Limits on the Adaptive Security of Yao's Garbling CRYPTO (2), 486-515. https://doi.org/10.1007/978-3-030-84245-1_17","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",185
100,Algorithms and Theory,Daniel Wichs,"August 11th, 2021",Targeted Lossy Functions and Applications,https://doi.org/10.1007/978-3-030-84259-8_15," Willy Quach, Brent Waters, Daniel Wichs. (2021). Targeted Lossy Functions and Applications CRYPTO (4), 424-453. https://doi.org/10.1007/978-3-030-84259-8_15","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",186
101,Algorithms and Theory,Hongyang Zhang,"August 24th, 2024",Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity,https://doi.org/10.1145/3637528.3671835," Dongyue Li, Aneesh Sharma, Hongyang R. Zhang. (2024). Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity KDD, 1542-1553. https://doi.org/10.1145/3637528.3671835","A key notion for modeling relationships is task affinity. Naively computing either of them requires repeatedly training on data pooled from various task combinations. We present a new algorithm Grad-TAG that can estimate task affinities without this repeated training. On our largest graph with 21M edges and 500 labeling tasks, our algorithm delivers an estimate accurate to within 5% of thetrue affinity.",187
102,Algorithms and Theory,Hongyang Zhang,"June 23rd, 2024",Learning Tree-Structured Composition of Data Augmentation,https://openreview.net/forum?id=lmgf03HeqV," Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang. (2024). Learning Tree-Structured Composition of Data Augmentation Trans. Mach. Learn. Res., 2024. https://openreview.net/forum?id=lmgf03HeqV","The problem of data augmentation is of significant importance across the spectrum of machine learning. The authors propose what I believe to be an intuitively clear and interesting approach for selecting sample transformations for creating a new training point instance. Although the approach of a top-down tree-based search is fairly simple, the added mixture of tree transforms idea for different data splits makes it rather interesting. The whole approach reduces the augmentation process complexity significantly. There are extensive experimental results that show the utility of the method, but there are no theoretical results that can provably establish the improvement of the method over other approaches. I find the lack of analyses reasonable due to the difficulty of the problem. I believe that a broad audience will be interested in this line of work since it has many practical applications (e.g., computational biology). The problem of data augmentation is of significant importance across the spectrum of machine learning. The authors propose what I believe to be an intuitively clear and interesting approach for selecting sample transformations for creating a new training point instance. Although the approach of a top-down tree-based search is fairly simple, the added mixture of tree transforms idea for different data splits makes it rather interesting. The whole approach reduces the augmentation process complexity significantly. There are extensive experimental results that show the utility of the method, but there are no theoretical results that can provably establish the improvement of the method over other approaches. I find the lack of analyses reasonable due to the difficulty of the problem.",188
103,Algorithms and Theory,Hongyang Zhang,"August 4th, 2023",Boosting Multitask Learning on Graphs through Higher-Order Task Affinities,https://doi.org/10.1145/3580305.3599265," Dongyue Li, Haotian Ju, Aneesh Sharma, Hongyang R. Zhang. (2023). Boosting Multitask Learning on Graphs through Higher-Order Task Affinities KDD, 1213-1222. https://doi.org/10.1145/3580305.3599265","Predicting node labels on a given graph is a widely studied problem with many applications, including community detection and molecular graph prediction. This paper considers predicting multiple node labeling functions on graphs simultaneously and revisits this problem from a multitask learning perspective. For a concrete example, consider overlapping community detection: each community membership is a binary node classification task. Due to complex overlapping patterns, we find that negative transfer is prevalent when we apply naive multitask learning to multiple community detection, as task relationships are highly nonlinear across different node labeling. To address the challenge, we develop an algorithm to cluster tasks into groups based on a higher-order task affinity measure. We then fit a multitask model on each task group, resulting in a boosting procedure on top of the baseline model. We estimate the higher-order task affinity measure between two tasks as the prediction loss of one task in the presence of another task and a random subset of other tasks. Then, we use spectral clustering on the affinity score matrix to identify task grouping. We design several speedup techniques to compute the higher-order affinity scores efficiently and show that they can predict negative transfers more accurately than pairwise task affinities. We validate our procedure using various community detection and molecular graph prediction data sets, showing favorable results compared with existing methods. Lastly, we provide a theoretical analysis to show that under a planted block model of tasks on graphs, our affinity scores can provably separate tasks into groups.",189
104,Algorithms and Theory,Hongyang Zhang,"January 1st, 2022",Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees,https://proceedings.mlr.press/v162/ju22a.html," Haotian Ju, Dongyue Li, Hongyang R. Zhang. (2022). Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees ICML, 10431-10461. https://proceedings.mlr.press/v162/ju22a.html","We consider transfer learning approaches that fine-tune a pretrained deep neural network on a target task. We investigate generalization properties of fine-tuning to understand the problem of overfitting, which often happens in practice. Previous works have shown that constraining the distance from the initialization of fine-tuning improves generalization. Using a PAC-Bayesian analysis, we observe that besides distance from initialization, Hessians affect generalization through the noise stability of deep neural networks against noise injections. Motivated by the observation, we develop Hessian distance-based generalization bounds for a wide range of fine-tuning methods. Next, we investigate the robustness of fine-tuning with noisy labels. We design an algorithm that incorporates consistent losses and distance-based regularization for fine-tuning. Additionally, we prove a generalization error bound of our algorithm under class conditional independent noise in the training dataset labels. We perform a detailed empirical study of our algorithm on various noisy environments and architectures. For example, on six image classification tasks whose training labels are generated with programmatic labeling, we show a 3.26% accuracy improvement over prior methods. Meanwhile, the Hessian distance measure of the fine-tuned network using our algorithm decreases by six times more than existing approaches.",190
105,Algorithms and Theory,Hongyang Zhang,"January 1st, 2022",Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations,https://proceedings.mlr.press/v162/zhang22z.html," Michael Zhang, Nimit Sharad Sohoni, Hongyang R. Zhang, Chelsea Finn, Christopher R√©. (2022). Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations ICML, 26484-26516. https://proceedings.mlr.press/v162/zhang22z.html","Spurious correlations pose a major challenge for robust machine learning. Models trained with empirical risk minimization (ERM) may learn to rely on correlations between class labels and spurious attributes, leading to poor performance on data groups without these correlations. This is challenging to address when the spurious attribute labels are unavailable. To improve worst-group performance on spuriously correlated data without training attribute labels, we propose Correct-N-Contrast (CNC), a contrastive approach to directly learn representations robust to spurious correlations. As ERM models can be good spurious attribute predictors, CNC works by (1) using a trained ERM model‚Äôs outputs to identify samples with the same class but dissimilar spurious features, and (2) training a robust model with contrastive learning to learn similar representations for these samples. To support CNC, we introduce new connections between worst-group error and a representation alignment loss that CNC aims to minimize. We empirically observe that worst-group error closely tracks with alignment loss, and prove that the alignment loss over a class helps upper-bound the class‚Äôs worst-group vs. average error gap. On popular benchmarks, CNC reduces alignment loss drastically, and achieves state-of-the-art worst-group accuracy by 3.6% average absolute lift. CNC is also competitive with oracle methods that require group labels.",191
106,Algorithms and Theory,Hongyang Zhang,"January 1st, 2021",Improved Regularization and Robustness for Fine-tuning in Neural Networks,https://proceedings.neurips.cc/paper/2021/hash/e4a93f0332b2519177ed55741ea4e5e7-Abstract.html," Dongyue Li, Hongyang R. Zhang. (2021). Improved Regularization and Robustness for Fine-tuning in Neural Networks NeurIPS, 27249-27262. https://proceedings.neurips.cc/paper/2021/hash/e4a93f0332b2519177ed55741ea4e5e7-Abstract.html","Part of Advances in Neural Information Processing Systems 34 (NeurIPS 2021) Dongyue Li, Hongyang Zhang A widely used algorithm for transfer learning is fine-tuning, where a pre-trained model is fine-tuned on a target task with a small amount of labeled data. When the capacity of the pre-trained model is much larger than the size of the target data set, fine-tuning is prone to overfitting and ""memorizing"" the training labels. Hence, an important question is to regularize fine-tuning and ensure its robustness to noise. To address this question, we begin by analyzing the generalization properties of fine-tuning. We present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the fine-tuned model. We empirically measure these quantities. Based on the analysis, we propose regularized self-labeling---the interpolation between regularization and self-labeling methods, including (i) layer-wise regularization to constrain the distance traveled in each layer; (ii) self label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. We validate our approach on an extensive collection of image and text data sets using multiple pre-trained model architectures. Our approach improves baseline methods by 1.76% (on average) for seven image classification tasks and 0.75% for a few-shot classification task. When the target data set includes noisy labels, our approach outperforms baseline methods by 3.56% on average in two noisy settings.",192
107,Algorithms and Theory,Hongyang Zhang,"October 22nd, 2020",Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in High-dimensional Linear Regression,https://arxiv.org/abs/2010.11750," Zhang, H.R., Yang, F., Wu, S., Su, W.J. and R√©, C., 2020. Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in High-dimensional Linear Regression. arXiv preprint arXiv:2010.11750.","The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes and covariate/model shifts, which can be used to study transfer effects: In a random-effects model, we give conditions to determine positive and negative transfers between learning two tasks versus single-task learning; the conditions reveal intricate relations between dataset shifts and transfer effects. Simulations justify the validity of the asymptotics in finite dimensions. Our analysis examines several functions of two different sample covariance matrices, revealing some estimates that generalize classical results in the random matrix theory literature, which may be of independent interest.",193
108,Algorithms and Theory,Hongyang Zhang,"July 23rd, 2020",Learning Over-Parametrized Two-Layer ReLU Neural Networks beyond NTK,https://arxiv.org/abs/2007.04596," Li, Y., Ma, T. and Zhang, H.R., 2020, July. Learning Over-parametrized Two-layer Neural Networks beyond NTK. In Conference on Learning Theory.","We consider the dynamic of gradient descent for learning a two-layer neural network. We assume the inputx‚ààRdis drawn from a Gaussian distribution and the label ofxsatisfiesf‚ãÜ(x)=a‚ä§|W‚ãÜx|, wherea‚ààRdis a nonnegative vector andW‚ãÜ‚ààRd√ódis an orthonormal matrix. We show that an over-parametrized two-layer neural network with ReLU activation, trained by gradient descent from random initialization, can provably learn the ground truth network with population loss at mosto(1/d)in polynomial time with polynomial samples. On the other hand, we prove that any kernel method, including Neural Tangent Kernel, with a polynomial number of samples ind, has population loss at leastŒ©(1/d).",194
109,Algorithms and Theory,Hongyang Zhang,"July 7th, 2020",On the Generalization Effects of Linear Transformations in Data Augmentation,https://arxiv.org/abs/2005.00695," Wu, S., Zhang, H.R., Valiant, G. and R√©, C., 2020. On the Generalization Effects of Linear Transformations in Data Augmentation. ICML.","Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations that preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations that mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST. Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms random sampling methods by 1.24% on CIFAR-100 using Wide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA Adversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",195
110,Algorithms and Theory,Hongyang Zhang,"May 2nd, 2020",Understanding and Improving Information Transfer in Multi-Task Learning,https://arxiv.org/abs/2005.00944," Wu, S., Zhang, H.R. and R√©, C., 2020. Understanding and Improving Information Transfer in Multi-Task Learning. ICLR.","We investigate multi-task learning approaches that use a shared feature representation for all tasks. To better understand the transfer of task information, we study an architecture with a shared module for all tasks and a separate output module for each task. We study the theory of this setting on linear and ReLU-activated models. Our key observation is that whether or not tasks' data are well-aligned can significantly affect the performance of multi-task learning. We show that misalignment between task data can cause negative transfer (or hurt performance) and provide sufficient conditions for positive transfer. Inspired by the theoretical insights, we show that aligning tasks' embedding layers leads to performance gains for multi-task training and transfer learning on the GLUE benchmark and sentiment analysis tasks; for example, we obtain a 2.35% GLUE score average improvement on 5 GLUE tasks over BERT-LARGE using our alignment method. We also design an SVD-based task reweighting scheme and show that it improves the robustness of multi-task training on a multi-label image dataset.",196
111,Algorithms and Theory,Hongyang Zhang,"May 1st, 2019",Pruning based Distance Sketches with Provable Guarantees on Random Graphs,https://arxiv.org/abs/1712.08709," Zhang, H., Yu, H. and Goel, A., 2019, May. Pruning based Distance Sketches with Provable Guarantees on Random Graphs. In The World Wide Web Conference.","Measuring the distances between vertices on graphs is one of the most fundamental components in network analysis. Since finding shortest paths requires traversing the graph, it is challenging to obtain distance information on large graphs very quickly. In this work, we present a preprocessing algorithm that is able to create landmark based distance sketches efficiently, with strong theoretical guarantees. When evaluated on a diverse set of social and information networks, our algorithm significantly improves over existing approaches by reducing the number of landmarks stored, preprocessing time, or stretch of the estimated distances.On Erd√∂s-R√©nyi graphs and random power law graphs with degree distribution exponent2<Œ≤<3, our algorithm outputs an exact distance data structure with space betweenŒò(n5/4)andŒò(n3/2)depending on the value ofŒ≤, wherenis the number of vertices. We complement the algorithm with tight lower bounds for Erdos-Renyi graphs and the case whenŒ≤is close to two.",197
112,Algorithms and Theory,Hongyang Zhang,"July 1st, 2018",Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations,https://arxiv.org/abs/1712.09203," Li, Y., Ma, T. and Zhang, H.R., 2018, July. Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations. In Conference On Learning Theory.","We show that the gradient descent algorithm provides an implicit regularization effect in the learning of over-parameterized matrix factorization models and one-hidden-layer neural networks with quadratic activations. Concretely, we show that givenO~(dr2)random linear measurements of a rankrpositive semidefinite matrixX‚ãÜ, we can recoverX‚ãÜby parameterizing it byUU‚ä§withU‚ààRd√ódand minimizing the squared loss, even ifr‚â™d. We prove that starting from a small initialization, gradient descent recoversX‚ãÜinO~(r‚àö)iterations approximately. The results solve the conjecture of Gunasekar et al.'17 under the restricted isometry property. The technique can be applied to analyzing neural networks with one-hidden-layer quadratic activations with some technical modifications.",198
113,Artificial Intelligence,Malihe Alikhani,"November 1st, 2024",Studying and Mitigating Biases in Sign Language Understanding Models,https://aclanthology.org/2024.emnlp-main.17," Katherine Atwell, Danielle Bragg, Malihe Alikhani. (2024). Studying and Mitigating Biases in Sign Language Understanding Models EMNLP, 268-283. https://aclanthology.org/2024.emnlp-main.17","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Ensuring that the benefits of sign language technologies are distributed equitably among all community members is crucial. Thus, it is important to address potential biases and inequities that may arise from the design or use of these resources. Crowd-sourced sign language datasets, such as the ASL Citizen dataset, are great resources for improving accessibility and preserving linguistic diversity, but they must be used thoughtfully to avoid reinforcing existing biases.In this work, we utilize the rich information about participant demographics and lexical features present in the ASL Citizen dataset to study and document the biases that may result from models trained on crowd-sourced sign datasets. Further, we apply several bias mitigation techniques during model training, and find that these techniques reduce performance disparities without decreasing accuracy. With the publication of this work, we release the demographic information about the participants in the ASL Citizen dataset to encourage future bias mitigation work in this space.",199
114,Artificial Intelligence,Malihe Alikhani,"December 1st, 2023",SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization,https://doi.org/10.18653/v1/2023.emnlp-main.799," Hyunwoo Kim , Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras , Malihe Alikhani, Gunhee Kim, Maarten Sap, Yejin Choi . (2023). SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization EMNLP, 12930-12949. https://doi.org/10.18653/v1/2023.emnlp-main.799","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Data scarcity has been a long standing issue in the field of open-domain social dialogue. To quench this thirst, we present SODA: the first publicly available, million-scale high-quality social dialogue dataset. By contextualizing social commonsense knowledge from a knowledge graph, we are able to distill an exceptionally broad spectrum of social interactions from a large language model. Human evaluation shows that conversations in SODA are more consistent, specific, and (surprisingly) natural than those in prior human-authored datasets. Using SODA, we train COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna). Experiments reveal COSMO is sometimes even preferred to the original human-written gold responses. Additionally, our results shed light on the distinction between knowledge-enriched conversations and natural social chitchats. We plan to make our data, model, and code public.",200
115,Artificial Intelligence,Malihe Alikhani,"July 1st, 2023",Learning to Generate Equitable Text in Dialogue from Biased Training Data,https://doi.org/10.18653/v1/2023.acl-long.163," Anthony Sicilia, Malihe Alikhani. (2023). Learning to Generate Equitable Text in Dialogue from Biased Training Data ACL (1), 2898-2917. https://doi.org/10.18653/v1/2023.acl-long.163","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The ingrained principles of fairness in a dialogue system‚Äôs decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn. To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative-performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.",201
116,Artificial Intelligence,Malihe Alikhani,"June 28th, 2022",Cross-Modal Coherence for Text-to-Image Retrieval,https://doi.org/10.1609/aaai.v36i10.21285," Malihe Alikhani, Fangda Han, Hareesh Ravi, Mubbasir Kapadia, Vladimir Pavlovic , Matthew Stone. (2022). Cross-Modal Coherence for Text-to-Image Retrieval AAAI, 10427-10435. https://doi.org/10.1609/aaai.v36i10.21285","Abstract Common image-text joint understanding techniques presume that images and the associated text can universally be characterized by a single implicit model. However, co-occurring images and text can be related in qualitatively different ways, and explicitly modeling it could improve the performance of current joint understanding models. In this paper, we train a Cross-Modal Coherence Model for text-to-image retrieval task. Our analysis shows that models trained with image‚Äìtext coherence relations can retrieve images originally paired with target text more often than coherence-agnostic models. We also show via human evaluation that images retrieved by the proposed coherence-aware model are preferred over a coherence-agnostic baseline by a huge margin. Our findings provide insights into the ways that different modalities communicate and the role of coherence relations in capturing commonsense inferences in text and imagery.",202
117,Artificial Intelligence,Christopher Amato,"December 10th, 2024",SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html," Ethan Rathbun, Christopher Amato, Alina Oprea. (2024). SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Ethan Rathbun, Christopher Amato, Alina Oprea Reinforcement learning (RL) is an actively growing field that is seeing increased usage in real-world, safety-critical applications -- making it paramount to ensure the robustness of RL algorithms against adversarial attacks. In this work we explore a particularly stealthy form of training-time attacks against RL -- backdoor poisoning. Here the adversary intercepts the training of an RL agent with the goal of reliably inducing a particular action when the agent observes a pre-determined trigger at inference time. We uncover theoretical limitations of prior work by proving their inability to generalize across domains and MDPs. Motivated by this, we formulate a novel poisoning attack framework which interlinks the adversary's objectives with those of finding an optimal policy -- guaranteeing attack success in the limit. Using insights from our theoretical analysis we develop ""SleeperNets"" as a universal backdoor attack which exploits a newly proposed threat model and leverages dynamic reward poisoning techniques. We evaluate our attack in 6 environments spanning multiple domains and demonstrate significant improvements in attack success over existing methods, while preserving benign episodic return.",203
118,Artificial Intelligence,Christopher Amato,"August 8th, 2024",Robot Navigation in Unseen Environments using Coarse Maps,https://doi.org/10.1109/ICRA57147.2024.10611256," Chengguang Xu, Christopher Amato, Lawson L. S. Wong. (2024). Robot Navigation in Unseen Environments using Coarse Maps ICRA, 2932-2938. https://doi.org/10.1109/ICRA57147.2024.10611256","Can an autonomous robot directly navigate in previously unseen environments using coarse maps? We propose the Coarse Map Navigator (CMN), a navigation framework that can perform robot navigation in unseen environments. Empirical results demonstrate that CMN achieves high navigation success rates in unseen. environments. The study was presented at the 2024 IEEE International Conference on Robotics and Automation (ICRA) in Yokohama, Japan. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",204
119,Artificial Intelligence,Christopher Amato,"December 13th, 2023",On-Robot Bayesian Reinforcement Learning for POMDPs,https://doi.org/10.1109/IROS55552.2023.10342114," Hai Nguyen, Sammie Katt, Yuchen Xiao, Christopher Amato. (2023). On-Robot Bayesian Reinforcement Learning for POMDPs IROS, 9480-9487. https://doi.org/10.1109/IROS55552.2023.10342114","Bayesian reinforcement learning (BRL) is uniquely positioned as such a solution method. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach can, for example, utilize typical low-level robot simulators and handle uncertainty over unknown dynamics of the environment. We empirically demonstrate its efficiency by performing on-robot learning in two human-ro Bot interaction tasks with uncertainty about human behavior, achieving near-optimal performance after only a handful of real-world episodes.",205
120,Artificial Intelligence,Christopher Amato,"May 31st, 2023",Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning,https://proceedings.mlr.press/v202/daley23a.html," Brett Daley, Martha White, Christopher Amato, Marlos C. Machado. (2023). Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning ICML, 6818-6835. https://proceedings.mlr.press/v202/daley23a.html","Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across Œª Œª -values in an off-policy control task.",206
121,Artificial Intelligence,Christopher Amato,"June 28th, 2022",A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning,https://ojs.aaai.org/index.php/AAAI/article/view/21171," Xueguang Lyu, Andrea Baisero, Yuchen Xiao, Christopher Amato. (2022). A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning AAAI, 9396-9404. https://ojs.aaai.org/index.php/AAAI/article/view/21171","Abstract Centralized Training for Decentralized Execution, where training is done in a centralized offline fashion, has become a popular solution paradigm in Multi-Agent Reinforcement Learning. Many such methods take the form of actor-critic with state-based critics, since centralized training allows access to the true system state, which can be useful during training despite not being available at execution time. State-based critics have become a common empirical choice, albeit one which has had limited theoretical justification or analysis. In this paper, we show that state-based critics can introduce bias in the policy gradient estimates, potentially undermining the asymptotic guarantees of the algorithm. We also show that, even if the state-based critics do not introduce any bias, they can still result in a larger gradient variance, contrary to the common intuition. Finally, we show the effects of the theories in practice by comparing different forms of centralized critics on a wide range of common benchmarks, and detail how various environmental properties are related to the effectiveness of different types of critics.",207
122,Artificial Intelligence,Christopher Amato,"August 11th, 2021",Reconciling Rewards with Predictive State Representations,https://doi.org/10.24963/ijcai.2021/299," Andrea Baisero, Christopher Amato. (2021). Reconciling Rewards with Predictive State Representations IJCAI, 2170-2176. https://doi.org/10.24963/ijcai.2021/299","Copyright ¬© 2025,",208
123,Artificial Intelligence,Christopher Amato,"January 1st, 2020",To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots,https://doi.org/10.1109/IROS45743.2020.9341607," Balint Gucsi, Danesh S. Tarapore, William Yeoh , Christopher Amato, Long Tran-Thanh. (2020). To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots IROS, 7935-7940. https://doi.org/10.1109/IROS45743.2020.9341607","Social robots can efficiently gather user preferences without exceeding the allowed user annoyance threshold. To do so, we use a Gazebo based simulated office environment with a TIAGo Steel robot. We then test our approach on the aforementioned simulated environment and demonstrate that it can accurately estimate user preferences.",209
124,Artificial Intelligence,Christopher Amato,"September 19th, 2019",Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net,https://arxiv.org/abs/1909.08776," Xiao, Yuchen & Hoffman, Joshua & Xia, Tian & Amato, Christopher. (2020). Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net.","In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec-MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near-centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.",210
125,Artificial Intelligence,Silvio Amir,"August 1st, 2024",Open (Clinical) LLMs are Sensitive to Instruction Phrasings,https://aclanthology.org/2024.bionlp-1.5," Alberto Mario Ceballos-Arroyo, Monica Munnangi, Jiuding Sun, Karen Y. C. Zhang, Denis Jered McInerney, Byron C. Wallace, Silvio Amir. (2024). Open (Clinical) LLMs are Sensitive to Instruction Phrasings BioNLP@ACL, 50-71. https://aclanthology.org/2024.bionlp-1.5","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain. This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs‚Äîsome general, others specialized‚Äîto natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that‚Äîperhaps surprisingly‚Äîdomain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",211
126,Artificial Intelligence,Silvio Amir,"June 20th, 2024",Investigating Mysteries of CoT-Augmented Distillation,https://doi.org/10.48550/arXiv.2406.14511," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2024). Investigating Mysteries of CoT-Augmented Distillation CoRR, abs/2406.14511. https://doi.org/10.48550/arXiv.2406.14511","Eliciting ""chain of thought"" (CoT) rationales -- sequences of token that convey a ""reasoning"" process -- has been shown to consistently improve LLM performance on tasks like question answering. More recent efforts have shown that such rationales can also be used for model distillation: Including CoT sequences (elicited from a large ""teacher"" model) in addition to target labels when fine-tuning a small student model yields (often substantial) improvements. In this work we ask: Why and how does this additional training signal help in model distillation? We perform ablations to interrogate this, and report some potentially surprising results. Specifically: (1) Placing CoT sequences after labels (rather than before) realizes consistently better downstream performance -- this means that no student ""reasoning"" is necessary at test time to realize gains. (2) When rationales are appended in this way, they need not be coherent reasoning sequences to yield improvements; performance increases are robust to permutations of CoT tokens, for example. In fact, (3) a small number of key tokens are sufficient to achieve improvements equivalent to those observed when full rationales are used in model distillation.",212
127,Artificial Intelligence,Silvio Amir,"March 29th, 2024",On-the-fly Definition Augmentation of LLMs for Biomedical NER,https://doi.org/10.48550/arXiv.2404.00152," Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik. (2024). On-the-fly Definition Augmentation of LLMs for Biomedical NER CoRR, abs/2404.00152. https://doi.org/10.48550/arXiv.2404.00152","Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code atthis https URL.",213
128,Artificial Intelligence,Silvio Amir,"July 1st, 2023",SemEval-2023 Task 8: Causal Medical Claim Identification and Related PIO Frame Extraction from Social Media Posts,https://aclanthology.org/2023.semeval-1.311," Vivek Khetan, Somin Wadhwa, Byron C. Wallace, Silvio Amir. (2023). SemEval-2023 Task 8: Causal Medical Claim Identification and Related PIO Frame Extraction from Social Media Posts SemEval@ACL, 2266-2274. https://aclanthology.org/2023.semeval-1.311","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Identification of medical claims from user-generated text data is an onerous but essential step for various tasks including content moderation, and hypothesis generation. SemEval-2023 Task 8 is an effort towards building those capabilities and motivating further research in this direction. This paper summarizes the details and results of shared task 8 at SemEval-2023 which involved identifying causal medical claims and extracting related Populations, Interventions, and Outcomes (‚ÄúPIO‚Äù) frames from social media (Reddit) text. This shared task comprised two subtasks: (1) Causal claim identification; and (2) PIO frame extraction. In total, seven teams participated in the task. Of the seven, six provided system descriptions which we summarize here. For the first subtask, the best approach yielded a macro-averaged F-1 score of 78.40, and for the second subtask, the best approach achieved token-level F-1 scores of 40.55 for Populations, 49.71 for Interventions, and 30.08 for Outcome frames.",214
129,Artificial Intelligence,Silvio Amir,"June 2nd, 2023",An Example of (Too Much) Hyper-Parameter Tuning In Suicide Ideation Detection,https://doi.org/10.1609/icwsm.v17i1.22227," Annika Marie Schoene, John E. Ortega, Silvio Amir, Kenneth Church . (2023). An Example of (Too Much) Hyper-Parameter Tuning In Suicide Ideation Detection ICWSM, 1158-1162. https://doi.org/10.1609/icwsm.v17i1.22227","Abstract This work starts with the TWISCO baseline, a benchmark of suicide-related content from Twitter. We find that hyper-parameter tuning can improve this baseline by 9%. We examined 576 combinations of hyper-parameters: learning rate, batch size, epochs and date range of training data. Reasonable settings of learning rate and batch size produce better results than poor settings. Date range is less conclusive. Balancing the date range of the training data to match the benchmark ought to improve performance, but the differences are relatively small. Optimal settings of learning rate and batch size are much better than poor settings, but optimal settings of date range are not that different from poor settings of date range. Finally, we end with concerns about reproducibility. Of the 576 experiments, 10% produced F1 performance above baseline. It is common practice in the literature to run many experiments and report the best, but doing so may be risky, especially given the sensitive nature of Suicide Ideation Detection.",215
130,Artificial Intelligence,Silvio Amir,"May 8th, 2023",Revisiting Relation Extraction in the era of Large Language Models,https://doi.org/10.48550/arXiv.2305.05003," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2023). Revisiting Relation Extraction in the era of Large Language Models CoRR, abs/2305.05003. https://doi.org/10.48550/arXiv.2305.05003","Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a \emph{sequence-to-sequence} task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA results. We release this model as a new baseline for RE tasks.",216
131,Artificial Intelligence,Silvio Amir,"May 5th, 2023","Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs",https://doi.org/10.48550/arXiv.2305.03642," Somin Wadhwa, Jay DeYoung, Benjamin E. Nye, Silvio Amir, Byron C. Wallace. (2023). Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs CoRR, abs/2305.03642. https://doi.org/10.48550/arXiv.2305.03642","Results from Randomized Controlled Trials (RCTs) establish the comparative effectiveness of interventions, and are in turn critical inputs for evidence-based care. However, results from RCTs are presented in (often unstructured) natural language articles describing the design, execution, and outcomes of trials; clinicians must manually extract findings pertaining to interventions and outcomes of interest from such articles. This onerous manual process has motivated work on (semi-)automating extraction of structured evidence from trial reports. In this work we propose and evaluate a text-to-text model built on instruction-tuned Large Language Models (LLMs) to jointly extract Interventions, Outcomes, and Comparators (ICO elements) from clinical abstracts, and infer the associated results reported. Manual (expert) and automated evaluations indicate that framing evidence extraction as a conditional generation task and fine-tuning LLMs for this purpose realizes considerable (‚àº20 point absolute F1 score) gains over the previous SOTA. We perform ablations and error analyses to assess aspects that contribute to model performance, and to highlight potential directions for further improvements. We apply our model to a collection of published RCTs through mid-2022, and release a searchable database of structured findings:this http URL",217
132,Artificial Intelligence,Silvio Amir,"October 12th, 2022","RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media",https://doi.org/10.48550/arXiv.2210.06331," Somin Wadhwa, Vivek Khetan, Silvio Amir, Byron C. Wallace. (2022). RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media CoRR, abs/2210.06331. https://doi.org/10.48550/arXiv.2210.06331","We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly annotated social media posts from Reddit spanning 24 health conditions. Annotations include demarcations of spans corresponding to medical claims, personal experiences, and questions. We collect additional granular annotations on identified claims. Specifically, we mark snippets that describe patient Populations, Interventions, and Outcomes (PIO elements) within these. Using this corpus, we introduce the task of retrieving trustworthy evidence relevant to a given claim made on social media. We propose a new method to automatically derive (noisy) supervision for this task which we use to train a dense retrieval model; this outperforms baseline models. Manual evaluation of retrieval results performed by medical doctors indicate that while our system performance is promising, there is considerable room for improvement. Collected annotations (and scripts to assemble the dataset), are available atthis https URL.",218
133,Artificial Intelligence,Silvio Amir,"August 16th, 2022",UserNLP‚Äô22: 2022 International Workshop on User-centered Natural Language Processing,https://doi.org/10.1145/3487553.3524879," Xiaolei Huang , Lucie Flek, Franck Dernoncourt, Charles Welch, Silvio Amir, Ramit Sawhney, Diyi Yang. (2022). UserNLP'22: 2022 International Workshop on User-centered Natural Language Processing WWW (Companion Volume), 1176-1177. https://doi.org/10.1145/3487553.3524879","We report goals, paper submissions, keynotes, and organizations of this UserNLP workshop. User-centered NLP can fill these gaps by explicitly considering stylistic variations across individuals or groups of individuals and focusing on user-level modeling tasks. While traditional NLP tasks tend to focus on single documents (e.g., sentiment analysis), user-centered NLP aims to make inferences for individual users, on the basis of one or more documents associated with that user. This workshop aims to create a platform where researchers can present rising challenges in building user-centered NLP models and discuss shared issues across multidisciplinary fields. We have received 11 submissions and accepted 6 of the submissions, which were reviewed by our 19 program committee members. The program invited four keynote talks from both academia and industry. We appreciate the valuable contributions from the organizing committee, program committee, keynote speakers, and the manuscript authors.",219
134,Artificial Intelligence,Silvio Amir,"June 6th, 2021",On the Impact of Random Seeds on the Fairness of Clinical Classifiers,https://doi.org/10.18653/v1/2021.naacl-main.299," Silvio Amir, Jan-Willem van de Meent, Byron C. Wallace. (2021). On the Impact of Random Seeds on the Fairness of Clinical Classifiers NAACL-HLT, 3808-3823. https://doi.org/10.18653/v1/2021.naacl-main.299","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III ‚Äî‚Äî the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of minority groups and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from stochasticity and small sample sizes.",220
135,Artificial Intelligence,Silvio Amir,"April 22nd, 2021",Demographic Representation and Collective Storytelling in the Me Too Twitter Hashtag Activism Movement,https://doi.org/10.1145/3449181," Aaron Mueller, Zach Wood-Doughty, Silvio Amir, Mark Dredze, Alicia Lynn Nobles. (2021). Demographic Representation and Collective Storytelling in the Me Too Twitter Hashtag Activism Movement Proc. ACM Hum. Comput. Interact., 5, 107:1-107:28. https://doi.org/10.1145/3449181","The #MeToo movement on Twitter has drawn attention to the pervasive nature of sexual harassment and violence. While #MeToo has been praised for providing support for self-disclosures of harassment or violence and shifting societal response, it has also been criticized for exemplifying how women of color have been discounted for their historical contributions to and excluded from feminist movements. Through an analysis of over 600,000 tweets from over 256,000 unique users, we examine online #MeToo conversations across gender and racial/ethnic identities and the topics that each demographic emphasized. We found that tweets authored by white women were overrepresented in the movement compared to other demographics, aligning with criticism of unequal representation. We found that intersected identities contributed differing narratives to frame the movement, co-opted the movement to raise visibility in parallel ongoing movements, employed the same hashtags both critically and supportively, and revived and created new hashtags in response to pivotal moments. Notably, tweets authored by black women often expressed emotional support and were critical about differential treatment in the justice system and by police. In comparison, tweets authored by white women and men often highlighted sexual harassment and violence by public figures and weaved in more general political discussions. We discuss the implications of this work for digital activism research and design, including suggestions to raise visibility by those who were under-represented in this hashtag activism movement. Content warning: this article discusses issues of sexual harassment and violence.",221
136,Artificial Intelligence,Javed Aslam,"October 30th, 2024","Don‚Äôt Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification",https://doi.org/10.48550/arXiv.2410.23066," Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu. (2024). Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification CoRR, abs/2410.23066. https://doi.org/10.48550/arXiv.2410.23066","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely heavily on multi-label attention layers to focus on key tokens in input text, but obtaining optimal attention weights is challenging and resource-intensive. To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses existing state-of-the-art methods across all metrics on mimicfull, mimicfifty, mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot scenarios, outperforming previous models specifically designed for few-shot scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36 percentage points on mimicfew, demonstrating its superior capability in handling rare codes. PLANT also shows remarkable data efficiency in few-shot scenarios, achieving precision comparable to traditional models with significantly less data. These results are achieved through key technical innovations: leveraging a pretrained Learning-to-Rank model as the planted attention layer, integrating mutual-information gain to enhance attention, introducing an inattention mechanism, and implementing a stateful-decoder to maintain context. Comprehensive ablation studies validate the importance of these contributions in realizing the performance gains.",222
137,Artificial Intelligence,Javed Aslam,"August 2nd, 2024",Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy,https://doi.org/10.1145/3626324," Maryam Aziz, Jesse Anderton, Kevin G. Jamieson, Alice Wang, Hugues Bouchard, Javed A. Aslam. (2025). Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy Trans. Recomm. Syst., 3, 4:1-4:22. https://doi.org/10.1145/3626324","Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely armed pure-exploration setting. We demonstrate that our algorithm is well suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches. Finally, we study a setting in which users are more likely to stream more-streamed podcasts independent of their general appeal and find that our proposed algorithm is robust to this type of popularity bias.",223
138,Artificial Intelligence,Javed Aslam,"January 1st, 2021",Improving Query Graph Generation for Complex Question Answering over Knowledge Base,https://doi.org/10.18653/v1/2021.emnlp-main.346," Kechen Qin, Cheng Li, Virgil Pavlu, Javed A. Aslam. (2021). Improving Query Graph Generation for Complex Question Answering over Knowledge Base EMNLP (1), 4201-4207. https://doi.org/10.18653/v1/2021.emnlp-main.346","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Most of the existing Knowledge-based Question Answering (KBQA) methods first learn to map the given question to a query graph, and then convert the graph to an executable query to find the answer. The query graph is typically expanded progressively from the topic entity based on a sequence prediction model. In this paper, we propose a new solution to query graph generation that works in the opposite manner: we start with the entire knowledge base and gradually shrink it to the desired query graph. This approach improves both the efficiency and the accuracy of query graph generation, especially for complex multi-hop questions. Experimental results show that our method achieves state-of-the-art performance on ComplexWebQuestion (CWQ) dataset.",224
139,Artificial Intelligence,Javed Aslam,"June 23rd, 2019",Adapting RNN Sequence Prediction Model to Multi-label Set Prediction,https://www.aclweb.org/anthology/N19-1321/," Conference Proceedings Adapting RNN Sequence Prediction Model to Multi-label Set Prediction. Qin, Kechen; Li, Cheng; Pavlu, Virgil; Aslam, Javed. Proceedings of the 2019 NAACL-HLT, Volume 1 (Long and Short Papers), 2019 8 jun I Association for Computational Linguistics, Minneapolis, Minnesota","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present an adaptation of RNN sequence models to the problem of multi-label classification for text, where the target is a set of labels, not a sequence. Previous such RNN models define probabilities for sequences but not for sets; attempts to obtain a set probability are after-thoughts of the network design, including pre-specifying the label order, or relating the sequence probability to the set probability in ad hoc ways. Our formulation is derived from a principled notion of set probability, as the sum of probabilities of corresponding permutation sequences for the set. We provide a new training objective that maximizes this set probability, and a new prediction objective that finds the most probable set on a test document. These new objectives are theoretically appealing because they give the RNN model freedom to discover the best label order, which often is the natural one (but different among documents). We develop efficient procedures to tackle the computation difficulties involved in training and prediction. Experiments on benchmark datasets demonstrate that we outperform state-of-the-art methods for this task.",225
140,Artificial Intelligence,Javed Aslam,"June 15th, 2019",Scaling Up Ordinal Embedding: A Landmark Approach,http://proceedings.mlr.press/v97/anderton19a.html," Anderton, J. & Aslam, J.. (2019). Scaling Up Ordinal Embedding: A Landmark Approach. Proceedings of the 36th International Conference on Machine Learning, in PMLR 97:282-290","Ordinal Embedding is the problem of placing n objects into R^d to satisfy constraints like ""object a is closer to b than to c."" It can accommodate data that embeddings from features or distances cannot, but is a more difficult problem. We propose a novel landmark-based method as a partial solution. At small to medium scales, we present a novel combination of existing methods with some new theoretical justification. For very large values of n optimizing over an entire embedding breaks down, so we propose a novel method which first embeds a subset of m << n objects and then embeds the remaining objects independently and in parallel. We prove a distance error bound for our method in terms of m and that it has O(dn log m) time complexity, and show empirically that it is able to produce high quality embeddings in a fraction of the time needed for any published method.",226
141,Artificial Intelligence,Javed Aslam,"March 24th, 2018",Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence,https://doi.org/10.48550/arXiv.1803.04665," Aziz, M., Anderton, J., Kaufmann, E. and Aslam, J.. (2018). ""Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence."" Proceedings of Algorithmic Learning Theory, in PMLR 83:3-24. DOI: 0.48550/arXiv.1803.04665","We consider the problem of near-optimal arm identification in the fixed confidence setting of the infinitely armed bandit problem when nothing is known about the arm reservoir distribution. We (1) introduce a PAC-like framework within which to derive and cast results; (2) derive a sample complexity lower bound for near-optimal arm identification; (3) propose an algorithm that identifies a nearly-optimal arm with high probability and derive an upper bound on its sample complexity which is within a log factor of our lower bound; and (4) discuss whether our log^2(1/delta) dependence is inescapable for ""two-phase"" (select arms first, identify the best later) algorithms in the infinite setting. This work permits the application of bandit models to a broader class of problems where fewer assumptions hold.",227
142,Artificial Intelligence,Javed Aslam,"January 17th, 2018",A Pipeline for Optimizing F1-Measure in Multi-label Text Classification,https://ieeexplore.ieee.org/abstract/document/8614173," B. Wang, C. Li, V. Pavlu, J. Aslam, ""A Pipeline for Optimizing F1-Measure in Multi-label Text Classification ,"" ICMLA, 2018.",Multi-label text classification is the machine learning task wherein each document is tagged with multiple labels. This task is uniquely challenging due to high dimensional features and correlated labels. Such text classifiers need to be regularized to prevent severe over-fitting in the high dimensional space. We propose a new pipeline which takes such algorithms and improves their F1-performance with careful training regularization and a new prediction strategy. We further demonstrate that support inference acts as a strong regularizer on the label prediction structure.,228
143,Artificial Intelligence,Javed Aslam,"October 23rd, 2015",Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model,https://doi.org/10.1145/2806416.2806492," P. Metrikov, V. Pavlu, J. A. Aslam. ""Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model"". Proceedings of the 24th ACM Conference on Information and Knowledge Management, Melbourne, Australia (2015). DOI: 10.1145/2806416.2806492","Existing approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors. A document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.",229
144,Artificial Intelligence,Javed Aslam,"September 29th, 2013",A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments,http://dx.doi.org/10.1145/2499178.2499198," Pavel Metrikov, Jie Wu, Jesse Anderton, Virgil Pavlu, and Javed A. Aslam. 2013. A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments. In Proceedings of the 2013 Conference on the Theory of Information Retrieval (ICTIR '13). Association for Computing Machinery, New York, NY, USA, 133‚Äì134. https://doi.org/10.1145/2499178.2499198","We consider noisy crowdsourced assessments and their impact on learning-to-rank algorithms. Starting with EM-weighted assessments, we modify LambdaMART in order to use smoothed probabilistic preferences over pairs of documents, directly as input to the ranking algorithm.",230
145,Artificial Intelligence,Javed Aslam,"March 24th, 2013",Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency,http://link.springer.com/chapter/10.1007/978-3-642-36973-5_78," P. Metrikov, V. Pavlu, J. A. Aslam, ""Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency"", Advances in Information Retrieval: 35th European Conference on IR Research (ECIR), Moscow, Russia (2013).  Best Poster Paper Award","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",231
146,Artificial Intelligence,David Bau,"November 1st, 2024",Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs,https://aclanthology.org/2024.emnlp-main.543," Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs EMNLP, 9727-9739. https://aclanthology.org/2024.emnlp-main.543","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b‚Äôs tokenizer splits the word ‚Äúpatrolling‚Äù into two tokens, ‚Äúpat‚Äù and ‚Äúrolling‚Äù, neither of which correspond to semantically meaningful units like ‚Äúpatrol‚Äù or ""-ing.‚Äù Similarly, the overall meanings of named entities like ‚ÄúNeil Young‚Äù and multi-word expressions like ‚Äúbreak a leg‚Äù cannot be directly inferred from their constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups of tokens into useful higher-level representations? In this work, we find that last token representations of named entities and multi-token words exhibit a pronounced ‚Äúerasure‚Äù effect, where information about previous and current tokens is rapidly forgotten in early layers. Using this observation, we propose a method to ‚Äúread out‚Äù the implicit vocabulary of an autoregressive LLM by examining differences in token representations across layers, and present results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is the first attempt to probe the implicit vocabulary of an LLM.",232
147,Artificial Intelligence,David Bau,"January 16th, 2024",Linearity of Relation Decoding in Transformer Language Models,https://openreview.net/forum?id=w7LU2s14kE," Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, David Bau. (2024). Linearity of Relation Decoding in Transformer Language Models ICLR. https://openreview.net/forum?id=w7LU2s14kE","Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations. For a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. The authors conduct experiments on 47 different relations, showing that linear approximations hold for some but not all relations.",233
148,Artificial Intelligence,David Bau,"January 16th, 2024",Function Vectors in Large Language Models,https://openreview.net/forum?id=AwyxtyMwaG," Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. (2024). Function Vectors in Large Language Models ICLR. https://openreview.net/forum?id=AwyxtyMwaG",This paper delves into the concept of function vectors (FVs) within autoregressive transformer language models (LLMs) FVs encapsulate task-specific information and exhibit robustness across various contexts. The study uncovers that FVs don't directly execute tasks but trigger the model to perform them through complex computations.,234
149,Artificial Intelligence,David Bau,"January 16th, 2024",Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking,https://openreview.net/forum?id=8sKcAWOf2D," Nikhil Prakash, Tamar Rott Shaham, Tal Haklay, Yonatan Belinkov, David Bau. (2024). Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking ICLR. https://openreview.net/forum?id=8sKcAWOf2D",The paper focuses on entity tracking (model inferring properties with an entity previously defined in the input context) to understand how LMs change during fine-tuning. They use a path-patching technique on synthetic dataset to isolate circuits responsible for entity tracking. They find all three models reach high faithfulness scores with the circuit identified in Llama-7B.,235
150,Artificial Intelligence,David Bau,"January 15th, 2024",Erasing Concepts from Diffusion Models,https://doi.org/10.1109/ICCV51070.2023.00230," Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau. (2023). Erasing Concepts from Diffusion Models ICCV, 2426-2436. https://doi.org/10.1109/ICCV51070.2023.00230","Motivated by concerns that large-scale diffusion models can produce undesirable output such as sexually explicit content or copyrighted artistic styles. We propose a fine-tuning method that can erase a visual concept from a pre-trained diffusion model, given only the name of the style. Unlike previous methods, our approach can remove concepts from a diffusion model permanently rather than modifying the output at the inference time, so it cannot be circumvented. Our code, data, and results are available at erasing.baulab.info.",236
151,Artificial Intelligence,David Bau,"November 8th, 2023",Future Lens: Anticipating Subsequent Tokens from a Single Hidden State,https://arxiv.org/abs/2311.04897," Pal, K., Sun, J., Yuan, A., Wallace, B.C., & Bau, D. (2023). Future Lens: Anticipating Subsequent Tokens from a Single Hidden State. ArXiv, abs/2311.04897.","We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at positiontin an input, can we reliably anticipate the tokens that will appear at positions‚â•t+2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a ""Future Lens"" visualization that uses these methods to create a new view of transformer states.",237
152,Artificial Intelligence,David Bau,"September 7th, 2023",FIND: A Function Description Benchmark for Evaluating Interpretability Methods,http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html," Sarah Schwettmann, Tamar Rott Shaham, Joanna Materzynska, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, Antonio Torralba . (2023). FIND: A Function Description Benchmark for Evaluating Interpretability Methods NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html",FIND (Function INterpretation and Description) is a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks. The results suggest that FIND will be useful for characterizing the performance of more sophisticated interpretable methods before they are applied to real- world models.,238
153,Artificial Intelligence,David Bau,"February 28th, 2022",Toward a Visual Concept Vocabulary for GAN Latent Space,https://doi.org/10.1109/ICCV48922.2021.00673," Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas, Antonio Torralba . (2021). Toward a Visual Concept Vocabulary for GAN Latent Space ICCV, 6784-6792. https://doi.org/10.1109/ICCV48922.2021.00673","New method for building open-ended vocabularies of primitive visual concepts. Concepts learned with our approach are reliable and composable, and enabling fine-grained manipulation of image style and content. Based on automatic identification of perceptually salient directions based on their layer selectivity. Human annotation of these directions with free-form, natural language descriptions. decomposition of these annotations into a visual concept vocabulary.",239
154,Artificial Intelligence,David Bau,"February 10th, 2022",Locating and Editing Factual Associations in GPT,https://arxiv.org/abs/2202.05262," Meng, K., Bau, D., Andonian, A., & Belinkov, Y. (2022). Locating and Editing Factual Associations in GPT. Neural Information Processing Systems.","We analyze the storage and recall of factual associations in autoregressive transformer language models, finding evidence that these associations correspond to localized, directly-editable computations. We first develop a causal intervention for identifying neuron activations that are decisive in a model's factual predictions. This reveals a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions while processing subject tokens. To test our hypothesis that these computations correspond to factual association recall, we modify feed-forward weights to update specific factual associations using Rank-One Model Editing (ROME). We find that ROME is effective on a standard zero-shot relation extraction (zsRE) model-editing task, comparable to existing methods. To perform a more sensitive evaluation, we also evaluate ROME on a new dataset of counterfactual assertions, on which it simultaneously maintains both specificity and generalization, whereas other methods sacrifice one or another. Our results confirm an important role for mid-layer feed-forward modules in storing factual associations and suggest that direct manipulation of computational mechanisms may be a feasible approach for model editing. The code, dataset, visualizations, and an interactive demo notebook are available atthis https URL",240
155,Artificial Intelligence,David Bau,"January 28th, 2022",Disentangling visual and written concepts in CLIP,https://doi.org/10.1109/CVPR52688.2022.01592," Joanna Materzynska, Antonio Torralba , David Bau. (2022). Disentangling visual and written concepts in CLIP CVPR, 16389-16398. https://doi.org/10.1109/CVPR52688.2022.01592","The CLIP network measures the similarity between natural text and images. In this work, we investigate the entanglement of the representation of word images and natural images in its image encoder. This is consistent with previous research that suggests that the meaning and the spelling of a word might be entangled deep within the network. We find that our methods are able to cleanly separate spelling capabilities of CLIP from the visual processing of natural images. On the other hand, we also find that CLIP has a strong ability to match nonsense words, suggesting that processing of letters is separated from processing of their meaning.",241
156,Artificial Intelligence,David Bau,"August 5th, 2021",Sketch Your Own GAN,https://peterwang512.github.io/GANSketching/," Sheng-Yu Wang, David Bau, and Jun-Yan Zhu. Sketch Your Own GAN. Proceedings of the IEEE/CVF International Conference on Computer Vision. (ICCV 2021)","Our method can customize a pre-trained GAN to match input sketches. Interpolation using our customized models. Latent space interpolation is smooth with our customized models. Image editing using our customized models. (a) Given a real image, (b) we project it to the original model's noise z using Huh et al. (c) We feed the projected z to the standing cat model trained on sketches. (d) we edit the image with `add fur` operation using GANSpace . We can interpolate between the customized model by interpolating the W-latent space.",242
157,Artificial Intelligence,David Bau,"January 1st, 2020",Diverse Image Generation via Self-Conditioned GANs,https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html," Steven Liu, Tongzhou Wang , David Bau, Jun-Yan Zhu, Antonio Torralba . (2020). Diverse Image Generation via Self-Conditioned GANs CVPR, 14274-14283. https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html","We introduce a simple but effective unsupervised method for generating diverse images. We train a class-conditional GAN model without using manually annotated class labels. Instead, our model is conditional on labels automatically derived from clustering in the discriminator's feature space. Our clustering step automatically discovers diverse modes, and explicitly requires the generator to cover them. Experiments on standard mode collapse benchmarks show that our method outperforms several competing methods when addressing mode collapse. Our method also performs well on large-scale datasets such as ImageNet and Places365, improving both diversity and standard metrics (e.g., Frechet Inception Distance), compared to previous methods.",243
158,Artificial Intelligence,Kenneth Church,"May 23rd, 2022",Emerging trends: General fine-tuning (gft),https://doi.org/10.1017/S1351324922000237," K. Church, X. Cai, Y. Ying, Z. Chen, G. Xun, Y. Bian. (2022). Emerging trends: General fine-tuning (gft). Natural Language Engineering, 28(4), 519-535. DOI: 10.1017/S1351324922000237","This paper describes gft (general fine-tuning), a little language for deep nets. gft makes deep nets accessible to a broad audience including non-programmers. It is standard practice in many fields to use statistics packages such as R. The paper is published in the online version with a free download.",244
159,Artificial Intelligence,Kenneth Church,"February 8th, 2022",Emerging trends: SOTA-Chasing,https://doi.org/10.1017/S1351324922000043," K. Church & V. Kordoni. (2022). Emerging Trends: SOTA-Chasing. Natural Language Engineering, 28(2), 249-269. DOI: 10.1017/S1351324922000043","Many papers are chasing state-of-the-art (SOTA) numbers. SOTA-chasing may be similar to the replication crisis in the scientific literature. Too much SOTA.-chasing could lead to claims of superhuman. performance, unrealistic expectations, and the next AI winter.",245
160,Artificial Intelligence,Kenneth Church,"May 31st, 2021","Emerging trends: Ethics, intimidation, and the Cold War",https://doi.org/10.1017/S135132492100005X," K. Church & V. Kordoni. (2021). Emerging trends: Ethics, intimidation, and the Cold War. Natural Language Engineering, 27(3), 379-390. DOI: 10.1017/S135132492100005X"," ACL has recently introduced a new process where there are special reviews of some papers for ethics. We would be more comfortable with the new ethics process if there were more checks and balances, due process and transparency. Otherwise, there is a risk that the process could intimidate authors in ways that are not that dissimilar to the ways that academics were intimidated during the Cold War.",246
161,Artificial Intelligence,Nate Derbinsky,"February 18th, 2025",Addressing Challenges in Teaching-Track Faculty Promotion,https://doi.org/10.1145/3641555.3704713," Christine Alvarado, Nate Derbinsky, Sarah Heckman, Manuel A. P√©rez-Qui√±ones, Harini Ramaprasad, Mark Sherriff. (2025). Addressing Challenges in Teaching-Track Faculty Promotion SIGCSE (2), 1685-1686. https://doi.org/10.1145/3641555.3704713","Interest in teaching-track faculty positions has been steadily increasing as enrollments in computer science degree programs continue to trend upward. While departments have welcomed these new teaching-track faculty members, senior faculty, department chairs, and university committees often struggle with how to best evaluate these faculty members during the promotion process. In our experience, some universities try to use a ""watered-down"" version of the tenure-track promotion standards with the intent of uniformity. Other universities have created whole new processes, which may be better at capturing the differences in teaching-track positions, but also can create a ""second-class citizen"" status for the teaching-track faculty members. For this panel, we will bring together teaching-track and tenured faculty who have been active in promotion committees, have written letters of support for teaching-track faculty, and have successfully guided junior faculty through the promotion process. Our goal is to shed light on the differing practices at various universities and help attendees understand how to best support junior teaching-track faculty.",247
162,Artificial Intelligence,Nate Derbinsky,"March 15th, 2024",Interviewing the Teaching Faculty Hiring Process,https://doi.org/10.1145/3626253.3631664," Geoffrey Challen, Victoria Dean, Nate Derbinsky, Matt X. Wang, Jacqueline Smith. (2024). Interviewing the Teaching Faculty Hiring Process SIGCSE (2), 1525-1526. https://doi.org/10.1145/3626253.3631664","As teaching-focused positions proliferate and university teaching careers become more professionalized, there is growing attention being paid to how teaching faculty are created. However, how teaching faculty are hired also deserves scrutiny. Teaching faculty hiring varies widely between institutions, raising questions of whether hiring processes are effectively identifying, evaluating, and recruiting qualified applicants, and which approaches are most effective. Variation in application requirements and interview processes may also result in a higher workload for teaching faculty candidates when compared to peers applying for other types of faculty positions. This panel brings together faculty with significant teaching faculty hiring experience and new teaching faculty who were very recently on the job market. Together we'll discuss what is and is not working in teaching faculty hiring, and how we might improve the process for both institutions and candidates. We anticipate engaging with those involved with hiring teaching faculty, as well as current and future teaching faculty candidates.",248
163,Artificial Intelligence,Nate Derbinsky,"July 19th, 2022",Using domain knowledge in coevolution and reinforcement learning to simulate a logistics enterprise,https://doi.org/10.1145/3520304.3528990," Ying Zhao , Erik Hemberg, Nate Derbinsky, Gabino Mata, Una-May O'Reilly. (2022). Using domain knowledge in coevolution and reinforcement learning to simulate a logistics enterprise GECCO Companion, 514-517. https://doi.org/10.1145/3520304.3528990","We demonstrate a framework (CoEv-Soar-RL) for a logistics enterprise to improve readiness, sustainment, and reduce operational risk. The CoEv-Soar-RL uses reinforcement learning and coevolutionary algorithms to improve the functions of a logistics enterprise value chain. We address: (1) holistic prediction, optimization, and simulation for the logistics enterprise readiness; (2) the uncertainty and lack of data which require large-scale systematic what-if scenarios to simulate potential new and unknown situations. In this paper, we perform four experiments to investigate how to integrate prediction and simulation to modify a logistics enterprise's demand models and generate synthetic data based. We use general domain knowledge to design simple operators for the coevolutionary search algorithm that provide realistic solutions for the simulation of the logistic enterprise. In addition, to evaluate generated solutions we learn a surrogate model of a logistic enterprise environment from historical data with Soar reinforcement learning. From our experiments we discover, and verify with subject matter experts, novel realistic solutions for the logistic enterprise. These novel solutions perform better than the historical data and where only found when we include knowledge derived from the historical data in the co-evolutionary search.",249
164,Artificial Intelligence,Jennifer Dy,"March 28th, 2022",Deep Layer-wise Networks Have Closed-Form Weights,https://proceedings.mlr.press/v151/tzu-wu22a.html," Chieh Tzu Wu, Aria Masoomi, Arthur Gretton, Jennifer G. Dy. (2022). Deep Layer-wise Networks Have Closed-Form Weights AISTATS, 188-225. https://proceedings.mlr.press/v151/tzu-wu22a.html","There is currently a debate within the neuroscience community over the likelihood of the brain performing backpropagation (BP). To better mimic the brain, training a network one layer at a time with only a ""single forward pass"" has been proposed as an alternative to bypass BP; we refer to these networks as ""layer-wise"" networks. We continue the work on layer-wise networks by answering two outstanding questions. First, do they have a closed-form solution? Second, how do we know when to stop adding more layers? This work proves that the ""Kernel Mean Embedding"" is the closed-form solution that achieves the network global optimum while driving these networks to converge towards a highly desirable kernel for classification; we call it the Neural Indicator Kernel.",250
165,Artificial Intelligence,Jennifer Dy,"February 23rd, 2021",Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth,https://doi.org/10.1109/ICMLA51294.2020.00124," Shi Dong , Zlatan Feric, Guangyu Li, Chieh Wu, April Z. Gu, Jennifer G. Dy, John Meeker, Ingrid Y. Padilla, Jos√© Cordero, Carmen Velez Vega, Zaira Rosario, Akram Alshawabkeh, David R. Kaeli. (2020). Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth ICMLA, 759-764. https://doi.org/10.1109/ICMLA51294.2020.00124","We propose Ensemble Learning models to identify factors contributing to preterm birth. Our work leverages a rich dataset collected by a NIEHS P42 Center in Puerto Rico. We propose two novel methods: 1) Missing Data Rate and Accuracy Based Aggregation (MAA) and 2) Entropy and Accuracy based Aggregation. Both proposed models balance the degree of data variance introduced by the missing data handling during the feature selection process, while maintaining model performance. Our results show a 42% improvement in sensitivity versus fallout over previous state-of-the-art methods. We leverage and compare multiple Ensemble Feature selection methods, including Complete Linear Aggregation, Weighted Mean Aggregation and Feature Occurrence Frequency (OFA)",251
166,Artificial Intelligence,Jennifer Dy,"December 1st, 2020",Instance-wise Feature Grouping,https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html," Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang , Peter J. Castaldi, Jennifer G. Dy. (2020). Instance-wise Feature Grouping NeurIPS. https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html","Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang, Peter Castaldi, Jennifer Dy In many learning problems, the domain scientist is often interested in discovering the groups of features that are redundant and are important for classification. Moreover, the features that belong to each group, and the important feature groups may vary per sample. But what do we mean by feature redundancy? In this paper, we formally define two types of redundancies using information theory: \textit{Representation} and \textit{Relevant redundancies}. We leverage these redundancies to design a formulation for instance-wise feature group discovery and reveal a theoretical guideline to help discover the appropriate number of groups. We approximate mutual information via a variational lower bound and learn the feature group and selector indicators with Gumbel-Softmax in optimizing our formulation. Experiments on synthetic data validate our theoretical claims. Experiments on MNIST, Fashion MNIST, and gene expression datasets show that our method discovers feature groups with high classification accuracies.",252
167,Artificial Intelligence,Ehsan Elhamifar,"September 16th, 2024",Error Detection in Egocentric Procedural Task Videos,https://doi.org/10.1109/CVPR52733.2024.01765," Shih-Po Lee, Zijia Lu, Zekun Zhang, Minh Hoai, Ehsan Elhamifar. (2024). Error Detection in Egocentric Procedural Task Videos CVPR, 18655-18666. https://doi.org/10.1109/CVPR52733.2024.01765","We present a new egocentric procedural error dataset containing videos with various types of errors as well as normal videos. We propose to combine holistic frame features with relations features, which we learn by building a graph using active object detection followed by a Graph Convolutional Network. To handle errors, unseen during training, we use our contrastive step prototype learning to learn multiple prototypes for each step, capturing variations of error-free step executions. By experiments on three datasets, we show that our proposed framework outperforms state-of-the-art video anomaly detection methods.",253
168,Artificial Intelligence,Ehsan Elhamifar,"September 16th, 2024",FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation,https://doi.org/10.1109/CVPR52733.2024.01721," Zijia Lu, Ehsan Elhamifar. (2024). FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation CVPR, 18175-18185. https://doi.org/10.1109/CVPR52733.2024.01721","We study supervised action segmentation, whose goal is to predict framewise action labels of a video. We propose an efficient Frame-Action Cross-attention Temporal modeling (FACT) framework that performs temporal modeling withframe and action features in parallel. FACT network contains aframe branch to learn frame-level information with convolutions and frame features, action branch to learning action-level depen-dencies with transformers and action tokens. We also propose a new matching loss to ensure each action to-ken uniquely encodes an action segment, thus better captures its semantics.",254
169,Artificial Intelligence,Ehsan Elhamifar,"September 16th, 2024",Learning to Segment Referred Objects from Narrated Egocentric Videos,https://doi.org/10.1109/CVPR52733.2024.01375," Yuhan Shen, Huiyu Wang, Xitong Yang, Matt Feiszli, Ehsan Elhamifar, Lorenzo Torresani, Effrosyni Mavroudi. (2024). Learning to Segment Referred Objects from Narrated Egocentric Videos CVPR, 14510-14520. https://doi.org/10.1109/CVPR52733.2024.01375","Egocentric videos provide a first-person perspective of the wearer's activities, involving simultaneous interactions with multiple objects. Given an egocentric video clip and a narration, our aim is to segment object instances mentioned in the narration, with-out using any spatial annotations during training. Our model harnesses vision-language models pre-trained on image-text pairs to embed region masks and object phrases. Our approach achieves state-of-the-art zero-shot pixel-level grounding performance compared to strong baselines under similar supervision.",255
170,Artificial Intelligence,Ehsan Elhamifar,"September 16th, 2024",Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos,https://doi.org/10.1109/CVPR52733.2024.01722," Yuhan Shen, Ehsan Elhamifar. (2024). Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos CVPR, 18186-18197. https://doi.org/10.1109/CVPR52733.2024.01722","We address the problem of online (streaming) action seg-mentation for egocentric procedural task videos. We propose an online action segmentation framework by first modifying existing architectures to make them causal. Third, we propose to learn task graphs from training videos and leverage them to obtain smooth and procedure-consistent segmentations. With the combination of progress and task graph with casualaction segmentation, our frame-work effectively addresses prediction uncertainty and over-segmentation. We also develop a novel action progress prediction module to dynamically estimate the progress of ongoing actions.",256
171,Artificial Intelligence,Ehsan Elhamifar,"November 3rd, 2022",Zero-Shot Attribute Attacks on Fine-Grained Recognition Models,https://doi.org/10.1007/978-3-031-20065-6_16," Nasim Shafiee, Ehsan Elhamifar. (2022). Zero-Shot Attribute Attacks on Fine-Grained Recognition Models ECCV (5), 262-282. https://doi.org/10.1007/978-3-031-20065-6_16","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",257
172,Artificial Intelligence,Ehsan Elhamifar,"September 27th, 2022",Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency,https://doi.org/10.1109/CVPR52688.2022.01928," Zijia Lu, Ehsan Elhamifar. (2022). Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency CVPR, 19871-19881. https://doi.org/10.1109/CVPR52688.2022.01928","We address the problem of set-supervised action learning, whose goal is to learn an action segmentation model using weak supervision. We propose an attention-based method with a new Pairwise Ordering Consistency (POC) loss that encourages that for each common action pair in two videos of the same task, the attentions of actions follow a similar ordering. Unlike existing sequence alignment methods, which misalign actions in videos with different orderings, our POC loss efficiently aligns videos with same action orders and is differentiable, which enables end-to-end training. Our method efficiently learns the actions and their temporal locations, therefore, extends the existing attention- based action localization methods.",258
173,Artificial Intelligence,Ehsan Elhamifar,"September 27th, 2022",Semi-Weakly-Supervised Learning of Complex Actions from Instructional Task Videos,https://doi.org/10.1109/CVPR52688.2022.00334," Yuhan Shen, Ehsan Elhamifar. (2022). Semi-Weakly-Supervised Learning of Complex Actions from Instructional Task Videos CVPR, 3334-3344. https://doi.org/10.1109/CVPR52688.2022.00334","We address the problem of action segmentation in instructional task videos with a small number of weakly-labeled training videos and a large number of unlabeled videos. We propose a general SWSL framework that can efficiently learn from both types of videos and can leverage any of the existingweakly-supervisedaction segmentation methods. We develop a Soft Restricted Edit (SRE) loss to encourage small variations between the predicted transcripts of unlLabeled videos and ground-truth transcripts of the weaklylabeled videos of the same task. By experiments on two benchmark datasets, we demonstrate that our approach can significantly improve the performance by using unlabeling videos.",259
174,Artificial Intelligence,Ehsan Elhamifar,"September 27th, 2022",Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling,https://doi.org/10.1109/CVPR52688.2022.00689," Dat Huynh, Jason Kuen, Zhe Lin, Jiuxiang Gu, Ehsan Elhamifar. (2022). Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling CVPR, 7010-7021. https://doi.org/10.1109/CVPR52688.2022.00689","Open-vocabulary instance segmentation aims at segmenting novel classes without mask annotations. We propose a cross-modal pseudo-labeling framework, which generates training pseudo masks by aligning word semantics in captions with visual features of object masks in images. We significantly improve mAP score by 4.5% on MS-COCO and 5.1% on the large-scale Open Images & Conceptual Captions datasets compared to the state-of-the-art.",260
175,Artificial Intelligence,Ehsan Elhamifar,"June 27th, 2012",Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation,http://link.springer.com/chapter/10.1007%2F978-3-642-30618-1_17," Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation, L. Tao, E. Elhamifar, S. Khudanpur, G. Hager, and R. Vidal, Information Processing in Computer Assisted Interventions (IPCAI), 2012.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",261
176,Artificial Intelligence,Tina Eliassi-Rad,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",262
177,Artificial Intelligence,Tina Eliassi-Rad,"August 5th, 2024",Using overlapping methods to counter adversaries in community detection,https://doi.org/10.1093/comnet/cnae030," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Using overlapping methods to counter adversaries in community detection J. Complex Networks, 12. https://doi.org/10.1093/comnet/cnae030","Community detection is a useful data triage tool that can identify subsets of the network that a data analyst should investigate. In an adversarial scenario, the graph may be manipulated to avoid scrutiny of certain nodes by the analyst. Robustness to such behaviour is an important consideration for data analysts in high-stakes scenarios such as cyber defense and counterterrorism. We find that, when the attacker has a sufficient budget, overlapping community detection methods outperform non-overlapping methods, often overwhelmingly so. Our extensible analytic framework enables network data analysts to take these attacks into account and use them to make better decisions about which nodes to focus on.",263
178,Artificial Intelligence,Tina Eliassi-Rad,"May 30th, 2024",Distributed constrained combinatorial optimization leveraging hypergraph neural networks,https://doi.org/10.1038/s42256-024-00833-7," Nasimeh Heydaribeni, Xinrui Zhan, Ruisi Zhang, Tina Eliassi-Rad, Farinaz Koushanfar. (2024). Distributed constrained combinatorial optimization leveraging hypergraph neural networks Nat. Mac. Intell., 6, 664-672. https://doi.org/10.1038/s42256-024-00833-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",264
179,Artificial Intelligence,Tina Eliassi-Rad,"February 21st, 2024",Complex network effects on the robustness of graph convolutional networks,https://doi.org/10.1007/s41109-024-00611-9," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Complex network effects on the robustness of graph convolutional networks Appl. Netw. Sci., 9, 5. https://doi.org/10.1007/s41109-024-00611-9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",265
180,Artificial Intelligence,Tina Eliassi-Rad,"January 16th, 2024","A Survey on Hypergraph Mining: Patterns, Tools, and Generators",https://doi.org/10.48550/arXiv.2401.08878," Geon Lee, Fanchen Bu, Tina Eliassi-Rad, Kijung Shin. (2024). A Survey on Hypergraph Mining: Patterns, Tools, and Generators CoRR, abs/2401.08878. https://doi.org/10.48550/arXiv.2401.08878","Hypergraphs, which belong to the family of higher-order networks, are a natural and powerful choice for modeling group interactions in the real world. For example, when modeling collaboration networks, which may involve not just two but three or more people, the use of hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for hypergraph mining. The goal of hypergraph mining is to find structural properties recurring in real-world hypergraphs across different domains, which we call patterns. To find patterns, we need tools. We divide hypergraph mining tools into three categories: (1) null models (which help test the significance of observed patterns), (2) structural elements (i.e., substructures in a hypergraph such as open and closed triangles), and (3) structural quantities (i.e., numerical tools for computing hypergraph patterns such as transitivity). There are also hypergraph generators, whose objective is to produce synthetic hypergraphs that are a faithful representation of real-world hypergraphs. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for each and offer in-depth discussions for future research on hypergraph mining.",266
181,Artificial Intelligence,Tina Eliassi-Rad,"December 18th, 2023",Using sequences of life-events to predict human lives,https://doi.org/10.1038/s43588-023-00573-5," Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Hvas Mortensen, Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann. (2024). Using sequences of life-events to predict human lives Nat. Comput. Sci., 4, 43-56. https://doi.org/10.1038/s43588-023-00573-5","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",267
182,Artificial Intelligence,Tina Eliassi-Rad,"November 14th, 2023",Attacking Shortest Paths by Cutting Edges,https://doi.org/10.1145/3622941," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2024). Attacking Shortest Paths by Cutting Edges ACM Trans. Knowl. Discov. Data, 18, 35:1-35:42. https://doi.org/10.1145/3622941","Identifying shortest paths between nodes in a network is a common graph analysis problem that is important for many applications involving routing of resources. An adversary that can manipulate the graph structure could alter traffic patterns to gain some benefit (e.g., make more money by directing traffic to a toll road). This article presents the Force Path Cut problem, in which an adversary removes edges from a graph to make a particular path the shortest between its terminal nodes. We prove that the optimization version of this problem is APX-hard but introduce PATHATTACK , a polynomial-time approximation algorithm that guarantees a solution within a logarithmic factor of the optimal value. In addition, we introduce the Force Edge Cut and Force Node Cut problems, in which the adversary targets a particular edge or node, respectively, rather than an entire path. We derive a nonconvex optimization formulation for these problems and derive a heuristic algorithm that uses PATHATTACK as a subroutine. We demonstrate all of these algorithms on a diverse set of real and synthetic networks, illustrating where the proposed algorithms provide the greatest improvement over baseline methods.",268
183,Artificial Intelligence,Tina Eliassi-Rad,"August 21st, 2023",TenGAN: adversarially generating multiplex tensor graphs,https://doi.org/10.1007/s10618-023-00947-3," William Shiao, Benjamin A. Miller, Kevin Chan , Paul L. Yu, Tina Eliassi-Rad, Evangelos E. Papalexakis. (2024). TenGAN: adversarially generating multiplex tensor graphs Data Min. Knowl. Discov., 38, 1-21. https://doi.org/10.1007/s10618-023-00947-3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",269
184,Artificial Intelligence,Tina Eliassi-Rad,"August 18th, 2023",Modeling self-propagating malware with epidemiological models,https://doi.org/10.1007/s41109-023-00578-z," Alesia Chernikova, Nicol√≤ Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. (2023). Modeling self-propagating malware with epidemiological models Appl. Netw. Sci., 8, 52. https://doi.org/10.1007/s41109-023-00578-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",270
185,Artificial Intelligence,Tina Eliassi-Rad,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",271
186,Artificial Intelligence,Tina Eliassi-Rad,"May 30th, 2023",Defense Against Shortest Path Attacks,https://doi.org/10.48550/arXiv.2305.19083," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2023). Defense Against Shortest Path Attacks CoRR, abs/2305.19083. https://doi.org/10.48550/arXiv.2305.19083","Identifying shortest paths between nodes in a network is an important task in applications involving routing of resources. Recent work has shown that a malicious actor can manipulate a graph to make traffic between two nodes of interest follow their target path. In this paper, we develop a defense against such attacks by modifying the weights of the graph that users observe. The defender must balance inhibiting the attacker against any negative effects of the defense on benign users. Specifically, the defender's goals are: (a) to recommend the shortest paths possible to users, (b) for the lengths of the shortest paths in the published graph to be close to those of the same paths in the true graph, and (c) to minimize the probability of an attack. We formulate the defense as a Stackelberg game in which the defender is the leader and the attacker is the follower. In this context, we also consider a zero-sum version of the game, in which the defender's goal is to minimize cost while achieving the minimum possible attack probability. We show that this problem is NP-hard and propose heuristic solutions based on increasing edge weights along target paths in both the zero-sum and non-zero-sum settings. Relaxing some constraints of the original problem, we formulate a linear program for local optimization around a feasible point. We present defense results with both synthetic and real network datasets and show that these methods often reach the lower bound of the defender's cost.",272
187,Artificial Intelligence,Tina Eliassi-Rad,"April 12th, 2023",STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core,https://doi.org/10.1137/1.9781611977653.ch46," David Liu, Tina Eliassi-Rad. (2023). STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core SDM, 406-414. https://doi.org/10.1137/1.9781611977653.ch46","Are the embeddings of a graph's degenerate core stable? What happens to the embeddings of nodes in the degenerate core as we systematically remove periphery nodes (by repeatedly peeling off Œ∫ -cores)? We discover three patterns w.r.t. instability in degenerate-core embeddings across a variety of popular graph embedding algorithms and datasets. We correlate instability with an increase in edge density, and then theoretically show that in the case of Erd√∂s-R√©nyi graphs embedded with Laplacian Eigenmaps, the best and worst possible embeddings become less distinguishable as density increases. Furthermore, we present the STABLE algorithm, which takes an existing graph embedding algorithm and makes it stable. We show the effectiveness of STABLE in terms of making the degenerate-core embedding stable and still producing state-of-the-art link prediction performance.",273
188,Artificial Intelligence,Tina Eliassi-Rad,"September 10th, 2021",PATHATTACK: Attacking Shortest Paths in Complex Networks,https://doi.org/10.1007/978-3-030-86520-7_33," B.A. Miller, Z. Shafi, W. Ruml, Y. Vorobeychik, T. Eliassi-Rad, S. Alfeld. ""PATHATTACK: Attacking Shortest Paths in Complex Networks"". In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD), September 2021.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",274
189,Artificial Intelligence,Usama Fayyad,"June 30th, 2020",Toward Foundations for Data Science and Analytics: A Knowledge Framework for Professional Standards,https://hdsr.mitpress.mit.edu/pub/6wx0qmkl/release/3?readingCollection=70ac5c46," ‚ÄúToward Foundations for Data Science and Analytics: A Knowledge Framework for Professional Standards‚Äù, U. Fayyad and H. Hamutcu. Harvard Data Science Review, vol. 2, issue 2, June 2020.",Abstract,275
190,Artificial Intelligence,Usama Fayyad,"August 1st, 2002",Evolving Data Into Mining Solutions For Insights,https://cacm.acm.org/magazines/2002/8/6991-evolving-data-into-mining-solutions-for-insights," ‚ÄúEvolving data into mining solutions for insights‚Äù, U.Fayyad and R. Uthurusamy, Communications of the ACM, vol. 45, issue 8, p. 28-31, August 2002.","Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Membership in ACM includes a subscription to Communications of the ACM (CACM), the computing industry's most trusted source for staying connected to the world of advanced computing. The capacity of digital data storage worldwide has doubled every nine months for at least a decade, at twice the rate predicted by Moore‚Äôs Law for the growth of computing power during the same period [ 5 ]. This less familiar but noteworthy phenomenon, which we call Storage Law, is among the reasons for the increasing importance and rapid growth of the field of data mining. The aggressive rate of growth of disk storage and the gap between Moore‚Äôs Law and Storage Law growth trends represents a very interesting pattern in the state of technology evolution. Our ability to capture and store data has far outpaced our ability to process and utilize it. This growing challenge has produced a phenomenon we call the data tombs, or data stores that are effectively write-only; data is deposited to merely rest in peace, since in all likelihood it will never be accessed again.",276
191,Artificial Intelligence,Sina Fazelpour,"October 25th, 2024",Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina,https://doi.org/10.48550/arXiv.2410.19599," Yuan Gao, Dokyun Lee, Gordon Burtch, Sina Fazelpour. (2024). Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina CoRR, abs/2410.19599. https://doi.org/10.48550/arXiv.2410.19599","Recent studies suggest large language models (LLMs) can exhibit human-like reasoning, aligning with human behavior in economic experiments, surveys, and political discourse. This has led many to propose that LLMs can be used as surrogates or simulations for humans in social science research. However, LLMs differ fundamentally from humans, relying on probabilistic patterns, absent the embodied experiences or survival objectives that shape human cognition. We assess the reasoning depth of LLMs using the 11-20 money request game. Nearly all advanced approaches fail to replicate human behavior distributions across many models. Causes of failure are diverse and unpredictable, relating to input language, roles, and safeguarding. These results advise caution when using LLMs to study human behavior or as surrogates or simulations.",277
192,Artificial Intelligence,Sina Fazelpour,"July 11th, 2024",Authenticity and exclusion: social media recommendation algorithms and the dynamics of belonging in professional networks,https://doi.org/10.48550/arXiv.2407.08552," Nil-Jana Akpinar, Sina Fazelpour. (2024). Authenticity and exclusion: social media recommendation algorithms and the dynamics of belonging in professional networks CoRR, abs/2407.08552. https://doi.org/10.48550/arXiv.2407.08552","Recent philosophical work has explored how the social identity of knowers influences how their contributions are received, assessed, and credited. However, a critical gap remains regarding the role of technology in mediating and enabling communication within today's epistemic communities. This paper addresses this gap by examining how social media platforms and their recommendation algorithms shape the professional visibility and opportunities of researchers from minority groups. Using agent-based simulations, we investigate this question with respect to components of a widely used recommendation algorithm, and uncover three key patterns: First, these algorithms disproportionately harm the professional visibility of researchers from minority groups, creating systemic patterns of exclusion. Second, within these minority groups, the algorithms result in greater visibility for users who more closely resemble the majority group, incentivizing assimilation at the cost of professional invisibility. Third, even for topics that strongly align with minority identities, content created by minority researchers is less visible to the majority than similar content produced by majority users. Importantly, these patterns emerge, even though individual engagement with professional content is independent of group identity. These findings have significant implications for philosophical discussions on epistemic injustice and exclusion, and for policy proposals aimed at addressing these harms. More broadly, they call for a closer examination of the pervasive, but often neglected role of AI and data-driven technologies in shaping today's epistemic communities.",278
193,Artificial Intelligence,Sina Fazelpour,"May 19th, 2022",Homophily and Incentive Effects in Use of Algorithms,https://doi.org/10.48550/arXiv.2205.09701," Riccardo Fogliato, Sina Fazelpour, Shantanu Gupta, Zachary C. Lipton, David Danks. (2022). Homophily and Incentive Effects in Use of Algorithms CoRR, abs/2205.09701. https://doi.org/10.48550/arXiv.2205.09701","As algorithmic tools increasingly aid experts in making consequential decisions, the need to understand the precise factors that mediate their influence has grown commensurately. In this paper, we present a crowdsourcing vignette study designed to assess the impacts of two plausible factors on AI-informed decision-making. First, we examine homophily -- do people defer more to models that tend to agree with them? -- by manipulating the agreement during training between participants and the algorithmic tool. Second, we considered incentives -- how do people incorporate a (known) cost structure in the hybrid decision-making setting? -- by varying rewards associated with true positives vs. true negatives. Surprisingly, we found limited influence of either homophily and no evidence of incentive effects, despite participants performing similarly to previous studies. Higher levels of agreement between the participant and the AI tool yielded more confident predictions, but only when outcome feedback was absent. These results highlight the complexity of characterizing human-algorithm interactions, and suggest that findings from social psychology may require re-examination when humans interact with algorithms.",279
194,Artificial Intelligence,Sina Fazelpour,"January 12th, 2022","Diversity, Trust and Conformity: a Simulation Study",https://doi.org/10.1017/psa.2021.25," Fazelpour, S., & Steel, D. (2022). Diversity, Trust and Conformity: A Simulation Study. Philosophy of Science, 1-29. doi:10.1017/psa.2021.25","Previous simulation models have found positive effects of cognitive diversity on group performance, but have not explored effects of diversity in demographics. In this paper, we present an agent-based model that captures two empirically supported hypotheses about how demographic diversity can improve group performance. The results of our simulations suggest that, even when social identities are not associated with distinctive task-related cognitive resources,¬†demographic diversity can benefit collective performance.",280
195,Artificial Intelligence,Sina Fazelpour,"July 30th, 2021",Fair Machine Learning Under Partial Compliance,https://doi.org/10.1145/3461702.3462521," Jessica Dai, Sina Fazelpour, and Zachary Lipton. 2021. Fair Machine Learning Under Partial Compliance. Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for Computing Machinery, New York, NY, USA, 55‚Äì65. doi:10.1145/3461702.3462521","Typically, fair machine learning research focuses on a single decision maker and assumes that the underlying population is stationary. However, many of the critical domains motivating this work are characterized by competitive marketplaces with many decision makers. Realistically, we might expect only a subset of them to adopt any non-compulsory fairness-conscious policy, a situation that political philosophers call partial compliance. This possibility raises important questions: how does partial compliance and the consequent strategic behavior of decision subjects affect the allocation outcomes? If k% of employers were to voluntarily adopt a fairness-promoting intervention, should we expect k% progress (in aggregate) towards the benefits of universal adoption, or will the dynamics of partial compliance wash out the hoped-for benefits? How might adopting a global (versus local) perspective impact the conclusions of an auditor? In this paper, we propose a simple model of an employment market, leveraging simulation as a tool to explore the impact of both interaction effects and incentive effects on outcomes and auditing metrics. Our key findings are that at equilibrium: (1) partial compliance by k% of employers can result in far less than proportional (k%) progress towards the full compliance outcomes; (2) the gap is more severe when fair employers match global (vs local) statistics; (3) choices of local vs global statistics can paint dramatically different pictures of the performance vis-a-vis fairness desiderata of compliant versus non-compliant employers; (4) partial compliance based on local parity measures can induce extreme segregation. Finally, we discuss implications for auditors and insights concerning the design of regulatory frameworks.",281
196,Artificial Intelligence,Sina Fazelpour,"June 8th, 2020",Norms in Counterfactual Selection,https://doi.org/10.1111/phpr.12691,"  Fazelpour, S. Norms in Counterfactual Selection. Philos Phenomenol Res. 2021; 103: 114‚Äì 139. doi:10.1111/phpr.12691","In this paper, I argue for a functional approach to understanding the selectivity of counterfactUAL cognition. I take some steps towards a systematic analysis by providing a qualitative, decision-theoretic account of one important function ofcounterfactual thinking. I make a case for employing this analysis by showing its value for assessing the rationality of imagination-driven counter Factual generation.",282
197,Artificial Intelligence,Sina Fazelpour,"June 3rd, 2020",Affect-biased attention and predictive processing,https://doi.org/10.1016/j.cognition.2020.104370," Ransom, Madeleine, Sina Fazelpour, Jelena Markovic, James Kryklywy, Evan T. Thompson, and Rebecca M. Todd. ""Affect-biased attention and predictive processing."" Cognition 203 (2020): 104370. doi:10.1016/j.cognition.2020.104370","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",283
198,Artificial Intelligence,Sina Fazelpour,"February 7th, 2020",Algorithmic Fairness from a Non-ideal Perspective,https://doi.org/10.1145/3375627.3375828," Sina Fazelpour and Zachary C. Lipton. 2020. Algorithmic Fairness from a Non-ideal Perspective. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES '20). Association for Computing Machinery, New York, NY, USA, 57‚Äì63. doi:10.1145/3375627.3375828","Inspired by recent breakthroughs in predictive modeling, practitioners in both industry and government have turned to machine learning with hopes of operationalizing predictions to drive automated decisions. Unfortunately, many social desiderata concerning consequential decisions, such as justice or fairness, have no natural formulation within a purely predictive framework. In the hopes of mitigating these problems, researchers have proposed a variety of metrics for quantifying deviations from various statistical parities that we might hope to observe in a fair world, offering a variety of algorithms that attempt to satisfy subsets of these parities or to trade off the degree to which they are satisfied against utility. In this paper, we connect this approach to fair machine learning to the literature on ideal and non-ideal methodological approaches in political philosophy. The ideal approach requires positing the principles according to which a just world would operate. In the most straightforward application of ideal theory, one supports a proposed policy by arguing that it closes a discrepancy between the real and ideal worlds. However, by failing to account for the mechanisms by which our non-ideal world arose, the responsibilities of various decision-makers, and the impacts of their actions, naive applications of ideal thinking can lead to misguided policies. In this paper, we demonstrate a connection between the recent literature on fair machine learning and the ideal approach in political philosophy, and show that some recently uncovered shortcomings in proposed algorithms reflect broader troubles faced by the ideal approach. We work this analysis through for different formulations of fairness and conclude with a critical discussion of real-world impacts and directions for new research.",284
199,Artificial Intelligence,Sina Fazelpour,"February 15th, 2019",Information elaboration and epistemic effects of diversity,https://doi.org/10.1007/s11229-019-02108-w," Steel, D., Fazelpour, S., Crewe, B. et al. Information elaboration and epistemic effects of diversity. Synthese 198, 1287‚Äì1307 (2021). doi:10.1007/s11229-019-02108-w","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",285
200,Artificial Intelligence,Sina Fazelpour,"June 15th, 2018",Multiple diversity concepts and their ethical-epistemic implications,https://doi.org/10.1007/s13194-018-0209-5," Steel, D., Fazelpour, S., Gillette, K. et al. Multiple diversity concepts and their ethical-epistemic implications. Euro Jnl Phil Sci 8, 761‚Äì780 (2018). doi:10.1007/s13194-018-0209-5","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",286
201,Artificial Intelligence,Sina Fazelpour,"June 13th, 2016",Attention in the predictive mind,https://doi.org/10.1016/j.concog.2016.06.011," Ransom, Madeleine, Sina Fazelpour, and Christopher Mole. ""Attention in the predictive mind."" Consciousness and cognition 47 (2017): 99-112. doi:10.1016/j.concog.2016.06.011","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",287
202,Artificial Intelligence,Sina Fazelpour,"December 25th, 2014",The Kantian brain: brain dynamics from a neurophenomenological perspective,https://doi.org/10.1016/j.conb.2014.12.006," Fazelpour S, Thompson E. The Kantian brain: brain dynamics from a neurophenomenological perspective. Curr Opin Neurobiol. 2015 Apr;31:223-9. doi: 10.1016/j.conb.2014.12.006","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",288
203,Artificial Intelligence,Yun Raymond Fu,"September 16th, 2024",Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering,https://doi.org/10.1109/CVPR52733.2024.01032," Zaid Khan , Yun Fu . (2024). Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering CVPR, 10854-10863. https://doi.org/10.1109/CVPR52733.2024.01032","The goal of selective prediction is to allow an a model to abstain when it may not be able to deliver a reliable prediction. Existing approaches to selective prediction typically require access to the internals of a model or study only unimodal models. We propose using the principle of neighborhood consistency to identify unreliable responses from a black-box vision-language model in question answering tasks. It is impossible to directly sample neighbors in feature space in a black box setting. Instead, we show that it is possible to use a smaller proxy model to approximately sample from the neighborhood. That is, the consistency of the model's responses over the neighborhood of a visual question will indicate re-liability.",289
204,Artificial Intelligence,Yun Raymond Fu,"September 16th, 2024",Rewrite the Stars,https://doi.org/10.1109/CVPR52733.2024.00544," Xu Ma , Xiyang Dai, Yue Bai, Yizhou Wang , Yun Fu . (2024). Rewrite the Stars CVPR, 5694-5703. https://doi.org/10.1109/CVPR52733.2024.00544","The study was published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. The work encourages further exploration across tasks, with codes available at https://github.com/ma-xu/Rewrite-the-Stars.",290
205,Artificial Intelligence,Yun Raymond Fu,"May 13th, 2024",Aligning Out-of-Distribution Web Images and Caption Semantics via Evidential Learning,https://doi.org/10.1145/3589334.3645653," Guohao Sun, Yue Bai, Xueying Yang, Yi Fang , Yun Fu , Zhiqiang Tao. (2024). Aligning Out-of-Distribution Web Images and Caption Semantics via Evidential Learning WWW, 2271-2281. https://doi.org/10.1145/3589334.3645653","Vision-language models, pre-trained on web-scale datasets, have the potential to greatly enhance the intelligence of web applications (e.g., search engines, chatbots, and art tools). Precisely, these models align disparate domains into a co-embedding space, achieving impressive zero-shot performance on multi-modal tasks (e.g., image-text retrieval, VQA). However, existing methods often rely on well-prepared data that less frequently contain noise and variability encountered in real-world scenarios, leading to severe performance drops in handling out-of-distribution (OOD) samples. This work first comprehensively analyzes the performance drop between in-distribution (ID) and OOD retrieval. Based on empirical observations, we introduce a novel approach, Evidential Language-Image Posterior (ELIP), to achieve robust alignment between web images and semantic knowledge across various OOD cases by leveraging evidential uncertainties. The proposed ELIP can be seamlessly integrated into general image-text contrastive learning frameworks, providing an efficient fine-tuning approach without exacerbating the need for additional data. To validate the effectiveness of ELIP, we systematically design a series of OOD cases (e.g., image distortion, spelling errors, and a combination of both) on two benchmark datasets to mimic noisy data in real-world web applications. Our experimental results demonstrate that ELIP improves the performance and robustness of mainstream pre-trained vision-language models facing OOD samples in image-text retrieval tasks.",291
206,Artificial Intelligence,Yun Raymond Fu,"March 24th, 2024",SkipDiff: Adaptive Skip Diffusion Model for High-Fidelity Perceptual Image Super-resolution,https://doi.org/10.1609/aaai.v38i5.28195," Xiaotong Luo, Yuan Xie , Yanyun Qu, Yun Fu . (2024). SkipDiff: Adaptive Skip Diffusion Model for High-Fidelity Perceptual Image Super-resolution AAAI, 4017-4025. https://doi.org/10.1609/aaai.v38i5.28195","Abstract It is well-known that image quality assessment usually meets with the problem of perception-distortion (p-d) tradeoff. The existing deep image super-resolution (SR) methods either focus on high fidelity with pixel-level objectives or high perception with generative models. The emergence of diffusion model paves a fresh way for image restoration, which has the potential to offer a brand-new solution for p-d trade-off. We experimentally observed that the perceptual quality and distortion change in an opposite direction with the increase of sampling steps. In light of this property, we propose an adaptive skip diffusion model (SkipDiff), which aims to achieve high-fidelity perceptual image SR with fewer sampling steps. Specifically, it decouples the sampling procedure into coarse skip approximation and fine skip refinement stages. A coarse-grained skip diffusion is first performed as a high-fidelity prior to obtaining a latent approximation of the full diffusion. Then, a fine-grained skip diffusion is followed to further refine the latent sample for promoting perception, where the fine time steps are adaptively learned by deep reinforcement learning. Meanwhile, this approach also enables faster sampling of diffusion model through skipping the intermediate denoising process to shorten the effective steps of the computation. Extensive experimental results show that our SkipDiff achieves superior perceptual quality with plausible reconstruction accuracy and a faster sampling speed.",292
207,Artificial Intelligence,Yun Raymond Fu,"March 24th, 2024",AdaFormer: Efficient Transformer with Adaptive Token Sparsification for Image Super-resolution,https://doi.org/10.1609/aaai.v38i5.28194," Xiaotong Luo, Zekun Ai, Qiuyuan Liang, Ding Liu, Yuan Xie , Yanyun Qu, Yun Fu . (2024). AdaFormer: Efficient Transformer with Adaptive Token Sparsification for Image Super-resolution AAAI, 4009-4016. https://doi.org/10.1609/aaai.v38i5.28194","Abstract Efficient transformer-based models have made remarkable progress in image super-resolution (SR). Most of these works mainly design elaborate structures to accelerate the inference of the transformer, where all feature tokens are propagated equally. However, they ignore the underlying characteristic of image content, i.e., various image regions have distinct restoration difficulties, especially for large images (2K-8K), failing to achieve adaptive inference. In this work, we propose an adaptive token sparsification transformer (AdaFormer) to speed up the model inference for image SR. Specifically, a texture-relevant sparse attention block with parallel global and local branches is introduced, aiming to integrate informative tokens from the global view instead of only in fixed local windows. Then, an early-exit strategy is designed to progressively halt tokens according to the token importance. To estimate the plausibility of each token, we adopt a lightweight confidence estimator, which is constrained by an uncertainty-guided loss to obtain a binary halting mask about the tokens. Experiments on large images have illustrated that our proposal reduces nearly 90% latency against SwinIR on Test8K, while maintaining a comparable performance.",293
208,Artificial Intelligence,Yun Raymond Fu,"January 16th, 2024",Don‚Äôt Judge by the Look: Towards Motion Coherent Video Representation,https://openreview.net/forum?id=RIcYTbpO38," Yitian Zhang, Yue Bai, Huan Wang, Yizhou Wang, Yun Fu. (2024). Don't Judge by the Look: Towards Motion Coherent Video Representation ICLR. https://openreview.net/forum?id=RIcYTbpO38","Current training pipelines in object recognition neglect Hue Jittering when doing data augmentation as it not only brings appearance changes that are detrimental to classification, but also the implementation is inefficient in practice. In this study, we investigate the effect of hue variance in the context of video understanding and find this variance to be beneficial since static appearances are less important in videos that contain motion information. Based on this observation, we propose a data augmentation method for video understanding, named Motion Coherent Augmentation (MCA), that introduces appearance variation in videos and implicitly encourages the model to prioritize motion patterns, rather than static appearances. Concretely, we propose an operation SwapMix to efficiently modify the appearance of video samples, and introduce Variation Alignment (VA) to resolve the distribution shift caused by SwapMix, enforcing the model to learn appearance invariant representations. Comprehensive empirical evaluation across various architectures and different datasets solidly validates the effectiveness and generalization ability of MCA, and the application of VA in other augmentation methods. Code is available at https://github.com/BeSpontaneous/MCA-pytorch . The paper investigates the effect of hue variance in video action recognition and finds it effective for learning motion from videos. Subsequently, the paper proposes the Motion Coherent Augmentation (MCA) method based on this observation. After taking into account the reviews, the responses from the authors, and reading the paper myself, AC recommends acceptance with a poster. AC strongly suggests the authors incorporate all the feedback and additional experiments required from the reviewers in the final version. Strengths and weaknesses are summarized below: Strengths:",294
209,Artificial Intelligence,Yun Raymond Fu,"January 16th, 2024",Efficient Modulation for Vision Networks,https://openreview.net/forum?id=ip5LHJs6QX," Xu Ma , Xiyang Dai, Jianwei Yang, Bin Xiao , Yinpeng Chen, Yun Fu , Lu Yuan. (2024). Efficient Modulation for Vision Networks ICLR. https://openreview.net/forum?id=ip5LHJs6QX","With fewer parameters, our EfficientMod-s performs 0.6 top-1 accuracy better than the prior state-of-the-art approach EfficientFormerV2-s2 without any training tricks. The majority of the benchmark is done for classification, but the design also leads to strong performance on segmentation and detection benchmarks.",295
210,Artificial Intelligence,Yun Raymond Fu,"August 22nd, 2023",NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-Shot Real Image Animation,https://doi.org/10.1109/CVPR52729.2023.00825," Yu Yin, Kamran Ghasedi, HsiangTao Wu, Jiaolong Yang, Xin Tong , Yun Fu . (2023). NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-Shot Real Image Animation CVPR, 8539-8548. https://doi.org/10.1109/CVPR52729.2023.00825","Nerf-based Generative models have shown impressive capacity in generating high-quality images with consistent 3D geometry. Despite successful synthesis of fake identity images randomly sampled from latent space, adopting these models for generating face images of real subjects is still a challenging task due to its so-called inversion issue. We propose a universal method to surgically finetune these NeRF-GAN models in order to achieve high-fidelity animation ofreal subjects only by a single image.",296
211,Artificial Intelligence,Yun Raymond Fu,"August 22nd, 2023",Real-Time Neural Light Field on Mobile Devices,https://doi.org/10.1109/CVPR52729.2023.00805," Junli Cao, Huan Wang, Pavlo Chemerys, Vladislav Shakhrai, Ju Hu, Yun Fu , Denys Makoviichuk, Sergey Tulyakov, Jian Ren. (2023). Real-Time Neural Light Field on Mobile Devices CVPR, 8328-8337. https://doi.org/10.1109/CVPR52729.2023.00805","Recent efforts in Neural Rendering Fields (NeRF) have shown impressive results on novel view synthesis by utilizing implicit neural representation to represent 3D scenes. Due to the process of volumetric rendering, the inference speed for NeRF is extremely slow, limiting the application scenarios of utilizing NeRF on resource-constrained hardware, such as mobile devices. In this work, we propose an efficient network that runs in real-time on mobile devices for neural rendering. We achieve similar image quality as NeRF and better quality than MobileNeRF (PSNR 26.15 vs. 25.91 on the real-world forward-facing dataset)",297
212,Artificial Intelligence,Yun Raymond Fu,"June 26th, 2023",Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution,https://ojs.aaai.org/index.php/AAAI/article/view/25333," Bin Sun , Yulun Zhang, Songyao Jiang, Yun Fu . (2023). Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution AAAI, 2375-2383. https://ojs.aaai.org/index.php/AAAI/article/view/25333","Abstract Convolutional neural network (CNN) has achieved great success on image super-resolution (SR). However, most deep CNN-based SR models take massive computations to obtain high performance. Downsampling features for multi-resolution fusion is an efficient and effective way to improve the performance of visual recognition. Still, it is counter-intuitive in the SR task, which needs to project a low-resolution input to high-resolution. In this paper, we propose a novel Hybrid Pixel-Unshuffled Network (HPUN) by introducing an efficient and effective downsampling module into the SR task. The network contains pixel-unshuffled downsampling and Self-Residual Depthwise Separable Convolutions. Specifically, we utilize pixel-unshuffle operation to downsample the input features and use grouped convolution to reduce the channels. Besides, we enhance the depthwise convolution's performance by adding the input feature to its output. The comparison findings demonstrate that, with fewer parameters and computational costs, our HPUN achieves and surpasses the state-of-the-art performance on SISR. All results are provided in the github https://github.com/Sun1992/HPUN.",298
213,Artificial Intelligence,Yun Raymond Fu,"June 26th, 2023",Layout Representation Learning with Spatial and Structural Hierarchies,https://ojs.aaai.org/index.php/AAAI/article/view/25092," Yue Bai, Dipu Manandhar, Zhaowen Wang, John P. Collomosse, Yun Fu . (2023). Layout Representation Learning with Spatial and Structural Hierarchies AAAI, 206-214. https://ojs.aaai.org/index.php/AAAI/article/view/25092","Abstract We present a novel hierarchical modeling method for layout representation learning, the core of design documents (e.g., user interface, poster, template). Existing works on layout representation often ignore element hierarchies, which is an important facet of layouts, and mainly rely on the spatial bounding boxes for feature extraction. This paper proposes a Spatial-Structural Hierarchical Auto-Encoder (SSH-AE) that learns hierarchical representation by treating a hierarchically annotated layout as a tree format. On the one side, we model SSH-AE from both spatial (semantic views) and structural (organization and relationships) perspectives, which are two complementary aspects to represent a layout. On the other side, the semantic/geometric properties are associated at multiple resolutions/granularities, naturally handling complex layouts. Our learned representations are used for effective layout search from both spatial and structural similarity perspectives. We also newly involve the tree-edit distance (TED) as an evaluation metric to construct a comprehensive evaluation protocol for layout similarity assessment, which benefits a systematic and customized layout search. We further present a new dataset of POSTER layouts which we believe will be useful for future layout research. We show that our proposed SSH-AE outperforms the existing methods achieving state-of-the-art performance on two benchmark datasets. Code is available at github.com/yueb17/SSH-AE.",299
214,Artificial Intelligence,Yun Raymond Fu,"September 27th, 2022",Towards Layer-wise Image Vectorization,https://doi.org/10.1109/CVPR52688.2022.01583," Xu Ma, Yuqian Zhou, Xingqian Xu, Bin Sun , Valerii Filev, Nikita Orlov, Yun Fu , Humphrey Shi. (2022). Towards Layer-wise Image Vectorization CVPR, 16293-16302. https://doi.org/10.1109/CVPR52688.2022.01583","LIVE can generate compact SVG forms with layer-wise structures that are semantically consistent with human perspective. With the help of this newly learned topology, LIVE initiates human editable SVGs for both designers and other downstream applications. Codes are made available at https. GitHub.com/Picsart-AI-Research/LIVE-Layerwise-Image- Vectorization. Published in: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",300
215,Artificial Intelligence,Yun Raymond Fu,"September 27th, 2022",Learning to Learn across Diverse Data Biases in Deep Face Recognition,https://doi.org/10.1109/CVPR52688.2022.00404," Chang Liu , Xiang Yu , Yi-Hsuan Tsai, Masoud Faraki, Ramin Moslemi, Manmohan Chandraker, Yun Fu . (2022). Learning to Learn across Diverse Data Biases in Deep Face Recognition CVPR, 4062-4072. https://doi.org/10.1109/CVPR52688.2022.00404","Convolutional Neural Networks have achieved remarkable success in face recognition. However, the data used for training CNNs is often imbalanced. Many bias variations such as ethnicity, head pose, occlusion and blur can jointly affect the accuracy significantly. We propose a sample level weighting approach termed Multi-variation Cosine Margin (MvCoM) which orthogonally enhances the face recognition losses to incorporate the importance of training samples.",301
216,Artificial Intelligence,Yun Raymond Fu,"June 28th, 2022",Adaptive Trajectory Prediction via Transferable GNN,https://doi.org/10.1109/CVPR52688.2022.00641," Yi Xu , Lichen Wang, Yizhou Wang , Yun Fu . (2022). Adaptive Trajectory Prediction via Transferable GNN CVPR, 6510-6521. https://doi.org/10.1109/CVPR52688.2022.00641","Pedestrian trajectory prediction is an essential component in a wide range of AI applications such as autonomous driving and robotics. Existing methods usually assume the training and testing motions follow the same pattern while ignoring the potential distribution differences (e.g., shopping mall and street). This issue results in inevitable performance decrease. We propose a novel Transferable Graph Neural Network (TGNN) frame-work, which jointly conducts trajectory prediction as well as domain alignment in a unified framework. To the best of our knowledge, our work is the pioneer which fills the gap in benchmarks and techniques for practical pedestrian trajectory prediction across different domains.",302
217,Artificial Intelligence,Yun Raymond Fu,"January 1st, 2022",Learning from Weakly-Labeled Web Videos via Exploring Sub-concepts,https://ojs.aaai.org/index.php/AAAI/article/view/20022," Kunpeng Li, Zizhao Zhang, Guanhang Wu, Xuehan Xiong, Chen-Yu Lee, Zhichao Lu, Yun Fu , Tomas Pfister. (2022). Learning from Weakly-Labeled Web Videos via Exploring Sub-concepts AAAI, 1341-1349. https://ojs.aaai.org/index.php/AAAI/article/view/20022","Abstract Learning visual knowledge from massive weakly-labeled web videos has attracted growing research interests thanks to the large corpus of easily accessible video data on the Internet. However, for video action recognition, the action of interest might only exist in arbitrary clips of untrimmed web videos, resulting in high label noises in the temporal space. To address this challenge, we introduce a new method for pre-training video action recognition models using queried web videos. Instead of trying to filter out potential noises, we propose to provide fine-grained supervision signals by defining the concept of Sub-Pseudo Label (SPL). Specifically, SPL spans out a new set of meaningful ""middle ground"" label space constructed by extrapolating the original weak labels during video querying and the prior knowledge distilled from a teacher model. Consequently, SPL provides enriched supervision for video models to learn better representations and improves data utilization efficiency of untrimmed videos. We validate the effectiveness of our method on four video action recognition datasets and a weakly-labeled image dataset. Experiments show that SPL outperforms several existing pre-training strategies and the learned representations lead to competitive results on several benchmarks.",303
218,Artificial Intelligence,Wengong Jin,"December 10th, 2024",Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer,http://papers.nips.cc/paper_files/paper/2024/hash/e6114e62fdb36d6d91ff43334e763a0e-Abstract-Conference.html," Tinglin Huang, Zhenqiao Song, Rex Ying, Wengong Jin. (2024). Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/e6114e62fdb36d6d91ff43334e763a0e-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Tinglin Huang, Zhenqiao Song, Rex Ying, Wengong Jin Nucleic acid-based drugs like aptamers have recently demonstrated great therapeutic potential. However, experimental platforms for aptamer screening are costly, and the scarcity of labeled data presents a challenge for supervised methods to learn protein-aptamer binding. To this end, we develop an unsupervised learning approach based on the predicted pairwise contact map between a protein and a nucleic acid and demonstrate its effectiveness in protein-aptamer binding prediction. Our model is based on FAFormer, a novel equivariant transformer architecture that seamlessly integrates frame averaging (FA) within each transformer block. This integration allows our model to infuse geometric information into node features while preserving the spatial semantics of coordinates, leading to greater expressive power than standard FA models. Our results show that FAFormer outperforms existing equivariant models in contact map prediction across three protein complex datasets, with over 10% relative improvement. Moreover, we curate five real-world protein-aptamer interaction datasets and show that the contact map predicted by FAFormer serves as a strong binding indicator for aptamer screening.",304
219,Artificial Intelligence,Wengong Jin,"May 1st, 2024",Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates,https://openreview.net/forum?id=ATvN9JnqZ8," Zhenqiao Song, Yunlong Zhao , Wenxian Shi, Wengong Jin, Yang Yang , Lei Li . (2024). Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates ICML. https://openreview.net/forum?id=ATvN9JnqZ8","Enzymes are genetically encoded biocatalysts capable of accelerating chemical reactions. How can we automatically design functional enzymes? In this paper, we propose EnzyGen, an approach to learn a unified model to design enzymes across all functional families. Our key idea is to generate an enzyme's amino acid sequence and their three-dimensional (3D) coordinates based on functionally important sites and substrates corresponding to a desired catalytic function. These sites are automatically mined from enzyme databases. EnzyGen consists of a novel interleaving network of attention and neighborhood equivariant layers, which captures both long-range correlation in an entire protein sequence and local influence from nearest amino acids in 3D space. To learn the generative model, we devise a joint training objective, including a sequence generation loss, a position prediction loss and an enzyme-substrate interaction loss. We further construct EnzyBench, a dataset with 3157 enzyme families, covering all available enzymes within the protein data bank (PDB). Experimental results show that our EnzyGen consistently achieves the best performance across all 323 testing families, surpassing the best baseline by 10.79% in terms of substrate binding affinity. These findings demonstrate EnzyGen's superior capability in designing well-folded and effective enzymes binding to specific substrates with high affinities. Our code, model and dataset are provided at https://github.com/LeiLiLab/EnzyGen . OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",305
220,Artificial Intelligence,Wengong Jin,"May 1st, 2024",RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching,https://openreview.net/forum?id=jxvqvZLBuU," Divya Nori, Wengong Jin. (2024). RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching ICML. https://openreview.net/forum?id=jxvqvZLBuU","The growing significance of RNA engineering in diverse biological applications has spurred interest in developing AI methods for structure-based RNA design. While diffusion models have excelled in protein design, adapting them for RNA presents new challenges due to RNA's conformational flexibility and the computational cost of fine-tuning large structure prediction models. To this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA sequence-structure design. Its denoising network integrates an RNA inverse folding model and a pre-trained RosettaFold2NA network for generation of RNA sequences and structures. The integration of inverse folding in the structure denoising process allows us to simplify training by fixing the structure prediction network. We further enhance the inverse folding model by conditioning it on inferred conformational ensembles to model dynamic RNA conformations. Evaluation on protein-conditioned RNA structure and sequence generation tasks demonstrates RNAFlow's advantage over existing RNA design methods. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",306
221,Artificial Intelligence,Wengong Jin,"May 1st, 2024",SurfPro: Functional Protein Design Based on Continuous Surface,https://openreview.net/forum?id=a8QpoEJCRI," Zhenqiao Song, Tinglin Huang, Lei Li , Wengong Jin. (2024). SurfPro: Functional Protein Design Based on Continuous Surface ICML. https://openreview.net/forum?id=a8QpoEJCRI","How can we design proteins with desired functions? We are motivated by a chemical intuition that both geometric structure and biochemical properties are critical to a protein's function. In this paper, we propose SurfPro, a new method to generate functional proteins given a desired surface and its associated biochemical properties. SurfPro comprises a hierarchical encoder that progressively models the geometric shape and biochemical features of a protein surface, and an autoregressive decoder to produce an amino acid sequence. We evaluate SurfPro on a standard inverse folding benchmark CATH 4.2 and two functional protein design tasks: protein binder design and enzyme design. Our SurfPro consistently surpasses previous state-of-the-art inverse folding methods, achieving a recovery rate of 57.78% on CATH 4.2 and higher success rates in terms of protein-protein binding and enzyme-substrate interaction scores OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",307
222,Artificial Intelligence,Bruce Maxwell,"September 16th, 2024",Logarithmic Lenses: Exploring Log RGB Data for Image Classification,https://doi.org/10.1109/CVPR52733.2024.01654," Bruce A. Maxwell, Sumegha Singhania, Avnish Patel, Rahul Kumar, Heather Fryling, Sihan Li, Haonan Sun, Ping He, Zewen Li. (2024). Logarithmic Lenses: Exploring Log RGB Data for Image Classification CVPR, 17470-17479. https://doi.org/10.1109/CVPR52733.2024.01654",The human visual system uses logarithmic sensors; differences and sums correspond to ratios and products. Features in log space will be invariant to intensity changes and robust to color balance changes. Log RGB space also reveals structure that is corrupted by typical pre-processing. We found that networks using log data train best with meta-parameters different than those used for sRGB or linear data. We introduce a new 10-category 10k RAW image data set (RAW10) for image classification and other purposes to enable further the exploration of log RGB as an input format for deep networks in computer vision. Conference on Computer Vision and Pattern Recognition (CVPR) 16-22 June 2024. and other. purposes to enabling further the Exploration of logRGB as a form of data.,308
223,Artificial Intelligence,Bruce Maxwell,"November 20th, 2023",Log RGB Images Provide Invariance to Intensity and Color Balance Variation for Convolutional Networks,http://proceedings.bmvc2023.org/635/," Bruce A. Maxwell, Sumegha Singhania, Heather Fryling, Haonan Sun. (2023). Log RGB Images Provide Invariance to Intensity and Color Balance Variation for Convolutional Networks BMVC, 635-642. http://proceedings.bmvc2023.org/635/",Abstract,309
224,Artificial Intelligence,Bruce Maxwell,"February 21st, 2018",Writing in CS: Why and How?,https://doi.org/10.1145/3159450.3159620," Mia Minnes, Bruce A. Maxwell, Stephanie R. Taylor, Phillip Barry. (2018). Writing in CS: Why and How? SIGCSE, 402-403. https://doi.org/10.1145/3159450.3159620","The importance of written communication and critical thinking in Computer Science is widely acknowledged. It was called out specifically in the curriculum guidelines ACM CS2013 [6] and has been the topic of a number of previous SIGCSE papers, for example [1-4]. Moreover, writing as a pedagogical practice can help make CS more accessible for a broader population. However, special challenges may arise for students who are English-language learners or have writing-specific learning differences.",310
225,Artificial Intelligence,Bruce Maxwell,"February 21st, 2018",Best Practices in Academia to Remedy Gender Bias in Tech,https://doi.org/10.1145/3159450.3159618," Ursula Wolz, Lina Battestilli, Bruce A. Maxwell, Susan H. Rodger, Michelle Trim. (2018). Best Practices in Academia to Remedy Gender Bias in Tech SIGCSE, 672-673. https://doi.org/10.1145/3159450.3159618","The New York Times published an op-ed by Anita Hill [3] suggesting that women in tech consider class action to remedy the gender bias that is increasingly being reported in the mass-media. This panel raises the question ""what are we doing in undergraduate programs to reduce the 'Mad Men', 'Brogrammer' culture she describes that is increasingly being reported in the popular press. Part of our mission as educators is to develop professional behavior so that our students entering the workforce not only understand what it means to act professionally, but understand that it is their responsibility to actively push back on the existing bias within the tech culture. As moderator Ursula Wolz brings a depth of insight from 40 years of industrial and academic experience, including a National Science Foundation project to broaden participation in computing [5]. She does not believe this problem can be solved through quantitative data collection on who does well in computer science, but that SIGCSE needs to begin to collect good stories (ala Sally Fincher [2]) on what constitute best practices to support diversity. The panelists present a range of perspectives that have the potential to establish new cultural norms in the single most influential industry in our economy.",311
226,Artificial Intelligence,Varun Mishra,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",312
227,Artificial Intelligence,Varun Mishra,"September 9th, 2024",Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment,https://doi.org/10.1145/3678584," Ha Le, Rithika Lakshminarayanan, Jixin Li, Varun Mishra , Stephen S. Intille. (2024). Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 111:1-111:35. https://doi.org/10.1145/3678584","ŒºEMA is a data collection method that prompts research participants with quick, answer-at-a-glance, single-multiple-choice self-report behavioral questions, thus enabling high-temporal-density self-report of up to four times per hour when implemented on a smartwatch. However, due to the small watch screen, ŒºEMA is better used to select among 2 to 5 multiple-choice answers versus allowing the collection of open-ended responses. We introduce an alternative and novel form of micro-interaction self-report using speech input - audio-ŒºEMA- where a short beep or vibration cues participants to verbally report their behavioral states, allowing for open-ended, temporally dense self-reports. We conducted a one-hour usability study followed by a within-subject, 6-day to 21-day free-living feasibility study in which participants self-reported their physical activities and postures once every 2 to 5 minutes. We qualitatively explored the usability of the system and identified factors impacting the response rates of this data collection method. Despite being interrupted 12 to 20 times per hour, participants in the free-living study were highly engaged with the system, with an average response rate of 67.7% for audio-ŒºEMA for up to 14 days. We discuss the factors that impacted feasibility; some implementation, methodological, and participant challenges we observed; and important considerations relevant to deploying audio-ŒºEMA in real-time activity recognition systems.",313
228,Artificial Intelligence,Varun Mishra,"August 14th, 2024",Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices,https://doi.org/10.48550/arXiv.2408.07784," Jiachen Li, Justin Steinberg, Elizabeth D. Mynatt, Varun Mishra . (2024). Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices CoRR, abs/2408.07784. https://doi.org/10.48550/arXiv.2408.07784","Mental health has become a growing concern among university students. While medication is a common treatment, understanding how university students manage their medication for mental health symptoms in real-world practice has not been fully explored. In this study, we conducted semi-structured interviews with university students to understand the unique challenges in the mental health medication management process and their coping strategies, particularly examining the role of various technologies in this process. We discovered that due to struggles with self-acceptance and the interdependent relationship between medication, symptoms, schedules, and life changes, the medication management process for students was a highly dynamic journey involving frequent dosage changes. Thus, students adopted flexible strategies of using minimal technology to manage their medication in different situations while maintaining a high degree of autonomy. Based on our findings, we propose design implications for future technologies to seamlessly integrate into their daily lives and assist students in managing their mental health medications.",314
229,Artificial Intelligence,Varun Mishra,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",315
230,Artificial Intelligence,Varun Mishra,"March 25th, 2024",Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic,https://doi.org/10.48550/arXiv.2403.17165," Jessilyn Dunn, Varun Mishra , Md. Mobashir Hasan Shandhi, Hayoung Jeong, Natasha Yamane, Yuna Watanabe, Bill Chen, Matthew S. Goodwin. (2024). Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic CoRR, abs/2403.17165. https://doi.org/10.48550/arXiv.2403.17165","Smartphones and wearable sensors offer an unprecedented ability to collect peripheral psychophysiological signals across diverse timescales, settings, populations, and modalities. However, open-source software development has yet to keep pace with rapid advancements in hardware technology and availability, creating an analytical barrier that limits the scientific usefulness of acquired data. We propose a community-driven, open-source peripheral psychophysiological signal pre-processing and analysis software framework that could advance biobehavioral health by enabling more robust, transparent, and reproducible inferences involving autonomic nervous system data.",316
231,Artificial Intelligence,Varun Mishra,"March 11th, 2024",SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild,https://doi.org/10.1109/JIOT.2024.3375299," Kobiljon Toshnazarov, Uichin Lee, Byung Hyung Kim, Varun Mishra , Lismer Andres Caceres Najarro, Youngtae Noh. (2024). SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild IEEE Internet Things J., 11, 21527-21545. https://doi.org/10.1109/JIOT.2024.3375299","We propose SOSW, a comprehensive methodology for robust sensor data processing by considering both physiological and contextual data. SOSW employs a two-layer machine learning (ML) architecture. The results are comparable to those achieved by the state-of-the-art methods that rely on dedicated wearables. The study was published in IEEE Internet of Things Journal ( Volume: 11 , Issue: 12 , 15 June 2024 ) The results indicate that our methodology can successfully detect stressful events with an F-1 score of up to 0.84 in laboratory conditions.",317
232,Artificial Intelligence,Varun Mishra,"January 16th, 2024",Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping,https://doi.org/10.1109/ACIIW59127.2023.10388164," Ohida Binte Amin, Varun Mishra , Aarti Sathyanarayana. (2023). Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping ACIIW, 1-4. https://doi.org/10.1109/ACIIW59127.2023.10388164","Depression is a prevalent mental health concern among students. Students with high neuroticism and increased depression exhibit greater variability in the number of social contacts. This may be because these students possess more emotional instability, self-esteem, and negative self-perception. Understanding the dynamic interplay between personality traits, social interactions, and depression can aid in developing targeted interventions to promote mental well-being for students.",318
233,Artificial Intelligence,Varun Mishra,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",319
234,Artificial Intelligence,Varun Mishra,"August 5th, 2023",Detecting Receptivity for mHealth Interventions,https://doi.org/10.1145/3614214.3614221," Varun Mishra , Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, David Kotz. (2023). Detecting Receptivity for mHealth Interventions GetMobile Mob. Comput. Commun., 27, 23-28. https://doi.org/10.1145/3614214.3614221","Just-In-Time Adaptive Interventions (JITAI) have the potential to provide effective support for health behavior by delivering the right type and amount of intervention at the right time. The timing of interventions is crucial to ensure that users are receptive and able to use the support provided. Previous research has explored the association of context and user-specific traits on receptivity and built machine-learning models to detect receptivity after the study was completed. However, for effective intervention delivery, JITAI systems need to make in-the-moment decisions about a user's receptivity. In this study, we deployed machinelearning models in a chatbot-based digital coach to predict receptivity for physical-activity interventions. We included a static model that was built before the study and an adaptive model that continuously updated itself during the study. Compared to a control model that sent intervention messages randomly, the machine-learning models improved receptivity by up to 36%. Receptivity to messages from the adaptive model increased over time.",320
235,Artificial Intelligence,Varun Mishra,"November 1st, 2021",FLIRT: A Feature Generation Toolkit for Wearable Data,https://www.sciencedirect.com/science/article/pii/S0169260721005356," F√∂ll, Simon, Martin Maritsch, Federica Spinola, Varun Mishra, Filipe Barata, Tobias Kowatsch, Elgar Fleisch, and Felix Wortmann. ""FLIRT: A Feature Generation Toolkit for Wearable Data."" Computer Methods and Programs in Biomedicine (2021): 106461.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",321
236,Artificial Intelligence,Varun Mishra,"September 24th, 2021",6th International Workshop on Mental Health and Well-being: Sensing and Intervention,https://doi.org/10.1145/3460418.3479264," Varun Mishra , Akane Sano, Sahiti Kunchay, Saeed Abdullah, Jakob E. Bardram, Elizabeth L. Murnane, Tanzeem Choudhury, Mirco Musolesi, Giovanna Nunes Vilaza, Rajalakshmi Nandakumar, Tauhidur Rahman. (2021). 6th International Workshop on Mental Health and Well-being: Sensing and Intervention UbiComp/ISWC Adjunct, 185-187. https://doi.org/10.1145/3460418.3479264","Mental health issues affect a significant portion of the world‚Äôs population and can result in debilitating and life-threatening outcomes. To address this increasingly pressing healthcare challenge, there is a need to research novel approaches for early detection and prevention. Toward this, ubiquitous systems can play a central role in revealing and tracking clinically relevant behaviors, contexts, and symptoms. Further, such systems can passively detect relapse onset and enable the opportune delivery of effective intervention strategies. However, despite their clear potential, the uptake of ubiquitous technologies into clinical mental healthcare is slow, and a number of challenges still face the overall efficacy of such technology-based solutions. The goal of this workshop is to bring together researchers interested in identifying, articulating, and addressing such issues and opportunities. Following the success of this workshop for the last five years, we aim to continue facilitating the UbiComp community in developing a holistic approach for sensing and intervention in the context of mental health.",322
237,Artificial Intelligence,Varun Mishra,"June 24th, 2021",Detecting Receptivity for mHealth Interventions in the Natural Environment,https://dl.acm.org/doi/10.1145/3463492," Varun Mishra, Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, and David Kotz. 2021. Detecting Receptivity for mHealth Interventions in the Natural Environment. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2, Article 74 (June 2021), 24 pages. DOI: https://doi.org/10.1145/3463492","Just-In-Time Adaptive Intervention (JITAI) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. A crucial aspect of JITAIs is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. Some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. For effective intervention delivery, however, a JITAI system needs to make in-the-moment decisions about a user's receptivity. To this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions. We leveraged prior work regarding receptivity to JITAIs and deployed a chatbot-based digital coach - Ally - that provided physical-activity interventions and motivated participants to achieve their step goals. We extended the original Ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. For comparison, we included a control model that sent intervention messages at random times. The app randomly selected a delivery model for each intervention message. We observed that the machine-learning models led up to a 40% improvement in receptivity as compared to the control model. Further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study.",323
238,Artificial Intelligence,Varun Mishra,"March 29th, 2021",When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads,https://dl.acm.org/doi/abs/10.1145/3448116," Kevin Koch, Varun Mishra, Shu Liu, Thomas Berger, Elgar Fleisch, David Kotz, and Felix Wortmann. 2021. When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 1, Article 19 (March 2021), 30 pages. DOI:https://doi.org/10.1145/3448116","Recent developments of novel in-vehicle interventions show the potential to transform the otherwise routine and mundane task of commuting into opportunities to improve the drivers' health and well-being. Prior research has explored the effectiveness of various in-vehicle interventions and has identified moments in which drivers could be interruptible to interventions. All the previous studies, however, were conducted in either simulated or constrained real-world driving scenarios on a pre-determined route. In this paper, we take a step forward and evaluate when drivers interact with in-vehicle interventions in unconstrained free-living conditions. To this end, we conducted a two-month longitudinal study with 10 participants, in which each participant was provided with a study car for their daily driving needs. We delivered two in-vehicle interventions - each aimed at improving affective well-being - and simultaneously recorded the participants' driving behavior. In our analysis, we found that several pre-trip characteristics (like trip length, traffic flow, and vehicle occupancy) and the pre-trip affective state of the participants had significant associations with whether the participants started an intervention or canceled a started intervention. Next, we found that several in-the-moment driving characteristics (like current road type, past average speed, and future brake behavior) showed significant associations with drivers' responsiveness to the intervention. Further, we identified several driving behaviors that ""negated"" the effectiveness of interventions and highlight the potential of using such ""negative"" driving characteristics to better inform intervention delivery. Finally, we compared trips with and without intervention and found that both interventions employed in our study did not have a negative effect on driving behavior. Based on our analyses, we provide solid recommendations on how to deliver interventions to maximize responsiveness and effectiveness and minimize the burden on the drivers.",324
239,Artificial Intelligence,Varun Mishra,"December 17th, 2020",Evaluating the Reproducibility of Physiological Stress Detection Models,https://dl.acm.org/doi/abs/10.1145/3432220," Varun Mishra, Sougata Sen, Grace Chen, Tian Hao, Jeffrey Rogers, Ching-Hua Chen, and David Kotz. 2020. Evaluating the Reproducibility of Physiological Stress Detection Models. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 4, Article 147 (December 2020), 29 pages. DOI:https://doi.org/10.1145/3432220","Recent advances in wearable sensor technologies have led to a variety of approaches for detecting physiological stress. Even with over a decade of research in the domain, there still exist many significant challenges, including a near-total lack of reproducibility across studies. Researchers often use some physiological sensors (custom-made or off-the-shelf), conduct a study to collect data, and build machine-learning models to detect stress. There is little effort to test the applicability of the model with similar physiological data collected from different devices, or the efficacy of the model on data collected from different studies, populations, or demographics. This paper takes the first step towards testing reproducibility and validity of methods and machine-learning models for stress detection. To this end, we analyzed data from 90 participants, from four independent controlled studies, using two different types of sensors, with different study protocols and research goals. We started by evaluating the performance of models built using data from one study and tested on data from other studies. Next, we evaluated new methods to improve the performance of stress-detection models and found that our methods led to a consistent increase in performance across all studies, irrespective of the device type, sensor type, or the type of stressor. Finally, we developed and evaluated a clustering approach to determine the stressed/not-stressed classification when applying models on data from different studies, and found that our approach performed better than selecting a threshold based on training data. This paper's thorough exploration of reproducibility in a controlled environment provides a critical foundation for deeper study of such methods, and is a prerequisite for tackling reproducibility in free-living conditions.",325
240,Artificial Intelligence,Mahsan Nourani,"December 8th, 2023",Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models,https://doi.org/10.1145/3626961," Chiradeep Roy, Mahsan Nourani, Shivvrat Arya, Mahesh Shanbhag, Tahrima Rahman, Eric D. Ragan, Nicholas Ruozzi, Vibhav Gogate. (2023). Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models ACM Trans. Interact. Intell. Syst., 13, 29:1-29:32. https://doi.org/10.1145/3626961","We consider the following video activity recognition (VAR) task: given a video, infer the set of activities being performed in the video and assign each frame to an activity. Although VAR can be solved accurately using existing deep learning techniques, deep networks are neither interpretable nor explainable and as a result their use is problematic in high stakes decision-making applications (in healthcare, experimental Biology, aviation, law, etc.). In such applications, failure may lead to disastrous consequences and therefore it is necessary that the user is able to either understand the inner workings of the model or probe it to understand its reasoning patterns for a given decision. We address these limitations of deep networks by proposing a new approach that feeds the output of a deep model into a tractable, interpretable probabilistic model called a dynamic conditional cutset network that is defined over the explanatory and output variables and then performing joint inference over the combined model. The two key benefits of using cutset networks are: (a) they explicitly model the relationship between the output and explanatory variables and as a result, the combined model is likely to be more accurate than the vanilla deep model and (b) they can answer reasoning queries in polynomial time and as a result, they can derive meaningful explanations by efficiently answering explanation queries. We demonstrate the efficacy of our approach on two datasets, Textually Annotated Cooking Scenes (TACoS), and wet lab, using conventional evaluation measures such as the Jaccard Index and Hamming Loss, as well as a human-subjects study.",326
241,Artificial Intelligence,Mahsan Nourani,"March 17th, 2023",An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality,https://doi.org/10.1109/TVCG.2023.3258693," Brett Benda, Shyam Prathish Sargunam, Mahsan Nourani, Eric D. Ragan. (2024). An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality IEEE Trans. Vis. Comput. Graph., 30, 4257-4270. https://doi.org/10.1109/TVCG.2023.3258693","Head tracking is commonly used in VR applications to allow users to naturally view 3D content using physical head movement. Controller and joystick controls are convenient for practical settings where full 360-degree physical rotation is not possible, such as when the user is sitting at a desk. Previous research has demonstrated that virtual or joystick-controlled view rotation to have drawbacks of sickness and disorientation compared to physical turning. Our findings indicate a preference by users towards directly-manipulated joystick-based rotations compared to user-initiated resetting and minimal effects of technique on spatial awareness.",327
242,Artificial Intelligence,Mahsan Nourani,"December 12th, 2022",On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications,https://doi.org/10.1145/3531066," Mahsan Nourani, Chiradeep Roy, Jeremy E. Block, Donald R. Honeycutt, Tahrima Rahman, Eric D. Ragan, Vibhav Gogate. (2022). On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications ACM Trans. Interact. Intell. Syst., 12, 28:1-28:29. https://doi.org/10.1145/3531066","While EXplainable Artificial Intelligence (XAI) approaches aim to improve human-AI collaborative decision-making by improving model transparency and mental model formations, experiential factors associated with human users can cause challenges in ways system designers do not anticipate. In this article, we first showcase a user study on how anchoring bias can potentially affect mental model formations when users initially interact with an intelligent system and the role of explanations in addressing this bias. Using a video activity recognition tool in cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. However, those who encountered weaknesses earlier made significantly fewer errors, since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Motivated by these findings and similar existing work, we formalize and present a conceptual model of user‚Äôs past experiences that examine the relations between user‚Äôs backgrounds, experiences, and human factors in XAI systems based on usage time. Our work presents strong findings and implications, aiming to raise the awareness of AI designers toward biases associated with user impressions and backgrounds.",328
243,Artificial Intelligence,Mahsan Nourani,"August 24th, 2022",DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification,https://doi.org/10.1109/MCG.2022.3201465," Mahsan Nourani, Chiradeep Roy, Donald R. Honeycutt, Eric D. Ragan, Vibhav Gogate. (2022). DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification IEEE Computer Graphics and Applications, 42, 37-46. https://doi.org/10.1109/MCG.2022.3201465"," Debugging some models, such as temporal multilabel classification (TMLC), can be especially more challenging due to the complexity of the analysis. We propose DETOXER, an interactive visual debugging system to support finding different error types and scopes through providing multiscope explanations.",329
244,Artificial Intelligence,Alina Oprea,"December 10th, 2024",SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html," Ethan Rathbun, Christopher Amato, Alina Oprea. (2024). SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Ethan Rathbun, Christopher Amato, Alina Oprea Reinforcement learning (RL) is an actively growing field that is seeing increased usage in real-world, safety-critical applications -- making it paramount to ensure the robustness of RL algorithms against adversarial attacks. In this work we explore a particularly stealthy form of training-time attacks against RL -- backdoor poisoning. Here the adversary intercepts the training of an RL agent with the goal of reliably inducing a particular action when the agent observes a pre-determined trigger at inference time. We uncover theoretical limitations of prior work by proving their inability to generalize across domains and MDPs. Motivated by this, we formulate a novel poisoning attack framework which interlinks the adversary's objectives with those of finding an optimal policy -- guaranteeing attack success in the limit. Using insights from our theoretical analysis we develop ""SleeperNets"" as a universal backdoor attack which exploits a newly proposed threat model and leverages dynamic reward poisoning techniques. We evaluate our attack in 6 environments spanning multiple domains and demonstrate significant improvements in attack success over existing methods, while preserving benign episodic return.",330
245,Artificial Intelligence,Alina Oprea,"November 1st, 2024",User Inference Attacks on Large Language Models,https://aclanthology.org/2024.emnlp-main.1014," Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu . (2024). User Inference Attacks on Large Language Models EMNLP, 18238-18265. https://aclanthology.org/2024.emnlp-main.1014","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text written by humans makes up the vast majority of the data used to pre-train and fine-tune large language models (LLMs). Many sources of this data‚Äîlike code, forum posts, personal websites, and books‚Äîare easily attributed to one or a few ‚Äúusers‚Äù. In this paper, we ask if it is possible to infer if any of a _user‚Äôs_ data was used to train an LLM. Not only would this constitute a breach of privacy, but it would also enable users to detect when their data was used for training. We develop the first effective attacks for _user inference_‚Äîat times, with near-perfect success‚Äîagainst LLMs. Our attacks are easy to employ, requiring only black-box access to an LLM and a few samples from the user, which _need not be the ones that were trained on_. We find, both theoretically and empirically, that certain properties make users more susceptible to user inference: being an outlier, having highly correlated examples, and contributing a larger fraction of data. Based on these findings, we identify several methods for mitigating user inference including training with example-level differential privacy, removing within-user duplicate examples, and reducing a user‚Äôs contribution to the training data. Though these provide partial mitigation, our work highlights the need to develop methods to fully protect LLMs from user inference.",331
246,Artificial Intelligence,Alina Oprea,"January 16th, 2024",Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning,https://openreview.net/forum?id=4DoSULcfG6," Harsh Chaudhari, Giorgio Severi, Alina Oprea, Jonathan R. Ullman. (2024). Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning ICLR. https://openreview.net/forum?id=4DoSULcfG6","The integration of Machine Learning in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for ML training purposes. One such privacy risk is Membership Inference (MI), in which an adversary seeks to determine whether a particular data point was included in the training dataset of a model. Current state-of-the-art MI approaches capitalize on access to the model‚Äôs predicted confidence scores to successfully perform membership inference.",332
247,Artificial Intelligence,Alina Oprea,"August 18th, 2023",Modeling self-propagating malware with epidemiological models,https://doi.org/10.1007/s41109-023-00578-z," Alesia Chernikova, Nicol√≤ Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. (2023). Modeling self-propagating malware with epidemiological models Appl. Netw. Sci., 8, 52. https://doi.org/10.1007/s41109-023-00578-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",333
248,Artificial Intelligence,Alina Oprea,"July 21st, 2023",SNAP: Efficient Extraction of Private Properties with Poisoning,https://doi.org/10.1109/SP46215.2023.10179334," Harsh Chaudhari, John Abascal, Alina Oprea, Matthew Jagielski, Florian Tram√®r, Jonathan R. Ullman. (2023). SNAP: Efficient Extraction of Private Properties with Poisoning SP, 400-417. https://doi.org/10.1109/SP46215.2023.10179334","Property inference attacks allow an adversary to extract global properties of the training dataset from a machine learning model. Such attacks have privacy implications for data owners sharing their datasets to train machine learning models. We design an efficient property inference attack, SNAP, which obtains higher attack success and requires lower amounts of poisoning than the state-of-the-art poisoning-based property inference attacked by Mahloujifar et al. [3]. For example, on the Census dataset, SNAP achieves 34% higher success rate than [3] while being 56.5√ó faster. We also extend our attack to infer whether a certain property was present at all during training and estimate the exact proportion of a property of interest efficiently.",334
249,Artificial Intelligence,Alina Oprea,"February 6th, 2023",One-shot Empirical Privacy Estimation for Federated Learning,https://doi.org/10.48550/arXiv.2302.03098," Galen Andrew, Peter Kairouz, Sewoong Oh, Alina Oprea, H. Brendan McMahan, Vinith Suriyakumar. (2023). One-shot Empirical Privacy Estimation for Federated Learning CoRR, abs/2302.03098. https://doi.org/10.48550/arXiv.2302.03098","Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel ""one-shot"" approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP training algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on well-established FL benchmark datasets under several adversarial threat models.",335
250,Artificial Intelligence,Alina Oprea,"January 23rd, 2023",Backdoor Attacks in Peer-to-Peer Federated Learning,https://doi.org/10.48550/arXiv.2301.09732," G√∂kberk Yar, Cristina Nita-Rotaru, Alina Oprea. (2023). Backdoor Attacks in Peer-to-Peer Federated Learning CoRR, abs/2301.09732. https://doi.org/10.48550/arXiv.2301.09732","Most machine learning applications rely on centralized learning processes, opening up the risk of exposure of their training datasets. While federated learning (FL) mitigates to some extent these privacy risks, it relies on a trusted aggregation server for training a shared global model. Recently, new distributed learning architectures based on Peer-to-Peer Federated Learning (P2PFL) offer advantages in terms of both privacy and reliability. Still, their resilience to poisoning attacks during training has not been investigated. In this paper, we propose new backdoor attacks for P2PFL that leverage structural graph properties to select the malicious nodes, and achieve high attack success, while remaining stealthy. We evaluate our attacks under various realistic conditions, including multiple graph topologies, limited adversarial visibility of the network, and clients with non-IID data. Finally, we show the limitations of existing defenses adapted from FL and design a new defense that successfully mitigates the backdoor attacks, without an impact on model accuracy.",336
251,Artificial Intelligence,Alina Oprea,"October 25th, 2022",Poisoning Attacks Against Machine Learning: Can Machine Learning Be Trustworthy?,https://doi.org/10.1109/MC.2022.3190787," Alina Oprea, Anoop Singhal, Apostol Vassilev . (2022). Poisoning Attacks Against Machine Learning: Can Machine Learning Be Trustworthy? Computer, 55, 94-99. https://doi.org/10.1109/MC.2022.3190787","Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the r... Show More Metadata Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Page(s): 94 - 99 Date of Publication: 25 October 2022 ISSN Information: DOI: 10.1109/MC.2022.3190787 Publisher: IEEE Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the r... Show More Metadata Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Page(s): 94 - 99 Date of Publication: 25 October 2022 ISSN Information: DOI: 10.1109/MC.2022.3190787 Publisher: IEEE Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Date of Publication: 25 October 2022 DOI: 10.1109/MC.2022.3190787 Publisher: IEEE",337
252,Artificial Intelligence,Alina Oprea,"September 13th, 2022",Machine Learning Security and Privacy,https://doi.org/10.1109/MSEC.2022.3188190," Nathalie Baracaldo, Alina Oprea. (2022). Machine Learning Security and Privacy IEEE Secur. Priv., 20, 11-13. https://doi.org/10.1109/MSEC.2022.3188190","This special issue explores emerging security and privacy aspects related to machine learning and artificial intelligence techniques. Machine learning and deep learning are increasingly deployed for automated decisions in many critical applications today. An area of research called adversarial machine learning has been developed to understand the security of machine learning in various settings. Other threats against machine learning include poisoning attacks, where an adversary controls a subset of data at training time, and privacy attacks in which an adversary is interested in learning sensitive information about the training data and model parameters.",338
253,Artificial Intelligence,Alina Oprea,"May 12th, 2022",How to Combine Membership-Inference Attacks on Multiple Updated Machine Learning Models,https://doi.org/10.56553/popets-2023-0078," Matthew Jagielski, Stanley Wu, Alina Oprea, Jonathan R. Ullman, Roxana Geambasu. (2023). How to Combine Membership-Inference Attacks on Multiple Updated Machine Learning Models Proc. Priv. Enhancing Technol., 2023, 211-232. https://doi.org/10.56553/popets-2023-0078","Authors: Matthew Jagielski (Google Research), Stanley Wu (Northeastern University), Alina Oprea (Northeastern University), Jonathan Ullman (Northeastern University), Roxana Geambasu (Columbia University) Volume: 2023 Issue: 3 Pages: 211‚Äì232 DOI: https://doi.org/10.56553/popets-2023-0078 Download PDF Abstract: A large body of research has shown that machine learning models are vulnerable to membership inference (MI) attacks that violate the privacy of the participants in the training data. Most MI research focuses on the case of a single standalone model, while production machine-learning platforms often update models over time, on data that often shifts in distribution, giving the attacker more information. This paper proposes new attacks that take advantage of one or more model updates to improve MI. A key part of our approach is to leverage rich information from standalone MI attacks mounted separately against the original and updated models, and to combine this information in specific ways to improve attack effectiveness. We propose a set of combination functions and tuning methods for each, and present both analytical and quantitative justification for various options. Our results on four public datasets show that our attacks are effective at using update information to give the adversary a significant advantage over attacks on standalone models, but also compared to a prior MI attack that takes advantage of model updates in a related machine-unlearning setting. We perform the first measurements of the impact of distribution shift on MI attacks with model updates, and show that a more drastic distribution shift results in significantly higher MI risk than a gradual shift. We also show that our attacks are effective at auditing differentially private fine tuning. We make our code public on Github: https://github.com/stanleykywu/model-updates. Keywords: membership inference, machine learning, update, entry inference, distribution shift",339
254,Artificial Intelligence,Alina Oprea,"January 1st, 2021",Subpopulation Data Poisoning Attacks,https://doi.org/10.1145/3460120.3485368," Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea. (2021). Subpopulation Data Poisoning Attacks CCS, 3104-3122. https://doi.org/10.1145/3460120.3485368","Machine learning systems are deployed in critical settings, but they might fail in unexpected ways, impacting the accuracy of their predictions. Poisoning attacks against machine learning induce adversarial modification of data used by a machine learning algorithm to selectively change its output when it is deployed. In this work, we introduce a novel data poisoning attack called a subpopulation attack, which is particularly relevant when datasets are large and diverse. We design a modular framework for subpopulation attacks, instantiate it with different building blocks, and show that the attacks are effective for a variety of datasets and machine learning models. We further optimize the attacks in continuous domains using influence functions and gradient optimization methods. Compared to existing backdoor poisoning attacks, subpopulation attacks have the advantage of inducing misclassification in naturally distributed data points at inference time, making the attacks extremely stealthy. We also show that our attack strategy can be used to improve upon existing targeted attacks. We prove that, under some assumptions, subpopulation attacks are impossible to defend against, and empirically demonstrate the limitations of existing defenses against our attacks, highlighting the difficulty of protecting machine learning against this threat.",340
255,Artificial Intelligence,Alina Oprea,"December 6th, 2018",Differentially Private Fair Learning,https://arxiv.org/abs/1812.02696," Jagielski, Matthew, Kearns, Michael, Mao, Jieming, Oprea, Alina, Roth, Aaron, Sharifi, Saeed, & Ullman, Jonathan. (2019). Differentially Private Fair Learning. Proceedings of the 36 Th International Conference on Machine Learning.","Motivated by settings in which predictive models may be required to be non-discriminatory with respect to certain attributes (such as race), but even collecting the sensitive attribute may be forbidden or restricted, we initiate the study of fair learning under the constraint of differential privacy. We design two learning algorithms that simultaneously promise differential privacy and equalized odds, a 'fairness' condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a private implementation of the equalized odds post-processing approach of [Hardt et al., 2016]. This algorithm is appealingly simple, but must be able to use protected group membership explicitly at test time, which can be viewed as a form of 'disparate treatment'. Our second algorithm is a differentially private version of the oracle-efficient in-processing approach of [Agarwal et al., 2018] that can be used to find the optimal fair classifier, given access to a subroutine that can solve the original (not necessarily fair) learning problem. This algorithm is more complex but need not have access to protected group membership at test time. We identify new tradeoffs between fairness, accuracy, and privacy that emerge only when requiring all three properties, and show that these tradeoffs can be milder if group membership may be used at test time. We conclude with a brief experimental evaluation.",341
256,Artificial Intelligence,Alina Oprea,"May 27th, 2018",Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,https://arxiv.org/abs/1804.00308," Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning  Matthew Jagielski, Alina Oprea, Chang Liu, Cristina Nita-Rotaru, and Bo Li  IEEE S&P (Oakland) 2018","As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",342
257,Artificial Intelligence,Lace Padilla,"September 10th, 2024",Impact of Vertical Scaling on Normal Probability Density Function Plots,https://doi.org/10.1109/TVCG.2024.3456396," Racquel Fygenson, Lace M. K. Padilla. (2025). Impact of Vertical Scaling on Normal Probability Density Function Plots IEEE Trans. Vis. Comput. Graph., 31, 984-994. https://doi.org/10.1109/TVCG.2024.3456396","Keeping vertical scaling consistent, and therefore maintaining equal pixel areas under PDF curves, results in the highest likelihood of accurate comparisons. Findings provide insights into the impact of vertical scaled on PDFs, and reveal the complicated nature of proportional area comparisons. In some contexts, we find including a y-axis can help reduce this effect. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the paper, you can download your copy of the IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 1 , January 2025 ) for free. The paper is available to download now for free by clicking here.",343
258,Artificial Intelligence,Lace Padilla,"September 9th, 2024","Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations",https://doi.org/10.1109/TVCG.2024.3456344," Anjana Arunkumar, Lace M. K. Padilla, Chris Bryan. (2025). Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations IEEE Trans. Vis. Comput. Graph., 31, 1169-1179. https://doi.org/10.1109/TVCG.2024.3456344","Mind wandering is a phenomenon where attention spontaneously shifts from a primary task to internal, task-related thoughts or unrelated distractions. Results show that mind wandering negatively affects short-term visualization recall, particularly for visualizations with little text annotation. Mind wandering also functions as an intermediate process linking visualization design elements to post-viewing measures, influencing how viewers engage with and interpret visual information over time. Overall, this research underscores the importance of incorporating mind wandering as aynamic measure in visualization design and evaluation, offering novel avenues for enhancing user engagement and comprehension.",344
259,Artificial Intelligence,Lace Padilla,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",345
260,Artificial Intelligence,Lace Padilla,"March 4th, 2024",Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs,https://doi.org/10.1109/TVCG.2024.3372620," Helia Hosseinpour, Laura E. Matzen, Kristin M. Divis, Spencer C. Castro, Lace M. K. Padilla. (2025). Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs IEEE Trans. Vis. Comput. Graph., 31, 1875-1887. https://doi.org/10.1109/TVCG.2024.3372620","Small multiples are a popular visualization method, displaying different views of a dataset using multiple frames, often with the same scale and axes. We found a linear decline in accuracy with increasing frames across seven tasks, which was not fully explained by differences in frame size. highlighting specific frames can mitigate some visual search difficulties but, surprisingly, not eliminate them. This research offers insights into optimizing the utility of small multiples by aligning them with human limitations. It was published in: IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 3 , March 2025 ) and will be published in the next issue of the journal.",346
261,Artificial Intelligence,Lace Padilla,"October 23rd, 2023",Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,https://doi.org/10.1109/TVCG.2023.3326589," Dominik Moritz, Lace M. K. Padilla, Francis Nguyen, Steven L. Franconeri. (2024). Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability IEEE Trans. Vis. Comput. Graph., 30, 306-315. https://doi.org/10.1109/TVCG.2023.3326589","Bias might arise because higher variability leads to stronger weighting in the average calculation. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders. The study was published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 30, Issue: 1, January 2024) We found this effect across two preregistered experiments with 140 and 420 participants. We can model the bias with the average of the data series and theAverage of the points drawn along the line.",347
262,Artificial Intelligence,Lace Padilla,"January 1st, 2023",Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations,https://doi.org/10.1109/TVCG.2022.3209457," Lace M. K. Padilla, Racquel Fygenson, Spencer C. Castro, Enrico Bertini. (2023). Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations IEEE Trans. Vis. Comput. Graph., 29, 12-22. https://doi.org/10.1109/TVCG.2022.3209457","The prevalence of inadequate SARS-COV-2 (COVID-19) responses may indicate a lack of trust in forecasts and risk communication. No work has empirically tested how multiple forecast visualization choices impact trust and task-based performance. The studies reveal that trust in. CO VID-19 forecast visualizations initially increases with the number of forecasts and then plateaus after. 6‚Äì9 forecasts. Participants were most trusting of visualizations that showed less visual information, including a 95% confidence. interval, single forecast, and grayscale encoded forecasts. was the most likely to evoke predictions that did not correspond with the actual CO VID -19 trend.",348
263,Artificial Intelligence,Jose Perea,"January 20th, 2024",Move schedules: fast persistence computations in coarse dynamic settings,https://doi.org/10.1007/s41468-023-00156-3," Matthew Piekenbrock, Jose A. Perea. (2024). Move schedules: fast persistence computations in coarse dynamic settings J. Appl. Comput. Topol., 8, 301-345. https://doi.org/10.1007/s41468-023-00156-3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",349
264,Artificial Intelligence,Jose Perea,"November 17th, 2023",DREiMac: Dimensionality Reduction with Eilenberg-MacLane Coordinates,https://doi.org/10.21105/joss.05791," Jose A. Perea, Luis Scoccola, Christopher J. Tralie. (2023). DREiMac: Dimensionality Reduction with Eilenberg-MacLane Coordinates J. Open Source Softw., 8, 5791. https://doi.org/10.21105/joss.05791","Editor: @fabian-s ( all papers ) Reviewers: @mtsch ( all reviews ), @raphaelreinauer ( all reviews ) Jose A. Perea ( 0000-0002-6440-5096 ), Luis Scoccola ( 0000-0002-4862-722X ), Christopher J. Tralie ( 0000-0003-4206-1963 ) Perea et al., (2023). DREiMac: Dimensionality Reduction with Eilenberg-MacLane Coordinates. Journal of Open Source Software, 8(91), 5791, https://doi.org/10.21105/joss.05791 topological data analysis unsupervised learning dimensionality reduction",350
265,Artificial Intelligence,Jose Perea,"September 5th, 2023",Sliding window persistence of quasiperiodic functions,https://doi.org/10.1007/s41468-023-00136-7," Hitesh Gakhar, Jose A. Perea. (2024). Sliding window persistence of quasiperiodic functions J. Appl. Comput. Topol., 8, 55-92. https://doi.org/10.1007/s41468-023-00136-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 228 Accesses",351
266,Artificial Intelligence,Jose Perea,"April 28th, 2023",Topological Data Analysis of Electroencephalogram Signals for Pediatric Obstructive Sleep Apnea,https://doi.org/10.48550/arXiv.2304.14853," Shashank Manjunath, Jose A. Perea, Aarti Sathyanarayana. (2023). Topological Data Analysis of Electroencephalogram Signals for Pediatric Obstructive Sleep Apnea CoRR, abs/2304.14853. https://doi.org/10.48550/arXiv.2304.14853","Topological data analysis (TDA) is an emerging technique for biological signal processing. TDA leverages the invariant topological features of signals in a metric space for robust analysis of signals even in the presence of noise. In this paper, we leverage TDA on brain connectivity networks derived from electroencephalogram (EEG) signals to identify statistical differences between pediatric patients with obstructive sleep apnea (OSA) and pediatric patients without OSA. We leverage a large corpus of data, and show that TDA enables us to see a statistical difference between the brain dynamics of the two groups.",352
267,Artificial Intelligence,Jose Perea,"December 16th, 2022",Learning on Persistence Diagrams as Radon Measures,https://doi.org/10.48550/arXiv.2212.08295," Alex Elchesen, Iryna Hartsock, Jose A. Perea, Tatum Rask. (2022). Learning on Persistence Diagrams as Radon Measures CoRR, abs/2212.08295. https://doi.org/10.48550/arXiv.2212.08295","Persistence diagrams are common descriptors of the topological structure of data appearing in various classification and regression tasks. They can be generalized to Radon measures supported on the birth-death plane and endowed with an optimal transport distance. Examples of such measures are expectations of probability distributions on the space of persistence diagrams. In this paper, we develop methods for approximating continuous functions on the space of Radon measures supported on the birth-death plane, as well as their utilization in supervised learning tasks. Indeed, we show that any continuous function defined on a compact subset of the space of such measures (e.g., a classifier or regressor) can be approximated arbitrarily well by polynomial combinations of features computed using a continuous compactly supported function on the birth-death plane (a template). We provide insights into the structure of relatively compact subsets of the space of Radon measures, and test our approximation methodology on various data sets and supervised learning tasks.",353
268,Artificial Intelligence,Jose Perea,"December 14th, 2022",Toroidal Coordinates: Decorrelating Circular Coordinates With Lattice Reduction,https://doi.org/10.48550/arXiv.2212.07201," Luis Scoccola, Hitesh Gakhar, Johnathan Bush, Nikolas Schonsheck, Tatum Rask, Ling Zhou, Jose A. Perea. (2022). Toroidal Coordinates: Decorrelating Circular Coordinates With Lattice Reduction CoRR, abs/2212.07201. https://doi.org/10.48550/arXiv.2212.07201","The circular coordinates algorithm of de Silva, Morozov, and Vejdemo-Johansson takes as input a dataset together with a cohomology class representing a1-dimensional hole in the data; the output is a map from the data into the circle that captures this hole, and that is of minimum energy in a suitable sense. However, when applied to several cohomology classes, the output circle-valued maps can be ""geometrically correlated"" even if the chosen cohomology classes are linearly independent. It is shown in the original work that less correlated maps can be obtained with suitable integer linear combinations of the cohomology classes, with the linear combinations being chosen by inspection. In this paper, we identify a formal notion of geometric correlation between circle-valued maps which, in the Riemannian manifold case, corresponds to the Dirichlet form, a bilinear form derived from the Dirichlet energy. We describe a systematic procedure for constructing low energy torus-valued maps on data, starting from a set of linearly independent cohomology classes. We showcase our procedure with computational examples. Our main algorithm is based on the Lenstra--Lenstra--Lov√°sz algorithm from computational number theory.",354
269,Artificial Intelligence,Jose Perea,"June 13th, 2022",Fiberwise dimensionality reduction of topologically complex data with vector bundles,https://doi.org/10.48550/arXiv.2206.06513," Luis Scoccola, Jose A. Perea. (2022). Fiberwise dimensionality reduction of topologically complex data with vector bundles CoRR, abs/2206.06513. https://doi.org/10.48550/arXiv.2206.06513","Datasets with non-trivial large scale topology can be hard to embed in low-dimensional Euclidean space with existing dimensionality reduction algorithms. We propose to model topologically complex datasets using vector bundles, in such a way that the base space accounts for the large scale topology, while the fibers account for the local geometry. This allows one to reduce the dimensionality of the fibers, while preserving the large scale topology. We formalize this point of view, and, as an application, we describe an algorithm which takes as input a dataset together with an initial representation of it in Euclidean space, assumed to recover part of its large scale topology, and outputs a new representation that integrates local representations, obtained through local linear dimensionality reduction, along the initial global representation. We demonstrate this algorithm on examples coming from dynamical systems and chemistry. In these examples, our algorithm is able to learn topologically faithful embeddings of the data in lower target dimension than various well known metric-based dimensionality reduction algorithms.",355
270,Artificial Intelligence,Jose Perea,"June 1st, 2022",Approximating Continuous Functions on Persistence Diagrams Using Template Functions,https://doi.org/10.1007/s10208-022-09567-7," Jose A. Perea, Elizabeth Munch, Firas A. Khasawneh. (2023). Approximating Continuous Functions on Persistence Diagrams Using Template Functions Found. Comput. Math., 23, 1215-1272. https://doi.org/10.1007/s10208-022-09567-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 584 Accesses",356
271,Artificial Intelligence,Jose Perea,"July 27th, 2021",A Comparative Study of Machine Learning Methods for Persistence Diagrams,https://doi.org/10.3389/frai.2021.681174," Danielle Barnes, Luis Polanco, Jose A. Perea. (2021). A Comparative Study of Machine Learning Methods for Persistence Diagrams Frontiers Artif. Intell., 4, 681174. https://doi.org/10.3389/frai.2021.681174","We review, evaluate, and compare the stable multi-scale kernel, persistence landscapes, persistence images, the ring of algebraic functions, template functions, and adaptive template systems. We apply and compare popular machine learning methods on five data sets. These data sets are commonly used in the above methods for featurization. We use them to evaluate predictive utility in real-world applications.",357
272,Artificial Intelligence,Ryan M. Rad,"April 8th, 2024",GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery,https://doi.org/10.48550/arXiv.2404.05180," Zhiyuan Yang, Ryan Rad. (2024). GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery CoRR, abs/2404.05180. https://doi.org/10.48550/arXiv.2404.05180","Solar Photovoltaic (PV) technology is increasingly recognized as a pivotal solution in the global pursuit of clean and renewable energy. This technology addresses the urgent need for sustainable energy alternatives by converting solar power into electricity without greenhouse gas emissions. It not only curtails global carbon emissions but also reduces reliance on finite, non-renewable energy sources. In this context, monitoring solar panel farms becomes essential for understanding and facilitating the worldwide shift toward clean energy. This study contributes to this effort by developing the first comprehensive global dataset of multispectral satellite imagery of solar panel farms. This dataset is intended to form the basis for training robust machine learning models, which can accurately map and analyze the expansion and distribution of solar panel farms globally. The insights gained from this endeavor will be instrumental in guiding informed decision-making for a sustainable energy future.this https URL",358
273,Artificial Intelligence,Ryan M. Rad,"November 1st, 2023",Remote Wildfire Detection using Multispectral Satellite Imagery and Vision Transformers,https://proceedings.mlr.press/v222/rad24a.html," Ryan Rad. (2023). Remote Wildfire Detection using Multispectral Satellite Imagery and Vision Transformers ACML, 1135-1150. https://proceedings.mlr.press/v222/rad24a.html","Wildfires pose a significant and recurring challenge in North America, impacting both human and natural environments. The size and severity of wildfires in the region have been increasing in recent years, making it a pressing concern for communities, ecosystems, and the economy. The accurate and timely detection of active wildfires in remote areas is crucial for effective wildfire management and mitigation efforts. In this research paper, we propose a robust approach for detecting active wildfires using multispectral satellite imagery by leveraging vision transformers and a vast repository of landsat- 8 8 satellite data with a 30 30 m spatial resolution in North America. Our methodology involves experimenting with vision transformers and deep convolutional neural networks for wildfire detection in multispectral satellite images. We compare the capabilities of these two architecture families in detecting wildfires within the multispectral satellite imagery. Furthermore, we propose a novel u-shape vision transformer that effectively captures spatial dependencies and learns meaningful representations from multispectral images, enabling precise discrimination between wildfire and non-wildfire regions. To evaluate the performance of our approach, we conducted experiments on a comprehensive dataset of wildfire incidents. The results demonstrate the effectiveness of the proposed method in accurately detecting active wildfires with an \textit{Dice Score or F 1 1 } of and \textit{Recall} of . Overall, our research presents a promising approach for leveraging vision transformers for multispectral satellite imagery to detect remote wildfires.",359
274,Artificial Intelligence,Saiph Savage,"January 13th, 2025",Data Enrichment Work and AI Labor in Latin America and the Caribbean,https://doi.org/10.48550/arXiv.2501.06981," Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage. (2025). Data Enrichment Work and AI Labor in Latin America and the Caribbean CoRR, abs/2501.06981. https://doi.org/10.48550/arXiv.2501.06981","The global AI surge demands crowdworkers from diverse languages and cultures. They are pivotal in labeling data for enabling global AI systems. Despite global significance, research has primarily focused on understanding the perspectives and experiences of US and India crowdworkers, leaving a notable gap. To bridge this, we conducted a survey with 100 crowdworkers across 16 Latin American and Caribbean countries. We discovered that these workers exhibited pride and respect for their digital labor, with strong support and admiration from their families. Notably, crowd work was also seen as a stepping stone to financial and professional independence. Surprisingly, despite wanting more connection, these workers also felt isolated from peers and doubtful of others' labor quality. They resisted collaboration and gender-based tools, valuing gender-neutrality. Our work advances HCI understanding of Latin American and Caribbean crowdwork, offering insights for digital resistance tools for the region.",360
275,Artificial Intelligence,Saiph Savage,"November 8th, 2024",A Culturally-Aware AI Tool for Crowdworkers: Leveraging Chronemics to Support Diverse Work Styles,https://doi.org/10.1145/3686899," Carlos Toxtli, Christopher Curtis, Saiph Savage. (2024). A Culturally-Aware AI Tool for Crowdworkers: Leveraging Chronemics to Support Diverse Work Styles Proc. ACM Hum. Comput. Interact., 8, 1-34. https://doi.org/10.1145/3686899","Crowdsourcing markets are expanding worldwide, but often feature standardized interfaces that ignore the cultural diversity of their workers, negatively impacting their well-being and productivity. To transform these workplace dynamics, this paper proposes creating culturally-aware workplace tools, specifically designed to adapt to the cultural dimensions of monochronic and polychronic work styles. We illustrate this approach with ""CultureFit,"" a tool that we engineered based on extensive research in Chronemics and culture theories. To study and evaluate our tool in the real world, we conducted a field experiment with 55 workers from 24 different countries. Our field experiment revealed that CultureFit significantly improved the earnings of workers from cultural backgrounds often overlooked in design. Our study is among the pioneering efforts to examine culturally aware digital labor interventions. It also provides access to a dataset with over two million data points on culture and digital work, which can be leveraged for future research in this emerging field. The paper concludes by discussing the importance and future possibilities of incorporating cultural insights into the design of tools for digital labor.",361
276,Artificial Intelligence,Saiph Savage,"May 11th, 2024",Designing Gig Worker Sousveillance Tools,https://doi.org/10.1145/3613904.3642614," Kimberly Do, Maya De Los Santos, Michael Muller, Saiph Savage. (2024). Designing Gig Worker Sousveillance Tools CHI, 384:1-384:19. https://doi.org/10.1145/3613904.3642614","As independently-contracted employees, gig workers disproportionately suffer the consequences of workplace surveillance, which include increased pressures to work, breaches of privacy, and decreased digital autonomy. Despite the negative impacts of workplace surveillance, gig workers lack the tools, strategies, and workplace social support to protect themselves against these harms. Meanwhile, some critical theorists have proposed sousveillance as a potential means of countering such abuses of power, whereby those under surveillance monitor those in positions of authority (e.g., gig workers collect data about requesters/platforms). To understand the benefits of sousveillance systems in the gig economy, we conducted semi-structured interviews and led co-design activities with gig workers. We use ‚Äúcare ethics‚Äù as a guiding concept to understand our interview and co-design data, while also focusing on empathic sousveillance technology design recommendations. Through our study we identify gig workers‚Äô attitudes towards and past experiences with sousveillance. We also uncover the type of sousveillance technologies imagined by workers, provide design recommendations, and finish by discussing how to create empowering, empathic spaces on gig platforms.",362
277,Artificial Intelligence,Saiph Savage,"March 4th, 2024",Unveiling AI-Driven Collective Action for a Worker-Centric Future,https://doi.org/10.1145/3616855.3637633," Saiph Savage. (2024). Unveiling AI-Driven Collective Action for a Worker-Centric Future WSDM, 6-7. https://doi.org/10.1145/3616855.3637633","Gig knowledge workers are a potent method for enhancing labor conditions on platforms like Upwork, Amazon Mechanical Turk, and Toloka. Existing systems for supporting collective action are inadequate for workers to identify and understand their different workplace problems, plan effective solutions, and put the solutions into action. Building solid AI enhanced technologies to enable gig worker collective action will pave the way for a fair and ethical gig economy.",363
278,Artificial Intelligence,Saiph Savage,"February 20th, 2024","Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning",https://doi.org/10.48550/arXiv.2402.12667," Derek Jacoby, Saiph Savage, Yvonne Coady. (2024). Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning CoRR, abs/2402.12667. https://doi.org/10.48550/arXiv.2402.12667","Increasing diversity in educational settings is challenging in part due to the lack of access to resources for non-traditional learners in remote communities. Post-pandemic platforms designed specifically for remote and hybrid learning -- supporting team-based collaboration online -- are positioned to bridge this gap. Our work combines the use of these new platforms with co-creation and collaboration tools for AI assisted remote Work-Integrated-Learning (WIL) opportunities, including efforts in community and with the public library system. This paper outlines some of our experiences to date, and proposes methods to further integrate AI education into community-driven applications for remote WIL.",364
279,Artificial Intelligence,Saiph Savage,"April 12th, 2023",Why Do We Need to Learn about Citational Practices? Recognizing Knowledge Production from the Global Souths and Beyond,https://doi.org/10.1145/3589256," Amy Ogan, Frederick M. C. van Amstel, Gabriela Molina Le√≥n, Juan Fernando Maestre, Kristin Williams, Nicola J. Bidwell, Pedro Reynolds-Cu√©llar, Saiph Savage, Sushil K. Oswal, Vishal Sharma. (2023). Why Do We Need to Learn about Citational Practices? Recognizing Knowledge Production from the Global Souths and Beyond XRDS, 29, 12-17. https://doi.org/10.1145/3589256","How do you decide which papers to cite, how many, and from which particular sources? We reflect and discuss the implications of these critical questions based on our experiences in the panel and workshops on the topic of citational justice that took place at CSCW, CLIHC, and India HCI in 2021.",365
280,Artificial Intelligence,Saiph Savage,"February 27th, 2023",4th Crowd Science Workshop ‚Äì CANDLE: Collaboration of Humans and Learning Algorithms for Data Labeling,https://doi.org/10.1145/3539597.3572703," Dmitry Ustalov, Saiph Savage, Niels van Berkel, Yang Liu. (2023). 4th Crowd Science Workshop - CANDLE: Collaboration of Humans and Learning Algorithms for Data Labeling WSDM, 1268. https://doi.org/10.1145/3539597.3572703","Crowdsourcing has been used to produce impactful and large-scale datasets for Machine Learning and Artificial Intelligence (AI), such as ImageNET, SuperGLUE, etc. Since the rise of crowdsourcing in early 2000s, the AI community has been studying its computational, system design, and data-centric aspects at various angles. We welcome the studies on developing and enhancing of crowdworker-centric tools, that offer task matching, requester assessment, instruction validation, among other topics. We are also interested in exploring methods that leverage the integration of crowdworkers to improve the recognition and performance of the machine learning models. Thus, we invite studies that focus on shipping active learning techniques, methods for joint learning from noisy data and from crowds, novel approaches for crowd-computer interaction, repetitive task automation, and role separation between humans and machines. Moreover, we invite works on designing and applying such techniques in various domains, including e-commerce and medicine.",366
281,Artificial Intelligence,Saiph Savage,"November 11th, 2022",Datavoidant: An AI System for Addressing Political Data Voids on Social Media,https://doi.org/10.1145/3555616," Claudia Flores-Saviaga, Shangbin Feng, Saiph Savage. (2022). Datavoidant: An AI System for Addressing Political Data Voids on Social Media Proc. ACM Hum. Comput. Interact., 6, 1-29. https://doi.org/10.1145/3555616","The limited information (data voids) on political topics relevant to underrepresented communities has facilitated the spread of disinformation. Independent journalists who combat disinformation in underrepresented communities have reported feeling overwhelmed because they lack the tools necessary to make sense of the information they monitor and address the data voids. In this paper, we present a system to identify and address political data voids within underrepresented communities. Armed with an interview study, indicating that the independent news media has the potential to address them, we designed an intelligent collaborative system, called Datavoidant. Datavoidant uses state-of-the-art machine learning models and introduces a novel design space to provide independent journalists with a collective understanding of data voids to facilitate generating content to cover the voids. We performed a user interface evaluation with independent news media journalists (N=22). These journalists reported that Datavoidant's features allowed them to more rapidly while easily having a sense of what was taking place in the information ecosystem to address the data voids. They also reported feeling more confident about the content they created and the unique perspectives they had proposed to cover the voids. We conclude by discussing how Datavoidant enables a new design space wherein individuals can collaborate to make sense of their information ecosystem and actively devise strategies to prevent disinformation.",367
282,Artificial Intelligence,Saiph Savage,"October 22nd, 2022",The Global Care Ecosystems of 3D Printed Assistive Devices,https://doi.org/10.1145/3537676," Saiph Savage, Claudia Flores-Saviaga, Rachel Rodney, Liliana Savage, Jon Schull, Jennifer Mankoff. (2022). The Global Care Ecosystems of 3D Printed Assistive Devices ACM Trans. Access. Comput., 15, 31:1-31:29. https://doi.org/10.1145/3537676","The popularity of 3D printed assistive technology has led to the emergence of new ecosystems of care, where multiple stakeholders (makers, clinicians, and recipients with disabilities) work toward creating new upper limb prosthetic devices. However, despite the increasing growth, we currently know little about the differences between these care ecosystems. Medical regulations and the prevailing culture have greatly impacted how ecosystems are structured and stakeholders work together, including whether clinicians and makers collaborate. To better understand these care ecosystems, we interviewed a range of stakeholders from multiple countries, including Brazil, Chile, Costa Rica, France, India, Mexico, and the U.S. Our broad analysis allowed us to uncover different working examples of how multiple stakeholders collaborate within these care ecosystems and the main challenges they face. Through our study, we were able to uncover that ecosystems with multi-stakeholder collaborations exist (something prior work had not seen), and these ecosystems showed increased success and impact. We also identified some of the key follow-up practices to reduce device abandonment. Of particular importance are to have ecosystems put in place follow-up practices that integrate formal agreements and compensations for participation (which do not need to be just monetary). We identified that these features helped to ensure multi-stakeholder involvement and ecosystem sustainability. We finished the article with socio-technical recommendations to create vibrant care ecosystems that include multiple stakeholders in the production of 3D printed assistive devices.",368
283,Artificial Intelligence,Saiph Savage,"April 28th, 2022",REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration,https://doi.org/10.1145/3491101.3503725," Andy Alorwu, Saiph Savage, Niels van Berkel, Dmitry Ustalov, Alexey Drutsa, Jonas Oppenlaender, Oliver Bates, Danula Hettiachchi, Ujwal Gadiraju, Jorge Gon√ßalves , Simo Hosio. (2022). REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration CHI Extended Abstracts, 88:1-88:7. https://doi.org/10.1145/3491101.3503725","Crowdworkers silently enable much of today‚Äôs AI-based products, with several online platforms offering a myriad of data labelling and content moderation tasks through convenient labour marketplaces. The HCI community has been increasingly interested in investigating the worker-centric issues inherent in the current model and seeking for potential improvements that could be implemented in the future. This workshop explores how a reimagined perspective on crowdsourcing platforms could provide a more equitable, fair, and rewarding experience. This includes not only the workers but also the platforms, who could benefit e.g. from better processes for worker onboarding, skills-development, and growth. We invite visionary takes in various formats on this topic to spread awareness of worker-centric research and developments to the CHI community. As a result of interactive ideation work in the workshop, we articulate a future direction roadmap for research centred around crowdsourcing platforms. Finally, as a specific interest area, the workshop seeks to study crowdwork from the context of the Global South, which has been arising as an important but critically understudied crowdsourcing market in recent years.",369
284,Artificial Intelligence,Saiph Savage,"October 1st, 2021",Quantifying the Invisible Labor in Crowd Work,https://arxiv.org/abs/2110.00169," Carlos Toxtli, Siddharth Suri, and Saiph Savage. 2021. Quantifying the Invisible Labor in Crowd Work. Proc. ACM Hum.-Comput. Interact. 5, CSCW2, Article 319 (October 2021), 26 pages. DOI:https://doi.org/10.1145/3476060","Crowdsourcing markets provide workers with a centralized place to find paid work. What may not be obvious at first glance is that, in addition to the work they do for pay, crowd workers also have to shoulder a variety of unpaid invisible labor in these markets, which ultimately reduces workers' hourly wages. Invisible labor includes finding good tasks, messaging requesters, or managing payments. However, we currently know little about how much time crowd workers actually spend on invisible labor or how much it costs them economically. To ensure a fair and equitable future for crowd work, we need to be certain that workers are being paid fairly for all of the work they do. In this paper, we conduct a field study to quantify the invisible labor in crowd work. We build a plugin to record the amount of time that 100 workers on Amazon Mechanical Turk dedicate to invisible labor while completing 40,903 tasks. If we ignore the time workers spent on invisible labor, workers' median hourly wage was3.76.But,weestimatedthatcrowdworkersinourstudyspent332.83. We found that the invisible labor differentially impacts workers depending on their skill level and workers' demographics. The invisible labor category that took the most time and that was also the most common revolved around workers having to manage their payments. The second most time-consuming invisible labor category involved hyper-vigilance, where workers vigilantly watched over requesters' profiles for newly posted work or vigilantly searched for labor. We hope that through our paper, the invisible labor in crowdsourcing becomes more visible, and our results help to reveal the larger implications of the continuing invisibility of labor in crowdsourcing.",370
285,Artificial Intelligence,Saiph Savage,"November 30th, 2020",Meta-Gig: Empowering Anyone to Create Crowd Marketplaces,http://dx.doi.org/10.47756/aihc.y5i1.62," TOXTLI, Carlos; SAVAGE, Saiph. Meta-Gig: Empowering anyone to create crowd marketplaces. Avances en Interacci√≥n Humano-Computadora, [S.l.], n. 1, p. 11-19, nov. 2020. ISSN 2594-2352. Available at: . Date accessed: 09 nov. 2021. doi: http://dx.doi.org/10.47756/aihc.y5i1.62.","Abstract Few have the power to create crowd markets. Existing marketplaces may thus not embody workers‚Äô or requesters‚Äô needs. In this paper, we imagine a future where anyone could create the crowd markets they desire. We study the characteristics of the markets that 40 workers and 40 requesters from Amazon Mechanical Turk propose. We uncover that workers pushed for marketplaces that either empowered workers to set their own salaries without requiring a minimum wage or had intelligent algorithms that could automatically decide the salaries while also ensuring everyone received a minimum wage. Requesters were consistent in their preference of paying by commission and preferred markets that automatically set the salary. Both workers and requesters advocated for mechanisms to ensure quality and flexible time schedules in the market. We conclude by discussing design implications from our findings.",371
286,Artificial Intelligence,Saiph Savage,"May 13th, 2019",TurkScanner: Predicting the Hourly Wage of Microtasks,https://doi.org/10.1145/3308558.3313716," Susumu Saito, Chun-Wei Chiang, Saiph Savage, Teppei Nakano, Tetsunori Kobayashi, Jeffrey P. Bigham. (2019). TurkScanner: Predicting the Hourly Wage of Microtasks WWW, 3187-3193. https://doi.org/10.1145/3308558.3313716","Workers in crowd markets struggle to earn a living. One reason for this is that it is difficult for workers to accurately gauge the hourly wages of microtasks, and they consequently end up performing labor with little pay. In general, workers are provided with little information about tasks, and are left to rely on noisy signals, such as textual description of the task or rating of the requester. This study explores various computational methods for predicting the working times (and thus hourly wages) required for tasks based on data collected from other workers completing crowd work. We provide the following contributions. (i) A data collection method for gathering real-world training data on crowd-work tasks and the times required for workers to complete them; (ii) TurkScanner: a machine learning approach that predicts the necessary working time to complete a task (and can thus implicitly provide the expected hourly wage). We collected 9,155 data records using a web browser extension installed by 84 Amazon Mechanical Turk workers, and explored the challenge of accurately recording working times both automatically and by asking workers. TurkScanner was created using ~ 150 derived features, and was able to predict the hourly wages of 69.6% of all the tested microtasks within a 75% error. Directions for future research include observing the effects of tools on people's working practices, adapting this approach to a requester tool for better price setting, and predicting other elements of work (e.g., the acceptance likelihood and worker task preferences.)",372
287,Artificial Intelligence,Rajagopal Venkatesaramani,"October 9th, 2024",Bayes-Nash Generative Privacy Protection Against Membership Inference Attacks,https://doi.org/10.48550/arXiv.2410.07414," Tao Zhang, Rajagopal Venkatesaramani, Rajat K. De, Bradley A. Malin, Yevgeniy Vorobeychik. (2024). Bayes-Nash Generative Privacy Protection Against Membership Inference Attacks CoRR, abs/2410.07414. https://doi.org/10.48550/arXiv.2410.07414","Membership inference attacks (MIAs) expose significant privacy risks by determining whether an individual's data is in a dataset. While differential privacy (DP) mitigates such risks, it has several limitations in achieving an optimal balance between utility and privacy, include limited resolution in expressing this tradeoff in only a few privacy parameters, and intractable sensitivity calculations that may be necessary to provide tight privacy guarantees. We propose a game-theoretic framework that models privacy protection from MIA as a Bayesian game between a defender and an attacker. In this game, a dataset is the defender's private information, with privacy loss to the defender (which is gain to the attacker) captured in terms of the attacker's ability to infer membership of individuals in the dataset. To address the strategic complexity of this game, we represent the mixed strategy of the defender as a neural network generator which maps a private dataset to its public representation (for example, noisy summary statistics), while the mixed strategy of the attacker is captured by a discriminator which makes membership inference claims. We refer to the resulting computational approach as a general-sum Generative Adversarial Network, which is trained iteratively by alternating generator and discriminator updates akin to conventional GANs. We call the defender's data sharing policy thereby obtained Bayes-Nash Generative Privacy (BNGP). The BNGP strategy avoids sensitivity calculations, supports compositions of correlated mechanisms, is robust to the attacker's heterogeneous preferences over true and false positives, and yields provable differential privacy guarantees, albeit in an idealized setting.",373
288,Artificial Intelligence,Rajagopal Venkatesaramani,"July 11th, 2024",CribNet: Enhancing Infant Safety in Cribs Through Vision-Based Hazard Detection,https://doi.org/10.1109/FG59268.2024.10581871," Shaotong Zhu, Amal Mathew, Elaheh Hatamimajoumerd, Michael Wan, Briana Taylor, Rajagopal Venkatesaramani, Sarah Ostadabbas. (2024). CribNet: Enhancing Infant Safety in Cribs Through Vision-Based Hazard Detection FG, 1-8. https://doi.org/10.1109/FG59268.2024.10581871","This paper proposes a new vision-based, infant-focused hazard detection framework, CribNet. The framework assess threats to in-crib safety in the form of blanket occlusions and hazardous toys. We show that the framework performs with over 80% mean average precision (mAP) in segmenting toys and blankets and accurately assessing hazards. The paper will be presented at the 2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)",374
289,Artificial Intelligence,Rajagopal Venkatesaramani,"June 3rd, 2024",A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics,https://doi.org/10.48550/arXiv.2406.01811," Tao Zhang, Rajagopal Venkatesaramani, Rajat K. De, Bradley A. Malin, Yevgeniy Vorobeychik. (2024). A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics CoRR, abs/2406.01811. https://doi.org/10.48550/arXiv.2406.01811","The advent of online genomic data-sharing services has sought to enhance the accessibility of large genomic datasets by allowing queries about genetic variants, such as summary statistics, aiding care providers in distinguishing between spurious genomic variations and those with clinical significance. However, numerous studies have demonstrated that even sharing summary genomic information exposes individual members of such datasets to a significant privacy risk due to membership inference attacks. While several approaches have emerged that reduce privacy risks by adding noise or reducing the amount of information shared, these typically assume non-adaptive attacks that use likelihood ratio test (LRT) statistics. We propose a Bayesian game-theoretic framework for optimal privacy-utility tradeoff in the sharing of genomic summary statistics. Our first contribution is to prove that a very general Bayesian attacker model that anchors our game-theoretic approach is more powerful than the conventional LRT-based threat models in that it induces worse privacy loss for the defender who is modeled as a von Neumann-Morgenstern (vNM) decision-maker. We show this to be true even when the attacker uses a non-informative subjective prior. Next, we present an analytically tractable approach to compare the Bayesian attacks with arbitrary subjective priors and the Neyman-Pearson optimal LRT attacks under the Gaussian mechanism common in differential privacy frameworks. Finally, we propose an approach for approximating Bayes-Nash equilibria of the game using deep neural network generators to implicitly represent player mixed strategies. Our experiments demonstrate that the proposed game-theoretic framework yields both stronger attacks and stronger defense strategies than the state of the art.",375
290,Artificial Intelligence,Rajagopal Venkatesaramani,"January 11th, 2023",Enabling Trade-offs in Privacy and Utility in Genomic Data Beacons and Summary Statistics,https://doi.org/10.48550/arXiv.2302.01763," Rajagopal Venkatesaramani, Zhiyu Wan, Bradley A. Malin, Yevgeniy Vorobeychik. (2023). Enabling Trade-offs in Privacy and Utility in Genomic Data Beacons and Summary Statistics CoRR, abs/2302.01763. https://doi.org/10.48550/arXiv.2302.01763","The collection and sharing of genomic data are becoming increasingly commonplace in research, clinical, and direct-to-consumer settings. The computational protocols typically adopted to protect individual privacy include sharing summary statistics, such as allele frequencies, or limiting query responses to the presence/absence of alleles of interest using web-services called Beacons. However, even such limited releases are susceptible to likelihood-ratio-based membership-inference attacks. Several approaches have been proposed to preserve privacy, which either suppress a subset of genomic variants or modify query responses for specific variants (e.g., adding noise, as in differential privacy). However, many of these approaches result in a significant utility loss, either suppressing many variants or adding a substantial amount of noise. In this paper, we introduce optimization-based approaches to explicitly trade off the utility of summary data or Beacon responses and privacy with respect to membership-inference attacks based on likelihood-ratios, combining variant suppression and modification. We consider two attack models. In the first, an attacker applies a likelihood-ratio test to make membership-inference claims. In the second model, an attacker uses a threshold that accounts for the effect of the data release on the separation in scores between individuals in the dataset and those who are not. We further introduce highly scalable approaches for approximately solving the privacy-utility tradeoff problem when information is either in the form of summary statistics or presence/absence queries. Finally, we show that the proposed approaches outperform the state of the art in both utility and privacy through an extensive evaluation with public datasets.",376
291,Artificial Intelligence,Rajagopal Venkatesaramani,"December 25th, 2021",Defending Against Membership Inference Attacks on Beacon Services,https://doi.org/10.1145/3603627," Rajagopal Venkatesaramani, Zhiyu Wan, Bradley A. Malin, Yevgeniy Vorobeychik. (2023). Defending Against Membership Inference Attacks on Beacon Services ACM Trans. Priv. Secur., 26, 42:1-42:32. https://doi.org/10.1145/3603627","Large genomic datasets are created through numerous activities, including recreational genealogical investigations, biomedical research, and clinical care. At the same time, genomic data has become valuable for reuse beyond their initial point of collection, but privacy concerns often hinder access. Beacon services have emerged to broaden accessibility to such data. These services enable users to query for the presence of a particular minor allele in a dataset, and information helps care providers determine if genomic variation is spurious or has some known clinical indication. However, various studies have shown that this process can leak information regarding if individuals are members of the underlying dataset. There are various approaches to mitigate this vulnerability, but they are limited in that they (1) typically rely on heuristics to add noise to the Beacon responses; (2) offer probabilistic privacy guarantees only, neglecting data utility; and (3) assume a batch setting where all queries arrive at once. In this article, we present a novel algorithmic framework to ensure privacy in a Beacon service setting with a minimal number of query response flips. We represent this problem as one of combinatorial optimization in both the batch setting and the online setting (where queries arrive sequentially). We introduce principled algorithms with both privacy and, in some cases, worst-case utility guarantees. Moreover, through extensive experiments, we show that the proposed approaches significantly outperform the state of the art in terms of privacy and utility, using a dataset consisting of 800 individuals and 1.3 million single nucleotide variants.",377
292,Artificial Intelligence,Rajagopal Venkatesaramani,"February 17th, 2021",Re-identification of Individuals in Genomic Datasets Using Public Face Images,https://arxiv.org/abs/2102.08557," Rajagopal Venkatesaramani, Bradley A. Malin, Yevgeniy Vorobeychik. (2021). Re-identification of Individuals in Genomic Datasets Using Public Face Images CoRR, abs/2102.08557. https://arxiv.org/abs/2102.08557","DNA sequencing is becoming increasingly commonplace, both in medical and direct-to-consumer settings. To promote discovery, collected genomic data is often de-identified and shared, either in public repositories, such as OpenSNP, or with researchers through access-controlled repositories. However, recent studies have suggested that genomic data can be effectively matched to high-resolution three-dimensional face images, which raises a concern that the increasingly ubiquitous public face images can be linked to shared genomic data, thereby re-identifying individuals in the genomic data. While these investigations illustrate the possibility of such an attack, they assume that those performing the linkage have access to extremely well-curated data. Given that this is unlikely to be the case in practice, it calls into question the pragmatic nature of the attack. As such, we systematically study this re-identification risk from two perspectives: first, we investigate how successful such linkage attacks can be when real face images are used, and second, we consider how we can empower individuals to have better control over the associated re-identification risk. We observe that the true risk of re-identification is likely substantially smaller for most individuals than prior literature suggests. In addition, we demonstrate that the addition of a small amount of carefully crafted noise to images can enable a controlled trade-off between re-identification success and the quality of shared images, with risk typically significantly lowered even with noise that is imperceptible to humans.",378
293,Artificial Intelligence,Byron Wallace,"November 1st, 2024",Learning from Natural Language Explanations for Generalizable Entity Matching,https://aclanthology.org/2024.emnlp-main.352," Somin Wadhwa, Adit Krishnan, Runhui Wang, Byron C. Wallace, Luyang Kong. (2024). Learning from Natural Language Explanations for Generalizable Entity Matching EMNLP, 6114-6129. https://aclanthology.org/2024.emnlp-main.352","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Entity matching is the task of linking records from different sources that refer to the same real-world entity. Past work has primarily treated entity linking as a standard supervised learning problem. However, supervised entity matching models often do not generalize well to new data, and collecting exhaustive labeled training data is often cost prohibitive. Further, recent efforts have adopted LLMs for this task in few/zero-shot settings, exploiting their general knowledge. But LLMs are prohibitively expensive for performing inference at scale for real-world entity matching tasks.As an efficient alternative, we re-cast entity matching as a conditional generation task as opposed to binary classification. This enables us to ‚Äúdistill‚Äù LLM reasoning into smaller entity matching models via natural language explanations. This approach achieves strong performance, especially on out-of-domain generalization tests (10.85% F-1) where standalone generative methods struggle. We perform ablations that highlight the importance of explanations, both for performance and model robustness.",379
294,Artificial Intelligence,Byron Wallace,"November 1st, 2024",Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs,https://aclanthology.org/2024.emnlp-main.543," Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs EMNLP, 9727-9739. https://aclanthology.org/2024.emnlp-main.543","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b‚Äôs tokenizer splits the word ‚Äúpatrolling‚Äù into two tokens, ‚Äúpat‚Äù and ‚Äúrolling‚Äù, neither of which correspond to semantically meaningful units like ‚Äúpatrol‚Äù or ""-ing.‚Äù Similarly, the overall meanings of named entities like ‚ÄúNeil Young‚Äù and multi-word expressions like ‚Äúbreak a leg‚Äù cannot be directly inferred from their constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups of tokens into useful higher-level representations? In this work, we find that last token representations of named entities and multi-token words exhibit a pronounced ‚Äúerasure‚Äù effect, where information about previous and current tokens is rapidly forgotten in early layers. Using this observation, we propose a method to ‚Äúread out‚Äù the implicit vocabulary of an autoregressive LLM by examining differences in token representations across layers, and present results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is the first attempt to probe the implicit vocabulary of an LLM.",380
295,Artificial Intelligence,Byron Wallace,"August 1st, 2024",Open (Clinical) LLMs are Sensitive to Instruction Phrasings,https://aclanthology.org/2024.bionlp-1.5," Alberto Mario Ceballos-Arroyo, Monica Munnangi, Jiuding Sun, Karen Y. C. Zhang, Denis Jered McInerney, Byron C. Wallace, Silvio Amir. (2024). Open (Clinical) LLMs are Sensitive to Instruction Phrasings BioNLP@ACL, 50-71. https://aclanthology.org/2024.bionlp-1.5","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain. This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs‚Äîsome general, others specialized‚Äîto natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that‚Äîperhaps surprisingly‚Äîdomain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",381
296,Artificial Intelligence,Byron Wallace,"August 1st, 2024",FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence,https://aclanthology.org/2024.acl-long.459," Sebastian Joseph, Lily Chen, Jan Trienes, Hannah Louisa G√∂ke, Monika Coers, Wei Xu , Byron C. Wallace, Junyi Jessy Li. (2024). FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence ACL (1), 8437-8464. https://aclanthology.org/2024.acl-long.459","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment. FactPICO consists of 345 plain language summaries of RCT abstracts generated from three LLMs (i.e., GPT-4, Llama-2, and Alpaca), with fine-grained evaluation and natural language rationales from experts. We assess the factuality of critical elements of RCTs in those summaries: Populations, Interventions, Comparators, Outcomes (PICO), as well as the reported findings concerning these. We also evaluate the correctness of the extra information (e.g., explanations) added by LLMs. Using FactPICO, we benchmark a range of existing factuality metrics, including the newly devised ones based on LLMs. We find that plain language summarization of medical evidence is still challenging, especially when balancing between simplicity and factuality, and that existing metrics correlate poorly with expert judgments on the instance level.",382
297,Artificial Intelligence,Byron Wallace,"August 1st, 2024",InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification,https://aclanthology.org/2024.acl-long.234," Jan Trienes, Sebastian Joseph, J√∂rg Schl√∂tterer, Christin Seifert, Kyle Lo, Wei Xu , Byron C. Wallace, Junyi Jessy Li. (2024). InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification ACL (1), 4263-4294. https://aclanthology.org/2024.acl-long.234","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of English medical study abstracts. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pairs and their linguistic suitability, our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss.",383
298,Artificial Intelligence,Byron Wallace,"June 20th, 2024",Investigating Mysteries of CoT-Augmented Distillation,https://doi.org/10.48550/arXiv.2406.14511," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2024). Investigating Mysteries of CoT-Augmented Distillation CoRR, abs/2406.14511. https://doi.org/10.48550/arXiv.2406.14511","Eliciting ""chain of thought"" (CoT) rationales -- sequences of token that convey a ""reasoning"" process -- has been shown to consistently improve LLM performance on tasks like question answering. More recent efforts have shown that such rationales can also be used for model distillation: Including CoT sequences (elicited from a large ""teacher"" model) in addition to target labels when fine-tuning a small student model yields (often substantial) improvements. In this work we ask: Why and how does this additional training signal help in model distillation? We perform ablations to interrogate this, and report some potentially surprising results. Specifically: (1) Placing CoT sequences after labels (rather than before) realizes consistently better downstream performance -- this means that no student ""reasoning"" is necessary at test time to realize gains. (2) When rationales are appended in this way, they need not be coherent reasoning sequences to yield improvements; performance increases are robust to permutations of CoT tokens, for example. In fact, (3) a small number of key tokens are sufficient to achieve improvements equivalent to those observed when full rationales are used in model distillation.",384
299,Artificial Intelligence,Byron Wallace,"June 1st, 2024",Towards Reducing Diagnostic Errors with Interpretable Risk Prediction,https://doi.org/10.18653/v1/2024.naacl-long.399," Denis Jered McInerney, William Dickinson, Lucy C. Flynn, Andrea Young, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace. (2024). Towards Reducing Diagnostic Errors with Interpretable Risk Prediction NAACL-HLT, 7193-7210. https://doi.org/10.18653/v1/2024.naacl-long.399","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Many diagnostic errors occur because clinicians cannot easily access relevant information in patient Electronic Health Records (EHRs). In this work we propose a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses; our ultimate aim is to increase access to evidence and reduce diagnostic errors. In particular, we propose a Neural Additive Model to make predictions backed by evidence with individualized risk estimates at time-points where clinicians are still uncertain, aiming to specifically mitigate delays in diagnosis and errors stemming from an incomplete differential. To train such a model, it is necessary to infer temporally fine-grained retrospective labels of eventual ‚Äútrue‚Äù diagnoses. We do so with LLMs, to ensure that the input text is from before a confident diagnosis can be made. We use an LLM to retrieve an initial pool of evidence, but then refine this set of evidence according to correlations learned by the model. We conduct an in-depth evaluation of the usefulness of our approach by simulating how it might be used by a clinician to decide between a pre-defined list of differential diagnoses.",385
300,Artificial Intelligence,Byron Wallace,"March 29th, 2024",On-the-fly Definition Augmentation of LLMs for Biomedical NER,https://doi.org/10.48550/arXiv.2404.00152," Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik. (2024). On-the-fly Definition Augmentation of LLMs for Biomedical NER CoRR, abs/2404.00152. https://doi.org/10.48550/arXiv.2404.00152","Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code atthis https URL.",386
301,Artificial Intelligence,Byron Wallace,"January 16th, 2024",Function Vectors in Large Language Models,https://openreview.net/forum?id=AwyxtyMwaG," Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. (2024). Function Vectors in Large Language Models ICLR. https://openreview.net/forum?id=AwyxtyMwaG",This paper delves into the concept of function vectors (FVs) within autoregressive transformer language models (LLMs) FVs encapsulate task-specific information and exhibit robustness across various contexts. The study uncovers that FVs don't directly execute tasks but trigger the model to perform them through complex computations.,387
302,Artificial Intelligence,Byron Wallace,"January 16th, 2024",Evaluating the Zero-shot Robustness of Instruction-tuned Language Models,https://openreview.net/forum?id=g9diuvxN6D," Jiuding Sun, Chantal Shaib, Byron C. Wallace. (2024). Evaluating the Zero-shot Robustness of Instruction-tuned Language Models ICLR. https://openreview.net/forum?id=g9diuvxN6D","Using novel (unobserved) but appropriate instruction phrasings consistently degrades model performance. Such natural instructions yield a wide variance in downstream performance, despite their semantic equivalence. We propose a simple method to mitigate this issue by introducing ``soft prompt'' embedding parameters and optimizing these to maximize the similarity between representations of semantically equivalent instructions.",388
303,Artificial Intelligence,Byron Wallace,"December 1st, 2023",Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews,https://aclanthology.org/2023.emnlp-main.626," Hye Sun Yun, Iain James Marshall, Thomas A. Trikalinos, Byron C. Wallace. (2023). Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews EMNLP, 10122-10139. https://aclanthology.org/2023.emnlp-main.626","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Medical systematic reviews play a vital role in healthcare decision making and policy. However, their production is time-consuming, limiting the availability of high-quality and up-to-date evidence summaries. Recent advancements in LLMs offer the potential to automatically generate literature reviews on demand, addressing this issue. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucination or omission. In healthcare, this can make LLMs unusable at best and dangerous at worst. We conducted 16 interviews with international systematic review experts to characterize the perceived utility and risks of LLMs in the specific context of medical evidence reviews. Experts indicated that LLMs can assist in the writing process by drafting summaries, generating templates, distilling information, and crosschecking information. They also raised concerns regarding confidently composed but inaccurate LLM outputs and other potential downstream harms, including decreased accountability and proliferation of low-quality reviews. Informed by this qualitative analysis, we identify criteria for rigorous evaluation of biomedical LLMs aligned with domain expert views.",389
304,Artificial Intelligence,Byron Wallace,"November 8th, 2023",Future Lens: Anticipating Subsequent Tokens from a Single Hidden State,https://arxiv.org/abs/2311.04897," Pal, K., Sun, J., Yuan, A., Wallace, B.C., & Bau, D. (2023). Future Lens: Anticipating Subsequent Tokens from a Single Hidden State. ArXiv, abs/2311.04897.","We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at positiontin an input, can we reliably anticipate the tokens that will appear at positions‚â•t+2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a ""Future Lens"" visualization that uses these methods to create a new view of transformer states.",390
305,Artificial Intelligence,Byron Wallace,"May 23rd, 2023",Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations,https://aclanthology.org/2023.acl-long.549," Lucy Lu Wang, Yulia Otmakhova , Jay DeYoung, Thinh Hung Truong, Bailey Kuehl, Erin Bransom, Byron C. Wallace. (2023). Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations ACL (1), 9871-9889. https://aclanthology.org/2023.acl-long.549","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Evaluating multi-document summarization (MDS) quality is difficult. This is especially true in the case of MDS for biomedical literature reviews, where models must synthesize contradicting evidence reported across different documents. Prior work has shown that rather than performing the task, models may exploit shortcuts that are difficult to detect using standard n-gram similarity metrics such as ROUGE. Better automated evaluation metrics are needed, but few resources exist to assess metrics when they are proposed. Therefore, we introduce a dataset of human-assessed summary quality facets and pairwise preferences to encourage and support the development of better automated evaluation methods for literature review MDS. We take advantage of community submissions to the Multi-document Summarization for Literature Review (MSLR) shared task to compile a diverse and representative sample of generated summaries. We analyze how automated summarization evaluation metrics correlate with lexical features of generated summaries, to other automated metrics including several we propose in this work, and to aspects of human-assessed summary quality. We find that not only do automated metrics fail to capture aspects of quality as assessed by humans, in many cases the system rankings produced by these metrics are anti-correlated with rankings according to human annotators.",391
306,Artificial Intelligence,Byron Wallace,"May 10th, 2023","Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",https://aclanthology.org/2023.acl-short.119," Chantal Shaib, Millicent L. Li, Sebastian Joseph, Iain James Marshall, Junyi Jessy Li, Byron C. Wallace. (2023). Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success) ACL (2), 1387-1407. https://aclanthology.org/2023.acl-short.119","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Large language models, particularly GPT-3, are able to produce high quality summaries ofgeneral domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized domains such as biomedicine. In this paper we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given no supervision. We consider bothsingle- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in thelatter, we assess the degree to which GPT-3 is able to synthesize evidence reported acrossa collection of articles. We design an annotation scheme for evaluating model outputs, withan emphasis on assessing the factual accuracy of generated summaries. We find that whileGPT-3 is able to summarize and simplify single biomedical articles faithfully, it strugglesto provide accurate aggregations of findings over multiple documents. We release all data,code, and annotations used in this work.",392
307,Artificial Intelligence,Byron Wallace,"May 8th, 2023",Revisiting Relation Extraction in the era of Large Language Models,https://doi.org/10.48550/arXiv.2305.05003," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2023). Revisiting Relation Extraction in the era of Large Language Models CoRR, abs/2305.05003. https://doi.org/10.48550/arXiv.2305.05003","Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a \emph{sequence-to-sequence} task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA results. We release this model as a new baseline for RE tasks.",393
308,Artificial Intelligence,Byron Wallace,"December 7th, 2022",That‚Äôs the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data,https://aclanthology.org/2022.emnlp-main.238," Jered Jered McInerney, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace. (2022). That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data EMNLP, 3626-3648. https://aclanthology.org/2022.emnlp-main.238","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Pretraining multimodal models on Electronic Health Records (EHRs) provides a means of learning representations that can transfer to downstream tasks with minimal supervision. Recent multimodal models induce soft local alignments between image regions and sentences. This is of particular interest in the medical domain, where alignments might highlight regions in an image relevant to specific phenomena described in free-text. While past work has suggested that attention ‚Äúheatmaps‚Äù can be interpreted in this manner, there has been little evaluation of such alignments. We compare alignments from a state-of-the-art multimodal (image and text) model for EHR with human annotations that link image regions to sentences. Our main finding is that the text has an often weak or unintuitive influence on attention; alignments do not consistently reflect basic anatomical information. Moreover, synthetic modifications ‚Äî such as substituting ‚Äúleft‚Äù for ‚Äúright‚Äù ‚Äî do not substantially influence highlights. Simple techniques such as allowing the model to opt out of attending to the image and few-shot finetuning show promise in terms of their ability to improve alignments with very little or no supervision. We make our code and checkpoints open-source.",394
309,Artificial Intelligence,Byron Wallace,"January 1st, 2022",Evaluating Factuality in Text Simplification,https://doi.org/10.18653/v1/2022.acl-long.506," Ashwin Devaraj, William Sheffield, Byron C. Wallace, Junyi Jessy Li. (2022). Evaluating Factuality in Text Simplification ACL (1), 7331-7345. https://doi.org/10.18653/v1/2022.acl-long.506","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Automated simplification models aim to make input texts more readable. Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader. However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information. Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all. The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated. We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs. We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models.",395
310,Artificial Intelligence,Byron Wallace,"January 1st, 2022",PHEE: A Dataset for Pharmacovigilance Event Extraction from Text,https://aclanthology.org/2022.emnlp-main.376," Zhaoyue Sun, Jiazheng Li , Gabriele Pergola, Byron C. Wallace, Bino John, Nigel Greene, Joseph Kim, Yulan He . (2022). PHEE: A Dataset for Pharmacovigilance Event Extraction from Text EMNLP, 5571-5587. https://aclanthology.org/2022.emnlp-main.376","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The primary goal of drug safety researchers and regulators is to promptly identify adverse drug reactions. Doing so may in turn prevent or reduce the harm to patients and ultimately improve public health. Evaluating and monitoring drug safety (i.e., pharmacovigilance) involves analyzing an ever growing collection of spontaneous reports from health professionals, physicians, and pharmacists, and information voluntarily submitted by patients. In this scenario, facilitating analysis of such reports via automation has the potential to rapidly identify safety signals. Unfortunately, public resources for developing natural language models for this task are scant. We present PHEE, a novel dataset for pharmacovigilance comprising over 5000 annotated events from medical case reports and biomedical literature, making it the largest such public dataset to date. We describe the hierarchical event schema designed to provide coarse and fine-grained information about patients‚Äô demographics, treatments and (side) effects. Along with the discussion of the dataset, we present a thorough experimental evaluation of current state-of-the-art approaches for biomedical event extraction, point out their limitations, and highlight open challenges to foster future research in this area.",396
311,Artificial Intelligence,Byron Wallace,"June 6th, 2021",On the Impact of Random Seeds on the Fairness of Clinical Classifiers,https://doi.org/10.18653/v1/2021.naacl-main.299," Silvio Amir, Jan-Willem van de Meent, Byron C. Wallace. (2021). On the Impact of Random Seeds on the Fairness of Clinical Classifiers NAACL-HLT, 3808-3823. https://doi.org/10.18653/v1/2021.naacl-main.299","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III ‚Äî‚Äî the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of minority groups and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from stochasticity and small sample sizes.",397
312,Artificial Intelligence,Robin Walters,"June 16th, 2024",Improving Convergence and Generalization Using Parameter Symmetries,https://openreview.net/forum?id=L0r0GphlIL," Bo Zhao, Robert M. Gower, Robin Walters , Rose Yu. (2024). Improving Convergence and Generalization Using Parameter Symmetries ICLR. https://openreview.net/forum?id=L0r0GphlIL","In many neural networks, different values of the parameters may result in the same loss value. We show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization. The reviewers are unanimous that this is a good submission and that it should be accepted.",398
313,Artificial Intelligence,Robin Walters,"May 1st, 2024",Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution,https://openreview.net/forum?id=59oXyDTLJv," Rui Wang , Elyssa F. Hofgard, Hang Gao , Robin Walters , Tess E. Smidt. (2024). Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution ICML. https://openreview.net/forum?id=59oXyDTLJv","Modeling symmetry breaking is essential for understanding the fundamental changes in the behaviors and properties of physical systems, from microscopic particle interactions to macroscopic phenomena like fluid dynamics and cosmic structures. Thus, identifying sources of asymmetry is an important tool for understanding physical systems. In this paper, we focus on learning asymmetries of data using relaxed group convolutions. We provide both theoretical and empirical evidence that this flexible convolution technique allows the model to maintain the highest level of equivariance that is consistent with data and discover the subtle symmetry-breaking factors in various physical systems. We employ various relaxed group convolution architectures to uncover various symmetry-breaking factors that are interpretable and physically meaningful in different physical systems, including the phase transition of crystal structure, the isotropy and homogeneity breaking in turbulent flow, and the time-reversal symmetry breaking in pendulum systems. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",399
314,Artificial Intelligence,Robin Walters,"May 1st, 2024",Latent Space Symmetry Discovery,https://openreview.net/forum?id=qstt2OguvM," Jianke Yang, Nima Dehmamy, Robin Walters , Rose Yu. (2024). Latent Space Symmetry Discovery ICML. https://openreview.net/forum?id=qstt2OguvM","Equivariant neural networks require explicit knowledge of the symmetry group. Automatic symmetry discovery methods aim to relax this constraint and learn invariance and equivariance from data. However, existing symmetry discovery methods are limited to simple linear symmetries and cannot handle the complexity of real-world data. We propose a novel generative model, Latent LieGAN (LaLiGAN), which can discover symmetries of nonlinear group actions. It learns a mapping from the data space to a latent space where the symmetries become linear and simultaneously discovers symmetries in the latent space. Theoretically, we show that our model can express nonlinear symmetries under some conditions about the group action. Experimentally, we demonstrate that our method can accurately discover the intrinsic symmetry in high-dimensional dynamical systems. LaLiGAN also results in a well-structured latent space that is useful for downstream tasks including equation discovery and long-term forecasting. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",400
315,Artificial Intelligence,Robin Walters,"January 16th, 2024",Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D,https://openreview.net/forum?id=UulwvAU1W0," Haojie Huang, Owen Howell, Dian Wang , Xupeng Zhu, Robert Platt , Robin Walters . (2024). Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D ICLR. https://openreview.net/forum?id=UulwvAU1W0",FourTran is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks. The paper presents a novel approach in robotic manipulation using Wigner D-matrices for fast cross-correlations in 3D pick and place tasks.,401
316,Artificial Intelligence,Robin Walters,"July 4th, 2023",SEIL: Simulation-augmented Equivariant Imitation Learning,https://doi.org/10.1109/ICRA48891.2023.10161252," Mingxi Jia, Dian Wang , Guanang Su, David Klee, Xupeng Zhu, Robin Walters, Robert Platt. (2023). SEIL: Simulation-augmented Equivariant Imitation Learning ICRA, 1845-1851. https://doi.org/10.1109/ICRA48891.2023.10161252","Simulation-augmented Equivariant Imitation Learning (SEIL) combines a novel augmentation strategy of supplementing expert trajectories with simulated transitions. SEIL can learn non-trivial manipulation tasks within ten demonstrations and outperform the baselines by a significant margin. IEEE Conference will be held in London, UK, on July 4, 2023.",402
317,Artificial Intelligence,Robin Walters,"July 4th, 2023",Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection,https://doi.org/10.1109/ICRA48891.2023.10160728," Haojie Huang, Dian Wang , Xupeng Zhu, Robin Walters, Robert Platt. (2023). Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection ICRA, 3882-3888. https://doi.org/10.1109/ICRA48891.2023.10160728",The problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. Here we propose a novel method and neural network model that enables better grasp success rates. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions.,403
318,Artificial Intelligence,Robin Walters,"February 1st, 2023",Generative Adversarial Symmetry Discovery,https://doi.org/10.48550/arXiv.2302.00236," Jianke Yang, Robin Walters, Nima Dehmamy, Rose Yu. (2023). Generative Adversarial Symmetry Discovery CoRR, abs/2302.00236. https://doi.org/10.48550/arXiv.2302.00236","Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation groupSO(n), restricted Lorentz groupSO(1,3)+in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.",404
319,Artificial Intelligence,Robin Walters,"July 17th, 2022",Toward Compositional Generalization in Object-Oriented World Modeling,https://proceedings.mlr.press/v162/zhao22b.html," Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2022). Toward Compositional Generalization in Object-Oriented World Modeling ICML, 26841-26864. https://proceedings.mlr.press/v162/zhao22b.html","Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves soft but more efficient compositional generalization.",405
320,Artificial Intelligence,Robin Walters,"May 4th, 2022",Probabilistic Symmetry for Multi-Agent Dynamics,https://proceedings.mlr.press/v211/sun23a.html," Sophia Huiwen Sun, Robin Walters, Jinxi Li, Rose Yu. (2023). Probabilistic Symmetry for Multi-Agent Dynamics L4DC, 1231-1244. https://proceedings.mlr.press/v211/sun23a.html","Learning multi-agent dynamics is a core AI problem with broad applications in robotics and autonomous driving. While most existing works focus on deterministic prediction, producing probabilistic forecasts to quantify uncertainty and assess risks is critical for downstream decision-making tasks such as motion planning and collision avoidance. Multi-agent dynamics often contains internal symmetry. By leveraging symmetry, specifically rotation equivariance, we can improve not only the prediction accuracy but also uncertainty calibration. We introduce Energy Score, a proper scoring rule, to evaluate probabilistic predictions. We propose a novel deep dynamics model, Probabilistic Equivariant Continuous COnvolution (PECCO) for probabilistic prediction of multi-agent trajectories. PECCO extends equivariant continuous convolution to model the joint velocity distribution of multiple agents. It uses dynamics integration to propagate the uncertainty from velocity to position. On both synthetic and real-world datasets, PECCO shows significant improvements in accuracy and calibration compared to non-equivariant baselines.",406
321,Artificial Intelligence,Robin Walters,"January 1st, 2022",Learning Symmetric Embeddings for Equivariant World Models,https://proceedings.mlr.press/v162/park22a.html," Jung Yeon Park, Ondrej Biza, Linfeng Zhao, Jan-Willem van de Meent, Robin Walters. (2022). Learning Symmetric Embeddings for Equivariant World Models ICML, 17372-17389. https://proceedings.mlr.press/v162/park22a.html","Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.",407
322,Artificial Intelligence,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",408
323,Artificial Intelligence,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",409
324,Artificial Intelligence,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",410
325,Artificial Intelligence,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",411
326,Artificial Intelligence,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",412
327,Artificial Intelligence,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",413
328,Artificial Intelligence,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",414
329,Artificial Intelligence,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",415
330,Artificial Intelligence,Lawson Wong,"August 8th, 2024",A Hierarchical Framework for Robot Safety using Whole-body Tactile Sensors,https://doi.org/10.1109/ICRA57147.2024.10610834," Shuo Jiang, Lawson L. S. Wong. (2024). A Hierarchical Framework for Robot Safety using Whole-body Tactile Sensors ICRA, 8021-8028. https://doi.org/10.1109/ICRA57147.2024.10610834","Using tactile signal is a natural way to perceive potential dangers and safeguard robots. One possible method is to use full-body tactile sensors on the robot and perform safety maneuvers when dangerous stimuli are detected. The results showed that our system dramatically reduced the overall collision chance compared with several baselines, and intelligently handled current collisions. Our proposed framework is generalizable to a wide variety of robots, enabling them to predict and avoid dangerous collisions.",416
331,Artificial Intelligence,Lawson Wong,"August 8th, 2024",Robot Navigation in Unseen Environments using Coarse Maps,https://doi.org/10.1109/ICRA57147.2024.10611256," Chengguang Xu, Christopher Amato, Lawson L. S. Wong. (2024). Robot Navigation in Unseen Environments using Coarse Maps ICRA, 2932-2938. https://doi.org/10.1109/ICRA57147.2024.10611256","Can an autonomous robot directly navigate in previously unseen environments using coarse maps? We propose the Coarse Map Navigator (CMN), a navigation framework that can perform robot navigation in unseen environments. Empirical results demonstrate that CMN achieves high navigation success rates in unseen. environments. The study was presented at the 2024 IEEE International Conference on Robotics and Automation (ICRA) in Yokohama, Japan. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",417
332,Artificial Intelligence,Lawson Wong,"August 8th, 2024",Snake Robot with Tactile Perception Navigates on Large-scale Challenging Terrain,https://doi.org/10.1109/ICRA57147.2024.10611384," Shuo Jiang, Adarsh Salagame, Alireza Ramezani, Lawson L. S. Wong. (2024). Snake Robot with Tactile Perception Navigates on Large-scale Challenging Terrain ICRA, 5090-5096. https://doi.org/10.1109/ICRA57147.2024.10611384","This study proposed a locomotion control framework for snake robots that integrates tactile perception to augment their adaptability to various terrains. Our approach embraces a hierarchical reinforcement learning (HRL) architecture, wherein the high-level orchestrates global navigation strategies and the low-level uses curriculum learning for local navigation maneuvers. We evaluated the navigation performance of the snake robot in complex large-scale cave exploration with challenging terrains to exhibit improvements in motion efficiency.",418
333,Artificial Intelligence,Lawson Wong,"October 30th, 2023",Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing,http://papers.nips.cc/paper_files/paper/2023/hash/317470b3fde29f3bb8d6dee563afffc4-Abstract-Conference.html," Jung Yeon Park, Lawson L. S. Wong, Robin Walters. (2023). Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/317470b3fde29f3bb8d6dee563afffc4-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Main Conference Track Jung Yeon Park, Lawson Wong, Robin Walters Data over non-Euclidean manifolds, often discretized as surface meshes, naturally arise in computer graphics and biological and physical systems. In particular, solutions to partial differential equations (PDEs) over manifolds depend critically on the underlying geometry. While graph neural networks have been successfully applied to PDEs, they do not incorporate surface geometry and do not consider local gauge symmetries of the manifold. Alternatively, recent works on gauge equivariant convolutional and attentional architectures on meshes leverage the underlying geometry but underperform in modeling surface PDEs with complex nonlinear dynamics. To address these issues, we introduce a new gauge equivariant architecture using nonlinear message passing. Our novel architecture achieves higher performance than either convolutional or attentional networks on domains with highly complex and nonlinear dynamics. However, similar to the non-mesh case, design trade-offs favor convolutional, attentional, or message passing networks for different tasks; we investigate in which circumstances our message passing method provides the most benefit.",419
334,Artificial Intelligence,Lawson Wong,"December 26th, 2022",Active Tactile Exploration using Shape-Dependent Reinforcement Learning,https://doi.org/10.1109/IROS47612.2022.9982266," Shuo Jiang, Lawson L. S. Wong. (2022). Active Tactile Exploration using Shape-Dependent Reinforcement Learning IROS, 8995-9002. https://doi.org/10.1109/IROS47612.2022.9982266", Tactile signals provide rich information about objects via touch and are essential for a robot to perform dex-terous manipulation. Exploring actively via tactile perception collects important information about the workspace. The Shape-Belief Encoder leverages the newly collected contact points to update the surface model and guides future exploration. We validate the proposed algorithm on simulated and real robots. The paper will be presented at the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),420
335,Artificial Intelligence,Lawson Wong,"July 17th, 2022",Toward Compositional Generalization in Object-Oriented World Modeling,https://proceedings.mlr.press/v162/zhao22b.html," Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2022). Toward Compositional Generalization in Object-Oriented World Modeling ICML, 26841-26864. https://proceedings.mlr.press/v162/zhao22b.html","Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves soft but more efficient compositional generalization.",421
336,Artificial Intelligence,Lawson Wong,"November 18th, 2020",Hierarchical Robot Navigation in Novel Environments Using Rough 2-D Maps,https://corlconf.github.io/corl2020/paper_442/," Xu, Chengguang, Chris Amato and Lawson L. S. Wong. ‚ÄúHierarchical Robot Navigation in Novel Environments using Rough 2-D Maps.‚Äù ArXiv abs/2106.03665 (2021): n. pag.",Abstract,422
337,Artificial Intelligence,Lawson Wong,"October 11th, 2020",Deep Imitation Learning for Bimanual Robotic Manipulation,https://proceedings.neurips.cc/paper/2020/hash/18a010d2a9813e91907ce88cd9143fdf-Abstract.html," Xie, Fan, A. M. Masum Bulbul Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson L. S. Wong and Rose Yu. ‚ÄúDeep Imitation Learning for Bimanual Robotic Manipulation.‚Äù ArXiv abs/2010.05134 (2020): n. pag.","Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) Fan Xie, Alexander Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson Wong, Rose Yu We present a deep imitation learning framework for robotic bimanual manipulation in a continuous state-action space. A core challenge is to generalize the manipulation skills to objects in different locations. We hypothesize that modeling the relational information in the environment can significantly improve generalization. To achieve this, we propose to (i) decompose the multi-modal dynamics into elemental movement primitives, (ii) parameterize each primitive using a recurrent graph neural network to capture interactions, and (iii) integrate a high-level planner that composes primitives sequentially and a low-level controller to combine primitive dynamics and inverse kinematics control. Our model is a deep, hierarchical, modular architecture. Compared to baselines, our model generalizes better and achieves higher success rates on several simulated bimanual robotic manipulation tasks. We open source the code for simulation, data, and models at: https://github.com/Rose-STL-Lab/HDR-IL.",423
338,Computational Biology,Kylie Ariel Bemis,"February 6th, 2023",A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images,https://doi.org/10.1093/bioinformatics/btad067," Dan Guo, Melanie Christine F√∂ll, Kylie A. Bemis, Olga Vitek. (2023). A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images Bioinform., 39. https://doi.org/10.1093/bioinformatics/btad067","Motivation Mass Spectrometry Imaging (MSI) analyzes complex biological samples such as tissues. It simultaneously characterizes the ions present in the tissue in the form of mass spectra, and the spatial distribution of the ions across the tissue in the form of ion images. Unsupervised clustering of ion images facilitates the interpretation in the spectral domain, by identifying groups of ions with similar spatial distributions. Unfortunately, many current methods for clustering ion images ignore the spatial features of the images, and are therefore unable to learn these features for clustering purposes. Alternative methods extract spatial features using deep neural networks pre-trained on natural image tasks; however, this is often inadequate since ion images are substantially noisier than natural images. Results We contribute a deep clustering approach for ion images that accounts for both spatial contextual features and noise. In evaluations on a simulated dataset and on four experimental datasets of different tissue types, the proposed method grouped ions from the same source into a same cluster more frequently than existing methods. We further demonstrated that using ion image clustering as a pre-processing step facilitated the interpretation of a subsequent spatial segmentation as compared to using either all the ions or one ion at a time. As a result, the proposed approach facilitated the interpretability of MSI data in both the spectral domain and the spatial domain. Availabilityand implementation The data and code are available at https://github.com/DanGuo1223/mzClustering . Supplementary information Supplementary data are available at Bioinformatics online. Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",424
339,Computational Biology,Kylie Ariel Bemis,"August 19th, 2019",Unsupervised segmentation of mass spectrometric ion images characterizes morphology of tissues,http://doi.org/10.1093/bioinformatics/btz345," D. Guo, K. A. Bemis, C. Rawlins, J. Agar, and O. Vitek. ‚ÄúUnsupervised segmentation of mass spectrometric ion images characterizes morphology of tissues.‚Äù Bioinformatics. 2019","Motivation Mass spectrometry imaging (MSI) characterizes the spatial distribution of ions in complex biological samples such as tissues. Since many tissues have complex morphology, treatments and conditions often affect the spatial distribution of the ions in morphology-specific ways. Evaluating the selectivity and the specificity of ion localization and regulation across morphology types is biologically important. However, MSI lacks algorithms for segmenting images at both single-ion and spatial resolution. Results This article contributes spatial-Dirichlet Gaussian mixture model (DGMM), an algorithm and a workflow for the analyses of MSI experiments, that detects components of single-ion images with homogeneous spatial composition. The approach extends DGMMs to account for the spatial structure of MSI. Evaluations on simulated and experimental datasets with diverse MSI workflows demonstrated that spatial-DGMM accurately segments ion images, and can distinguish ions with homogeneous and heterogeneous spatial distribution. We also demonstrated that the extracted spatial information is useful for downstream analyses, such as detecting morphology-specific ions, finding groups of ions with similar spatial patterns, and detecting changes in chemical composition of tissues between conditions. Availability and implementation The data and code are available at https://github.com/Vitek-Lab/IonSpattern . Supplementary information Supplementary data are available at Bioinformatics online. Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",425
340,Computational Biology,Kylie Ariel Bemis,"August 19th, 2019",Statistical detection of differentially abundant ions in mass spectrometry-based imaging experiments with complex designs,http://doi.org/10.1016/j.ijms.2018.07.006," K. A. Bemis, D. Guo, A. Harry, M. Thomas, I. Lanekoff, M. Stenzel-Poore, S. Stevens, J. Laskin, and O. Vitek. ‚ÄúStatistical detection of differentially abundant ions in mass spectrometry-based imaging experiments with complex designs.‚Äù International Journal of Mass Spectrometry. 2019.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",426
341,Computational Biology,Benjamin Gyori,"March 14th, 2023",Prediction and curation of missing biomedical identifier mappings with Biomappings,https://doi.org/10.1093/bioinformatics/btad130," Charles Tapley Hoyt, Amelia L. Hoyt, Benjamin M. Gyori. (2023). Prediction and curation of missing biomedical identifier mappings with Biomappings Bioinform., 39. https://doi.org/10.1093/bioinformatics/btad130","Motivation Biomedical identifier resources (such as ontologies, taxonomies, and controlled vocabularies) commonly overlap in scope and contain equivalent entries under different identifiers. Maintaining mappings between these entries is crucial for interoperability and the integration of data and knowledge. However, there are substantial gaps in available mappings motivating their semi-automated curation. Results Biomappings implements a curation workflow for missing mappings which combines automated prediction with human-in-the-loop curation. It supports multiple prediction approaches and provides a web-based user interface for reviewing predicted mappings for correctness, combined with automated consistency checking. Predicted and curated mappings are made available in public, version-controlled resource files on GitHub. Biomappings currently makes available 9274 curated mappings and 40¬†691 predicted ones, providing previously missing mappings between widely used identifier resources covering small molecules, cell lines, diseases, and other concepts. We demonstrate the value of Biomappings on case studies involving predicting and curating missing mappings among cancer cell lines as well as small molecules tested in clinical trials. We also present how previously missing mappings curated using Biomappings were contributed back to multiple widely used community ontologies. Availability and implementation The data and code are available under the CC0 and MIT licenses at https://github.com/biopragmatics/biomappings . Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",427
342,Computational Biology,Benjamin Gyori,"March 6th, 2023",NDEx IQuery: a multi-method network gene set analysis leveraging the Network Data Exchange,https://doi.org/10.1093/bioinformatics/btad118," Rudolf T. Pillich, Jing Chen, Christopher Churas, Dylan Fong, Benjamin M. Gyori, Trey Ideker, Klas Karis, Sophie N. Liu, Keiichiro Ono, Alexander R. Pico, Dexter Pratt. (2023). NDEx IQuery: a multi-method network gene set analysis leveraging the Network Data Exchange Bioinform., 39. https://doi.org/10.1093/bioinformatics/btad118","Motivation The investigation of sets of genes using biological pathways is a common task for researchers and is supported by a wide variety of software tools. This type of analysis generates hypotheses about the biological processes that are active or modulated in a specific experimental context. Results The Network Data Exchange Integrated Query (NDEx IQuery) is a new tool for network and pathway-based gene set interpretation that complements or extends existing resources. It combines novel sources of pathways, integration with Cytoscape, and the ability to store and share analysis results. The NDEx IQuery web application performs multiple gene set analyses based on diverse pathways and networks stored in NDEx. These include curated pathways from WikiPathways and SIGNOR, published pathway figures from the last 27‚Äâyears, machine-assembled networks using the INDRA system, and the new NCI-PID v2.0, an updated version of the popular NCI Pathway Interaction Database. NDEx IQuery‚Äôs integration with MSigDB and cBioPortal now provides pathway analysis in the context of these two resources. Availability and implementation NDEx IQuery is available at https://www.ndexbio.org/iquery and is implemented in Javascript and Java. Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",428
343,Computational Biology,Benjamin Gyori,"August 14th, 2022",ChemicalX: A Deep Learning Library for Drug Pair Scoring,https://doi.org/10.1145/3534678.3539023," Benedek Rozemberczki, Charles Tapley Hoyt, Anna Gogleva, Piotr Grabowski, Klas Karis, Andrej Lamov, Andriy Nikolov, Sebastian Nilsson, Micha√´l Ughetto, Yu Wang , Tyler Derr, Benjamin M. Gyori. (2022). ChemicalX: A Deep Learning Library for Drug Pair Scoring KDD, 3819-3828. https://doi.org/10.1145/3534678.3539023","In this paper, we introduce ChemicalX, a PyTorch-based deep learning library designed for providing a range of state of the art models to solve the drug pair scoring task. The primary objective of the library is to make deep drug pair scoring models accessible to machine learning researchers and practitioners in a streamlined framework. The design of ChemicalX reuses existing high level model training utilities, geometric deep learning, and deep chemistry layers from the PyTorch ecosystem. Our system provides neural network layers, custom pair scoring architectures, data loaders, and batch iterators for end users. We showcase these features with example code snippets and case studies to highlight the characteristics of ChemicalX. A range of experiments on real world drug-drug interaction, polypharmacy side effect, and combination synergy prediction tasks demonstrate that the models available in ChemicalX are effective at solving the pair scoring task. Finally, we show that ChemicalX could be used to train and score machine learning models on large drug pair datasets with hundreds of thousands of compounds on commodity hardware.",429
344,Computational Biology,Wengong Jin,"December 10th, 2024",Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer,http://papers.nips.cc/paper_files/paper/2024/hash/e6114e62fdb36d6d91ff43334e763a0e-Abstract-Conference.html," Tinglin Huang, Zhenqiao Song, Rex Ying, Wengong Jin. (2024). Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/e6114e62fdb36d6d91ff43334e763a0e-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Tinglin Huang, Zhenqiao Song, Rex Ying, Wengong Jin Nucleic acid-based drugs like aptamers have recently demonstrated great therapeutic potential. However, experimental platforms for aptamer screening are costly, and the scarcity of labeled data presents a challenge for supervised methods to learn protein-aptamer binding. To this end, we develop an unsupervised learning approach based on the predicted pairwise contact map between a protein and a nucleic acid and demonstrate its effectiveness in protein-aptamer binding prediction. Our model is based on FAFormer, a novel equivariant transformer architecture that seamlessly integrates frame averaging (FA) within each transformer block. This integration allows our model to infuse geometric information into node features while preserving the spatial semantics of coordinates, leading to greater expressive power than standard FA models. Our results show that FAFormer outperforms existing equivariant models in contact map prediction across three protein complex datasets, with over 10% relative improvement. Moreover, we curate five real-world protein-aptamer interaction datasets and show that the contact map predicted by FAFormer serves as a strong binding indicator for aptamer screening.",430
345,Computational Biology,Wengong Jin,"May 1st, 2024",Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates,https://openreview.net/forum?id=ATvN9JnqZ8," Zhenqiao Song, Yunlong Zhao , Wenxian Shi, Wengong Jin, Yang Yang , Lei Li . (2024). Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates ICML. https://openreview.net/forum?id=ATvN9JnqZ8","Enzymes are genetically encoded biocatalysts capable of accelerating chemical reactions. How can we automatically design functional enzymes? In this paper, we propose EnzyGen, an approach to learn a unified model to design enzymes across all functional families. Our key idea is to generate an enzyme's amino acid sequence and their three-dimensional (3D) coordinates based on functionally important sites and substrates corresponding to a desired catalytic function. These sites are automatically mined from enzyme databases. EnzyGen consists of a novel interleaving network of attention and neighborhood equivariant layers, which captures both long-range correlation in an entire protein sequence and local influence from nearest amino acids in 3D space. To learn the generative model, we devise a joint training objective, including a sequence generation loss, a position prediction loss and an enzyme-substrate interaction loss. We further construct EnzyBench, a dataset with 3157 enzyme families, covering all available enzymes within the protein data bank (PDB). Experimental results show that our EnzyGen consistently achieves the best performance across all 323 testing families, surpassing the best baseline by 10.79% in terms of substrate binding affinity. These findings demonstrate EnzyGen's superior capability in designing well-folded and effective enzymes binding to specific substrates with high affinities. Our code, model and dataset are provided at https://github.com/LeiLiLab/EnzyGen . OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",431
346,Computational Biology,Wengong Jin,"May 1st, 2024",RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching,https://openreview.net/forum?id=jxvqvZLBuU," Divya Nori, Wengong Jin. (2024). RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching ICML. https://openreview.net/forum?id=jxvqvZLBuU","The growing significance of RNA engineering in diverse biological applications has spurred interest in developing AI methods for structure-based RNA design. While diffusion models have excelled in protein design, adapting them for RNA presents new challenges due to RNA's conformational flexibility and the computational cost of fine-tuning large structure prediction models. To this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA sequence-structure design. Its denoising network integrates an RNA inverse folding model and a pre-trained RosettaFold2NA network for generation of RNA sequences and structures. The integration of inverse folding in the structure denoising process allows us to simplify training by fixing the structure prediction network. We further enhance the inverse folding model by conditioning it on inferred conformational ensembles to model dynamic RNA conformations. Evaluation on protein-conditioned RNA structure and sequence generation tasks demonstrates RNAFlow's advantage over existing RNA design methods. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",432
347,Computational Biology,Wengong Jin,"May 1st, 2024",SurfPro: Functional Protein Design Based on Continuous Surface,https://openreview.net/forum?id=a8QpoEJCRI," Zhenqiao Song, Tinglin Huang, Lei Li , Wengong Jin. (2024). SurfPro: Functional Protein Design Based on Continuous Surface ICML. https://openreview.net/forum?id=a8QpoEJCRI","How can we design proteins with desired functions? We are motivated by a chemical intuition that both geometric structure and biochemical properties are critical to a protein's function. In this paper, we propose SurfPro, a new method to generate functional proteins given a desired surface and its associated biochemical properties. SurfPro comprises a hierarchical encoder that progressively models the geometric shape and biochemical features of a protein surface, and an autoregressive decoder to produce an amino acid sequence. We evaluate SurfPro on a standard inverse folding benchmark CATH 4.2 and two functional protein design tasks: protein binder design and enzyme design. Our SurfPro consistently surpasses previous state-of-the-art inverse folding methods, achieving a recovery rate of 57.78% on CATH 4.2 and higher success rates in terms of protein-protein binding and enzyme-substrate interaction scores OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",433
348,Computational Biology,Predrag Radivojac,"June 28th, 2024",An algorithm for decoy-free false discovery rate estimation in XL-MS/MS proteomics,https://doi.org/10.1093/bioinformatics/btae233," Yisu Peng, Shantanu Jain, Predrag Radivojac. (2024). An algorithm for decoy-free false discovery rate estimation in XL-MS/MS proteomics Bioinform., 40, i428-i436. https://doi.org/10.1093/bioinformatics/btae233","Motivation Cross-linking tandem mass spectrometry (XL-MS/MS) is an established analytical platform used to determine distance constraints between residues within a protein or from physically interacting proteins, thus improving our understanding of protein structure and function. To aid biological discovery with XL-MS/MS, it is essential that pairs of chemically linked peptides be accurately identified, a process that requires: (i) database search, that creates a ranked list of candidate peptide pairs for each experimental spectrum and (ii) false discovery rate (FDR) estimation, that determines the probability of a false match in a group of top-ranked peptide pairs with scores above a given threshold. Currently, the only available FDR estimation mechanism in XL-MS/MS is the target-decoy approach (TDA). However, despite its simplicity, TDA has both theoretical and practical limitations that impact the estimation accuracy and increase run time over potential decoy-free approaches (DFAs). Results We introduce a novel decoy-free framework for FDR estimation in XL-MS/MS. Our approach relies on multi-sample mixtures of skew normal distributions, where the latent components correspond to the scores of correct peptide pairs (both peptides identified correctly), partially incorrect peptide pairs (one peptide identified correctly, the other incorrectly), and incorrect peptide pairs (both peptides identified incorrectly). To learn these components, we exploit the score distributions of first- and second-ranked peptide-spectrum matches for each experimental spectrum and subsequently estimate FDR using a novel expectation-maximization algorithm with constraints. We evaluate the method on ten datasets and provide evidence that the proposed DFA is theoretically sound and a viable alternative to TDA owing to its good performance in terms of accuracy, variance of estimation, and run time. Availability and implementation https://github.com/shawn-peng/xlms Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",434
349,Computational Biology,Predrag Radivojac,"March 4th, 2020",Fast nonparametric estimation of class proportions in the positive-unlabeled classification setting,https://ojs.aaai.org//index.php/AAAI/article/view/6151," Zeiberg, D., Jain, S., & Radivojac, P. (2020). Fast Nonparametric Estimation of Class Proportions in the Positive-Unlabeled Classification Setting. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 6729-6736. https://doi.org/10.1609/aaai.v34i04.6151","Abstract Estimating class proportions has emerged as an important direction in positive-unlabeled learning. Well-estimated class priors are key to accurate approximation of posterior distributions and are necessary for the recovery of true classification performance. While significant progress has been made in the past decade, there remains a need for accurate strategies that scale to big data. Motivated by this need, we propose an intuitive and fast nonparametric algorithm to estimate class proportions. Unlike any of the previous methods, our algorithm uses a sampling strategy to repeatedly (1) draw an example from the set of positives, (2) record the minimum distance to any of the unlabeled examples, and (3) remove the nearest unlabeled example. We show that the point of sharp increase in the recorded distances corresponds to the desired proportion of positives in the unlabeled set and train a deep neural network to identify that point. Our distance-based algorithm is evaluated on forty datasets and compared to all currently available methods. We provide evidence that this new approach results in the most accurate performance and can be readily used on large datasets.",435
350,Computational Biology,Predrag Radivojac,"July 20th, 2019",A new class of metrics for learning on real-valued and structured data,https://dl.acm.org/doi/abs/10.1007/s10618-019-00622-6," Yang R, Jiang Y, Mathews S, Housworth EA, Hahn MW, Radivojac P. A new class of metrics for learning on real-valued and structured data. Data Min. Knowl. Disc. (2019) 33(4): 995-1016.","We propose a new class of metrics on sets, vectors, and functions that can be used in various stages of data mining, including exploratory data analysis, learning, and result interpretation. These new distance functions unify and generalize some of the popular metrics, such as the Jaccard and bag distances on sets, Manhattan distance on vector spaces, and Marczewski-Steinhaus distance on integrable functions. We prove that the new metrics are complete and show useful relationships with f-divergences for probability distributions. To further extend our approach to structured objects such as ontologies, we introduce information-theoretic metrics on directed acyclic graphs drawn according to a fixed probability distribution. We conduct empirical investigation to demonstrate the effectiveness on real-valued, high-dimensional, and structured data. Overall, the new metrics compare favorably to multiple similarity and dissimilarity functions traditionally used in data mining, including the Minkowski ($$L^p$$Lp) family, the fractional $$L^p$$Lp family, two f-divergences, cosine distance, and two correlation coefficients. We provide evidence that they are particularly appropriate for rapid processing of high-dimensional and structured data in distance-based learning.",436
351,Computational Biology,Predrag Radivojac,"June 14th, 2019",Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007112," Pagel KA, Antaki D, Lian A, Mort M, Cooper DN, Sebat J, Iakoucheva LM, Mooney SD, Radivojac P. Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome. PLoS Comput. Biol. (2019) 15(6): e1007112.","Machine learning method, MutPred-Indel, predicts pathogenicity and identifies types of functional residues impacted by non-frameshifting insertion/deletion variation. The model shows good predictive performance as well as the ability to identify impacted structural and functional residues including secondary structure, intrinsic disorder, metal and macromolecular binding, post-translational modifications and allosteric sites.",437
352,Computational Biology,Predrag Radivojac,"March 14th, 2019",Estimating classification accuracy in positive-unlabeled learning: characterization and correction strategies,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6417800/," Ramola R, Jain S, Radivojac P. Estimating classification accuracy in positive-unlabeled learning: characterization and correction strategies. Pac. Symp. Biocomput. (2019) 24: 124-135.","Abstract Accurately estimating performance accuracy of machine learning classifiers is of fundamental importance in biomedical research with potentially societal consequences upon the deployment of best-performing tools in everyday life. Although classification has been extensively studied over the past decades, there remain understudied problems when the training data violate the main statistical assumptions relied upon for accurate learning and model characterization. This particularly holds true in the open world setting where observations of a phenomenon generally guarantee its presence but the absence of such evidence cannot be interpreted as the evidence of its absence. Learning from such data is often referred to as positive-unlabeled learning, a form of semi-supervised learning where all labeled data belong to one (say, positive) class. To improve the best practices in the field, we here study the quality of estimated performance in positive-unlabeled learning in the biomedical domain. We provide evidence that such estimates can be wildly inaccurate, depending on the fraction of positive examples in the unlabeled data and the fraction of negative examples mislabeled as positives in the labeled data. We then present correction methods for four such measures and demonstrate that the knowledge or accurate estimates of class priors in the unlabeled data and noise in the labeled data are sufficient for the recovery of true classification performance. We provide theoretical support as well as empirical evidence for the efficacy of the new performance estimation methods. Keywords: Positive-unlabeled learning, AlphaMax, Matthews correlation, accuracy estimation",438
353,Computational Biology,Predrag Radivojac,"July 20th, 2018",On whom should I perform this lab test next? An active feature elicitation approach,https://www.ijcai.org/proceedings/2018/486," Natarajan S, Das S, Ramanan N, Kunapuli G, Radivojac P. On whom should I perform this lab test next? An active feature elicitation approach. Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 3498-3505, Stockholm, Sweden, July 2018.","Copyright ¬© 2025,",439
354,Computational Biology,Predrag Radivojac,"July 20th, 2018",Enumerating consistent sub-graphs of directed acyclic graphs: an insight into biomedical ontologies,https://www.ncbi.nlm.nih.gov/pubmed/29949985," Peng Y, Jiang Y, Radivojac P. Enumerating consistent sub-graphs of directed acyclic graphs: an insight into biomedical ontologies. Bioinformatics (2018) 34(13): i313-i322.","Abstract Motivation: Modern problems of concept annotation associate an object of interest (gene, individual, text document) with a set of interrelated textual descriptors (functions, diseases, topics), often organized in concept hierarchies or ontologies. Most ontology can be seen as directed acyclic graphs (DAGs), where nodes represent concepts and edges represent relational ties between these concepts. Given an ontology graph, each object can only be annotated by a consistent sub-graph; that is, a sub-graph such that if an object is annotated by a particular concept, it must also be annotated by all other concepts that generalize it. Ontologies therefore provide a compact representation of a large space of possible consistent sub-graphs; however, until now we have not been aware of a practical algorithm that can enumerate such annotation spaces for a given ontology. Results: We propose an algorithm for enumerating consistent sub-graphs of DAGs. The algorithm recursively partitions the graph into strictly smaller graphs until the resulting graph becomes a rooted tree (forest), for which a linear-time solution is computed. It then combines the tallies from graphs created in the recursion to obtain the final count. We prove the correctness of this algorithm, propose several practical accelerations, evaluate it on random graphs and then apply it to characterize four major biomedical ontologies. We believe this work provides valuable insights into the complexity of concept annotation spaces and its potential influence on the predictability of ontological annotation. Availability and implementation: https://github.com/shawn-peng/counting-consistent-sub-DAG. Supplementary information: Supplementary data are available at Bioinformatics online.",440
355,Computational Biology,Predrag Radivojac,"July 15th, 2017",When loss-of-function is loss of function: assessing mutational signatures and impact of loss-of-function genetic variants,https://www.ncbi.nlm.nih.gov/pubmed/28882004," Pagel KA, Pejaver V, Lin GN, Nam H, Mort M, Cooper DN, Sebat J, Iakoucheva LM, Mooney SD, Radivojac P. When loss-of-function is loss of function: assessing mutational signatures and impact of loss-of-function genetic variants. Bioinformatics (2017) 33(14): i389-i398.","Abstract Motivation: Loss-of-function genetic variants are frequently associated with severe clinical phenotypes, yet many are present in the genomes of healthy individuals. The available methods to assess the impact of these variants rely primarily upon evolutionary conservation with little to no consideration of the structural and functional implications for the protein. They further do not provide information to the user regarding specific molecular alterations potentially causative of disease. Results: To address this, we investigate protein features underlying loss-of-function genetic variation and develop a machine learning method, MutPred-LOF, for the discrimination of pathogenic and tolerated variants that can also generate hypotheses on specific molecular events disrupted by the variant. We investigate a large set of human variants derived from the Human Gene Mutation Database, ClinVar and the Exome Aggregation Consortium. Our prediction method shows an area under the Receiver Operating Characteristic curve of 0.85 for all loss-of-function variants and 0.75 for proteins in which both pathogenic and neutral variants have been observed. We applied MutPred-LOF to a set of 1142 de novo vari3ants from neurodevelopmental disorders and find enrichment of pathogenic variants in affected individuals. Overall, our results highlight the potential of computational tools to elucidate causal mechanisms underlying loss of protein function in loss-of-function variants. Availability and implementation: http://mutpred.mutdb.org. Contact: predrag@indiana.edu.",441
356,Computational Biology,Predrag Radivojac,"February 20th, 2017",Recovering true classifier performance in positive-unlabeled learning,https://arxiv.org/abs/1702.00518," Jain S, White M, Radivojac P. Recovering true classifier performance in positive-unlabeled learning. AAAI Conference on Artificial Intelligence, AAAI 2017, pp. 2066-2072, San Francisco, California, U.S.A., February 2017.","A common approach in positive-unlabeled learning is to train a classification model between labeled and unlabeled data. This strategy is in fact known to give an optimal classifier under mild conditions; however, it results in biased empirical estimates of the classifier performance. In this work, we show that the typically used performance measures such as the receiver operating characteristic curve, or the precision-recall curve obtained on such data can be corrected with the knowledge of class priors; i.e., the proportions of the positive and negative examples in the unlabeled data. We extend the results to a noisy setting where some of the examples labeled positive are in fact negative and show that the correction also requires the knowledge of the proportion of noisy examples in the labeled positives. Using state-of-the-art algorithms to estimate the positive class prior and the proportion of noise, we experimentally evaluate two correction approaches and demonstrate their efficacy on real-life data.",442
357,Computational Biology,Predrag Radivojac,"December 1st, 2016",Estimating the class prior and posterior from noisy positives and unlabeled data,https://papers.nips.cc/paper/6168-estimating-the-class-prior-and-posterior-from-noisy-positives-and-unlabeled-data," Jain S, White M, Radivojac P. Estimating the class prior and posterior from noisy positives and unlabeled data. Advances in Neural Information Processing Systems, NIPS 2016, pp. 2693-2701, Barcelona, Spain, December 2016.","Part of Advances in Neural Information Processing Systems 29 (NIPS 2016) Shantanu Jain, Martha White, Predrag Radivojac We develop a classification algorithm for estimating posterior distributions from positive-unlabeled data, that is robust to noise in the positive labels and effective for high-dimensional data. In recent years, several algorithms have been proposed to learn from positive-unlabeled data; however, many of these contributions remain theoretical, performing poorly on real high-dimensional data that is typically contaminated with noise. We build on this previous work to develop two practical classification algorithms that explicitly model the noise in the positive labels and utilize univariate transforms built on discriminative classifiers. We prove that these univariate transforms preserve the class prior, enabling estimation in the univariate space and avoiding kernel density estimation for high-dimensional data. The theoretical development and parametric and nonparametric algorithms proposed here constitute an important step towards wide-spread use of robust classification algorithms for positive-unlabeled data.",443
358,Computational Biology,Predrag Radivojac,"August 26th, 2016",The loss and gain of functional amino acid residues is a common mechanism causing human inherited disease.,https://www.ncbi.nlm.nih.gov/pubmed/27564311," Lugo-Martinez J, Pejaver V, Pagel KA, Jain S, Mort M, Cooper DN, Mooney SD, Radivojac P. The loss and gain of functional amino acid residues is a common mechanism causing human inherited disease. PLoS Comput. Biol. (2016) 12(8): e1005091.","Abstract Elucidating the precise molecular events altered by disease-causing genetic variants represents a major challenge in translational bioinformatics. To this end, many studies have investigated the structural and functional impact of amino acid substitutions. Most of these studies were however limited in scope to either individual molecular functions or were concerned with functional effects (e.g. deleterious vs. neutral) without specifically considering possible molecular alterations. The recent growth of structural, molecular and genetic data presents an opportunity for more comprehensive studies to consider the structural environment of a residue of interest, to hypothesize specific molecular effects of sequence variants and to statistically associate these effects with genetic disease. In this study, we analyzed data sets of disease-causing and putatively neutral human variants mapped to protein 3D structures as part of a systematic study of the loss and gain of various types of functional attribute potentially underlying pathogenic molecular alterations. We first propose a formal model to assess probabilistically function-impacting variants. We then develop an array of structure-based functional residue predictors, evaluate their performance, and use them to quantify the impact of disease-causing amino acid substitutions on catalytic activity, metal binding, macromolecular binding, ligand binding, allosteric regulation and post-translational modifications. We show that our methodology generates actionable biological hypotheses for up to 41% of disease-causing genetic variants mapped to protein structures suggesting that it can be reliably used to guide experimental validation. Our results suggest that a significant fraction of disease-causing human variants mapping to protein structures are function-altering both in the presence and absence of stability disruption.",444
359,Computational Biology,Olga Vitek,"June 30th, 2023",Optimal adjustment sets for causal query estimation in partially observed biomolecular networks,https://doi.org/10.1093/bioinformatics/btad270," Sara Mohammad Taheri, Vartika Tewari, Rohan Kapre, Ehsan Rahiminasab, Karen Sachs, Charles Tapley Hoyt, Jeremy Zucker, Olga Vitek. (2023). Optimal adjustment sets for causal query estimation in partially observed biomolecular networks Bioinform., 39, 494-503. https://doi.org/10.1093/bioinformatics/btad270","Causal query estimation in biomolecular networks commonly selects a ‚Äòvalid adjustment set‚Äô, i.e. a subset of network variables that eliminates the bias of the estimator. A same query may have multiple valid adjustment sets, each with a different variance. When networks are partially observed, current methods use graph-based criteria to find an adjustment set that minimizes asymptotic variance. Unfortunately, many models that share the same graph topology, and therefore same functional dependencies, may differ in the processes that generate the observational data. In these cases, the topology-based criteria fail to distinguish the variances of the adjustment sets. This deficiency can lead to sub-optimal adjustment sets, and to miss-characterization of the effect of the intervention. We propose an approach for deriving ‚Äòoptimal adjustment sets‚Äô that takes into account the nature of the data, bias and finite-sample variance of the estimator, and cost. It empirically learns the data generating processes from historical experimental data, and characterizes the properties of the estimators by simulation. We demonstrate the utility of the proposed approach in four biomolecular Case studies with different topologies and different data generation processes. The implementation and reproducible Case studies are at https://github.com/srtaheri/OptimalAdjustmentSet . Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",445
360,Computational Biology,Olga Vitek,"February 6th, 2023",A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images,https://doi.org/10.1093/bioinformatics/btad067," Dan Guo, Melanie Christine F√∂ll, Kylie A. Bemis, Olga Vitek. (2023). A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images Bioinform., 39. https://doi.org/10.1093/bioinformatics/btad067","Motivation Mass Spectrometry Imaging (MSI) analyzes complex biological samples such as tissues. It simultaneously characterizes the ions present in the tissue in the form of mass spectra, and the spatial distribution of the ions across the tissue in the form of ion images. Unsupervised clustering of ion images facilitates the interpretation in the spectral domain, by identifying groups of ions with similar spatial distributions. Unfortunately, many current methods for clustering ion images ignore the spatial features of the images, and are therefore unable to learn these features for clustering purposes. Alternative methods extract spatial features using deep neural networks pre-trained on natural image tasks; however, this is often inadequate since ion images are substantially noisier than natural images. Results We contribute a deep clustering approach for ion images that accounts for both spatial contextual features and noise. In evaluations on a simulated dataset and on four experimental datasets of different tissue types, the proposed method grouped ions from the same source into a same cluster more frequently than existing methods. We further demonstrated that using ion image clustering as a pre-processing step facilitated the interpretation of a subsequent spatial segmentation as compared to using either all the ions or one ion at a time. As a result, the proposed approach facilitated the interpretability of MSI data in both the spectral domain and the spatial domain. Availabilityand implementation The data and code are available at https://github.com/DanGuo1223/mzClustering . Supplementary information Supplementary data are available at Bioinformatics online. Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",446
361,Computational Biology,Olga Vitek,"August 12th, 2022",Effective Use of Likert Scales in Visualization Evaluations: A Systematic Review,https://doi.org/10.1111/cgf.14521," Laura South, David Saffo, Olga Vitek, Cody Dunne, Michelle A. Borkin. (2022). Effective Use of Likert Scales in Visualization Evaluations: A Systematic Review Comput. Graph. Forum, 41, 43-55. https://doi.org/10.1111/cgf.14521","Abstract Likert scales are often used in visualization evaluations to produce quantitative estimates of subjective attributes, such as ease of use or aesthetic appeal. However, the methods used to collect, analyze, and visualize data collected with Likert scales are inconsistent among evaluations in visualization papers. In this paper, we examine the use of Likert scales as a tool for measuring subjective response in a systematic review of 134 visualization evaluations published between 2009 and 2019. We find that papers with both objective and subjective measures do not hold the same reporting and analysis standards for both aspects of their evaluation, producing less rigorous work for the subjective qualities measured by Likert scales. Additionally, we demonstrate that many papers are inconsistent in their interpretations of Likert data as discrete or continuous and may even sacrifice statistical power by applying nonparametric tests unnecessarily. Finally, we identify instances where key details about Likert item construction with the potential to bias participant responses are omitted from evaluation methodology reporting, inhibiting the feasibility and reliability of future replication studies. We summarize recommendations from other fields for best practices with Likert data in visualization evaluations, based on the results of our survey. A full copy of this paper and all supplementary material are available at https://osf.io/exbz8/ .",447
362,Computer Science Education,Adeel Bhutta,"February 13th, 2020",Selective Subtraction for Handheld Cameras,https://doi.org/10.1109/ACCESS.2020.2973655," Adeel A. Bhutta, Imran Nazir Junejo, Hassan Foroosh. (2020). Selective Subtraction for Handheld Cameras IEEE Access, 8, 36556-36568. https://doi.org/10.1109/ACCESS.2020.2973655"," background subtraction techniques model the background of the scene using the stationarity property. Most moving objects become foreground indiscriminately, except in dynamic scenes. We introduce a novel concept of background as the objects other than the foreground. The reference plane is defined a moving object or human walk and the projective depth is defined as the distance between the reference plane and other objects in the scene. We show that this technique is relatively immune to camera motion and performs well for hand-held cameras. It is potentially more powerful than standard methods because of its flexibility of making it possible to select in real-time what to filter out as background. The technique performs better than standard background subtractions without the need for training, camera calibration, disparity map estimation or special camera configurations.",448
363,Computer Science Education,Ryan Bockmon,"December 5th, 2023",Investigating Themes of Student-Generated Analogies,https://doi.org/10.1145/3576882.3617914," Colton Harper, Ryan Bockmon, Stephen Cooper. (2023). Investigating Themes of Student-Generated Analogies CompEd (1), 64-70. https://doi.org/10.1145/3576882.3617914","Student-generated analogies hold potential in facilitating understanding of abstract computing concepts, as they exercise valuable computing skills, such as abstraction, re-representation, and relational reasoning. Helping students develop their own analogies is difficult, and limited research exists on scaffolding for student-generated analogies in computing education and STEM education more broadly. This exploratory study examines an open-ended student-generated analogy process, for the concept of variable scope within an introductory computer science course. The primary goal of this study is to lay the foundation for scaffolding strategies to more fully realize the potential of student-generated analogy as an educational tool. In this study, students engaged individually or in small groups to create analogies for describing variable scope. A brief training period and minimal scaffolding were provided, encouraging less restricted exploration of analogy development, while establishing a baseline for students' analogy development skills for future studies. This open-ended approach aligns with the current state of practice in STEM education for student-generated analogies. The analysis, grounded in analogical reasoning, revealed strengths, weaknesses, recurring challenges, providing a foundation for future work in developing targeted scaffolding strategies. Key findings such as difficulties in structural alignment, and strengths like high internal domain consistency, offer valuable insights for future targeted scaffolding strategies to be developed for improved analogy development in computing education.",449
364,Computer Science Education,Ryan Bockmon,"December 5th, 2023",Validating a Language-Independent CS1 Learning Outcomes Assessment,https://doi.org/10.1145/3576882.3617910," Aditya Jain, Ryan Bockmon, Chris Bourke, Steve Cooper. (2023). Validating a Language-Independent CS1 Learning Outcomes Assessment CompEd (1), 78-83. https://doi.org/10.1145/3576882.3617910","Assessing learning outcomes in computer science education is essential as it is an indicator of student progress, the effectiveness of teaching methods, and areas for improvement. Aptitude tests have been widely used to measure these learning outcomes; however, they are not without their issues with reliability, difficulty, and applicability across courses and institutions. To address these issues, this study aims to contribute to the development of a reliable, language-independent testing instrument that accurately evaluates students' performance, capabilities, and grasp of the learning outcomes from an introductory computer science course. In this study, we employed the Second Computer Science 1 Exam Revised version 2 (SCS1Rv2) as a post-assessment tool to measure learning outcomes. The SCS1Rv2 was administered in three CS1 course sections, and the results were compared with the final grades of the students. The validation of the SCS1Rv2 was done using Item Response Theory where the test was assessed for its difficulty and reliability. We found that the SCS1Rv2 is a reasonable predictor of course learning outcomes. The intent of this study is to aid in the creation of a standardized, reliable, and effective testing instrument that can be used across different courses and institutions. The SCS1Rv2 has the potential to be a valuable tool in its development.",450
365,Computer Science Education,Ryan Bockmon,"March 3rd, 2023",Validation of the Placement Skill Inventory: A CS0/CS1 Placement Exam,https://doi.org/10.1145/3545945.3569738," Ryan Bockmon, Chris Bourke. (2023). Validation of the Placement Skill Inventory: A CS0/CS1 Placement Exam SIGCSE (1), 39-45. https://doi.org/10.1145/3545945.3569738","Student success in introductory computing course continues to be a major challenge. Though there has been much research and innovation in recent years to help reduce high failure rates, a substantial population of students still struggle in a typical CS1 course. In this paper we create an argument of validity of the Placement Skills Inventory (PSIv1). The goal of the PSIv1 is to help advise and place students into an appropriate introductory computing course. While placement exams have been developed in the past, the goal of PSIv1 is to differentiate students who will be successful in a CS1 course and those that would be better served taking a CS0 course as their first computing course. In contrast, traditional placement exams have focused on differentiating students between CS1 and CS2. The PSIv1 is a combination of two instruments, the Computational Thinking Concepts and Skills Test and the Second Computer Science 1 Exam Revised Version 2. These two instruments measure students' computation thinking skills and prior programming knowledge respectively. The PSIv1 was administered to all students enrolled in either a CS0 or CS1 during the first two weeks of the semester. We use Item Response Theory to create an argument of validity of the PSIv1 and look at differences in scores on the PSIv1 based on if a student passed or failed a CS0 and CS1 course. We then used the results to create an advising strategy and criteria to help students decided if they should enroll in a CS0 or CS1 course.",451
366,Computer Science Education,Ryan Bockmon,"September 21st, 2022",What‚Äôs your placebo?,https://doi.org/10.1145/3528085," Ryan Bockmon, Stephen Cooper. (2022). What's your placebo? Commun. ACM, 65, 31-33. https://doi.org/10.1145/3528085",The dangers of participation bias in educational studies.,452
367,Computer Science Education,Carla E. Brodley,"February 18th, 2025",Does Reducing Curricular Complexity Impact Student Success in Computer Science?,https://doi.org/10.1145/3641554.3701915," Sumukhi Ganesan, Albert Lionelle, Catherine Gill, Carla E. Brodley. (2025). Does Reducing Curricular Complexity Impact Student Success in Computer Science? SIGCSE (1), 360-366. https://doi.org/10.1145/3641554.3701915","Computer science degree requirements often have a rigid pre- and corequisite structure, which can impede a student's progression through a degree and in particular can add one or more semesters to time to completion, particularly for those students who need to retake a course that serves as a prerequisite to other courses and for students who are not calculus-ready when they enter university. In this paper, we present the results of a comparative analysis of curricula before and after a major structural revision. The first curriculum adheres to the conventional, rigid prerequisite structure, while the second emphasizes student choice and multiple pathways through the degree. No changes were made to course content/outcomes between the two versions. Employing curricular metrics such as complexity and centrality, we examine the degree progress of 3010 students over a six-year period. Specifically, our investigation looks at the impact of reducing curricular complexity on student attrition from and attraction to the CS major. The new curriculum, with a 60% reduction in curricular structural complexity, showed both increased retention of students over the old curriculum (67% to 98%) and an increase in the number of students converting from undeclared to computer science (44% to 69%). Our findings demonstrate that reducing curricular complexity need not compromise program rigor and can benefit students by providing greater flexibility and ensuring earlier exposure to (and therefore retention in) CS.",453
368,Computer Science Education,Carla E. Brodley,"February 18th, 2025",Student Application Trends for Teaching Assistant Positions,https://doi.org/10.1145/3641554.3701789," Felix Muzny, Abdulaziz Suria, Carla E. Brodley. (2025). Student Application Trends for Teaching Assistant Positions SIGCSE (1), 798-804. https://doi.org/10.1145/3641554.3701789","We present a comprehensive analysis of teaching assistant (TA) application preferences, with the goal of identifying whether there are significant differences in the courses students prefer to TA for based on student identity. Our data was gathered over the span of four years and represents 15,000+ individual applications for all courses in Khoury College of Computer Sciences. Focusing on the dimensions of applicant program level (undergraduate versus Master's students), gender, and international versus domestic student designation, we perform an analysis of application patterns. Our results show that program level, gender, and international status all play roles in student application behavior. Further, we identify specific courses that are preferred by various subsets of students, such as a strong affinity of students who have gone through a Master's bridge program to apply to those courses and a tendency for women and non-binary students to apply at greater rates to our first-year seminar, data science, and databases courses. Finally, we investigate the relationship between instructor gender and applicant gender--revealing that when women and non-binary applicants prefer certain courses, these courses tend to also have a greater-than-average representation of women and non-binary instructors. As a result of this analysis, we present three recommended next steps to gain deeper understanding of the observed patterns. This work demonstrates that with a centralized TA application system, an institution can gain a comprehensive understanding of application behaviors--leading to informed decisions about where to potentially intervene, especially with an eye toward broadening participation in computing at all levels.",454
369,Computer Science Education,Carla E. Brodley,"July 1st, 2024",An Analysis of the Math Requirements of 199 CS BS/BA Degrees at 158 U.S. Universities,https://doi.org/10.1145/3661482," Carla E. Brodley, McKenna Quam, Mark Allen Weiss. (2024). An Analysis of the Math Requirements of 199 CS BS/BA Degrees at 158 U.S. Universities Commun. ACM, 67, 122-131. https://doi.org/10.1145/3661482","There is no consensus across U.S. universities as to the placement of discrete math and calculus in the CS course sequence, and indeed early placement serves as an institutional barrier that affects students' discovery, retention, and persistence in computing.",455
370,Computer Science Education,Carla E. Brodley,"June 28th, 2024",The BPC Relevance of Common Assessment in the Introductory Sequence,https://doi.org/10.1145/3637891," Carla E. Brodley, Catherine Gill. (2024). The BPC Relevance of Common Assessment in the Introductory Sequence Commun. ACM, 67, 24-26. https://doi.org/10.1145/3637891",Ensuring course outcomes by using the same assignments and exams across all sections.,456
371,Computer Science Education,Carla E. Brodley,"March 15th, 2024",Re-making CS Departments for Generation CS,https://doi.org/10.1145/3626253.3631655," Kathleen J. Lehman, Carla E. Brodley, Mark Guzdial, Paul Tymann, Aman Yadav. (2024). Re-making CS Departments for Generation CS SIGCSE (2), 1535-1536. https://doi.org/10.1145/3626253.3631655","In response to the enrollment surge that started in many CS depart- ments around 2006, the Computing Research Association published a report on ""Generation CS"", which named a pervasive theme in computing education: more and a greater diversity of students are seeking computing education, even if not as traditional CS ma- jors. However, our curricula and departments have stayed much the same. We still mostly prepare students for software develop- ment jobs in the technology industry, while we rarely identify the damage that same industry has caused in our democratic societies. How do we do better? How do we change to meet the needs of a changing society? What strategies should we apply? We know that large-scale change will require structural shifts, but such shifts are likely to be slow and expensive, whereas smaller, ""boots on the ground"" initiatives can positively impact individuals but do little to change the systems that underlie the deeper-seated problems in computing. Navigating this paradox is imperative to our success as a field. Our panel will address the big questions about how to make structural changes in computing education in order to meet the greater needs of Generation CS.",457
372,Computer Science Education,Carla E. Brodley,"March 7th, 2024",Does Curricular Complexity in Computer Science Influence the Representation of Women CS Graduates?,https://doi.org/10.1145/3626252.3630835," Albert Lionelle, Mckenna Quam, Carla E. Brodley, Catherine Gill. (2024). Does Curricular Complexity in Computer Science Influence the Representation of Women CS Graduates? SIGCSE (1), 729-735. https://doi.org/10.1145/3626252.3630835","Not all degree programs are created equal. Indeed, the structure, prerequisites and overall complexity of some programs create barriers that impede student success. Inspired by the methodology of previous papers investigating the inverse relationship between curricular complexity and program quality, in this paper we investigate the relationship between curricular complexity and the representation of women earning CS degrees. We created curricular maps of 60 computer science degrees and calculated measures such as program complexity, course blocking, delay factor, and total math/CS credits to understand complexity's correlation with the representation of women CS majors. Our results show that degree complexity, blocking factor, and delay factor are all inversely related to the representation of women. In addition, we present the courses that most commonly impede student progress and provide suggestions to enhance degree programs based on the insights gained.",458
373,Computer Science Education,Carla E. Brodley,"March 7th, 2024","Collecting, Analyzing, and Acting on Intersectional, Longitudinal Data and Pass/Fail/Withdraw Rates in Computing Courses",https://doi.org/10.1145/3626252.3630806," Felix Muzny, Megan Giordano, Emma Sommers, Carla E. Brodley. (2024). Collecting, Analyzing, and Acting on Intersectional, Longitudinal Data and Pass/Fail/Withdraw Rates in Computing Courses SIGCSE (1), 909-915. https://doi.org/10.1145/3626252.3630806","We present the Center for Inclusive Computing's data collection and visualization system, which enables computing departments to track and visualize their enrollment and course outcome data intersectionally and longitudinally. The system tracks the impact of institutional changes in how computing (particularly the introductory sequence) is discovered and experienced by undergraduates as measured by course outcome and persistence data. To date we have worked with and collected data from 52 U.S. computing departments. Collected data spans 2018-present and contains term-by- term, intersectional course enrollment and outcome data for CS 1-3, while also tracking declared majors and persistence to graduation. Drawing on our experience working with these universities we present guidelines for the analysis of intersectional, longitudinal data alongside our recommendations for actionable next steps. We present three case studies grounded in an analysis of CS1, demon- strating how an institution can understand their own computing program and develop interventions-specifically with an eye toward broadening participation in computing.",459
374,Computer Science Education,Carla E. Brodley,"July 21st, 2022",Why universities must resist GPA-based enrollment caps in the face of surging enrollments,https://doi.org/10.1145/3544547," Carla E. Brodley. (2022). Why universities must resist GPA-based enrollment caps in the face of surging enrollments Commun. ACM, 65, 20-22. https://doi.org/10.1145/3544547",Considering the challenges for universities to adapt their business models to changing student demands.,460
375,Computer Science Education,Carla E. Brodley,"March 3rd, 2022",Interdisciplinary Computing Majors (CS+X): Making it work at your University,https://doi.org/10.1145/3478432.3499174," Carla E. Brodley, Valerie Barr. (2022). Interdisciplinary Computing Majors (CS+X): Making it work at your University SIGCSE (2), 1182. https://doi.org/10.1145/3478432.3499174","As computing becomes increasingly relevant to all disciplines, interdisciplinary computing degrees become increasingly important. These interdisciplinary majors: 1) address the increasing need for computing knowledge across all disciplines; 2) have the potential to increase a student's employability; 3) give employers the opportunity to hire students who are trained in two fields relevant to the company; 4) by reducing the number of requirements for the computing degree, can alleviate some of the pressure faced by CS departments from booming enrollments ; and 5) broaden participation in computing - in particular, to increase the percentage of women. Despite these opportunities, as of 2022 there are only a few schools that have embraced this mission. There are significant implementation challenges to interdisciplinary majors: 1) university/college budget models often financially discourage interdisciplinary degrees; 2) difficulty determining the ""unit"" that will administer the combined degree; 3) already large demands on CS faculty time; 4) advisors/faculty must be trained to advise interdisciplinary majors; and 5) both disciplines have to agree to reduce their major course requirements. In this BoF session we will discuss these and other obstacles identified at the range of institutions represented at SIGCSE and how to overcome these implementation challenges.",461
376,Computer Science Education,Carla E. Brodley,"January 1st, 2021",Diagnosing why Representation Remains Elusive at your University: Lessons Learned from the Center for Inclusive Computing‚Äôs Site Visits,https://doi.org/10.1109/RESPECT51740.2021.9620552," Carla E. Brodley, Catherine Gill, Sally Wynn. (2021). Diagnosing why Representation Remains Elusive at your University: Lessons Learned from the Center for Inclusive Computing's Site Visits RESPECT, 1-4. https://doi.org/10.1109/RESPECT51740.2021.9620552","Best practices to support women in undergraduate computing are known and are being adopted. departments can move faster and see better results by developing a deeper understanding of issues unique to their institution. The Center for Inclusive Computing (CIC) awards grants to colleges and universities to support the implementation of evidence-based approaches. After 22 site visits, we have developed a strategy to uncover institutional barriers and issues through targeted questioning of key stakeholders. The site visit reveals if the institution has accurately diagnosed the issues and if the proposed interventions are appropriately aligned with the identified problems.",462
377,Computer Science Education,Carla E. Brodley,"December 31st, 2015",Clinical Vestibular Testing Assessed With Machine-Learning Algorithms,https://doi.org/10.1001/jamaoto.2014.3519," Adrian J. Priesol, Mengfei Cao, Carla E. Brodley, Richard F. Lewis. ""Clinical Vestibular Testing Assessed With Machine-Learning Algorithms."" JAMA Otolaryngol Head Neck Surg, 2015. DOI: 10.1001/jamaoto.2014.3519",Rotational testing should be considered the primary test to diagnose unilateral peripheralvestibular damage in patients with dizziness or imbalance. The diagnostic accuracy of. the vestibula test battery increased from 72.4% to 93.4%. when the data were analyzed with the optimal machine-learning classifier.,463
378,Computer Science Education,Nate Derbinsky,"February 18th, 2025",Addressing Challenges in Teaching-Track Faculty Promotion,https://doi.org/10.1145/3641555.3704713," Christine Alvarado, Nate Derbinsky, Sarah Heckman, Manuel A. P√©rez-Qui√±ones, Harini Ramaprasad, Mark Sherriff. (2025). Addressing Challenges in Teaching-Track Faculty Promotion SIGCSE (2), 1685-1686. https://doi.org/10.1145/3641555.3704713","Interest in teaching-track faculty positions has been steadily increasing as enrollments in computer science degree programs continue to trend upward. While departments have welcomed these new teaching-track faculty members, senior faculty, department chairs, and university committees often struggle with how to best evaluate these faculty members during the promotion process. In our experience, some universities try to use a ""watered-down"" version of the tenure-track promotion standards with the intent of uniformity. Other universities have created whole new processes, which may be better at capturing the differences in teaching-track positions, but also can create a ""second-class citizen"" status for the teaching-track faculty members. For this panel, we will bring together teaching-track and tenured faculty who have been active in promotion committees, have written letters of support for teaching-track faculty, and have successfully guided junior faculty through the promotion process. Our goal is to shed light on the differing practices at various universities and help attendees understand how to best support junior teaching-track faculty.",464
379,Computer Science Education,Nate Derbinsky,"March 15th, 2024",Interviewing the Teaching Faculty Hiring Process,https://doi.org/10.1145/3626253.3631664," Geoffrey Challen, Victoria Dean, Nate Derbinsky, Matt X. Wang, Jacqueline Smith. (2024). Interviewing the Teaching Faculty Hiring Process SIGCSE (2), 1525-1526. https://doi.org/10.1145/3626253.3631664","As teaching-focused positions proliferate and university teaching careers become more professionalized, there is growing attention being paid to how teaching faculty are created. However, how teaching faculty are hired also deserves scrutiny. Teaching faculty hiring varies widely between institutions, raising questions of whether hiring processes are effectively identifying, evaluating, and recruiting qualified applicants, and which approaches are most effective. Variation in application requirements and interview processes may also result in a higher workload for teaching faculty candidates when compared to peers applying for other types of faculty positions. This panel brings together faculty with significant teaching faculty hiring experience and new teaching faculty who were very recently on the job market. Together we'll discuss what is and is not working in teaching faculty hiring, and how we might improve the process for both institutions and candidates. We anticipate engaging with those involved with hiring teaching faculty, as well as current and future teaching faculty candidates.",465
380,Computer Science Education,Nate Derbinsky,"July 19th, 2022",Using domain knowledge in coevolution and reinforcement learning to simulate a logistics enterprise,https://doi.org/10.1145/3520304.3528990," Ying Zhao , Erik Hemberg, Nate Derbinsky, Gabino Mata, Una-May O'Reilly. (2022). Using domain knowledge in coevolution and reinforcement learning to simulate a logistics enterprise GECCO Companion, 514-517. https://doi.org/10.1145/3520304.3528990","We demonstrate a framework (CoEv-Soar-RL) for a logistics enterprise to improve readiness, sustainment, and reduce operational risk. The CoEv-Soar-RL uses reinforcement learning and coevolutionary algorithms to improve the functions of a logistics enterprise value chain. We address: (1) holistic prediction, optimization, and simulation for the logistics enterprise readiness; (2) the uncertainty and lack of data which require large-scale systematic what-if scenarios to simulate potential new and unknown situations. In this paper, we perform four experiments to investigate how to integrate prediction and simulation to modify a logistics enterprise's demand models and generate synthetic data based. We use general domain knowledge to design simple operators for the coevolutionary search algorithm that provide realistic solutions for the simulation of the logistic enterprise. In addition, to evaluate generated solutions we learn a surrogate model of a logistic enterprise environment from historical data with Soar reinforcement learning. From our experiments we discover, and verify with subject matter experts, novel realistic solutions for the logistic enterprise. These novel solutions perform better than the historical data and where only found when we include knowledge derived from the historical data in the co-evolutionary search.",466
381,Computer Science Education,Arjun Guha,"October 31st, 2024",SelfCodeAlign: Self-Alignment for Code Generation,http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html," Yuxiang Wei , Federico Cassano, Jiawei Liu , Yifeng Ding, Naman Jain, Zachary Mueller, Harm de Vries, Leandro von Werra, Arjun Guha, Lingming Zhang . (2024). SelfCodeAlign: Self-Alignment for Code Generation NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html","Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models to follow human instructions. Most models are finetuned with costly human-annotated instruction-response pairs. We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs.",467
382,Computer Science Education,Arjun Guha,"October 8th, 2024",Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs,https://doi.org/10.1145/3689735," Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Anders Freeman, Carolyn Jane Anderson, Molly Q. Feldman, Michael Greenberg , Abhinav Jangda, Arjun Guha. (2024). Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs Proc. ACM Program. Lang., 8, 677-708. https://doi.org/10.1145/3689735","Large Language Models of Code have started to have a significant impact on programming practice. The quality of code produced by a Code LLM varies significantly by programming language. This paper presents an effective approach for boosting the performance of Code LLMs on low-resource languages using semi-synthetic data. The MultiPL-T approach is easy to apply to new languages, and is significantly more efficient and effective than alternatives such as training longer.",468
383,Computer Science Education,Arjun Guha,"March 25th, 2022",Flexible and Optimal Dependency Management via Max-SMT,https://doi.org/10.1109/ICSE48619.2023.00124," Donald Pinckney, Federico Cassano, Arjun Guha, Jonathan Bell , Massimiliano Culpo, Todd Gamblin. (2023). Flexible and Optimal Dependency Management via Max-SMT ICSE, 1418-1429. https://doi.org/10.1109/ICSE48619.2023.00124","NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. NPM dependency solver has several shortcomings. We present Pacsolve, a unifying framework and implementation for dependency solving. We then build Maxnpm, a complete, drop-in replacement for NPM. We are presenting our findings at the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) All our code and data is open and available. Back to Mail Online home. Back To the page you came from.""Maxnpm: A Drop-in Replacement For NPM""",469
384,Computer Science Education,Arjun Guha,"October 15th, 2021",Solver-based gradual type migration,https://doi.org/10.1145/3485488," Luna Phipps-Costin, Carolyn Jane Anderson, Michael Greenberg, and Arjun Guha. 2021. ‚ÄúSolver-based gradual type migration‚Äù. Proc. ACM Program. Lang. 5, OOPSLA, Article 111 (October 2021), 27 pages. DOI: 10.1145/3485488","Gradually typed languages allow programmers to mix statically and dynamically typed code, enabling them to incrementally reap the benefits of static typing as they add type annotations to their code. However, this type migration process is typically a manual effort with limited tool support. This paper examines the problem of automated type migration: given a dynamic program, infer additional or improved type annotations. Existing type migration algorithms prioritize different goals, such as maximizing type precision, maintaining compatibility with unmigrated code, and preserving the semantics of the original program. We argue that the type migration problem involves fundamental compromises: optimizing for a single goal often comes at the expense of others. Ideally, a type migration tool would flexibly accommodate a range of user priorities. We present TypeWhich, a new approach to automated type migration for the gradually-typed lambda calculus with some extensions. Unlike prior work, which relies on custom solvers, TypeWhich produces constraints for an off-the-shelf MaxSMT solver. This allows us to easily express objectives, such as minimizing the number of necessary syntactic coercions, and constraining the type of the migration to be compatible with unmigrated code. We present the first comprehensive evaluation of GTLC type migration algorithms, and compare TypeWhich to four other tools from the literature. Our evaluation uses prior benchmarks, and a new set of ""challenge problems."" Moreover, we design a new evaluation methodology that highlights the subtleties of gradual type migration. In addition, we apply TypeWhich to a suite of benchmarks for Grift, a programming language based on the GTLC. TypeWhich is able to reconstruct all human-written annotations on all but one program.",470
385,Computer Science Education,Arjun Guha,"September 27th, 2021",Iterative Program Synthesis for Adaptable Social Navigation,https://doi.org/10.1109/IROS51168.2021.9636540," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Iterative Program Synthesis for Adaptable Social Navigation,"" 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021, pp. 6256-6261. DOI: 10.1109/IROS51168.2021.9636540","Robot social navigation is influenced by human preferences and environment-specific scenarios such as elevators and doors. State-of-the-art approaches to social navigation fall into two categories: model-based social constraints and learning-based approaches. We propose Iterative Dimension Informed Program Synthesis (IDIPS) to address these limitations by learning and adapting social navigation in the form of human-readable symbolic programs. IDIPS works by combining pro-gram synthesis, parameter optimization, predicate repair, and iterative human demonstration to learn and adapt model-free action selection policies. and generates policies that can be transferred from simulation to real-world robots with minimal effort.",471
386,Computer Science Education,Arjun Guha,"April 21st, 2021",Accelerating graph sampling for graph machine learning using GPUs,https://doi.org/10.1145/3447786.3456244," Abhinav Jangda, Sandeep Polisetty, Arjun Guha, and Marco Serafini. 2021. Accelerating graph sampling for graph machine learning using GPUs. In Proceedings of the Sixteenth European Conference on Computer Systems (EuroSys ‚Äô21). Association for Computing Machinery, New York, NY, USA, 311‚Äì326. DOI: 10.1145/3447786.3456244","Representation learning algorithms automatically learn the features of data. Several representation learning algorithms for graph data, such as DeepWalk, node2vec, and Graph-SAGE, sample the graph to produce mini-batches that are suitable for training a DNN. However, sampling time can be a significant fraction of training time, and existing systems do not efficiently parallelize sampling. Sampling is an ""embarrassingly parallel"" problem and may appear to lend itself to GPU acceleration, but the irregularity of graphs makes it hard to use GPU resources effectively. This paper presents NextDoor, a system designed to effectively perform graph sampling on GPUs. NextDoor employs a new approach to graph sampling that we call transit-parallelism, which allows load balancing and caching of edges. NextDoor provides end-users with a high-level abstraction for writing a variety of graph sampling algorithms. We implement several graph sampling applications, and show that NextDoor runs them orders of magnitude faster than existing systems.",472
387,Computer Science Education,Arjun Guha,"November 15th, 2020",Wasm/k: delimited continuations for WebAssembly,https://doi.org/10.1145/3426422.3426978," Donald Pinckney, Arjun Guha, and Yuriy Brun. 2020. Wasm/k: delimited continuations for WebAssembly. In Proceedings of the 16th ACM SIGPLAN International Symposium on Dynamic Languages(DLS 2020). Association for Computing Machinery, New York, NY, USA, 16‚Äì28. DOI: 10.1145/3426422.3426978","WebAssembly is designed to be an alternative to JavaScript that is a safe, portable, and efficient compilation target for a variety of languages. The performance of high-level languages depends not only on the underlying performance of WebAssembly, but also on the quality of the generated WebAssembly code. In this paper, we identify several features of high-level languages that current approaches can only compile to WebAssembly by generating complex and inefficient code. We argue that these problems could be addressed if WebAssembly natively supported first-class continuations. We then present Wasm/k, which extends WebAssembly with delimited continuations. Wasm/k introduces no new value types, and thus does not require significant changes to the WebAssembly type system (validation). Wasm/k is safe, even in the presence of foreign function calls (e.g., to and from JavaScript). Finally, Wasm/k is amenable to efficient implementation: we implement Wasm/k as a local change to Wasmtime, an existing WebAssembly JIT. We evaluate Wasm/k by implementing C/k, which adds delimited continuations to C/C++. C/k uses Emscripten and its implementation serves as a case study on how to use Wasm/k in a compiler that targets WebAssembly. We present several case studies using C/k, and show that on implementing green threads, it can outperform the state-of-the-art approach Asyncify with an 18% improvement in performance and a 30% improvement in code size.",473
388,Computer Science Education,Arjun Guha,"November 13th, 2020",TacTok: semantics-aware proof synthesis,https://doi.org/10.1145/3428299," Emily First, Yuriy Brun, and Arjun Guha. ""TacTok: semantics-aware proof synthesis."" Proceedings of the ACM on Programming Languages, v.4 , 2020. DOI: 10.1145/3428299","TacTok outperforms WeightedRandom and WeightedGreedy, and is complementary to CoqHammer and ASTactic. For 24 out of the 26 projects, TacTok can synthesize proof scripts for some theorem the prior tools cannot. Together with TacTok, 11.5% more theoresms can be proven automatically than by CoquHammer alone.",474
389,Computer Science Education,Arjun Guha,"November 12th, 2020",Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,https://doi.org/10.48550/arXiv.2008.04133," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,"" Conference on Robot Learning (CoRL), 2020. DOI: 10.48550/arXiv.2008.04133","Action selection policies (ASPs), used to compose low-level robot skills into complex high-level tasks are commonly represented as neural networks (NNs) in the state of the art. Such a paradigm, while very effective, suffers from a few key problems: 1) NNs are opaque to the user and hence not amenable to verification, 2) they require significant amounts of training data, and 3) they are hard to repair when the domain changes. We present two key insights about ASPs for robotics. First, ASPs need to reason about physically meaningful quantities derived from the state of the world, and second, there exists a layered structure for composing these policies. Leveraging these insights, we introduce layered dimension-informed program synthesis (LDIPS) - by reasoning about the physical dimensions of state variables, and dimensional constraints on operators, LDIPS directly synthesizes ASPs in a human-interpretable domain-specific language that is amenable to program repair. We present empirical results to demonstrate that LDIPS 1) can synthesize effective ASPs for robot soccer and autonomous driving domains, 2) requires two orders of magnitude fewer training examples than a comparable NN representation, and 3) can repair the synthesized ASPs with only a small number of corrections when transferring from simulation to real robots.",475
390,Computer Science Education,Arjun Guha,"April 3rd, 2020",Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing,https://ojs.aaai.org/index.php/AAAI/article/view/7065," Joseph Spitzer, Joydeep Biswas, Arjun Guha. (2020). Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing AAAI, 13412-13419. https://ojs.aaai.org/index.php/AAAI/article/view/7065","Abstract Robots are a popular platform for introducing computing and artificial intelligence to novice programmers. However, programming state-of-the-art robots is very challenging, and requires knowledge of concurrency, operation safety, and software engineering skills, which can take years to teach. In this paper, we present an approach to introducing computing that allows students to safely and easily program high-performance robots. We develop a platform for students to program RoboCup Small Size League robots using JavaScript. The platform 1) ensures physical safety at several levels of abstraction, 2) allows students to program robots using JavaScript in the browser, without the need to install software, and 3) presents a simplified JavaScript semantics that shields students from confusing language features. We discuss our experience running a week-long workshop using this platform, and analyze over 3,000 student-written program revisions to provide empirical evidence that our approach does help students.",476
391,Computer Science Education,Arjun Guha,"February 15th, 2019",Formal Foundations of Serverless Computing,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2019-jangda-lambda-lambda.html," Abhinav Jangda, Donald Pinckney, Yuriy Brun, and Arjun Guha. Formal Foundations of Serverless Computing. ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages and Applications (OOPSLA), 2019. Distinguished Paper Award","Serverless computing (also known as functions as a service) is a new cloud computing abstraction that makes it easier to write robust, large-scale web services. In serverless computing, programmers write what are called serverless functions, and the cloud platform transparently manages the operating system, resource allocation, load-balancing, and fault tolerance. When demand for the service spikes, the platform automatically allocates additional hardware to the service and manages load-balancing; when demand falls, the platform silently deallocates idle resources; and when the platform detects a failure, it transparently retries affected requests. In 2014, Amazon Web Services introduced the first serverless platform, AWS Lambda, and similar abstractions are now available on all major cloud computing platforms. Unfortunately, the serverless computing abstraction exposes several low-level operational details that make it hard for programmers to write and reason about their code. This paper sheds light on this problem by presenting Œª Œõ , an operational semantics of the essence of serverless computing. Despite being a small (half a page) core calculus, Œª Œõ models all the low-level details that serverless functions can observe. To show that Œª Œõ is useful, we present three applications. First, to ease reasoning about code, we present a simplified naive semantics of serverless execution and precisely characterize when the naive semantics and Œª Œõ coincide. Second, we augment Œª Œõ with a key-value store to allow reasoning about stateful serverless functions. Third, since a handful of serverless platforms support serverless function composition, we show how to extend Œª Œõ with a composition language. We have implemented this composition language and show that it outperforms prior work. The latest version of this paper, corrects an error in Definition 4.2 and thus the proof of Theorem 4.3, which were found in the published version. PDF available on arXiv",477
392,Computer Science Education,Arjun Guha,"February 5th, 2018",Interactive Robot Transition Repair With SMT,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2018-holtz-srtr.html," Jarrett Holtz, Arjun Guha, and Joydeep Biswas. Interactive Robot Transition Repair with SMT. International Joint Conference on Artificial Intelligence and the European Conference on Artificial Intelligence (IJCAI-ECAI), 2018","Complex robot behaviors are often structured as state machines, where states encapsulate actions and a transition function switches between states. Since transitions depend on physical parameters, when the environment changes, a roboticist has to painstakingly readjust the parameters to work in the new environment. We present interactive SMT-based Robot Transition Repair* (SRTR): instead of manually adjusting parameters, we ask the roboticist to identify a few instances where the robot is in a wrong state and what the right state should be. An automated analysis of the transition function 1) identifies adjustable parameters, 2) converts the transition function into a system of logical constraints, and 3) formulates the constraints and user-supplied corrections as a MaxSMT problem that yields new parameter values. We show that finds new parameters 1) quickly, 2) with few corrections, and 3) that the parameters generalize to new scenarios. We also show that a SRTR-corrected state machine can outperform a more complex, expert-tuned state machine. PDF available on arXiv",478
393,Computer Science Education,Arjun Guha,"September 17th, 2015",Rehearsal: A Configuration Verification Tool for Puppet,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2016-rehearsal.html," Rian Shambaugh, Aaron Weiss, and Arjun Guha. Rehearsal: A Configuration Verification Tool for Puppet. ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2016","Large-scale data centers and cloud computing have turned system configuration into a challenging problem. Several widely-publicized outages have been blamed not on software bugs, but on configuration bugs. To cope, thousands of organizations use system configuration languages to manage their computing infrastructure. Of these, Puppet is the most widely used with thousands of paying customers and many more open-source users. The heart of Puppet is a domain-specific language that describes the state of a system. Puppet already performs some basic static checks, but they only prevent a narrow range of errors. Furthermore, testing is ineffective because many errors are only triggered under specific machine states that are difficult to predict and reproduce. With several examples, we show that a key problem with Puppet is that configurations can be non-deterministic. This paper presents Rehearsal, a verification tool for Puppet configurations. Rehearsal implements a sound, complete, and scalable determinacy analysis for Puppet. To develop it, we (1) present a formal semantics for Puppet, (2) use several analyses to shrink our models to a tractable size, and (3) frame determinism-checking as decidable formulas for an SMT solver. Rehearsal then leverages the determinacy analysis to check other important properties, such as idempotency. Finally, we apply Rehearsal to several real-world Puppet configurations. PLDI Artifact Virtual Machine PDF available on arXiv",479
394,Computer Science Education,Lama Hamandi,"February 18th, 2025",Gamification of Computer Science Algorithms,https://doi.org/10.1145/3641555.3705033," Lama Hamandi, Hla Htoo, Senay Tilahun, Haider Amin. (2025). Gamification of Computer Science Algorithms SIGCSE (2), 1733. https://doi.org/10.1145/3641555.3705033","Educational games have emerged as powerful tools for enhancing learning experiences across various subjects and age groups. This project represents an innovative approach to combining educational content with highly interactive and engaging gameplay to teach important Computer Science concepts such as data structures and Algorithms. Existing implementations offer visualizations of algorithms and data structures, but lack the interactivity required for active participation of students. This project aims to foster active learning by allowing students to solve examples through directly selecting, swapping and manipulating nodes and edges of graphs. This game presents a platform for college students to learn and actively practice the Heap data structure, Heapsort algorithm, and minimum weight spanning tree Algorithms such as Kruskal and Prim. Built using JavaScript, HTML, CSS, and Three.js, the game incorporates a 3D interactive environment to pilot these concepts. The platform includes two modes: a training mode, allowing penalty-free practice, and a regular mode with a scoring system, a leaderboard and limited lives to foster engagement, challenge and competitiveness with peers. Multiple levels of difficulty, immediate feedback, and a carefully tailored hint system were designed to support stepwise learning and enhance interactive experience. Anonymous Data collection of number of mistakes, time spent and change of score per level, runs in the background without storing identifying information on the students. An interface for instructors allows professors to visualize students' data, track improvement, and analyze students' comprehension and performance. Gamification of additional algorithms is currently being developed.",480
395,Computer Science Education,Lama Hamandi,"March 15th, 2024",Project-based Activities to Introduce Hardware in a Software-focused Course,https://doi.org/10.1145/3626253.3633425," Lama Hamandi, Mark Leslie Miller, Shivakumar Mathapathi. (2024). Project-based Activities to Introduce Hardware in a Software-focused Course SIGCSE (2), 1899. https://doi.org/10.1145/3626253.3633425","This workshop introduces attendees to the low-level components used in the design of computer hardware, allowing them to experiment with the hardware-software interface. Attendees explore hands-on experiments that are designed for students unlikely to encounter hardware topics in their course of study. These experiments are offered in bridge courses of a graduate program enrolling students without a Computer Science background at Northeastern University (the Align MSCS Program). The workshop consists of 3 groupings of hardware experiments. In one grouping, attendees use breadboarding to construct digital circuits. Transistors and resistors are used to design logic gates; then logic gates are used to design an arithmetic circuit (Half Adder); finally, two Half Adders with an OR gate are cascaded to build a larger adder. In the second grouping, attendees explore the interface between hardware and software, making software concepts tangible. Changing a bit from 0 to 1 in software causes a voltage change on a pin, causing light-emitting diodes (LEDs) to light. Operations executed on a Pico microcontroller illustrate programming concepts like ASCII representation and data structures. Additional Python constructs enable the implementation of counters and games. In the third grouping, attendees write C code to realize Linked list, Tree, and Graph implementations on Raspberry Pi (RSPi). These C programs enable hardware components by activating the hardware I/O ports of RSPi.",481
396,Computer Science Education,Lama Hamandi,"October 22nd, 2020",Connected and Autonomous Electric Vehicles: Quality of Experience Survey and Taxonomy,https://doi.org/10.1016/j.vehcom.2020.100312," Damaj, I., Serhal, D., Hamandi, L., and Zantout, R., and Mouftah, H., ‚ÄúConnected and Autonomous Electric Vehicles: Quality of Experience Survey and Taxonomy‚Äù, Vehicular Communications, v.28, 2021, 100312, SSN 2214-2096","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",482
397,Computer Science Education,Jeongkyu Lee,"March 15th, 2024",SQLearn: Automated SQL Statement Assessment using Structure-based Analysis,https://doi.org/10.1145/3626253.3635607," Sumukhi Ganesan, Tianchou Gong, Jeongkyu Lee. (2024). SQLearn: Automated SQL Statement Assessment using Structure-based Analysis SIGCSE (2), 1644-1645. https://doi.org/10.1145/3626253.3635607","In the world of database education, SQL (Structured Query Language) is often the first and crucial step toward developing data analysis and manipulation skills. As the world moves on to data-driven technologies and businesses, the need to educate students in writing accurate and efficient SQL queries has become paramount. Traditional SQL evaluation modes often rely on limited, subjective, and labor-intensive manual grading, which impedes the integration of practical assignments into the curriculum. This poster introduces SQLearn, an innovative automated assessment tool for SQL education. We aim to build a comprehensive platform that addresses submission, evaluation, and review needs amongst students and educators. Here we highlight our assessment approach which breaks down student-submitted queries into Abstract Syntax Trees (AST) and uses cosine similarity to evaluate them. Experimental results show that the proposed approach is effective, not only in binary grading of queries but also in assigning partial grades. The tool also offers an interactive platform to submit and receive feedback, enabling students to refine their SQL skills and gain insights into query structure and optimization. By automating the assessment process, educators can focus on refining the curriculum and channel more time into instruction and research.",483
398,Computer Science Education,Jeongkyu Lee,"March 1st, 2024",MRI Segmentation of Musculoskeletal Components Using U-Net: Preliminary Results,https://doi.org/10.1145/3640900.3640902," Divit Vasu, Seungmoon Song, Hans Kainz, Jeongkyu Lee. (2024). MRI Segmentation of Musculoskeletal Components Using U-Net: Preliminary Results ICBBB, 30-35. https://doi.org/10.1145/3640900.3640902","Recent advances in medical imaging and computer vision offer unprecedented potential for objective, automated, and personalized diagnosis and treatment in healthcare. A pivotal area where this potential is yet to be fully harnessed lies in the processing of MRI data for the extraction of musculoskeletal features, crucial for patient-specific musculoskeletal modeling. Such models hold significance for assessing neuromusculoskeletal diseases and analyzing human movement. This manuscript presents our initial efforts in developing a method that utilizes deep learning to segment specific anatomical structures, namely osseous and myeloid tissues, from MRI scans, with minimal annotated data. We place particular emphasis on a convolutional neural network (CNN) approach, utilizing the U-Net architecture. Our work elaborates on the segmentation process, demonstrates results on individual MRI slices, and proposes a method for volumetric analysis. We also explore potential enhancements for achieving more precise segmentations and robust feature extraction. The promising initial findings advocate for a future where the segmentation of intricate anatomical structures becomes more accessible, efficient, and rapid.",484
399,Computer Science Education,Jeongkyu Lee,"March 4th, 2022",Detection of Northern Corn Leaf Blight Disease in Real Environment Using Optimized YOLOv3,https://doi.org/10.1109/CCWC54503.2022.9720782," Brian Song, Jeongkyu Lee. (2022). Detection of Northern Corn Leaf Blight Disease in Real Environment Using Optimized YOLOv3 CCWC, 475-480. https://doi.org/10.1109/CCWC54503.2022.9720782","New York State's second top agricultural product is maize and they are the fourth largest producer in the nation. Maize diseases, in particular northern corn leaf blight (NLB), can be difficult to detect under real world conditions. A novel deep learning method is introduced that is based off of the low latency YOLOv3 object detection algorithm. Average precision results were 0.774, 0.806, and 0.821 for base, dense, and dense-attention, respectively. The study was published in the IEEE 12th Annual Computing and Communication Workshop and Conference.",485
400,Computer Science Education,Jeongkyu Lee,"October 28th, 2021",An Event Detection Platform to Detect Gender Using Deep Learning,https://ieeexplore.ieee.org/document/9298104," Abdulrahman Aldhaheri, Khaled Almgren and Jeongkyu Lee, ‚ÄúAn Event Detection Platform to Detect Gender Using Deep Learning,‚Äù Proc. of the 11th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON), pp. 360-364, October 28‚Äì31, 2020"," clickstreams quantify users' movements based on the items they click on an e- commerce website. The proposed approach utilizes deep learning and has been tested on a real-world dataset. The study was published in the Proceedings of the 2020 11th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference.",486
401,Computer Science Education,Jeongkyu Lee,"January 17th, 2021",Topological Data Analysis for Classification of Heart Disease Data,https://ieeexplore.ieee.org/abstract/document/9373116," Fatima Ali Aljanobi, and Jeongkyu Lee, ‚ÄúTopological Data Analysis for Classification of Heart Disease Data,‚Äù Proc. of 2021 IEEE International Conference on Big Data and Smart Computing (BigComp 2021), January 17‚Äì20, 2021.","Topological Data Analysis (TDA) is based on the principle that data has shape and meaning. This method has been shown to increase the efficiency of processes across several fields such as health care and computational biology. The mapper algorithm was used for predicting heart disease by using two UCI heart disease datasets (Cleveland and Statlog) As a result, we have observed an accuracy of 99.32% in the Cleveland dataset and 99.62% in. the Statlog dataset in predicting heart Disease.",487
402,Computer Science Education,Jeongkyu Lee,"November 11th, 2019",Miniature Humanoid Upgrade for Material Handling Tasks in Humanoid Challenge,https://asmedigitalcollection.asme.org/IMECE/proceedings-abstract/IMECE2019/59414/V004T05A008/1073170," Kiwon Sohn, Jeongkyu Lee, and Kevin Huang. ‚ÄúMiniature Humanoid Upgrade for Material Handling Tasks in Humanoid Challenge,‚Äù Proceedings of the ASME 2019 International Mechanical Engineering Congress and Exposition. Volume 4: Dynamics, Vibration, and Control. Salt Lake City, Utah, USA. November 11‚Äì14, 2019","Miniature Humanoid Upgrade for Material Handling Tasks in Humanoid Challenge. Proceedings of the ASME 2019 International Mechanical Engineering Congress and Exposition. Volume 4: Dynamics, Vibration, and Control . Salt Lake City, Utah, USA. V004T05A008. Volume Subject Area: Dynamics,. Vibrations,. and Control. Topics: Materials handling, Robotics, Robots, Teams, Computer software. Disasters , Hardware , Mobile robots , Navigation , Students. This content is only available via PDF. You do not currently have access to this content.",488
403,Computer Science Education,Jeongkyu Lee,"January 1st, 2019",Mapping Areas using Computer Vision Algorithms and Drones,http://arxiv.org/abs/1901.00211," Bashar Alhafni, Saulo Fernando Guedes, Lays Cavalcante Ribeiro, Juhyun Park, Jeongkyu Lee. (2019). Mapping Areas using Computer Vision Algorithms and Drones CoRR, abs/1901.00211. http://arxiv.org/abs/1901.00211","The goal of this paper is to implement a system, titled as Drone Map Creator (DMC) using Computer Vision techniques. DMC can process visual information from an HD camera in a drone and automatically create a map by stitching together visual information captured by a drone. The proposed approach employs the Speeded up robust features (SURF) method to detect the key points for each image frame; then the corresponding points between the frames are identified by maximizing the determinant of a Hessian matrix. Finally, two images are stitched together by using the identified points. Our results show that despite some limitations from the external environment, we could have successfully stitched images together along video sequences.",489
404,Computer Science Education,Jeongkyu Lee,"December 17th, 2018",AD or Non-AD: A Deep Learning Approach to Detect Advertisements from Magazines,https://www.mdpi.com/1099-4300/20/12/982," Almgren, K., Krishna, M., Aljanobi, F., and Jeongkyu Lee, ‚ÄúAD or Non-AD: A Deep Learning Approach to Detect Advertisements from Magazines,‚Äù Entropy, 20(12), 982, 2019.","The aim is to identify key features of advertising images and to apply them to real-world application. We employed convolutional neural networks to classify scanned images as either advertisements or non-advertisements (i.e., articles) The results show that the proposed approach outperforms other classifiers and the related work in terms of accuracy. The proposed work will eventually help improve marketing strategies, which requires the classification of advertising pictures from magazines. It is published in the Open Access journal Entropy 2018 , 20 (12), 982; https://doi.org/10.3390/e20120982. It belongs to the Special Issue The 20th Anniversary of Entropy - Recent Advances in Entropy and Information-Theoretic Concepts and Their Applications. We employed a convolutional neural network to extract meaningful features from the scanned images. We tested our approach on a large dataset, which contains 3885 images from different magazines. The results show that our approach is feasible for detecting advertisements, and it also outperforms other classifiers in terms of accuracy. In the future, we will investigate different features of magazine advertisements, such as semantics, and work with different filters. We also aim to determine the content of advertisements and categorize them by industry (such as food, tourism, automobiles, etc.) This would make our model‚Äôs output include more than two classes. We would like to make clear that this is not an endorsement of any of the methods or techniques used in the study. The opinions expressed in this article are those of the authors and do not reflect the views of the IEEE. Researchers at MDPI, Basel, Switzerland, used a convolutional neural network. Multiple requests from the same IP address are counted as one view. Results published in the 20th issue of Entropy, a journal of the American Association for the Advancement of the Arts and Sciences (AAAS) and the American Mathematical Society (AMAS) This article is open access and shareable under the CC BY 4.0 license.",490
405,Computer Science Education,Jeongkyu Lee,"February 26th, 2016",H2Hadoop: Improving Hadoop Performance Using the Metadata of Related Jobs,https://ieeexplore.ieee.org/abstract/document/7420665," Hamoud Alshammari, Jeongkyu Lee, and Hassan Bajwa, ‚ÄúH2Hadoop: Improving Hadoop Performance Using the Metadata of Related Jobs,‚Äù IEEE Trans. Cloud Computing 6(4): 1031-1040, 2018.","H2Hadoop has certain limitations that could be exploited to execute the job efficiently. By adding control features to the Name node, H2 hadoop can intelligently direct and assign tasks to the DataNodes that contain the required data. Comparing with native Hadoops, H1Hadoops reduces CPU time, number of read operations, and another Hadooper factors. Also provides a better solution for ‚Äútext data‚Äù, such as finding DNA sequence and the motif of a DNA sequence.",491
406,Computer Science Education,Benjamin Lerner,"February 22nd, 2022",Integrated Data Science for Secondary Schools: Design and Assessment of a Curriculum,https://doi.org/10.1145/3478431.3499311," Emmanuel Schanzer, Nancy Pfenning, Flannery Denny, Sam Dooman, Joe Gibbs Politz, Benjamin S. Lerner, Kathi Fisler, Shriram Krishnamurthi. (2022). Integrated Data Science for Secondary Schools: Design and Assessment of a Curriculum SIGCSE (1), 22-28. https://doi.org/10.1145/3478431.3499311","We propose that secondary-school data-science curricula should be based on four key ingredients: two are technical (programming and statistics, with visualization sitting at their intersection), while two are human-facing (meaningful domains, and civic responsibility). We describe their relationship and argue for their importance. Based on this, we then present the Bootstrap:Data Science curriculum, designed for integration into multiple disciplines and settings. It achieves this by (a) being designed as a set of remix-able lessons, and (b) letting classes and students choose personally meaningful datasets. We also initiate the process of evaluating this curriculum. We create two assessment instruments, one focused on learning and the other on personalization and engagement. We provide very preliminary data gathered from students and teachers.",492
407,Computer Science Education,Benjamin Lerner,"March 5th, 2021",Evolving a K-12 Curriculum for Integrating Computer Science into Mathematics,https://doi.org/10.1145/3408877.3432546," Kathi Fisler, Emmanuel Schanzer, Steve Weimar, Annie Fetter, K. Ann Renninger, Shriram Krishnamurthi, Joe Gibbs Politz, Benjamin S. Lerner, Jennifer Poole, Christine Koerner. (2021). Evolving a K-12 Curriculum for Integrating Computer Science into Mathematics SIGCSE, 59-65. https://doi.org/10.1145/3408877.3432546","Integrating computing into other subjects promises to address many challenges to offering standalone CS courses in K-12 contexts. Integrated curricula must be designed carefully, however, to both meet learning objectives of the host discipline and to gain traction with teachers. We describe the multi-year evolution of Bootstrap, a curriculum for integrating computing into middle- and high-school mathematics. We discuss the initial design and the various modifications we have made over the years to better support math instruction, leading to our goal of using integrated curricula to cover standards in both math and CS. We provide advice for others aiming for integration and raise questions for CS educators about how we might better support learning in other disciplines.",493
408,Computer Science Education,Benjamin Lerner,"April 30th, 2020",Data Science as a Route to AI for Middle- and High-School Students,https://arxiv.org/abs/2005.01794," Shriram Krishnamurthi, Emmanuel Schanzer, Joe Gibbs Politz, Benjamin S. Lerner, Kathi Fisler, Sam Dooman. (2020). Data Science as a Route to AI for Middle- and High-School Students CoRR, abs/2005.01794. https://arxiv.org/abs/2005.01794","The Bootstrap Project's Data Science curriculum has trained about 100 teachers who are using it around the country. It is specifically designed to aid adoption at a wide range of institutions. It emphasizes valuable curricular goals by drawing on both the education literature and on prior experience with other computing outreach projects. It embraces ""three P's"" of data-oriented thinking: the promise, pitfalls, and perils. This paper briefly describes the curriculum's design, content, and outcomes, and explains its value on the road to AI curricula.",494
409,Computer Science Education,Albert Lionelle,"February 18th, 2025",Does ABET Accreditation Influence the Representation of Women in CS Programs?,https://doi.org/10.1145/3641555.3705168," Stefanie Colino Dube, Albert Lionelle. (2025). Does ABET Accreditation Influence the Representation of Women in CS Programs? SIGCSE (2), 1427-1428. https://doi.org/10.1145/3641555.3705168","Curricular analytics can help researchers in computer science (CS) education understand the structural barriers preventing students from discovering and completing the major, especially those underrepresented in tech. Prior research has found an inverse relationship between curricular complexity and percent of CS graduates who identify as women. This study expands upon previous research by focusing specifically on ABET accredited curriculum with respect to complexity and the representation of women. We created curricular maps for 40 ABET and 40 non-ABET programs. Initial findings show that non-ABET programs, on average, have a higher degree of representation of women (33% compared to 21%). Further, the average complexity score for ABET accredited programs is 219, where as non-ABET programs is 133. This poster discusses the use of curricular analytics, our preliminary findings, and further questions to be addressed as part of this work.",495
410,Computer Science Education,Albert Lionelle,"February 18th, 2025",Does Reducing Curricular Complexity Impact Student Success in Computer Science?,https://doi.org/10.1145/3641554.3701915," Sumukhi Ganesan, Albert Lionelle, Catherine Gill, Carla E. Brodley. (2025). Does Reducing Curricular Complexity Impact Student Success in Computer Science? SIGCSE (1), 360-366. https://doi.org/10.1145/3641554.3701915","Computer science degree requirements often have a rigid pre- and corequisite structure, which can impede a student's progression through a degree and in particular can add one or more semesters to time to completion, particularly for those students who need to retake a course that serves as a prerequisite to other courses and for students who are not calculus-ready when they enter university. In this paper, we present the results of a comparative analysis of curricula before and after a major structural revision. The first curriculum adheres to the conventional, rigid prerequisite structure, while the second emphasizes student choice and multiple pathways through the degree. No changes were made to course content/outcomes between the two versions. Employing curricular metrics such as complexity and centrality, we examine the degree progress of 3010 students over a six-year period. Specifically, our investigation looks at the impact of reducing curricular complexity on student attrition from and attraction to the CS major. The new curriculum, with a 60% reduction in curricular structural complexity, showed both increased retention of students over the old curriculum (67% to 98%) and an increase in the number of students converting from undeclared to computer science (44% to 69%). Our findings demonstrate that reducing curricular complexity need not compromise program rigor and can benefit students by providing greater flexibility and ensuring earlier exposure to (and therefore retention in) CS.",496
411,Computer Science Education,Albert Lionelle,"January 15th, 2024","Teach Students to Study Using Quizzes, Study Behavior Visualization, and Reflection: A Case Study in an Introduction to Programming Course",https://doi.org/10.1145/3629296.3629362," Marcia C. Moraes, Albert Lionelle, Sudipto Ghosh, James E. Folkestad. (2023). Teach Students to Study Using Quizzes, Study Behavior Visualization, and Reflection: A Case Study in an Introduction to Programming Course ICETC, 409-415. https://doi.org/10.1145/3629296.3629362","Due to a long history of using rote memorization and rereading as the primary means to study, students are coming to the University with misconceptions about study strategies that are beneficial for their performance and long-term learning. Techniques such as spaced retrieval practice, interleaving, and metacognition are proven by cognitive and educational researchers as strategies that greatly improve learning. They focus on helping students to own responsibility for their learning and retention of information. Considering their benefits, quizzes were re-branded to be formative low-stakes retrieval practice activities (RPAs) in an Introduction to Programming Course (CS1), meaning that students would use the quizzes as learning tools, testing themselves in a spaced and interleaved manner as many times as they want during the semester. Additionally, the U-Behavior learning and teaching method was used. This method applies visualizations of student's study habits and self-reflections to help students to be aware of their study practices, reflect on them, and change their study routine to improve performance and long-term learning. Study behaviors were analyzed and the final Canvas exam, final coding exam, and final course grades were compared for students who spaced and interleaved their practice with students who did not. Results showed a statistically significant increase in all grades evaluated for students who practiced using this novel combination of spacing and interleaving integrated with U-Behavior visualizations and RPA reflection activities for learning.",497
412,Computer Science Education,Albert Lionelle,"March 3rd, 2023",A Flexible Formative/Summative Grading System for Large Courses,https://doi.org/10.1145/3545945.3569810," Albert Lionelle, Sudipto Ghosh, Marcia Moraes, Tran Winick, Lindsey Nielsen. (2023). A Flexible Formative/Summative Grading System for Large Courses SIGCSE (1), 624-630. https://doi.org/10.1145/3545945.3569810","Students in entry level CS courses come from diverse backgrounds and are learning study and time management skills. Our belief for their success is that they must master a growth mindset and that the final grade should represent their final mastery of topics in the course. Traditional grading systems tend to be too restrictive and hinder a growth mindset. They require strict deadlines that fail to easily account for student accommodations and learning differences. Furthermore, they run into averaging and scaling issues with 59% of a score counting as failing, making it difficult for students to redeem grades even if they later demonstrate mastery of topics. We designed a formative/summative grading system in our CS0 and CS1 classes for both on-campus and online students to support a structured growth mindset. Students can redo formative assignments and are provided flexible deadlines. They demonstrate their mastery in summative assignments. While being inspired by other grading systems, our system works seamlessly with auto-grading tools used in large, structured courses. Despite the flexibility, the courses provided a level of rigor before allowing students to continue onto the next course. Overall, 65% of students resubmitted assignments increasing their scores, participated in ungraded assignments, and used formative assignments for additional practice without a distinction between race or gender. These students went to the traditional follow-on CS2 course and 94% passed compared with 71% who took CS1 with a traditional grading system.",498
413,Computer Science Education,Albert Lionelle,"February 22nd, 2022",Increase Performance and Retention: Teach Students How To Study,https://doi.org/10.1145/3478431.3499340," Albert Lionelle, Sudipto Ghosh, Shannon Ourada, Westin Musser. (2022). Increase Performance and Retention: Teach Students How To Study SIGCSE (1), 349-355. https://doi.org/10.1145/3478431.3499340","Intervention in the form of changing one's teaching style is beneficial for boosting student grades and retention. However, in spite of the availability of multiple intervention approaches, a key hindrance is reliance on the belief that students know how to study. We dedicated time and resources to not only teach the discipline of Computer Science, but also to teach students how to study using techniques grounded in psychology. We offered a one-credit ""booster"" course to students taking CS 2: Data Structures. Through direct advisor intervention based on the first exam grade, students were encouraged to take the booster course along with traditional interventions. We then tracked student growth across exams for the course as students were learning and being held accountable to study techniques not often emphasized in Computer Science. The students continued to increase their grades throughout the semester relative to the students who chose to not take the booster class. The students who were targeted for intervention but did not take the booster course continued to have lower grades throughout the semester, and only 41% of them passed the course. Students who participated in the booster course showed a 31% rate of growth across the semester, taking a failing grade to a passing grade, with 100% passing the course with a C or above. These results show a significant influence to help students succeed, which led to higher retention and increased grades. If we want students to truly succeed, we must teach them to study.",499
414,Computer Science Education,Albert Lionelle,"February 22nd, 2022",Increase Performance in CS 2 via a Spiral Redesign of CS 1,https://doi.org/10.1145/3478431.3499339," Albert Lionelle, Sudipto Ghosh, Benjamin Say, J. Ross Beveridge. (2022). Increase Performance in CS 2 via a Spiral Redesign of CS 1 SIGCSE (1), 502-508. https://doi.org/10.1145/3478431.3499339","Computer Science (CS 1) offerings in most universities tend to be notoriously difficult. Over the past 60 years about a third of the students either fail or drop out of the course. Past research has focused on improving teaching methods through small changes without changing the overall course structure. The premise of our research is that restructuring the CS 1 course using a Spiral pedagogy based on principles for improving memory and recall can help students learn the information and retain it for future courses. Using the principles of Spacing, Interleaving, Elaboration, Practiced Retrieval, and Reflection, we fundamentally redesigned CS 1 with a complete reordering of topics. We evaluated the newly designed CS 1 by comparing the students with those coming from a traditional offering in terms of (1) CS 1 performance, (2) retention of students between CS 1 and 2, and (3) CS 2 performance. We demonstrate that the Spiral method helped students outperform those who learn via the traditional method by 9% on final exam scores in CS 1. Retention is increased between CS 1 and CS 2 with a 19.2% increase for women, and 9.2% overall. Furthermore, students continue to do better in CS 2 with increased grades across all assessments and show a 15% increase in passing grades. We provide a framework for the Spiral methodology so that others may replicate the design. Our results lead us to consider evaluating and improving the underlying methodology with which we teach Computer Science.",500
415,Computer Science Education,Albert Lionelle,"February 26th, 2020",CS 0: Culture and Coding,https://doi.org/10.1145/3328778.3366795," Albert Lionelle, Josette Grinslad, J. Ross Beveridge. (2020). CS 0: Culture and Coding SIGCSE, 227-233. https://doi.org/10.1145/3328778.3366795","In 2018, Colorado State University redesigned their CS-0 course to become a general education requirement for the university within Arts and Humanities, and a guaranteed transfer course across the state for a similar category in other universities. The first CS course in the State to be accepted as a GT-Pathway course. This redesign had to be carefully done due to a need to introduce liberal arts style topics such as CS History, Philosophy and Ethics and Inclusive Design issues, while maintaining current coding and student success standards that were already expected for the CS-0 at the university. We termed this combination as Culture and Coding. In order to add more without reducing retention, the course was redesigned around the Psychology of Learning and spacing of topics in a ""Spiral"" Manner. Each topic was briefly introduced, and throughout the semester, students would dive deeper into the topics. This allowed for a 50% reduction of time focused on teaching coding topics, with students performing equivalent on exams compared to previous models of the course that focused 100% of the time on coding topics. Furthermore, students taught by the spiral teaching method outperformed students taught using traditional methods in the follow-on course. Our evaluation suggests that the spiral model of teaching computer science may allow for greater retention of topics, allowing classes to either cover additional concepts or go more in depth on current topics.",501
416,Computer Science Education,Albert Lionelle,"February 21st, 2018",Quantifying the Benefits of Prior Programming Experience in an Introductory Computer Science Course,https://doi.org/10.1145/3159450.3159480," Chris Wilcox, Albert Lionelle. (2018). Quantifying the Benefits of Prior Programming Experience in an Introductory Computer Science Course SIGCSE, 80-85. https://doi.org/10.1145/3159450.3159480","The superior performance of students with prior exposure to programming has long been evident to faculty that teach introductory courses. In this paper we replicate previous studies that quantify the difference between students with and without previous programming experience, and we provide further focus on gender differences. Our research is based on an initial CS1 course that we divided into a section with students having previous programming experience (P) and two sections for students without (N). Both sections of CS1 were taught with the same curriculum and assessments. We find that the advantages of prior experience are substantial, with P students outscoring N students by more than 6% on exams and 10% on programming quizzes. However, the performance gap between P and N students narrows considerably by the end of the following CS2 course, with no significant difference in overall scores. Analyzing results by gender, our data shows that 22% of N students in CS1 are female versus only 12% of P students. However, the female students with prior exposure outperform their male peers in all areas. Another finding of our research is the confirmation of a significant difference in confidence between female and male students.",502
417,Computer Science Education,Felix Muzny,"February 18th, 2025",Student Application Trends for Teaching Assistant Positions,https://doi.org/10.1145/3641554.3701789," Felix Muzny, Abdulaziz Suria, Carla E. Brodley. (2025). Student Application Trends for Teaching Assistant Positions SIGCSE (1), 798-804. https://doi.org/10.1145/3641554.3701789","We present a comprehensive analysis of teaching assistant (TA) application preferences, with the goal of identifying whether there are significant differences in the courses students prefer to TA for based on student identity. Our data was gathered over the span of four years and represents 15,000+ individual applications for all courses in Khoury College of Computer Sciences. Focusing on the dimensions of applicant program level (undergraduate versus Master's students), gender, and international versus domestic student designation, we perform an analysis of application patterns. Our results show that program level, gender, and international status all play roles in student application behavior. Further, we identify specific courses that are preferred by various subsets of students, such as a strong affinity of students who have gone through a Master's bridge program to apply to those courses and a tendency for women and non-binary students to apply at greater rates to our first-year seminar, data science, and databases courses. Finally, we investigate the relationship between instructor gender and applicant gender--revealing that when women and non-binary applicants prefer certain courses, these courses tend to also have a greater-than-average representation of women and non-binary instructors. As a result of this analysis, we present three recommended next steps to gain deeper understanding of the observed patterns. This work demonstrates that with a centralized TA application system, an institution can gain a comprehensive understanding of application behaviors--leading to informed decisions about where to potentially intervene, especially with an eye toward broadening participation in computing at all levels.",503
418,Computer Science Education,Felix Muzny,"March 7th, 2024","Collecting, Analyzing, and Acting on Intersectional, Longitudinal Data and Pass/Fail/Withdraw Rates in Computing Courses",https://doi.org/10.1145/3626252.3630806," Felix Muzny, Megan Giordano, Emma Sommers, Carla E. Brodley. (2024). Collecting, Analyzing, and Acting on Intersectional, Longitudinal Data and Pass/Fail/Withdraw Rates in Computing Courses SIGCSE (1), 909-915. https://doi.org/10.1145/3626252.3630806","We present the Center for Inclusive Computing's data collection and visualization system, which enables computing departments to track and visualize their enrollment and course outcome data intersectionally and longitudinally. The system tracks the impact of institutional changes in how computing (particularly the introductory sequence) is discovered and experienced by undergraduates as measured by course outcome and persistence data. To date we have worked with and collected data from 52 U.S. computing departments. Collected data spans 2018-present and contains term-by- term, intersectional course enrollment and outcome data for CS 1-3, while also tracking declared majors and persistence to graduation. Drawing on our experience working with these universities we present guidelines for the analysis of intersectional, longitudinal data alongside our recommendations for actionable next steps. We present three case studies grounded in an analysis of CS1, demon- strating how an institution can understand their own computing program and develop interventions-specifically with an eye toward broadening participation in computing.",504
419,Computer Science Education,Felix Muzny,"March 6th, 2023",Ungrading with Empathy: An Experiment in Ungrading for Intermediate Data Science,https://doi.org/10.1145/3545947.3573258," Laney Strange, Felix Muzny. (2023). Ungrading with Empathy: An Experiment in Ungrading for Intermediate Data Science SIGCSE (2), 1274. https://doi.org/10.1145/3545947.3573258","We implemented a model for grading weekly assignments in an intermediate data science course that explicitly gave students useful feedback on their code while not evaluating it on the traditional metrics of correctness or style. This ungrading policy was used in a 150-student course led by 2 instructors and 11 Teaching Assistants (TAs). Our ungrading policy was designed to extend empathy towards students and to give them useful, actionable feedback. Our policy reduced the stress that students felt each week, stabilized the amount of time they spent on assignments, and ask them to reflect on their code to request feedback from the teaching team. Students could receive full credit for a homework assignment even if it was incomplete, making office hours less hectic. Students could also submit their homework after working on it for a certain number of hours, even if a bug still existed. Our ungrading policy also helped our TAs feel valued. They gave feedback based on general expectations rather than a point-based rubric, allowing them to share their own expertise. TAs gave feedback only when requested, which was therefore more likely to be read.",505
420,Computer Science Education,Felix Muzny,"March 3rd, 2023",Teaching Assistant Training: An Adjustable Curriculum for Computing Disciplines,https://doi.org/10.1145/3545945.3569866," Felix Muzny, Michael D. Shah. (2023). Teaching Assistant Training: An Adjustable Curriculum for Computing Disciplines SIGCSE (1), 430-436. https://doi.org/10.1145/3545945.3569866","We present an adaptable curriculum for training undergraduate and graduate teaching assistants (TAs) in computing disciplines that is modular, synchronous, and explicitly mirrors the teaching techniques that are used in our classes. Our curriculum is modular, with each component able to be expanded or compressed based on institutional needs and resources. It is appropriate for TAs from CS1 through advanced computing classes. In addition to being easily adjustable to institutional needs, this curriculum holds two important positions. First, that synchronous training is most effective. Second, that it is vital the curriculum is designed based on peer-to-peer learning and actively incorporates abstract pedagogical reflection into the materials. When TAs are taught the content, it is grounded in the same techniques that we are encouraging them to use and that, as computing faculty, we ourselves use. Finally, we posit that student-TA interactions are a specific site of amplifying and attenuating inequality in computing classrooms. By providing a curriculum that is easily accessible and sensitive to both the technical and interpersonal needs of pedagogical training, we aim to create a more welcoming environment for all learners in computing disciplines. Based on our experience teaching this curriculum to more than 900 TAs at two institutions in four different formats, we offer insights and recommendations to using and adjusting this curriculum under varying circumstances. We release the curriculum in its entirety to the computing education community (at https://cic.northeastern.edu/ta-training/).",506
421,Computer Science Education,Felix Muzny,"August 10th, 2022",The Effectiveness of Embedded Values Analysis Modules in Computer Science Education: An Empirical Study,https://doi.org/10.48550/arXiv.2208.05453," Matthew Kopec, Meica Magnani, Vance Ricks, Roben Torosyan, John Basl, Nicholas Miklaucic, Felix Muzny, Ronald Sandler, Christo Wilson, Adam Wisniewski-Jensen, Cora Lundgren, Kevin Mills, Mark Wells. (2022). The Effectiveness of Embedded Values Analysis Modules in Computer Science Education: An Empirical Study CoRR, abs/2208.05453. https://doi.org/10.48550/arXiv.2208.05453","Embedding ethics modules within computer science courses has become a popular response to the growing recognition that CS programs need to better equip their students to navigate the ethical dimensions of computing technologies like AI, machine learning, and big data analytics. However, the popularity of this approach has outpaced the evidence of its positive outcomes. To help close that gap, this empirical study reports positive results from Northeastern's program that embeds values analysis modules into CS courses. The resulting data suggest that such modules have a positive effect on students' moral attitudes and that students leave the modules believing they are more prepared to navigate the ethical dimensions they will likely face in their eventual careers. Importantly, these gains were accomplished at an institution without a philosophy doctoral program, suggesting this strategy can be effectively employed by a wider range of institutions than many have thought.",507
422,Computer Science Education,Vance Ricks,"August 10th, 2022",The Effectiveness of Embedded Values Analysis Modules in Computer Science Education: An Empirical Study,https://doi.org/10.48550/arXiv.2208.05453," Matthew Kopec, Meica Magnani, Vance Ricks, Roben Torosyan, John Basl, Nicholas Miklaucic, Felix Muzny, Ronald Sandler, Christo Wilson, Adam Wisniewski-Jensen, Cora Lundgren, Kevin Mills, Mark Wells. (2022). The Effectiveness of Embedded Values Analysis Modules in Computer Science Education: An Empirical Study CoRR, abs/2208.05453. https://doi.org/10.48550/arXiv.2208.05453","Embedding ethics modules within computer science courses has become a popular response to the growing recognition that CS programs need to better equip their students to navigate the ethical dimensions of computing technologies like AI, machine learning, and big data analytics. However, the popularity of this approach has outpaced the evidence of its positive outcomes. To help close that gap, this empirical study reports positive results from Northeastern's program that embeds values analysis modules into CS courses. The resulting data suggest that such modules have a positive effect on students' moral attitudes and that students leave the modules believing they are more prepared to navigate the ethical dimensions they will likely face in their eventual careers. Importantly, these gains were accomplished at an institution without a philosophy doctoral program, suggesting this strategy can be effectively employed by a wider range of institutions than many have thought.",508
423,Computer Science Education,Vance Ricks,"August 13th, 2021",Toward a rational and ethical sociotechnical system of autonomous vehicles: A novel application of multi-criteria decision analysis,https://doi.org/10.1371/journal.pone.0256224," Dubljevic V, List G, Milojevich J, Ajmeri N, Bauer WA, Singh MP, et al. (2021) Toward a rational and ethical sociotechnical system of autonomous vehicles: A novel application of multi-criteria decision analysis. PLoS ONE 16(8): e0256224. https://doi.org/10.1371/journal.pone.0256224","The impacts of autonomous vehicles (AV) are widely anticipated to be socially, economically, and ethically significant. A reliable assessment of the harms and benefits of their large-scale deployment requires a multi-disciplinary approach. We obtained opinions from 19 disciplinary experts to assess the significance of 13 potential harms and eight potential benefits.",509
424,Computer Science Education,Sami Rollins,"February 18th, 2025",An MS in CS for non-CS Majors: A Ten Year Retrospective,https://doi.org/10.1145/3641554.3701928," Logan W. Schmidt, Caitlin J. Kidder, Ildar Akhmetov, Megan Bebis, Alan C. Jamieson, Albert Lionelle, Sarah Maravetz, Sami Rollins, Ethan Selinger. (2025). An MS in CS for non-CS Majors: A Ten Year Retrospective SIGCSE (1), 1036-1042. https://doi.org/10.1145/3641554.3701928","For the last 10 years, our university has offered a two-semester bridge into a master's in computer science for people with undergraduate degrees in non-computing disciplines. Since its inception, the program has expanded to eight campuses across North America and has opened admission to students from all disciplines, including non-STEM disciplines. The bridge program has over 2000 currently enrolled students, with more than 50% women every year since 2020, and domestic enrollment has increased relative to direct entry master's students. Our data show that bridge students, including those with non-STEM backgrounds, perform comparably to direct entry students in terms of GPA. We attribute much of the program's success to institutional investment in resources specifically designed to meet the unique needs of bridge students. These resources include dedicated academic and career advising, co-curricular programming, and the hiring of full-time teaching faculty specifically recruited to teach these bridge students. This paper examines data pertaining to the bridge program and MSCS from 2013 to 2023; it includes analyses of the expansion of the bridge program to eight campuses in North America, the admission of students with non-STEM degrees to the bridge, the achievement of enrolling over 50% women and non-binary identifying students, the success of bridge students in the MSCS program and in obtaining job placements, and domestic student enrollment growth as compared to traditional direct entry master's students.",510
425,Computer Science Education,Sami Rollins,"October 13th, 2021",Helping Academically Talented STEM Students with Financial Need Succeed,https://doi.org/10.1109/FIE49875.2021.9637250," A. N. Kumar, M. Doyle, V. Hong, A. Joshi, S. Kurkovsky and S. Rollins, ""Helping Academically Talented STEM Students with Financial Need Succeed,"" 2021 IEEE Frontiers in Education Conference (FIE), 2021, pp. 1-9, DOI: 10.1109/FIE49875.2021.9637250.","Research to Practice Full Paper presents the experiences and lessons learned from five programs that provide financial awards and a holistic student support structure to low-income, academically talented students in Science, Technology, Engineering, and Mathematics (STEM) This report synthesizes the experiences of a diverse set of institutions, both public and private, that vary in size and geographic location. Our work is intended to serve as a guide for educators who wish to implement programs to support students from financially disadvantaged and/or historically marginalized groups. By sharing our experiences and pain points, we hope to make it easier for them to design and implement effective programs adapted to their institutional needs and contexts.",511
426,Computer Science Education,Sami Rollins,"July 26th, 2021",Understanding Professional Identity Development Among Computer Science Students,https://peer.asee.org/37962," Sami N. Rollins, Alark Joshi, Xornam Apedoe, Sophie Engle, Matthew Malensek, and Gian Bruno.  ""Understanding Professional Identity Development Among Computer Science Students"".  2021 ASEE Virtual Annual Conference Content Access, Virtual Conference, 2021, July.  ASEE Conferences, 2021. https://peer.asee.org/37962","Second-year students rated themselves higher for recognition, interest and performance/competence items. This suggests that students who have spent a year in our program have developed a greater sense of computing identity, the authors say. In Fall 2019, we began a scholarship program to support low-income, academically talented students.",512
427,Computer Science Education,Ilmi Yoon,"December 10th, 2023",Validated Image Caption Rating Dataset,http://papers.nips.cc/paper_files/paper/2023/hash/c0b91f9a3587bf35287f41dba5d20233-Abstract-Datasets_and_Benchmarks.html," Lothar D. Narins, Andrew T. Scott, Aakash Gautam, Anagha Kulkarni , Mar Castanon, Benjamin Kao, Shasta Ihorn, Yue-Ting Siu, James M. Mason, Alexander Blum, Ilmi Yoon. (2023). Validated Image Caption Rating Dataset NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/c0b91f9a3587bf35287f41dba5d20233-Abstract-Datasets_and_Benchmarks.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Datasets and Benchmarks Track Lothar D Narins, Andrew Scott, Aakash Gautam, Anagha Kulkarni, Mar Castanon, Benjamin Kao, Shasta Ihorn, Yue-Ting Siu, James M. Mason, Alexander Blum, Ilmi Yoon We present a new high-quality validated image caption rating (VICR) dataset. How well a caption fits an image can be difficult to assess due to the subjective nature of caption quality. How do we evaluate whether a caption is good? We generated a new dataset to help answer this question by using our new image caption rating system, which consists of a novel robust rating scale and gamified approach to gathering human ratings. We show that our approach is consistent and teachable. 113 participants were involved in generating the dataset, which is composed of 68,217 ratings among 15,646 image-caption pairs. Our new dataset has greater inter-rater agreement than the state of the art, and custom machine learning rating predictors that were trained on our dataset outperform previous metrics. We improve over Flickr8k-Expert in Kendall's W W by 12\% and in Fleiss' Œ∫ Œ∫ by 19\%, and thus provide a new benchmark dataset for image caption rating. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",513
428,Cybersecurity and Privacy,Tamara Bonaci,"January 6th, 2022",Continuous Operator Authentication for Teleoperated Systems Using Hidden Markov Models,https://doi.org/10.1145/3488901," Junjie Yan, Kevin Huang , Kyle Lindgren, Tamara Bonaci, Howard Jay Chizeck. (2022). Continuous Operator Authentication for Teleoperated Systems Using Hidden Markov Models ACM Trans. Cyber Phys. Syst., 6, 6:1-6:25. https://doi.org/10.1145/3488901","In this article, we present a novel approach for continuous operator authentication in teleoperated robotic processes based on Hidden Markov Models (HMM). While HMMs were originally developed and widely used in speech recognition, they have shown great performance in human motion and activity modeling. We make an analogy between human language and teleoperated robotic processes (i.e., words are analogous to a teleoperator‚Äôs gestures, sentences are analogous to the entire teleoperated task or process) and implement HMMs to model the teleoperated task. To test the continuous authentication performance of the proposed method, we conducted two sets of analyses. We built a virtual reality (VR) experimental environment using a commodity VR headset (HTC Vive) and haptic feedback enabled controller (Sensable PHANToM Omni) to simulate a real teleoperated task. An experimental study with 10 subjects was then conducted. We also performed simulated continuous operator authentication by using the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). The performance of the model was evaluated based on the continuous (real-time) operator authentication accuracy as well as resistance to a simulated impersonation attack. The results suggest that the proposed method is able to achieve 70% (VR experiment) and 81% (JIGSAWS dataset) continuous classification accuracy with as short as a 1-second sample window. It is also capable of detecting an impersonation attack in real-time.",514
429,Cybersecurity and Privacy,Tamara Bonaci,"October 27th, 2020",Your signature is your password: Haptic Passwords on Mobile Devices,https://arxiv.org/abs/2010.14007," Junjie Yan, Tamara Bonaci, Howard Jay Chizeck. (2020). Your signature is your password: Haptic Passwords on Mobile Devices CoRR, abs/2010.14007. https://arxiv.org/abs/2010.14007","In this paper, a new behavioral biometric password based on haptic interaction is described. This ""haptic password"" system is built on a device that has a force-sensitive screen. The user authentication process leverages maximal overlap discrete wavelet transform (MODWT) based feature extraction along with a customized classifier as well as an adaptive template scheme to accommodate users' variations over time. An experimental study was conducted with 29 subjects and we investigated the authentication performance with multiple user postures under simulated forgery attacks. The performance of the model is evaluated based on authentication accuracies. The results suggest that this proposed haptic password system achieves robust high authentication accuracy and scalability, as well as forgery-proof performance.",515
430,Cybersecurity and Privacy,Tamara Bonaci,"January 24th, 2020",An Overview of Fingerprint-Based Authentication: Liveness Detection and Beyond,https://arxiv.org/abs/2001.09183," Filipp Demenschonok, Jason Harrigan, Tamara Bonaci. (2020). An Overview of Fingerprint-Based Authentication: Liveness Detection and Beyond CoRR, abs/2001.09183. https://arxiv.org/abs/2001.09183","In this paper, we provide an overview of fingerprint sensing methods used for authentication. We analyze the current fingerprint sensing technologies, from algorithmic, as well as from hardware perspectives. We then focus on methods to detect physical liveness, defined as techniques that can be used to ensure that a living human user is attempting to authenticate on a system. We analyze how effective these methods are at preventing attacks where a malicious entity tries to trick a fingerprint-based authentication system to accept a fake finger as a real one (spoofing attacks). We then identify broader attack points against biometric data, such as fingerprints. Finally, we propose novel measures to protect fingerprint data.",516
431,Cybersecurity and Privacy,David Choffnes,"November 4th, 2024",IoT Bricks Over v6: Understanding IPv6 Usage in Smart Homes,https://doi.org/10.1145/3646547.3688457," Tianrui Hu, Daniel J. Dubois, David R. Choffnes. (2024). IoT Bricks Over v6: Understanding IPv6 Usage in Smart Homes IMC, 595-611. https://doi.org/10.1145/3646547.3688457","Recent years have seen growing interest and support for IPv6 in residential networks. While nearly all modern networking devices and operating systems support IPv6, it remains unclear how this basic support translates into higher-layer functionality, privacy, and security in consumer IoT devices. In this paper, we present the first comprehensive study of IPv6 usage in smart homes in a testbed equipped with 93 distinct, popular consumer IoT devices. We investigate whether and how they support and use IPv6, focusing on factors such as IPv6 addressing, configuration, DNS and destinations, and privacy and security practices. We find that, despite most devices having some degree of IPv6 support, in an IPv6-only network just 20.4% transmit data to Internet IPv6 destinations, and only 8.6% remain functional, indicating that consumer IoT devices are not yet ready for IPv6 networks. Furthermore, 16.1% of devices use easily traceable IPv6 addresses, posing privacy risks. Our findings highlight the inadequate IPv6 support in consumer IoT devices compared to conventional devices such as laptops and mobile phones. This gap is concerning, as it may lead to not only usability issues but also privacy and security risks for smart home users.",517
432,Cybersecurity and Privacy,David Choffnes,"October 24th, 2023","Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem",https://doi.org/10.1145/3618257.3624803," Umar Iqbal, Pouneh Nikkhah Bahrami, Rahmadi Trimananda, Hao Cui, Alexander Gamero-Garrido, Daniel J. Dubois, David R. Choffnes, Athina Markopoulou, Franziska Roesner, Zubair Shafiq. (2023). Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem IMC, 569-583. https://doi.org/10.1145/3618257.3624803","Smart speakers collect voice commands, which can be used to infer sensitive information about users. Given the potential for privacy harms, there is a need for greater transparency and control over the data collected, used, and shared by smart speaker platforms as well as third party skills supported on them. To bridge this gap, we build a framework to measure data collection, usage, and sharing by the smart speaker platforms. We apply our framework to the Amazon smart speaker ecosystem. Our results show that Amazon and third parties, including advertising and tracking services that are unique to the smart speaker ecosystem, collect smart speaker interaction data. We also find that Amazon processes smart speaker interaction data to infer user interests and uses those inferences to serve targeted ads to users. Smart speaker interaction also leads to ad targeting and as much as 30X higher bids in ad auctions, from third party advertisers. Finally, we find that Amazon's and third party skills' data practices are often not clearly disclosed in their policy documents.",518
433,Cybersecurity and Privacy,David Choffnes,"October 24th, 2023",In the Room Where It Happens: Characterizing Local Communication and Threats in Smart Homes,https://doi.org/10.1145/3618257.3624830," Aniketh Girish, Tianrui Hu, Vijay Prakash, Daniel J. Dubois, Srdjan Matic, Danny Yuxing Huang, Serge Egelman, Joel Reardon, Juan Tapiador, David R. Choffnes, Narseo Vallina-Rodriguez. (2023). In the Room Where It Happens: Characterizing Local Communication and Threats in Smart Homes IMC, 437-456. https://doi.org/10.1145/3618257.3624830","The network communication between Internet of Things (IoT) devices on the same local network has significant implications for platform and device interoperability, security, privacy, and correctness. Yet, the analysis of local home Wi-Fi network traffic and its associated security and privacy threats have been largely ignored by prior literature, which typically focuses on studying the communication between IoT devices and cloud end-points, or detecting vulnerable IoT devices exposed to the Internet. In this paper, we present a comprehensive and empirical measurement study to shed light on the local communication within a smart home deployment and its threats. We use a unique combination of passive network traffic captures, protocol honeypots, dynamic mobile app analysis, and crowdsourced IoT data from participants to identify and analyze a wide range of device activities on the local network. We then analyze these datasets to characterize local network protocols, security and privacy threats associated with them. Our analysis reveals vulnerable devices, insecure use of network protocols, and sensitive data exposure by IoT devices. We provide evidence of how this information is exfiltrated to remote servers by mobile apps and third-party SDKs, potentially for household fingerprinting, surveillance and cross-device tracking. We make our datasets and analysis publicly available to support further research in this area.",519
434,Cybersecurity and Privacy,David Choffnes,"October 25th, 2022",A comparative analysis of certificate pinning in Android & iOS,https://doi.org/10.1145/3517745.3561439," Amogh Pradeep, Muhammad Talha Paracha, Protick Bhowmick, Ali Davanian, Abbas Razaghpanah, Taejoong Chung, Martina Lindorfer, Narseo Vallina-Rodriguez, Dave Levin, David R. Choffnes. (2022). A comparative analysis of certificate pinning in Android & iOS IMC, 605-618. https://doi.org/10.1145/3517745.3561439","TLS certificate pinning is a security mechanism used by applications to protect their network traffic against malicious certificate authorities. Pinning can provide enhanced security to defend against malicious third-party access to sensitive data in transit. It can also hide an app's personal data collection from users and auditors. Prior studies found pinning was rarely used in the Android ecosystem, except in high-profile, security-sensitive apps.",520
435,Cybersecurity and Privacy,David Choffnes,"November 2nd, 2021",IoTLS: understanding TLS usage in consumer IoT devices,https://doi.org/10.1145/3487552.3487830," Muhammad Talha Paracha, Daniel J. Dubois, Narseo Vallina-Rodriguez, David R. Choffnes. (2021). IoTLS: understanding TLS usage in consumer IoT devices Internet Measurement Conference, 165-178. https://doi.org/10.1145/3487552.3487830","Consumer IoT devices are becoming increasingly popular, with most leveraging TLS to provide connection security. In this work, we study a large number of TLS-enabled consumer IoT devices to shed light on how effectively they use TLS, in terms of establishing secure connections and correctly validating certificates, and how observed behavior changes over time. To this end, we gather more than two years of TLS network traffic from IoT devices, conduct active probing to test for vulnerabilities, and develop a novel blackbox technique for exploring the trusted root stores in IoT devices by exploiting a side-channel through TLS Alert Messages. We find a wide range of behaviors across devices, with some adopting best security practices but most being vulnerable in one or more of the following ways: use of old/insecure protocol versions and/or ciphersuites, lack of certificate validation, and poor maintenance of root stores. Specifically, we find that at least 8 IoT devices still include distrusted certificates in their root stores, 11/32 devices are vulnerable to TLS interception attacks, and that many devices fail to adopt modern protocol features over time. Our findings motivate the need for IoT manufacturers to audit, upgrade, and maintain their devices' TLS implementations in a consistent and uniform way that safeguards all of their network traffic.",521
436,Cybersecurity and Privacy,David Choffnes,"October 1st, 2021",A Comparative Study of Dark Patterns Across Mobile and Web Modalities,https://doi.org/10.1145/3479521," Johanna Gunawan, Amogh Pradeep, David Choffnes, Woodrow Hartzog, and Christo Wilson. ""A Comparative Study of Dark Patterns Across Mobile and Web Modalities"". Proceedings of the ACM: Human-Computer Interaction, 5(CSCW2), October, 2021. DOI: 10.1145/3479521","Dark patterns are user interface elements that can influence a person's behavior against their intentions or best interests. Prior work identified these patterns in websites and mobile apps, but little is known about how the design of platforms might impact dark pattern manifestations and related human vulnerabilities. In this paper, we conduct a comparative study of mobile application, mobile browser, and web browser versions of 105 popular services to investigate variations in dark patterns across modalities. We perform manual tests, identify dark patterns in each service, and examine how they persist or differ by modality. Our findings show that while services can employ some dark patterns equally across modalities, many dark patterns vary between platforms, and that these differences saddle people with inconsistent experiences of autonomy, privacy, and control. We conclude by discussing broader implications for policymakers and practitioners, and provide suggestions for furthering dark patterns research.",522
437,Cybersecurity and Privacy,Michael Ann DeVito,"November 8th, 2024",Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge,https://doi.org/10.48550/arXiv.2501.14648," Leah Hope Ajmani, Talia Bhatt, Michael Ann DeVito. (2025). Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge CoRR, abs/2501.14648. https://doi.org/10.48550/arXiv.2501.14648","Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy -- one's ability to govern knowledge about themselves -- as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one's epistemic autonomy, we present six stories from two trans women: (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants.",523
438,Cybersecurity and Privacy,Michael Ann DeVito,"April 26th, 2024",Safety and Community Context: Exploring a Transfeminist Approach to Sapphic Relationship Platforms,https://doi.org/10.1145/3653694," Michael Ann DeVito, Jessica L. Feuston, Erika Melder, Christen Malloy, Cade Ponder, Jed R. Brubaker. (2024). Safety and Community Context: Exploring a Transfeminist Approach to Sapphic Relationship Platforms Proc. ACM Hum. Comput. Interact., 8, 1-34. https://doi.org/10.1145/3653694","Relationship platforms (e.g., dating apps) are crucial tools for sapphics (trans women, cisgender women, and nonbinary people who are attracted to other sapphics). However, current platforms are not designed in a way that accounts for sapphic lived experience, especially the lived experience of sapphics who hold multiple marginalized identity characteristics. Even on platforms that do exist for sapphics, transgender women and nonbinary people are often subject to discrimination, fetishization, and stigmatization. To aid in the design of platforms that better serve the needs of multiply marginalized sapphics, we engaged a diverse group of 25 sapphics in six rounds of community discussion on key topics for relationship platform design. Based on participant discussions, we identify key challenges when designing for multiply marginalized sapphics around relationship structures, gender and sexuality classification, and safety priorities for interaction. We present two design priorities alongside community-sourced design directions which can help future designers address these challenges: identity-centric safety and community-based information formats.",524
439,Cybersecurity and Privacy,Michael Ann DeVito,"January 1st, 2024",Whose Knowledge is Valued? Epistemic Injustice in CSCW Applications,https://doi.org/10.1145/3687062," Leah Hope Ajmani, Jasmine C. Foriest, Jordan Taylor, Kyle Pittman, Sarah A. Gilbert, Michael Ann DeVito. (2024). Whose Knowledge is Valued? Epistemic Injustice in CSCW Applications Proc. ACM Hum. Comput. Interact., 8, 1-28. https://doi.org/10.1145/3687062","Social computing scholars have long known that people do not interact with knowledge in straightforward ways, especially in digital environments. While policies around knowledge are essential for targeting misinformation, they are value-laden; in choosing how to present information, we undermine non-traditional, often non-Western, ways of knowing. Epistemic injustice is the systemic exclusion of certain people and methods from the knowledge canon. Epistemic injustice chips away at one's testimony and vocabulary until they are stripped of their due right to know and understand. In this paper, we articulate how epistemic injustice in sociotechnical applications leads to material harm. Inspired by a hybrid collaborative autoethnography of 14 CSCW practitioners, we present three cases of epistemic injustice in sociotechnical applications: online transgender healthcare, identity sensemaking on r/bisexual, and Indigenous ways of knowing on r/AskHistorians. We further explore signature tensions across our autoethnographic materials and relate them to previous CSCW research areas and personal non-technological experiences. We argue that epistemic injustice can serve as a unifying and intersectional lens for CSCW research by surfacing dimensions of epistemic community and power. Finally, we present a call to action of three changes the CSCW community should make to move toward its own goals of research justice. We call for CSCW researchers to center individual experiences, bolster communities, and remediate issues of epistemic power as a means towards epistemic justice. In sum, we recount, synthesize, and propose solutions for the various forms of epistemic injustice that CSCW sites of study---including CSCW itself---propagate.",525
440,Cybersecurity and Privacy,Michael Ann DeVito,"May 8th, 2021",Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research,https://doi.org/10.1145/3411763.3450403," Michael Ann DeVito, Caitlin Lustig, Ellen Simpson, Kimberley R. Allison, Tya S. Chuanromanee, Katta Spiel, Amy J. Ko, Jennifer Ann Rode, Brianna Dym, Michael J. Muller, Morgan Klaus Scheuerman, Ashley Marie Walker, Jed R. Brubaker, Alex A. Ahmed. (2021). Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research CHI Extended Abstracts, 159:1-159:3. https://doi.org/10.1145/3411763.3450403","As Queer Human-Computer Interaction (HCI) becomes an established part of the larger field, both in terms of research on and with queer populations and in terms of employing queering theories and methods, the role of queer researchers has become a timely topic of discussion. However, these discussions have largely centered around member-researcher status and positionality when working with queer populations. Based on insights gathered at multiple ACM events over the past two years, we identified two pressing issues: (1) we need to better support queer people doing HCI research not specific to queer populations, and (2) we need to identify how to best support member-researchers in leading Queer HCI while including collaborators beyond the queer community. This Special Interest Group (SIG) aims to directly address these challenges by convening a broad community of queer researchers and allies, working not only on explicitly-queer topics but across a broad range of HCI topics.",526
441,Cybersecurity and Privacy,Laura Edelson,"June 6th, 2023",Understanding the (In)Effectiveness of Content Moderation: A Case Study of Facebook in the Context of the U.S. Capitol Riot,https://doi.org/10.48550/arXiv.2301.02737," Ian Goldstein, Laura Edelson, Damon McCoy, Tobias Lauinger. (2023). Understanding the (In)Effectiveness of Content Moderation: A Case Study of Facebook in the Context of the U.S. Capitol Riot CoRR, abs/2301.02737. https://doi.org/10.48550/arXiv.2301.02737","Social media networks commonly employ content moderation as a tool to limit the spread of harmful content. However, the efficacy of this strategy in limiting the delivery of harmful content to users is not well understood. In this paper, we create a framework to quantify the efficacy of content moderation and use our metrics to analyze content removal on Facebook within the U.S. news ecosystem. In a data set of over 2M posts with 1.6B user engagements collected from 2,551 U.S. news sources before and during the Capitol Riot on January 6, 2021, we identify 10,811 removed posts. We find that the active engagement life cycle of Facebook posts is very short, with 90% of all engagement occurring within the first 30 hours after posting. Thus, even relatively quick intervention allowed significant accrual of engagement before removal, and prevented only 21% of the predicted engagement potential during a baseline period before the U.S. Capitol attack. Nearly a week after the attack, Facebook began removing older content, but these removals occurred so late in these posts' engagement life cycles that they disrupted less than 1% of predicted future engagement, highlighting the limited impact of this intervention. Content moderation likely has limits in its ability to prevent engagement, especially in a crisis, and we recommend that other approaches such as slowing down the rate of content diffusion be investigated.",527
442,Cybersecurity and Privacy,Laura Edelson,"August 1st, 2022",An Audit of Facebook‚Äôs Political Ad Policy Enforcement,https://www.usenix.org/conference/usenixsecurity22/presentation/lepochat," Victor Le Pochat, Laura Edelson, Tom van Goethem, Wouter Joosen, Damon McCoy, Tobias Lauinger. (2022). An Audit of Facebook's Political Ad Policy Enforcement USENIX Security Symposium, 607-624. https://www.usenix.org/conference/usenixsecurity22/presentation/lepochat","Victor Le Pochat, imec-DistriNet, KU Leuven; Laura Edelson, New York University; Tom Van Goethem and Wouter Joosen, imec-DistriNet, KU Leuven; Damon McCoy and Tobias Lauinger, New York University Distinguished Paper Award Winner Major technology companies strive to protect the integrity of political advertising on their platforms by implementing and enforcing self-regulatory policies that impose transparency requirements on political ads. In this paper, we quantify whether Facebook‚Äôs current enforcement correctly identifies political ads and ensures compliance by advertisers. In a comprehensive, large-scale analysis of 4.2 million political and 29.6 million non-political ads from 215,030 advertisers, we identify ads correctly detected as political (true positives), ads incorrectly detected (false positives), and ads missed by detection (false negatives). Facebook‚Äôs current enforcement appears imprecise: 61% more ads are missed than are detected worldwide, and 55% of U.S. detected ads are in fact non-political. Detection performance is uneven across countries, with some having up to 53 times higher false negative rates among clearly political pages than in the U.S. Moreover, enforcement appears inadequate for preventing systematic violations of political advertising policies: for example, advertisers were able to continue running political ads without disclosing them while they were temporarily prohibited in the U.S. We attribute these flaws to five gaps in Facebook‚Äôs current enforcement and transparency implementation, and close with recommendations to improve the security of the online political ad ecosystem. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. ¬© USENIX 2025 EIN 13-3055038",528
443,Cybersecurity and Privacy,Kevin Fu,"January 10th, 2025",Learning Flexible Heterogeneous Coordination with Capability-Aware Shared Hypernetworks,https://doi.org/10.48550/arXiv.2501.06058," Kevin Fu, Pierce Howell, Shalin Jain, Harish Ravichandar. (2025). Learning Flexible Heterogeneous Coordination with Capability-Aware Shared Hypernetworks CoRR, abs/2501.06058. https://doi.org/10.48550/arXiv.2501.06058","Recent advances have enabled heterogeneous multi-robot teams to learn complex and effective coordination. However, existing architectural designs that support heterogeneous teams tend to force a trade-off between expressivity and efficiency. Some attempt to encode diverse behaviors within a single shared architecture by appending the input with an ID unique to each robot or robot type. These designs improve sample and parameter efficiency but tend to limit behavioral diversity. Others use a separate policy for each robot, enabling greater diversity at the cost of efficiency and generalization. We view these two designs as ends of a spectrum and explore a middle-ground approach that enables efficient learning of diverse behaviors. Inspired by work in transfer learning and meta RL, and building upon prior work in trait-based task allocation, we propose Capability-Aware Shared Hypernetworks (CASH), a general-purpose soft weight sharing architecture that uses hypernetworks to enable a single architecture to dynamically adapt to each robot and the current context. Intuitively, CASH encodes shared decision making strategies that can be adapted to each robot based on local observations and the robots' individual and collective capabilities (e.g., speed and payload). CASH explicitly captures the impact of capabilities on collective behavior, enabling zero-shot generalization to unseen robots or team compositions. We conducted experiments across four heterogeneous coordination tasks and three learning paradigms (imitation learning, value-based, and policy-gradient RL) using SOTA multi-robot simulation (JaxMARL) and hardware (Robotarium) platforms. Across all conditions, CASH generates appropriately diverse behaviors and outperforms baseline architectures in task performance and sample efficiency during training and zero-shot generalization while utilizing 60%-80% fewer learnable parameters.",529
444,Cybersecurity and Privacy,Kevin Fu,"November 28th, 2023",Adversarial Computer Vision via Acoustic Manipulation of Camera Sensors,https://doi.org/10.1109/TDSC.2023.3334618," Yushi Cheng, Xiaoyu Ji , Wenjun Zhu, Shibo Zhang, Kevin Fu, Wenyuan Xu . (2024). Adversarial Computer Vision via Acoustic Manipulation of Camera Sensors IEEE Trans. Dependable Secur. Comput., 21, 3734-3750. https://doi.org/10.1109/TDSC.2023.3334618","Autonomous vehicles increasingly rely on camera-based computer vision systems to perceive environments and make critical driving decisions. To improve image quality, image stabilizers with inertial sensors are added to reduce image blurring caused by camera jitters. This trend creates a new attack surface. By emitting deliberately designed acoustic signals, an adversary can control the output of an inertial sensor, which triggers unnecessary motion compensation and results in a blurred image. These blurred images can induce object misclassification, affecting safety-critical decision-making. We model the feasibility of such acoustic manipulation and design an attack framework that can accomplish three types of attacks.",530
445,Cybersecurity and Privacy,Joshua Gancher,"September 20th, 2024",Secure Synthesis of Distributed Cryptographic Applications,https://doi.org/10.1109/CSF61375.2024.00021," Cosku Acay, Joshua Gancher, Rolph Recto, Andrew C. Myers. (2024). Secure Synthesis of Distributed Cryptographic Applications CSF, 433-448. https://doi.org/10.1109/CSF61375.2024.00021","Developing secure distributed systems is difficult, and even harder when advanced cryptography must be used to achieve security goals. We advocate using secure program partitioning to synthesize cryptographic applications. Instead of implementing a system of communicating processes, the programmer implements a centralized, sequential program, which is automatically compiled into a secure distributed version that uses cryptography. We prove that our result guarantees robust hyperproperty preservation, an important criterion for compiler correctness that preserves all source-level security properties in target programs. The proof targets hybrid protocols, which abstract cryptographic mechanisms as idealized functionalities. It relies on a novel unification of simulation-based security, information-flow control, choreographic programming, and sequentialization techniques for concurrent programs.",531
446,Cybersecurity and Privacy,Joshua Gancher,"June 18th, 2021","Viaduct: an extensible, optimizing compiler for secure distributed programs",https://doi.org/10.1145/3453483.3454074," Cosku Acay, Rolph Recto, Joshua Gancher, Andrew C. Myers, Elaine Shi. (2021). Viaduct: an extensible, optimizing compiler for secure distributed programs PLDI, 740-755. https://doi.org/10.1145/3453483.3454074","Modern distributed systems involve interactions between principals with limited trust, so cryptographic mechanisms are needed to protect confidentiality and integrity. At the same time, most developers lack the training to securely employ cryptography. We present Viaduct, a compiler that transforms high-level programs into secure, efficient distributed realizations. Viaduct's source language allows developers to declaratively specify security policies by annotating their programs with information flow labels. The compiler uses these labels to synthesize distributed programs that use cryptography efficiently while still defending the source-level security policy. The Viaduct approach is general, and can be easily extended with new security mechanisms. Our implementation of the Viaduct compiler comes with an extensible runtime system that includes plug-in support for multiparty computation, commitments, and zero-knowledge proofs. We have evaluated the system on a set of benchmarks, and the results indicate that our approach is feasible and can use cryptography in efficient, nontrivial ways.",532
447,Cybersecurity and Privacy,Ariel Hamlin,"December 22nd, 2023",Upgrading Fuzzy Extractors,https://eprint.iacr.org/2023/1941," Chlo√© Cachet, Ariel Hamlin, Maryam Rezapour, Benjamin Fuller . (2023). Upgrading Fuzzy Extractors IACR Cryptol. ePrint Arch., 2023, 1941. https://eprint.iacr.org/2023/1941",Fuzzy extractors derive stable keys from noisy sources non-interactively. It is known one cannot reuse an arbitrary fuzzy Extractor; each enrollment can leak a constant fraction of the input entropy. We show a generic upgrade for a private fuzzy extractor using multi-bit compute and compare (MBCC) obfuscation.,533
448,Cybersecurity and Privacy,Ariel Hamlin,"August 1st, 2023","Multi random projection inner product encryption, applications to proximity searchable encryption for the iris biometric",https://doi.org/10.1016/j.ic.2023.105059," Chlo√© Cachet, Sohaib Ahmad, Luke Demarest, Serena Riback, Ariel Hamlin, Benjamin Fuller . (2023). Multi random projection inner product encryption, applications to proximity searchable encryption for the iris biometric Inf. Comput., 293, 105059. https://doi.org/10.1016/j.ic.2023.105059","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",534
449,Cybersecurity and Privacy,Ariel Hamlin,"May 30th, 2022",Proximity Searchable Encryption for the Iris Biometric,https://doi.org/10.1145/3488932.3497754," Chlo√© Cachet, Sohaib Ahmad, Luke Demarest, Ariel Hamlin, Benjamin Fuller . (2022). Proximity Searchable Encryption for the Iris Biometric AsiaCCS, 1004-1018. https://doi.org/10.1145/3488932.3497754","For small vector sizes multiple unrelated biometrics are returned in the search. For vectors of length 1024 this reduces time to run setup from 23 days to 4 minutes. The distance-revealing scheme can search a small (hundreds) database in 4 minutes while the distance-hiding scheme is not yet practical, requiring 3.5 hours.",535
450,Cybersecurity and Privacy,Zhengzhong Jin,"November 21st, 2023",Scalable Multiparty Garbling,https://doi.org/10.1145/3576915.3623132," Gabrielle Beck, Aarushi Goel, Aditya Hegde , Abhishek Jain , Zhengzhong Jin, Gabriel Kaptchuk. (2023). Scalable Multiparty Garbling CCS, 2158-2172. https://doi.org/10.1145/3576915.3623132","Multiparty garbling is the most popular approach for constant-round secure multiparty computation (MPC). Despite being the focus of significant research effort, instantiating prior approaches to multiparty garbling results in constant-round MPC that can not realistically accommodate large numbers of parties. In this work we present the first global-scale multiparty garbling protocol. The per-party communication complexity of our protocol decreases as the number of parties participating in the protocol increases - for the first time matching the asymptotic communication complexity of non-constant round MPC protocols. Our protocol achieves malicious security in the honest-majority setting and relies on the hardness of the Learning Party with Noise assumption.",536
451,Cybersecurity and Privacy,Zhengzhong Jin,"August 9th, 2023",A Note on Non-interactive Zero-Knowledge from CDH,https://doi.org/10.1007/978-3-031-38551-3_23," Geoffroy Couteau, Abhishek Jain , Zhengzhong Jin, Willy Quach. (2023). A Note on Non-interactive Zero-Knowledge from CDH CRYPTO (4), 731-764. https://doi.org/10.1007/978-3-031-38551-3_23","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",537
452,Cybersecurity and Privacy,Zhengzhong Jin,"August 9th, 2023",Correlation Intractability and SNARGs from Sub-exponential DDH,https://doi.org/10.1007/978-3-031-38551-3_20," Arka Rai Choudhuri, Sanjam Garg, Abhishek Jain , Zhengzhong Jin, Jiaheng Zhang. (2023). Correlation Intractability and SNARGs from Sub-exponential DDH CRYPTO (4), 635-668. https://doi.org/10.1007/978-3-031-38551-3_20","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",538
453,Cybersecurity and Privacy,Engin Kirda,"November 13th, 2021",T-Reqs: HTTP Request Smuggling with Differential Fuzzing,https://doi.org/10.1145/3460120.3485384," Bahruz Jabiyev, Steven Sprecher, Kaan Onarlioglu, Engin Kirda. (2021). T-Reqs: HTTP Request Smuggling with Differential Fuzzing CCS, 1805-1820. https://doi.org/10.1145/3460120.3485384","HTTP Request Smuggling (HRS) is an attack that exploits the HTTP processing discrepancies between two servers deployed in a proxy-origin configuration, allowing attackers to smuggle hidden requests through the proxy. While this idea is not new, HRS is soaring in popularity due to recently revealed novel exploitation techniques and real-life abuse scenarios. In this work, we step back from the highly-specific exploits hogging the spotlight, and present the first work that systematically explores HRS within a scientific framework. We design an experiment infrastructure powered by a novel grammar-based differential fuzzer, test 10 popular server/proxy/CDN technologies in combinations, identify pairs that result in processing discrepancies, and discover exploits that lead to HRS. Our experiment reveals previously unknown ways to manipulate HTTP requests for exploitation, and for the first time documents the server pairs prone to HRS.",539
454,Cybersecurity and Privacy,Engin Kirda,"February 9th, 2020",Discovering algorithmic denial-of-service vulnerabilities through guided micro-fuzzing,https://arxiv.org/abs/2002.03416," Blair, William, Andrea Mambretti, Sajjad Arshad, Michael Weissbacher, William K. Robertson, Engin Kirda and Manuel Egele. ‚ÄúHotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing.‚Äù ArXiv abs/2002.03416 (2020): n. pag.","Contemporary fuzz testing techniques focus on identifying memory corruption vulnerabilities that allow adversaries to achieve either remote code execution or information disclosure. Meanwhile, Algorithmic Complexity (AC)vulnerabilities, which are a common attack vector for denial-of-service attacks, remain an understudied threat. In this paper, we present HotFuzz, a framework for automatically discovering AC vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high CPU utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values.",540
455,Cybersecurity and Privacy,Engin Kirda,"February 25th, 2016",TrueClick: automatically distinguishing trick banners from genuine download links,http://dl.acm.org/citation.cfm?id=2664279," ""TrueClick: automatically distinguishing trick banners from genuine download links"" S Duman, K Onarlioglu, AO Ulusoy, W Robertson, E Kirda- Proceedings of the 30th Annual Computer Security, 2014","The ubiquity of Internet advertising has made it a popular target for attackers. One well-known instance of these attacks is the widespread use of trick banners that use social engineering techniques to lure victims into clicking on deceptive fake links, potentially leading to a malicious domain or malware. A recent and pervasive trend by attackers is to imitate the ""download"" or ""play"" buttons in popular file sharing sites (e.g., one-click hosters, video-streaming sites, bittorrent sites) in an attempt to trick users into clicking on these fake banners instead of the genuine link. In this paper, we explore the problem of automatically assisting Internet users in detecting malicious trick banners and helping them identify the correct link. We present a set of features to characterize trick banners based on their visual properties such as image size, color, placement on the enclosing webpage, whether they contain animation effects, and whether they consistently appear with the same visual properties on consecutive loads of the same webpage. We have implemented a tool called TrueClick, which uses image processing and machine learning techniques to build a classifier based on these features to automatically detect the trick banners on a webpage. Our approach automatically classifies trick banners, and requires no manual effort to compile blacklists as current approaches do. Our experiments show that TrueClick results in a 3.55 factor improvement in correct link selection in the absence of other ad blocking software, and that it can detect trick banners missed by a popular ad detection tool, Adblock Plus.",541
456,Cybersecurity and Privacy,Engin Kirda,"July 16th, 2015",BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications,http://link.springer.com/chapter/10.1007/978-3-662-47854-7_21," Ozcan, Ahmet Talha, et al. ""BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications."" Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2015. 355-369.|","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",542
457,Cybersecurity and Privacy,Ada Lerner,"August 1st, 2024",Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit,https://www.usenix.org/conference/usenixsecurity24/presentation/tabassum," Madiha Tabassum, Alana Mackey, Ashley Schuett, Ada Lerner. (2024). Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit USENIX Security Symposium. https://www.usenix.org/conference/usenixsecurity24/presentation/tabassum","Madiha Tabassum, Northeastern University; Alana Mackey, Wellesley College; Ashley Schuett, George Washington University; Ada Lerner, Northeastern University Social media platforms often rely on volunteer moderators to combat hate and harassment and create safe online environments. In the face of challenges combating hate and harassment, moderators engage in mutual support with one another. We conducted a qualitative content analysis of 115 hate and harassment-related threads from r/ModSupport and r/modhelp, two major subreddit forums for this type of mutual support. We analyze the challenges moderators face; complex tradeoffs related to privacy, utility, and harassment; and major challenges in the relationship between moderators and platform admins. We also present the first systematization of how platform features (including especially security, privacy, and safety features) are misused for online abuse, and drawing on this systematization we articulate design themes for platforms that want to resist such misuse. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. ¬© USENIX 2025 EIN 13-3055038",543
458,Cybersecurity and Privacy,Ada Lerner,"August 1st, 2024",‚ÄòCustodian of Online Communities‚Äô: How Moderator Mutual Support in Communities Help Fight Hate and Harassment Online,https://www.usenix.org/conference/soups2024/presentation/tabassum-madiha," Madiha Tabassum, Alana Mackey, Ada Lerner. (2024). 'Custodian of Online Communities': How Moderator Mutual Support in Communities Help Fight Hate and Harassment Online SOUPS @ USENIX Security Symposium, 297-314. https://www.usenix.org/conference/soups2024/presentation/tabassum-madiha","Madiha Tabassum, Northeastern University; Alana Mackey, Wellesley College; Ada Lerner, Northeastern University Volunteer moderators play a crucial role in safeguarding online communities, actively combating hate, harassment, and inappropriate content while enforcing community standards. Prior studies have examined moderation tools and practices, moderation challenges, and the emotional labor and burnout of volunteer moderators. However, researchers have yet to delve into the ways moderators support one another in combating hate and harassment within the communities they moderate through participation in meta-communities of moderators. To address this gap, we have conducted a qualitative content analysis of 115 hate and harassment-related threads from r/ModSupport and r/modhelp, two major subreddit forums for moderators for this type of mutual support. Our study reveals that moderators seek assistance on topics ranging from fighting attacks to understanding Reddit policies and rules to just venting their frustration. Other moderators respond to these requests by validating their frustration and challenges, showing emotional support, and providing information and tangible resources to help with their situation. Based on these findings, we share the implications of our work in facilitating platform and peer support for online volunteer moderators on Reddit and similar platforms. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. ¬© USENIX 2025 EIN 13-3055038",544
459,Cybersecurity and Privacy,Ada Lerner,"May 11th, 2024",Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom,https://doi.org/10.1145/3613904.3642664," Kelly Wang, Dan Bially Levy, Kien T. Nguyen, Ada Lerner, Abigail Marsh. (2024). Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom CHI, 575:1-575:13. https://doi.org/10.1145/3613904.3642664","The privacy practices of transformative fandom are of interest to HCI researchers both for the community‚Äôs high proportion of queer members and for the community‚Äôs sophisticated privacy norms and behaviors. We investigated fans‚Äô use of single-serving websites on Carrd.co (‚ÄúCarrds‚Äù) as personal profiles linked from Twitter accounts. We scraped Twitter to gather 5252 Carrds from fans in a variety of fandoms, which we analyzed using a combination of keyword searches and hand-coding. Fans‚Äô Carrds frequently disclose queer identity, and articulate a complex system of community values and boundary management. Inspired by how these findings aren‚Äôt well-explained by individual theories of privacy, we articulate first steps towards a theory of collective privacy based in a communal process of values construction, trust building, and personal disclosure that we believe helps us to understand the sophisticated nature of fans‚Äô observed behaviors.",545
460,Cybersecurity and Privacy,Ada Lerner,"April 26th, 2024",Privacy Norms of Transformative Fandom: A Case Study of an Activity-Defined Community,https://doi.org/10.1145/3637388," Abby Marsh, Ada Lerner. (2024). Privacy Norms of Transformative Fandom: A Case Study of an Activity-Defined Community Proc. ACM Hum. Comput. Interact., 8, 1-29.","Transformative media fandom is a remarkably coherent, long-lived, and diverse community united primarily by shared engagement in the varied activities of fandom. Its social norms are highly-developed and frequently debated, and have been studied by the CSCW and Media Studies communities in the past, but rarely using the tools and theories of privacy, despite fannish norms often bearing strongly on privacy. We use privacy scholarship and existing theories thereof to examine these norms and bring an additional perspective to understanding fandom communities. In this work, we analyze over 250,000 words of ""meta'' essays and comments on those essays, reflecting the views and debates of hundreds of fans on these privacy norms. Drawing on Solove's theory of privacy as an aggregation of different ideas and on a variety of other academic theories of privacy, we analyze these norms as highly effective at protecting the integrity of fannish activities. We then articulate the value of studying these sorts of diverse ""activity-defined'' communities, arguing that such approaches grant us greater power to understand privacy experiences in ways that are specific, contextual, and intersectional yet still generalizable where possible.",546
461,Cybersecurity and Privacy,Ada Lerner,"December 24th, 2023",SoK: Technical Implementation and Human Impact of Internet Privacy Regulations,https://doi.org/10.48550/arXiv.2312.15383," Eleanor Birrell, Jay Rodolitz, Angel Ding, Jenna Lee, Emily McReynolds, Jevan Hutson, Ada Lerner. (2023). SoK: Technical Implementation and Human Impact of Internet Privacy Regulations CoRR, abs/2312.15383. https://doi.org/10.48550/arXiv.2312.15383","Growing recognition of the potential for exploitation of personal data and of the shortcomings of prior privacy regimes has led to the passage of a multitude of new online privacy regulations. Some of these laws -- notably the European Union's General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) -- have been the focus of large bodies of research by the computer science community, while others have received less attention. In this work, we analyze a set of Internet privacy and data protection regulations drawn from around the world -- both those that have frequently been studied by computer scientists and those that have not -- and develop a taxonomy of rights granted and obligations imposed by these laws. We then leverage this taxonomy to systematize 270 technical research papers published in computer science venues that investigate the impact of these laws and explore how technical solutions can complement legal protections. Finally, we analyze the results in this space through an interdisciplinary lens and make recommendations for future work at the intersection of computer science and legal privacy.",547
462,Cybersecurity and Privacy,Ada Lerner,"September 20th, 2023","‚ÄúIt‚Äôs a Fair Game‚Äù, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents",https://doi.org/10.48550/arXiv.2309.11653," Zhiping Zhang, Michelle Jia, Hao-Ping Hank Lee, Bingsheng Yao, Sauvik Das, Ada Lerner, Dakuo Wang, Tianshi Li. (2023). ""It's a Fair Game"", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents CoRR, abs/2309.11653. https://doi.org/10.48550/arXiv.2309.11653","The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigm shifts to protect the privacy of LLM-based CA users.",548
463,Cybersecurity and Privacy,Ada Lerner,"November 14th, 2022",Buying Privacy: User Perceptions of Privacy Threats from Mobile Apps,https://doi.org/10.48550/arXiv.2211.07235," Jenny Tang, Hannah Shoemaker, Leah Teffera, Eleanor Birrell, Ada Lerner. (2022). Buying Privacy: User Perceptions of Privacy Threats from Mobile Apps CoRR, abs/2211.07235. https://doi.org/10.48550/arXiv.2211.07235","As technology and technology companies have grown in power, ubiquity, and societal influence, some companies -- and notably some mobile apps -- have come to be perceived as privacy threats. Prior work has considered how various factors impact perceptions of threat, including social factors, political speech, and user-interface design. In this work, we investigate how user-visible context clues impact perceptions about whether a mobile application application poses a privacy threat. We conduct a user study with 2109 users in which we find that users depend on context clues -- such as presence of advertising and occurrence (and timing of payment) -- to determine the extent to which a mobile app poses a privacy threat. We also quantify how accurately user assessments match published data collection practices, and we identify a commonly-held misconception about how payments are processed. This work provides new insight into how users assess the privacy threat posed by mobile apps and into social norms around data collection.",549
464,Cybersecurity and Privacy,Ada Lerner,"August 7th, 2022",How Well Do My Results Generalize Now? The External Validity of Online Privacy and Security Surveys,https://doi.org/10.48550/arXiv.2202.14036," Jenny Tang, Eleanor Birrell, and Ada Lerner. ""How Well Do My Results Generalize Now? The External Validity of Online Privacy and Security Surveys."" In Symposium on Usable Privacy and Security (SOUPS), 2022.","Privacy and security researchers often rely on data collected through online crowdsourcing platforms such as Amazon Mechanical Turk (MTurk) and Prolific. Prior work -- which used data collected in the United States between 2013 and 2017 -- found that MTurk responses regarding security and privacy were generally representative for people under 50 or with some college education. However, the landscape of online crowdsourcing has changed significantly over the last five years, with the rise of Prolific as a major platform and the increasing presence of bots. This work attempts to replicate the prior results about the external validity of online privacy and security surveys. We conduct an online survey on MTurk (n=800), a gender-balanced survey on Prolific (n=800), and a representative survey on Prolific (n=800) and compare the responses to a probabilistic survey conducted by the Pew Research Center (n=4272). We find that MTurk response quality has degraded over the last five years, and our results do not replicate the earlier finding about the generalizability of MTurk responses. By contrast, we find that data collected through Prolific is generally representative for questions about user perceptions and experiences, but not for questions about security and privacy knowledge. We also evaluate the impact of Prolific settings, attention check questions, and statistical methods on the external validity of online surveys, and we develop recommendations about best practices for conducting online privacy and security surveys.",550
465,Cybersecurity and Privacy,Ada Lerner,"July 11th, 2022",The Buffet Overflow Caf√©,https://doi.org/10.1109/MSEC.2022.3173122," Tadayoshi Kohno, Camille Cobb, Ada Lerner, Michelle Lin, Adam Shostack. (2022). The Buffet Overflow Caf√© IEEE Secur. Priv., 20, 4-7. https://doi.org/10.1109/MSEC.2022.3173122","Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Metadata Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Page(s): 4 - 7 Date of Publication: 11 July 2022 ISSN Information: DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Metadata Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Page(s): 4 - 7 Date of Publication: 11 July 2022 ISSN Information: DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Date of Publication: 11 July 2022 DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE",551
466,Cybersecurity and Privacy,Ada Lerner,"March 16th, 2021",Defining Privacy: How Users Interpret Technical Terms in Privacy Policies,https://doi.org/10.2478/popets-2021-0038," Jenny Tang, Hannah Shoemaker, Ada Lerner, and Eleanor Birrell. ""Defining Privacy: How Users Interpret Technical Terms in Privacy Policies."" In Proceedings on Privacy Enhancing Technologies, 2021(3):70-94., 2021. DOI: 10.2478/popets-2021-0038","Authors: Jenny Tang (Wellesley College), Hannah Shoemaker (Pomona College), Ada Lerner (Wellesley College), Eleanor Birrell (Pomona College) Volume: 2021 Issue: 3 Pages: 70‚Äì94 DOI: https://doi.org/10.2478/popets-2021-0038 Download PDF Abstract: Recent privacy regulations such as GDPR and CCPA have emphasized the need for transparent, understandable privacy policies. This work investigates the role technical terms play in policy transparency. We identify potentially misunderstood technical terms that appear in privacy policies through a survey of current privacy policies and a pilot user study. We then run a user study on Amazon Mechanical Turk to evaluate whether users can accurately define these technical terms, to identify commonly held misconceptions, and to investigate how the use of technical terms affects users‚Äô comfort with privacy policies. We find that technical terms are broadly misunderstood and that particular misconceptions are common. We also find that the use of technical terms affects users‚Äô comfort with various privacy policies and their reported likeliness to accept those policies. We conclude that current use of technical terms in privacy policies poses a challenge to policy transparency and user privacy, and that companies should take steps to mitigate this effect. Keywords: privacy policies, policy transparency",552
467,Cybersecurity and Privacy,Ada Lerner,"April 23rd, 2020",Privacy and Activism in the Transgender Community,https://doi.org/10.1145/3313831.3376339," Ada Lerner, Helen Yuxun He, Anna Kawakami, Silvia Catherine Zeamer, and Roberto Hoyle. 2020. Privacy and Activism in the Transgender Community. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). Association for Computing Machinery, New York, NY, USA, 1‚Äì13. DOI: 10.1145/3313831.3376339","Transgender people are marginalized, facing specific privacy concerns and high risk of online and offline harassment, discrimination, and violence. They also benefit tremendously from technology. We conducted semi-structured interviews with 18 transgender people from 3 U.S. cities about their computer security and privacy experiences broadly construed. Participants frequently returned to themes of activism and prosocial behavior, such as protest organization, political speech, and role-modeling transgender identities, so we focus our analysis on these themes. We identify several prominent risk models related to visibility, luck, and identity that participants used to analyze their own risk profiles, often as distinct or extreme. These risk perceptions may heavily influence transgender people's defensive behaviors and self-efficacy, jeopardizing their ability to defend themselves or gain technology's benefits. We articulate design lessons emerging from these ideas, contrasting and relating them to lessons about other marginalized groups whenever possible.",553
468,Cybersecurity and Privacy,Alan Mislove,"October 25th, 2022",Measurement and analysis of implied identity in ad delivery optimization,https://doi.org/10.1145/3517745.3561450," Levi Kaplan, Nicole Gerzon, Alan Mislove, Piotr Sapiezynski. (2022). Measurement and analysis of implied identity in ad delivery optimization IMC, 195-209. https://doi.org/10.1145/3517745.3561450","The study was published in the open-source journal, The Open Knowledge Project. It is published by the Open Knowledge Foundation, a non-profit organization. We find dramatic skews in who ultimately sees ads solely based on the demographics of the person in the ads. These findings bring up novel technical, legal, and policy questions and underscore the need to better understand how platforms deliver ads.",554
469,Cybersecurity and Privacy,Alan Mislove,"November 2nd, 2021",Selfish & opaque transaction ordering in the Bitcoin blockchain: the case for chain neutrality,https://doi.org/10.1145/3487552.3487823," Johnnatan Messias, Mohamed Alzayat, Balakrishnan Chandrasekaran , Krishna P. Gummadi, Patrick Loiseau, Alan Mislove. (2021). Selfish & opaque transaction ordering in the Bitcoin blockchain: the case for chain neutrality Internet Measurement Conference, 320-335. https://doi.org/10.1145/3487552.3487823","Most public blockchain protocols, including the popular Bitcoin and Ethereum blockchains, do not formally specify the order in which miners should select transactions from the pool of pending (or uncommitted) transactions for inclusion in the blockchain. Over the years, informal conventions or ""norms"" for transaction ordering have, however, emerged via the use of shared software by miners, e.g., the GetBlockTemplate (GBT) mining protocol in Bitcoin Core. Today, a widely held view is that Bitcoin miners prioritize transactions based on their offered ""transaction fee-per-byte."" Bitcoin users are, consequently, encouraged to increase the fees to accelerate the commitment of their transactions, particularly during periods of congestion. In this paper, we audit the Bitcoin blockchain and present statistically significant evidence of mining pools deviating from the norms to accelerate the commitment of transactions for which they have (i) a selfish or vested interest, or (ii) received dark-fee payments via opaque (non-public) side-channels. As blockchains are increasingly being used as a record-keeping substrate for a variety of decentralized (financial technology) systems, our findings call for an urgent discussion on defining neutrality norms that miners must adhere to when ordering transactions in the chains. Finally, we make our data sets and scripts publicly available.",555
470,Cybersecurity and Privacy,Alan Mislove,"August 9th, 2021",The ties that un-bind: decoupling IP from web services and sockets for robust addressing agility at CDN-scale,https://doi.org/10.1145/3452296.3472922," Marwan Fayed, Lorenz Bauer, Vasileios Giotsas, Sami Kerola, Marek Majkowski, Pavel Odintsov, Jakub Sitnicki, Taejoong Chung, Dave Levin, Alan Mislove, Christopher A. Wood, Nick Sullivan. (2021). The ties that un-bind: decoupling IP from web services and sockets for robust addressing agility at CDN-scale SIGCOMM, 433-446. https://doi.org/10.1145/3452296.3472922","The couplings between IP addresses, names of content or services, and socket interfaces, are too tight. This impedes system manageability, growth, and overall provisioning. In turn, large-scale content providers are forced to use staggering numbers of addresses, ultimately leading to address exhaustion (IPv4) and inefficiency (IPv6). In this paper, we revisit IP bindings, entirely. We attempt to evolve addressing conventions by decoupling IP in DNS and from network sockets. Alongside technologies such as SNI and ECMP, a new architecture emerges that ``unbinds'' IP from services and servers, thereby returning IP's role to merely that of reachability. The architecture is under evaluation at a major CDN in multiple datacenters. We show that addresses can be generated randomly \emph{per-query}, for 20M+ domains and services, from as few as ~4K addresses, 256 addresses, and even \emph{one} IP address. We explain why this approach is transparent to routing, L4/L7 load-balancers, distributed caching, and all surrounding systems -- and is \emph{highly desirable}. Our experience suggests that many network-oriented systems and services (e.g., route leak mitigation, denial of service, measurement) could be improved, and new ones designed, if built with addressing agility.",556
471,Cybersecurity and Privacy,Alan Mislove,"August 2nd, 2021",A Large-Scale Analysis of Deployed Traffic Differentiation Practices,https://doi.org/10.1145/3341302.3342092," Fangfan Li, Arian Akhavan Niaki, David Choffnes, Phillipa Gill, and Alan Mislove. 2019. A large-scale analysis of deployed traffic differentiation practices. In Proceedings of the ACM Special Interest Group on Data Communication (SIGCOMM '19). Association for Computing Machinery, New York, NY, USA, 130‚Äì144. DOI: 10.1145/3341302.3342092","Net neutrality has been the subject of considerable public debate over the past decade. Despite the potential impact on content providers and users, there is currently a lack of tools or data for stakeholders to independently audit the net neutrality policies of network providers. In this work, we address this issue by conducting a one-year study of content-based traffic differentiation policies deployed in operational networks, using results from 1,045,413 crowdsourced measurements conducted by 126,249 users across 2,735 ISPs in 183 countries/regions. We develop and evaluate a methodology that combines individual per-device measurements to form high-confidence, statistically significant inferences of differentiation practices, including fixed-rate bandwidth limits (i.e., throttling) and delayed throttling practices. Using this approach, we identify differentiation in both cellular and WiFi networks, comprising 30 ISPs in 7 countries. We also investigate the impact of throttling practices on video streaming resolution for several popular video streaming providers.",557
472,Cybersecurity and Privacy,Alan Mislove,"March 1st, 2021",Building and Auditing Fair Algorithms: A Case Study in Candidate Screening,https://doi.org/10.1145/3442188.3445928," Christo Wilson, Avijit Ghosh, Shan Jiang, Alan Mislove, Lewis Baker, Janelle Szary, Kelly Trindel, and Frida Polli. ""Building and Auditing Fair Algorithms: A Case Study in Candidate Screening."" In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2021). Virtual Event, Canada, March, 2021. DOI: 10.1145/3442188.3445928","Academics, activists, and regulators are increasingly urging companies to develop and deploy sociotechnical systems that are fair and unbiased. Achieving this goal, however, is complex: the developer must (1) deeply engage with social and legal facets of ""fairness"" in a given context, (2) develop software that concretizes these values, and (3) undergo an independent algorithm audit to ensure technical correctness and social accountability of their algorithms. To date, there are few examples of companies that have transparently undertaken all three steps. In this paper we outline a framework for algorithmic auditing by way of a case-study of pymetrics, a startup that uses machine learning to recommend job candidates to their clients. We discuss how pymetrics approaches the question of fairness given the constraints of ethical, regulatory, and client demands, and how pymetrics' software implements adverse impact testing. We also present the results of an independent audit of pymetrics' candidate screening tool. We conclude with recommendations on how to structure audits to be practical, independent, and constructive, so that companies have better incentive to participate in third party audits, and that watchdog groups can be better prepared to investigate companies.",558
473,Cybersecurity and Privacy,Alan Mislove,"February 11th, 2016",Peeking Beneath the Hood of Uber,http://dl.acm.org/citation.cfm?id=2815681," Chen, Le, Alan Mislove, and Christo Wilson. ""Peeking Beneath the Hood of Uber."" Proceedings of the 2015 ACM Conference on Internet Measurement Conference. ACM, 2015.","Recently, Uber has emerged as a leader in the ""sharing economy"". Uber is a ""ride sharing"" service that matches willing drivers with customers looking for rides. However, unlike other open marketplaces (e.g., AirBnB), Uber is a black-box: they do not provide data about supply or demand, and prices are set dynamically by an opaque ""surge pricing"" algorithm. The lack of transparency has led to concerns about whether Uber artificially manipulate prices, and whether dynamic prices are fair to customers and drivers. In order to understand the impact of surge pricing on passengers and drivers, we present the first in-depth investigation of Uber. We gathered four weeks of data from Uber by emulating 43 copies of the Uber smartphone app and distributing them throughout downtown San Francisco (SF) and midtown Manhattan. Using our dataset, we are able to characterize the dynamics of Uber in SF and Manhattan, as well as identify key implementation details of Uber's surge price algorithm. Our observations about Uber's surge price algorithm raise important questions about the fairness and transparency of this system.",559
474,Cybersecurity and Privacy,Alan Mislove,"October 28th, 2015",Identifying Traffic Differentiation in Mobile Networks,https://doi.org/10.1145/2815675.2815691," Arash Molavi Kakhki, Abbas Razaghpanah, Hyungjoon Koo, Anke Li, Rajeshkumar Golani, David Choffnes, Phillipa Gill, and Alan Mislove. ‚ÄúIdentifying traffic differentiation in mobile networks.‚Äù Proceedings of the 2015 Internet Measurement Conference. 2015. DOI: 10.1145/2815675.2815691","Traffic differentiation---giving better (or worse) performance to certain classes of Internet traffic---is a well-known but poorly understood traffic management policy. There is active discussion on whether and how ISPs should be allowed to differentiate Internet traffic, but little data about current practices to inform this discussion. Previous work attempted to address this problem for fixed line networks; however, there is currently no solution that works in the more challenging mobile environment. In this paper, we present the design, implementation, and evaluation of the first system and mobile app for identifying traffic differentiation for arbitrary applications in the mobile environment (i.e., wireless networks such as cellular and WiFi, used by smartphones and tablets). The key idea is to use a VPN proxy to record and replay the network traffic generated by arbitrary applications, and compare it with the network behavior when replaying this traffic outside of an encrypted tunnel. We perform the first known testbed experiments with actual commercial shaping devices to validate our system design and demonstrate how it outperforms previous work for detecting differentiation. We released our app and collected differentiation results from 12 ISPs in 5 countries. We find that differentiation tends to affect TCP traffic (reducing rates by up to 60%) and that interference from middleboxes (including video-transcoding devices) is pervasive. By exposing such behavior, we hope to improve transparency for users and help inform future policies.",560
475,Cybersecurity and Privacy,Cristina Nita-Rotaru,"December 9th, 2024",Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking,https://doi.org/10.1145/3658644.3670301," Ben Weintraub, Jiwon Kim, Ran Tao, Cristina Nita-Rotaru, Hamed Okhravi, Dave (Jing) Tian, Benjamin E. Ujcich. (2024). Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking CCS, 3630-3644. https://doi.org/10.1145/3658644.3670301","Intent-based networking (IBN) enables network administrators to express high-level goals and network policies without needing to specify low-level forwarding configurations, topologies, or protocols. Administrators can define intents that capture the overall behavior they want from the network, and an IBN controller compiles such intents into low-level configurations that get installed in the network and implement the desired behavior. We discovered that current IBN specifications and implementations do not specify that flow rule installation orderings should be enforced, which leads to temporal vulnerabilities where, for a limited time, attackers can exploit indeterminate connectivity behavior to gain unauthorized network access. In this paper, we analyze the causes of such temporal vulnerabilities and their security impacts with a representative case study via the ONOS IBN implementation. We devise the Phantom Link attack and demonstrate a working exploit to highlight the security impacts. To defend against such attacks, we propose Spotlight, a detection method that can alert a system administrator of risky intent updates prone to exploitable temporal vulnerabilities. Spotlight is effective in identifying risky updates using realistic network topologies and policies. We show that Spotlight can detect risky updates in a mean time of 0.65 seconds for topologies of over 1,300 nodes.",561
476,Cybersecurity and Privacy,Cristina Nita-Rotaru,"December 9th, 2024",Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network,https://doi.org/10.1145/3658644.3670315," Ben Weintraub, Satwik Prabhu Kumble, Cristina Nita-Rotaru, Stefanie Roos. (2024). Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network CCS, 2562-2576. https://doi.org/10.1145/3658644.3670315","The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network. In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using them we re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment.",562
477,Cybersecurity and Privacy,Cristina Nita-Rotaru,"December 9th, 2024",Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups,https://doi.org/10.1145/3658644.3690259," Christof Ferreira Torres, Albin Mamuti, Ben Weintraub, Cristina Nita-Rotaru, Shweta Shinde. (2024). Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups CCS, 2591-2605. https://doi.org/10.1145/3658644.3690259","The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging. In this paper, we investigate the prevalence and impact of MEV on Ethereum and prominent rollups such as Arbitrum, Optimism, and zkSync over a nearly three-year period. Our analysis encompasses various metrics including volume, profits, costs, competition, and response time to MEV opportunities. We discover that MEV is widespread on rollups, with trading volume comparable to Ethereum. We also find that, although MEV costs are lower on rollups, profits are also significantly lower compared to Ethereum. Additionally, we examine the prevalence of sandwich attacks on rollups. While our findings did not detect any sandwiching activity on popular rollups, we did identify the potential for cross-layer sandwich attacks facilitated by transactions that are sent across rollups and Ethereum. Consequently, we propose and evaluate the feasibility of three novel attacks that exploit cross-layer transactions, revealing that attackers could have already earned approximately 2 million USD through cross-layer sandwich attacks.",563
478,Cybersecurity and Privacy,Cristina Nita-Rotaru,"July 17th, 2019",Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols,https://doi.org/10.1609/aaai.v33i01.33019478," Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser, Cristina Nita-Rotaru. (2019). Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols AAAI, 9478-9483. https://doi.org/10.1609/aaai.v33i01.33019478",Abstract Grammar-based fuzzing is a technique used to find software vulnerabilities by injecting well-formed inputs generated following rules that encode application semantics. Most grammar-based fuzzers for network protocols rely on human experts to manually specify these rules. In this work we study automated learning of protocol rules from textual specifications (i.e. RFCs). We evaluate the automatically extracted protocol rules by applying them to a state-of-the-art fuzzer for transport protocols and show that it leads to a smaller number of test cases while finding the same attacks as the system that uses manually specified rules.,564
479,Cybersecurity and Privacy,Cristina Nita-Rotaru,"October 15th, 2018",Cross-App Poisoning in Software-Defined Networking,https://doi.org/10.1145/3243734.3243759," Benjamin E. Ujcich, Samuel Jero, Anne Edmundson, Qi Wang , Richard Skowyra, James Landry, Adam Bates , William H. Sanders, Cristina Nita-Rotaru, Hamed Okhravi. (2018). Cross-App Poisoning in Software-Defined Networking CCS, 648-663. https://doi.org/10.1145/3243734.3243759","Software-defined networking (SDN) continues to grow in popularity because of its programmable and extensible control plane realized through network applications (apps). However, apps introduce significant security challenges that can systemically disrupt network operations, since apps must access or modify data in a shared control plane state. If our understanding of how such data propagate within the control plane is inadequate, apps can co-opt other apps, causing them to poison the control plane's integrity. We present a class of SDN control plane integrity attacks that we call cross-app poisoning (CAP), in which an unprivileged app manipulates the shared control plane state to trick a privileged app into taking actions on its behalf. We demonstrate how role-based access control (RBAC) schemes are insufficient for preventing such attacks because they neither track information flow nor enforce information flow control (IFC). We also present a defense, ProvSDN, that uses data provenance to track information flow and serves as an online reference monitor to prevent CAP attacks. We implement ProvSDN on the ONOS SDN controller and demonstrate that information flow can be tracked with low-latency overheads.",565
480,Cybersecurity and Privacy,Cristina Nita-Rotaru,"May 27th, 2018",Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,https://arxiv.org/abs/1804.00308," Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning  Matthew Jagielski, Alina Oprea, Chang Liu, Cristina Nita-Rotaru, and Bo Li  IEEE S&P (Oakland) 2018","As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",566
481,Cybersecurity and Privacy,Cristina Nita-Rotaru,"October 23rd, 2017",Chizpurfle: A Gray-Box Android Fuzzer for Vendor Service Customizations,http://ieeexplore.ieee.org/document/8109068/," Antonio Ken Iannillo, Roberto Natella, Domenico Cotroneo, Cristina Nita-Rotaru. IEEE ISSRE 2017, September 2017","Chizpurfle is a novel ""gray-box"" fuzzing tool for vendor-specific Android services. Testing these services is challenging for existing tools, since vendors do not provide source code and the services cannot be run on a device emulator. Chiz Purfle has been designed to run on an unmodified Android OS on an actual device. The tool automatically discovers, fuzzes, and profiles proprietary services.",567
482,Cybersecurity and Privacy,Cristina Nita-Rotaru,"September 1st, 2017",BEADS: Automated Attack Discovery in OpenFlow-based SDN Systems,https://link.springer.com/chapter/10.1007/978-3-319-66332-6_14," Samuel Jero, Xiangyu Bu, Hamed Okhravi, Cristina Nita-Rotaru, Richard Skowyra, Sonia Fahmy. RAID 2017, September 2017","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",568
483,Cybersecurity and Privacy,Cristina Nita-Rotaru,"June 29th, 2017",Analyzing Operational Behavior of Stateful Protocol Implementations for Detecting Semantic Bugs,http://ieeexplore.ieee.org/document/8023160/," Endadul Hoque, Omar Chowdhury, Sze Yiu Chau, Cristina Nita-Rotaru, Ninghui Li. IEEE DSN 2017, June 2017","Network protocol implementations must comply with their specifications that include properties describing the correct operational behavior of the protocol. Due to inconsistent interpretations of the specification, developers can unknowingly introduce semantic bugs, which cause the implementations to violate the respective properties. Detecting such bugs in stateful protocols becomes significantly difficult as their operations depend on their internal state machines and complex interactions between the protocol logic. We present an automated tool to help developers analyze their protocol implementations and detect semantic bugs violating the temporal properties of the protocols. The paper was published in the 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)",569
484,Cybersecurity and Privacy,Alina Oprea,"December 10th, 2024",SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html," Ethan Rathbun, Christopher Amato, Alina Oprea. (2024). SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Ethan Rathbun, Christopher Amato, Alina Oprea Reinforcement learning (RL) is an actively growing field that is seeing increased usage in real-world, safety-critical applications -- making it paramount to ensure the robustness of RL algorithms against adversarial attacks. In this work we explore a particularly stealthy form of training-time attacks against RL -- backdoor poisoning. Here the adversary intercepts the training of an RL agent with the goal of reliably inducing a particular action when the agent observes a pre-determined trigger at inference time. We uncover theoretical limitations of prior work by proving their inability to generalize across domains and MDPs. Motivated by this, we formulate a novel poisoning attack framework which interlinks the adversary's objectives with those of finding an optimal policy -- guaranteeing attack success in the limit. Using insights from our theoretical analysis we develop ""SleeperNets"" as a universal backdoor attack which exploits a newly proposed threat model and leverages dynamic reward poisoning techniques. We evaluate our attack in 6 environments spanning multiple domains and demonstrate significant improvements in attack success over existing methods, while preserving benign episodic return.",570
485,Cybersecurity and Privacy,Alina Oprea,"November 1st, 2024",User Inference Attacks on Large Language Models,https://aclanthology.org/2024.emnlp-main.1014," Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu . (2024). User Inference Attacks on Large Language Models EMNLP, 18238-18265. https://aclanthology.org/2024.emnlp-main.1014","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text written by humans makes up the vast majority of the data used to pre-train and fine-tune large language models (LLMs). Many sources of this data‚Äîlike code, forum posts, personal websites, and books‚Äîare easily attributed to one or a few ‚Äúusers‚Äù. In this paper, we ask if it is possible to infer if any of a _user‚Äôs_ data was used to train an LLM. Not only would this constitute a breach of privacy, but it would also enable users to detect when their data was used for training. We develop the first effective attacks for _user inference_‚Äîat times, with near-perfect success‚Äîagainst LLMs. Our attacks are easy to employ, requiring only black-box access to an LLM and a few samples from the user, which _need not be the ones that were trained on_. We find, both theoretically and empirically, that certain properties make users more susceptible to user inference: being an outlier, having highly correlated examples, and contributing a larger fraction of data. Based on these findings, we identify several methods for mitigating user inference including training with example-level differential privacy, removing within-user duplicate examples, and reducing a user‚Äôs contribution to the training data. Though these provide partial mitigation, our work highlights the need to develop methods to fully protect LLMs from user inference.",571
486,Cybersecurity and Privacy,Alina Oprea,"January 16th, 2024",Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning,https://openreview.net/forum?id=4DoSULcfG6," Harsh Chaudhari, Giorgio Severi, Alina Oprea, Jonathan R. Ullman. (2024). Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning ICLR. https://openreview.net/forum?id=4DoSULcfG6","The integration of Machine Learning in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for ML training purposes. One such privacy risk is Membership Inference (MI), in which an adversary seeks to determine whether a particular data point was included in the training dataset of a model. Current state-of-the-art MI approaches capitalize on access to the model‚Äôs predicted confidence scores to successfully perform membership inference.",572
487,Cybersecurity and Privacy,Alina Oprea,"August 18th, 2023",Modeling self-propagating malware with epidemiological models,https://doi.org/10.1007/s41109-023-00578-z," Alesia Chernikova, Nicol√≤ Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. (2023). Modeling self-propagating malware with epidemiological models Appl. Netw. Sci., 8, 52. https://doi.org/10.1007/s41109-023-00578-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",573
488,Cybersecurity and Privacy,Alina Oprea,"July 21st, 2023",SNAP: Efficient Extraction of Private Properties with Poisoning,https://doi.org/10.1109/SP46215.2023.10179334," Harsh Chaudhari, John Abascal, Alina Oprea, Matthew Jagielski, Florian Tram√®r, Jonathan R. Ullman. (2023). SNAP: Efficient Extraction of Private Properties with Poisoning SP, 400-417. https://doi.org/10.1109/SP46215.2023.10179334","Property inference attacks allow an adversary to extract global properties of the training dataset from a machine learning model. Such attacks have privacy implications for data owners sharing their datasets to train machine learning models. We design an efficient property inference attack, SNAP, which obtains higher attack success and requires lower amounts of poisoning than the state-of-the-art poisoning-based property inference attacked by Mahloujifar et al. [3]. For example, on the Census dataset, SNAP achieves 34% higher success rate than [3] while being 56.5√ó faster. We also extend our attack to infer whether a certain property was present at all during training and estimate the exact proportion of a property of interest efficiently.",574
489,Cybersecurity and Privacy,Alina Oprea,"February 6th, 2023",One-shot Empirical Privacy Estimation for Federated Learning,https://doi.org/10.48550/arXiv.2302.03098," Galen Andrew, Peter Kairouz, Sewoong Oh, Alina Oprea, H. Brendan McMahan, Vinith Suriyakumar. (2023). One-shot Empirical Privacy Estimation for Federated Learning CoRR, abs/2302.03098. https://doi.org/10.48550/arXiv.2302.03098","Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel ""one-shot"" approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP training algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on well-established FL benchmark datasets under several adversarial threat models.",575
490,Cybersecurity and Privacy,Alina Oprea,"January 23rd, 2023",Backdoor Attacks in Peer-to-Peer Federated Learning,https://doi.org/10.48550/arXiv.2301.09732," G√∂kberk Yar, Cristina Nita-Rotaru, Alina Oprea. (2023). Backdoor Attacks in Peer-to-Peer Federated Learning CoRR, abs/2301.09732. https://doi.org/10.48550/arXiv.2301.09732","Most machine learning applications rely on centralized learning processes, opening up the risk of exposure of their training datasets. While federated learning (FL) mitigates to some extent these privacy risks, it relies on a trusted aggregation server for training a shared global model. Recently, new distributed learning architectures based on Peer-to-Peer Federated Learning (P2PFL) offer advantages in terms of both privacy and reliability. Still, their resilience to poisoning attacks during training has not been investigated. In this paper, we propose new backdoor attacks for P2PFL that leverage structural graph properties to select the malicious nodes, and achieve high attack success, while remaining stealthy. We evaluate our attacks under various realistic conditions, including multiple graph topologies, limited adversarial visibility of the network, and clients with non-IID data. Finally, we show the limitations of existing defenses adapted from FL and design a new defense that successfully mitigates the backdoor attacks, without an impact on model accuracy.",576
491,Cybersecurity and Privacy,Alina Oprea,"October 25th, 2022",Poisoning Attacks Against Machine Learning: Can Machine Learning Be Trustworthy?,https://doi.org/10.1109/MC.2022.3190787," Alina Oprea, Anoop Singhal, Apostol Vassilev . (2022). Poisoning Attacks Against Machine Learning: Can Machine Learning Be Trustworthy? Computer, 55, 94-99. https://doi.org/10.1109/MC.2022.3190787","Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the r... Show More Metadata Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Page(s): 94 - 99 Date of Publication: 25 October 2022 ISSN Information: DOI: 10.1109/MC.2022.3190787 Publisher: IEEE Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the r... Show More Metadata Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Page(s): 94 - 99 Date of Publication: 25 October 2022 ISSN Information: DOI: 10.1109/MC.2022.3190787 Publisher: IEEE Abstract: Many practical applications benefit from machine learning and artificial intelligence technologies, but their security needs to be studied in more depth. We discuss the risk of poisoning attacks against the training stage of machine learning and challenges of defending against them. Published in: Computer ( Volume: 55 , Issue: 11 , November 2022 ) Date of Publication: 25 October 2022 DOI: 10.1109/MC.2022.3190787 Publisher: IEEE",577
492,Cybersecurity and Privacy,Alina Oprea,"September 13th, 2022",Machine Learning Security and Privacy,https://doi.org/10.1109/MSEC.2022.3188190," Nathalie Baracaldo, Alina Oprea. (2022). Machine Learning Security and Privacy IEEE Secur. Priv., 20, 11-13. https://doi.org/10.1109/MSEC.2022.3188190","This special issue explores emerging security and privacy aspects related to machine learning and artificial intelligence techniques. Machine learning and deep learning are increasingly deployed for automated decisions in many critical applications today. An area of research called adversarial machine learning has been developed to understand the security of machine learning in various settings. Other threats against machine learning include poisoning attacks, where an adversary controls a subset of data at training time, and privacy attacks in which an adversary is interested in learning sensitive information about the training data and model parameters.",578
493,Cybersecurity and Privacy,Alina Oprea,"May 12th, 2022",How to Combine Membership-Inference Attacks on Multiple Updated Machine Learning Models,https://doi.org/10.56553/popets-2023-0078," Matthew Jagielski, Stanley Wu, Alina Oprea, Jonathan R. Ullman, Roxana Geambasu. (2023). How to Combine Membership-Inference Attacks on Multiple Updated Machine Learning Models Proc. Priv. Enhancing Technol., 2023, 211-232. https://doi.org/10.56553/popets-2023-0078","Authors: Matthew Jagielski (Google Research), Stanley Wu (Northeastern University), Alina Oprea (Northeastern University), Jonathan Ullman (Northeastern University), Roxana Geambasu (Columbia University) Volume: 2023 Issue: 3 Pages: 211‚Äì232 DOI: https://doi.org/10.56553/popets-2023-0078 Download PDF Abstract: A large body of research has shown that machine learning models are vulnerable to membership inference (MI) attacks that violate the privacy of the participants in the training data. Most MI research focuses on the case of a single standalone model, while production machine-learning platforms often update models over time, on data that often shifts in distribution, giving the attacker more information. This paper proposes new attacks that take advantage of one or more model updates to improve MI. A key part of our approach is to leverage rich information from standalone MI attacks mounted separately against the original and updated models, and to combine this information in specific ways to improve attack effectiveness. We propose a set of combination functions and tuning methods for each, and present both analytical and quantitative justification for various options. Our results on four public datasets show that our attacks are effective at using update information to give the adversary a significant advantage over attacks on standalone models, but also compared to a prior MI attack that takes advantage of model updates in a related machine-unlearning setting. We perform the first measurements of the impact of distribution shift on MI attacks with model updates, and show that a more drastic distribution shift results in significantly higher MI risk than a gradual shift. We also show that our attacks are effective at auditing differentially private fine tuning. We make our code public on Github: https://github.com/stanleykywu/model-updates. Keywords: membership inference, machine learning, update, entry inference, distribution shift",579
494,Cybersecurity and Privacy,Alina Oprea,"January 1st, 2021",Subpopulation Data Poisoning Attacks,https://doi.org/10.1145/3460120.3485368," Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea. (2021). Subpopulation Data Poisoning Attacks CCS, 3104-3122. https://doi.org/10.1145/3460120.3485368","Machine learning systems are deployed in critical settings, but they might fail in unexpected ways, impacting the accuracy of their predictions. Poisoning attacks against machine learning induce adversarial modification of data used by a machine learning algorithm to selectively change its output when it is deployed. In this work, we introduce a novel data poisoning attack called a subpopulation attack, which is particularly relevant when datasets are large and diverse. We design a modular framework for subpopulation attacks, instantiate it with different building blocks, and show that the attacks are effective for a variety of datasets and machine learning models. We further optimize the attacks in continuous domains using influence functions and gradient optimization methods. Compared to existing backdoor poisoning attacks, subpopulation attacks have the advantage of inducing misclassification in naturally distributed data points at inference time, making the attacks extremely stealthy. We also show that our attack strategy can be used to improve upon existing targeted attacks. We prove that, under some assumptions, subpopulation attacks are impossible to defend against, and empirically demonstrate the limitations of existing defenses against our attacks, highlighting the difficulty of protecting machine learning against this threat.",580
495,Cybersecurity and Privacy,Alina Oprea,"December 6th, 2018",Differentially Private Fair Learning,https://arxiv.org/abs/1812.02696," Jagielski, Matthew, Kearns, Michael, Mao, Jieming, Oprea, Alina, Roth, Aaron, Sharifi, Saeed, & Ullman, Jonathan. (2019). Differentially Private Fair Learning. Proceedings of the 36 Th International Conference on Machine Learning.","Motivated by settings in which predictive models may be required to be non-discriminatory with respect to certain attributes (such as race), but even collecting the sensitive attribute may be forbidden or restricted, we initiate the study of fair learning under the constraint of differential privacy. We design two learning algorithms that simultaneously promise differential privacy and equalized odds, a 'fairness' condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a private implementation of the equalized odds post-processing approach of [Hardt et al., 2016]. This algorithm is appealingly simple, but must be able to use protected group membership explicitly at test time, which can be viewed as a form of 'disparate treatment'. Our second algorithm is a differentially private version of the oracle-efficient in-processing approach of [Agarwal et al., 2018] that can be used to find the optimal fair classifier, given access to a subroutine that can solve the original (not necessarily fair) learning problem. This algorithm is more complex but need not have access to protected group membership at test time. We identify new tradeoffs between fairness, accuracy, and privacy that emerge only when requiring all three properties, and show that these tradeoffs can be milder if group membership may be used at test time. We conclude with a brief experimental evaluation.",581
496,Cybersecurity and Privacy,Alina Oprea,"May 27th, 2018",Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,https://arxiv.org/abs/1804.00308," Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning  Matthew Jagielski, Alina Oprea, Chang Liu, Cristina Nita-Rotaru, and Bo Li  IEEE S&P (Oakland) 2018","As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",582
497,Cybersecurity and Privacy,William Robertson,"August 2nd, 2024",A Viewpoint: Safer Heaps With Practical Architectural Security Primitives,https://doi.org/10.1109/MSEC.2024.3404672," William K. Robertson, Manuel Egele. (2024). A Viewpoint: Safer Heaps With Practical Architectural Security Primitives IEEE Secur. Priv., 22, 62-65. https://doi.org/10.1109/MSEC.2024.3404672","We argue that architectural security primitives are a promising basis for fast and secure program heaps. We discuss MPKAlloc, a recent research effort demonstrating the concrete benefits of this approach using Intel MPK to harden a production allocator. We end by discussing promising future directions for the field.",583
498,Cybersecurity and Privacy,William Robertson,"July 4th, 2021",SoK: Enabling Security Analyses of Embedded Systems via Rehosting,https://doi.org/10.1145/3433210.3453093," Fasano, Andrew, et al. ""SoK: Enabling Security Analyses of Embedded Systems via Rehosting."" Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security. 2021.","Closely monitoring the behavior of a software system during its execution enables developers and analysts to observe, and ultimately understand, how it works. This kind of dynamic analysis can be instrumental to reverse engineering, vulnerability discovery, exploit development, and debugging. While these analyses are typically well-supported for homogeneous desktop platforms (e.g., x86 desktop PCs), they can rarely be applied in the heterogeneous world of embedded systems. One approach to enable dynamic analyses of embedded systems is to move software stacks from physical systems into virtual environments that sufficiently model hardware behavior. This process which we call ""rehosting"" poses a significant research challenge with major implications for security analyses. Although rehosting has traditionally been an unscientific and ad-hoc endeavor undertaken by domain experts with varying time and resources at their disposal, researchers are beginning to address rehosting challenges systematically and in earnest. In this paper, we establish that emulation is insufficient to conduct large-scale dynamic analysis of real-world hardware systems and present rehosting as a firmware-centric alternative. Furthermore, we taxonomize preliminary rehosting efforts, identify the fundamental components of the rehosting process, and propose directions for future research.",584
499,Cybersecurity and Privacy,William Robertson,"June 4th, 2021",Evaluating Synthetic Bugs,https://doi.org/10.1145/3433210.3453096," Joshua Bundt, Andrew Fasano, Brendan Dolan-Gavitt, William Robertson, and Tim Leek. (2021). ""Evaluating Synthetic Bugs"". In Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security (ASIA CCS '21). Association for Computing Machinery, New York, NY, USA, 716‚Äì730. DOI: 10.1145/3433210.3453096","Fuzz testing has been used to find bugs in programs since the 1990s, but despite decades of dedicated research, there is still no consensus on which fuzzing techniques work best. One reason for this is the paucity of ground truth: bugs in real programs with known root causes and triggering inputs are difficult to collect at a meaningful scale. Bug injection technologies that add synthetic bugs into real programs seem to offer a solution, but the differences in finding these synthetic bugs versus organic bugs have not previously been explored at a large scale. Using over 80 years of CPU time, we ran eight fuzzers across 20 targets from the Rode0day bug-finding competition and the LAVA-M corpus. Experiments were standardized with respect to compute resources and metrics gathered. These experiments show differences in fuzzer performance as well as the impact of various configuration options. For instance, it is clear that integrating symbolic execution with mutational fuzzing is very effective and that using dictionaries improves performance. Other conclusions are less clear-cut; for example, no one fuzzer beat all others on all tests. It is noteworthy that no fuzzer found any organic bugs (i.e., one reported in a CVE), despite 50 such bugs being available for discovery in the fuzzing corpus. A close analysis of results revealed a possible explanation: a dramatic difference between where synthetic and organic bugs live with respect to the ""main path"" discovered by fuzzers. We find that recent updates to bug injection systems have made synthetic bugs more difficult to discover, but they are still significantly easier to find than organic bugs in our target programs. Finally, this study identifies flaws in bug injection techniques and suggests a number of axes along which synthetic bugs should be improved.",585
500,Cybersecurity and Privacy,William Robertson,"February 9th, 2020",Discovering algorithmic denial-of-service vulnerabilities through guided micro-fuzzing,https://arxiv.org/abs/2002.03416," Blair, William, Andrea Mambretti, Sajjad Arshad, Michael Weissbacher, William K. Robertson, Engin Kirda and Manuel Egele. ‚ÄúHotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing.‚Äù ArXiv abs/2002.03416 (2020): n. pag.","Contemporary fuzz testing techniques focus on identifying memory corruption vulnerabilities that allow adversaries to achieve either remote code execution or information disclosure. Meanwhile, Algorithmic Complexity (AC)vulnerabilities, which are a common attack vector for denial-of-service attacks, remain an understudied threat. In this paper, we present HotFuzz, a framework for automatically discovering AC vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high CPU utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values.",586
501,Cybersecurity and Privacy,William Robertson,"July 1st, 2017",Semi-automated Discovery of Server-Based Information Oversharing Vulnerabilities in Android Applications,https://doi.org/10.1145/3092703.3092708," Wil Koch, Abdelberi Chaabane, Manuel Egele, William Robertson, Engin Kirda ,In Proceedings of the International Symposium on Software Testing and Analysis (ISSTA) ,Santa Barbara, CA, USA ,July 2017","Modern applications are often split into separate client and server tiers that communicate via message passing over the network. One well-understood threat to privacy for such applications is the leakage of sensitive user information either in transit or at the server. In response, an array of defensive techniques have been developed to identify or block unintended or malicious information leakage. However, prior work has primarily considered privacy leaks originating at the client directed at the server, while leakage in the reverse direction -- from the server to the client -- is comparatively under-studied. The question of whether and to what degree this leakage constitutes a threat remains an open question. We answer this question in the affirmative with Hush, a technique for semi-automatically identifying Server-based InFormation OvershariNg (SIFON) vulnerabilities in multi-tier applications. In particular, the technique detects SIFON vulnerabilities using a heuristic that overshared sensitive information from server-side APIs will not be displayed by the application's user interface. The technique first performs a scalable static program analysis to screen applications for potential vulnerabilities, and then attempts to confirm these candidates as true vulnerabilities with a partially-automated dynamic analysis. Our evaluation over a large corpus of Android applications demonstrates the effectiveness of the technique by discovering several previously-unknown SIFON vulnerabilities in eight applications.",587
502,Cybersecurity and Privacy,William Robertson,"July 16th, 2015",BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications,http://link.springer.com/chapter/10.1007/978-3-662-47854-7_21," Ozcan, Ahmet Talha, et al. ""BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications."" Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2015. 355-369.|","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",588
503,Cybersecurity and Privacy,Abhi Shelat,"August 16th, 2024",Secure Multiparty Computation with Identifiable Abort via Vindicating Release,https://doi.org/10.1007/978-3-031-68397-8_2," Ran Cohen, Jack Doerner, Yashvanth Kondi, Abhi Shelat. (2024). Secure Multiparty Computation with Identifiable Abort via Vindicating Release CRYPTO (8), 36-73. https://doi.org/10.1007/978-3-031-68397-8_2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",589
504,Cybersecurity and Privacy,Abhi Shelat,"May 25th, 2022",Guaranteed Output in $O(\sqrt{n})$ Rounds for Round-Robin Sampling Protocols,https://doi.org/10.1007/978-3-031-06944-4_9," Ran Cohen, Jack Doerner, Yashvanth Kondi, Abhi Shelat. (2022). Guaranteed Output in $O(sqrt{n})$ Rounds for Round-Robin Sampling Protocols EUROCRYPT (1), 241-271. https://doi.org/10.1007/978-3-031-06944-4_9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",590
505,Cybersecurity and Privacy,Abhi Shelat,"August 10th, 2020",Multiparty Generation of an RSA Modulus,https://doi.org/10.1007/978-3-030-56877-1_3," Megan Chen, Ran Cohen, Jack Doerner, Yashvanth Kondi, Eysa Lee, Schuyler Rosefield, Abhi Shelat. (2020). Multiparty Generation of an RSA Modulus CRYPTO (3), 64-93. https://doi.org/10.1007/978-3-030-56877-1_3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",591
506,Cybersecurity and Privacy,Abhi Shelat,"November 6th, 2019",Securely Sampling Biased Coins with Applications to Differential Privacy,https://doi.org/10.1145/3319535.3354256," Jeffrey Champion, Abhi Shelat, Jonathan R. Ullman. (2019). Securely Sampling Biased Coins with Applications to Differential Privacy CCS, 603-614. https://doi.org/10.1145/3319535.3354256","We design an efficient method for sampling a large batch of d independent coins with a given bias p ‚àà [0,1]. The folklore secure computation method for doing so requires O(lambda + log d) communication and computation per coin to achieve total statistical difference 2-lambda. We present an exponential improvement over the folklore method that uses just O(log(lambda+log d)) gates per coin when sampling d coins with total statistical difference 2-lambda. We present a variant of our work that also concretely beats the folklore method for lambda ‚â• 60 which are parameters that are often used in practice. Our new technique relies on using specially designed oblivious data structures to achieve biased coin samples that take an expected 2 random bits to sample. Using our new sampling technique, we present an implementation of the differentially private report-noisy-max mechanism (a more practical implementation of the celebrated exponential mechanism) as a secure multi-party computation. Our benchmarks show that one can run this mechanism on a domain of size d=212 in 6 seconds and up to d=219 in 14 minutes. As far as we know, this is the first complete distributed implementation of either of these mechanisms.",592
507,Cybersecurity and Privacy,Abhi Shelat,"August 1st, 2019",Adaptively Secure MPC with Sublinear Communication Complexity,https://doi.org/10.1007/978-3-030-26951-7_2," Ran Cohen, Abhi Shelat, Daniel Wichs. (2019). Adaptively Secure MPC with Sublinear Communication Complexity CRYPTO (2), 30-60. https://doi.org/10.1007/978-3-030-26951-7_2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",593
508,Cybersecurity and Privacy,Abhi Shelat,"October 15th, 2018",A better method to analyze blockchain consistency,https://dl.acm.org/doi/10.1145/3243734.3243814," Kiffer, Lucianna, Rajmohan Rajaraman, and Abhi Shelat. ""A better method to analyze blockchain consistency."" Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 2018.","The celebrated Nakamoto consensus protocol [16] ushered in several new consensus applications including cryptocurrencies. A few recent works [7, 17] have analyzed important properties of blockchains, including most significantly, consistency, which is a guarantee that all honest parties output the same sequence of blocks throughout the execution of the protocol. To establish consistency, the prior analysis of Pass, Seeman and Shelat [17] required a careful counting of certain combinatorial events that was difficult to apply to variations of Nakamoto. The work of Garay, Kiayas, and Leonardas [7] provides another method of analyzing the blockchain under the simplifying assumption that the network was synchronous. The contribution of this paper is the development of a simple Markov-chain based method for analyzing consistency properties of blockchain protocols. The method includes a formal way of stating strong concentration bounds as well as easy ways to concretely compute the bounds. We use our new method to answer a number of basic questions about consistency of blockchains: Our new analysis provides a tighter guarantee on the consistency property of Nakamoto's protocol, including for parameter regimes which [17] could not consider; We analyze a family of delaying attacks first presented in [17], and extend them to other protocols; We analyze how long a participant should wait before considering a high-value transaction ""confirmed""; We analyze the consistency of CliqueChain, a variation of the Chainweb [14] system; We provide the first rigorous consistency analysis of GHOST [20] and also analyze a folklore ""balancing""-attack. In each case, we use our framework to experimentally analyze the consensus bounds for various network delay parameters and adversarial computing percentages. We hope our techniques enable authors of future blockchain proposals to provide a more rigorous analysis of their schemes.",594
509,Cybersecurity and Privacy,Abhi Shelat,"July 25th, 2018","Multi-Key Searchable Encryption, Revisited",https://eprint.iacr.org/2018/018," Ariel Hamlin, Abhi Shelat, Mor Weiss, Daniel Wichs: Multi-Key Searchable Encryption, Revisited. Public Key Cryptography (1) 2018: 95-124","Ariel Hamlin, abhi shelat, Mor Weiss, and Daniel Wichs We consider a setting where users store their encrypted documents on a remote server and can selectively share documents with each other. A user should be able to perform keyword searches over all the documents she has access to, including the ones that others shared with her. The contents of the documents, and the search queries, should remain private from the server. This setting was considered by Popa et al. (NSDI '14) who developed a new cryptographic primitive called Multi-Key Searchable Encryption (MKSE), together with an instantiation and an implementation within a system called Mylar, to address this goal. Unfortunately, Grubbs et al. (CCS '16) showed that the proposed MKSE definition fails to provide basic security guarantees, and that the Mylar system is susceptible to simple attacks. Most notably, if a malicious Alice colludes with the server and shares a document with an honest Bob then the privacy of all of Bob's search queries is lost. In this work we revisit the notion of MKSE and propose a new strengthened definition that rules out the above attacks. We then construct MKSE schemes meeting our definition. We first give a simple and efficient construction using only pseudorandom functions. This construction achieves our strong security definition at the cost of increasing the server storage overhead relative to Mylar, essentially replicating the document each time it is shared. We also show that high server storage overhead is not inherent, by giving an alternate (albeit impractical) construction that manages to avoid it using obfuscation. BibTeX Copy to clipboard",595
510,Cybersecurity and Privacy,Mohit Singhal,"October 13th, 2023",Impact of Stricter Content Moderation on Parler‚Äôs Users‚Äô Discourse,https://doi.org/10.48550/arXiv.2310.08844," Nihal Kumarswamy, Mohit Singhal, Shirin Nilizadeh. (2023). Impact of Stricter Content Moderation on Parler's Users' Discourse CoRR, abs/2310.08844. https://doi.org/10.48550/arXiv.2310.08844","Social media platforms employ various content moderation techniques to remove harmful, offensive, and hate speech content. The moderation level varies across platforms; even over time, it can evolve in a platform. For example, Parler, a fringe social media platform popular among conservative users, was known to have the least restrictive moderation policies. After linking the 2021 US Capitol Riots and the activity of some groups on Parler on January 12, 2021, it was removed from the Apple and Google App Store and suspended from Amazon Cloud hosting service.",596
511,Cybersecurity and Privacy,Mohit Singhal,"August 4th, 2023",Auditing Yelp‚Äôs Business Ranking and Review Recommendation Through the Lens of Fairness,https://doi.org/10.48550/arXiv.2308.02129," Mohit Singhal, Javier Pacheco, Tanushree Debi, Seyyed Mohammad Sadegh Moosavi Khorzooghi, Abolfazl Asudeh, Gautam Das , Shirin Nilizadeh. (2023). Auditing Yelp's Business Ranking and Review Recommendation Through the Lens of Fairness CoRR, abs/2308.02129. https://doi.org/10.48550/arXiv.2308.02129","Auditing is critical to ensuring the fairness and reliability of decision-making systems. However, auditing a black-box system for bias can be challenging due to the lack of transparency in the model's internal workings. In many web applications, such as Yelp, it is challenging, if not impossible, to manipulate their inputs systematically to identify bias in the output. Yelp connects users and businesses, where users identify new businesses and simultaneously express their experiences through reviews. Yelp recommendation software moderates user-provided content by categorizing it into recommended and not-recommended sections. The recommended reviews, among other attributes, are used by Yelp's ranking algorithm to rank businesses in a neighborhood. Due to Yelp's substantial popularity and its high impact on local businesses' success, understanding the bias of its algorithms is crucial.This data-driven study, for the first time, investigates the bias of Yelp's business ranking and review recommendation system. We examine three hypotheses to assess if Yelp's recommendation software shows bias against reviews of less established users with fewer friends and reviews and if Yelp's business ranking algorithm shows bias against restaurants located in specific neighborhoods, particularly in hotspot regions, with specific demographic compositions. Our findings show that reviews of less-established users are disproportionately categorized as not-recommended. We also find a positive association between restaurants' location in hotspot regions and their average exposure. Furthermore, we observed some cases of severe disparity bias in cities where the hotspots are in neighborhoods with less demographic diversity or higher affluence and education levels.",597
512,Cybersecurity and Privacy,Mohit Singhal,"July 31st, 2023","SoK: Content Moderation in Social Media, from Guidelines to Enforcement, and Research to Practice",https://doi.org/10.1109/EuroSP57164.2023.00056," Mohit Singhal, Chen Ling , Pujan Paudel, Poojitha Thota, Nihal Kumarswamy, Gianluca Stringhini, Shirin Nilizadeh. (2023). SoK: Content Moderation in Social Media, from Guidelines to Enforcement, and Research to Practice EuroS&P, 868-895. https://doi.org/10.1109/EuroSP57164.2023.00056",Social media platforms have been establishing content moderation guidelines and employing various moderation policies. The goal of this paper is to study these community guidelines and moderation practices. We identify the differences between the content moderation employed in mainstream and fringe social media platforms. We have in-depth applied discussions on both research and practical challenges and solutions. We cover over two hundred interdisciplinary research papers about moderation strategies.,598
513,Cybersecurity and Privacy,Mohit Singhal,"June 2nd, 2023",Cybersecurity Misinformation Detection on Social Media: Case Studies on Phishing Reports and Zoom‚Äôs Threat,https://doi.org/10.1609/icwsm.v17i1.22189," Mohit Singhal, Nihal Kumarswamy, Shreyasi Kinhekar, Shirin Nilizadeh. (2023). Cybersecurity Misinformation Detection on Social Media: Case Studies on Phishing Reports and Zoom's Threat ICWSM, 796-807. https://doi.org/10.1609/icwsm.v17i1.22189","Abstract Prior work has extensively studied misinformation related to news, politics, and health, however, misinformation can also be about technological topics. While less controversial, such misinformation can severely impact companies‚Äô reputations and revenues, and users‚Äô online experiences. Recently, social media has also been increasingly used as a novel source of knowledgebase for extracting timely and relevant security threats, which are fed to the threat intelligence systems for better performance. However, with possible campaigns spreading false security threats, these systems can become vulnerable to poisoning attacks. In this work, we proposed novel approaches for detecting misinformation about cybersecurity and privacy threats on social media, focusing on two topics with different types of misinformation: phishing websites and Zoom‚Äôs security & privacy threats. We developed a framework for detecting inaccurate phishing claims on Twitter. Using this framework, we could label about 9% of URLs and 22% of phishing reports as misinformation. We also proposed another framework for detecting misinformation related to Zoom‚Äôs security and privacy threats on multiple platforms. Our classifiers showed great performance with more than 98% accuracy. Employing these classifiers on the posts from Facebook, Instagram, Reddit, and Twitter, we found respectively that about 18%, 3%, 4%, and 3% of posts were misinformation. In addition, we studied the characteristics of misinformation posts, their authors, and their timelines, which helped us identify campaigns.",599
514,Cybersecurity and Privacy,Jessica Staddon,"November 21st, 2024",Assessment of LLM Responses to End-user Security Questions,https://doi.org/10.48550/arXiv.2411.14571," Vijay Prakash, Kevin Lee, Arkaprabha Bhattacharya, Danny Yuxing Huang, Jessica Staddon. (2024). Assessment of LLM Responses to End-user Security Questions CoRR, abs/2411.14571. https://doi.org/10.48550/arXiv.2411.14571","Answering end user security questions is challenging. While large language models (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have shown promise in answering a variety of questions outside of security. We studied LLM performance in the area of end user security by qualitatively evaluating 3 popular LLMs on 900 systematically collected end user security questions.While LLMs demonstrate broad generalist ``knowledge'' of end user security information, there are patterns of errors and limitations across LLMs consisting of stale and inaccurate answers, and indirect or unresponsive communication styles, all of which impacts the quality of information received. Based on these patterns, we suggest directions for model improvement and recommend user strategies for interacting with LLMs when seeking assistance with security.",600
515,Cybersecurity and Privacy,Jessica Staddon,"October 14th, 2024",Can LLMs be Scammed? A Baseline Measurement Study,https://doi.org/10.48550/arXiv.2410.13893," Udari Madhushani Sehwag, Kelly Patel, Francesca Mosca, Vineeth Ravi, Jessica Staddon. (2024). Can LLMs be Scammed? A Baseline Measurement Study CoRR, abs/2410.13893. https://doi.org/10.48550/arXiv.2410.13893","Despite the importance of developing generative AI models that can effectively resist scams, current literature lacks a structured framework for evaluating their vulnerability to such threats. In this work, we address this gap by constructing a benchmark based on the FINRA taxonomy and systematically assessing Large Language Models' (LLMs') vulnerability to a variety of scam tactics. First, we incorporate 37 well-defined base scam scenarios reflecting the diverse scam categories identified by FINRA taxonomy, providing a focused evaluation of LLMs' scam detection capabilities. Second, we utilize representative proprietary (GPT-3.5, GPT-4) and open-source (Llama) models to analyze their performance in scam detection. Third, our research provides critical insights into which scam tactics are most effective against LLMs and how varying persona traits and persuasive techniques influence these vulnerabilities. We reveal distinct susceptibility patterns across different models and scenarios, underscoring the need for targeted enhancements in LLM design and deployment.",601
516,Cybersecurity and Privacy,Jessica Staddon,"May 11th, 2024",Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints,https://doi.org/10.1145/3613904.3642033," Arkaprabha Bhattacharya, Kevin Lee, Vineeth Ravi, Jessica Staddon, Rosanna Bellini. (2024). Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints CHI, 354:1-354:20. https://doi.org/10.1145/3613904.3642033","Digital financial services can introduce new digital-safety risks for users, particularly survivors of intimate partner financial abuse (IPFA). To offer improved support for such users, a comprehensive understanding of their support needs and the barriers they face to redress by financial institutions is essential. Drawing from a dataset of 2.7 million customer complaints, we implement a bespoke workflow that utilizes language-modeling techniques and expert human review to identify complaints describing IPFA. Our mixed-method analysis provides insight into the most common digital financial products involved in these attacks, and the barriers consumers report encountering when doing so. Our contributions are twofold; we offer the first human-labeled dataset for this overlooked harm and provide practical implications for technical practice, research, and design for better supporting and protecting survivors of IPFA.",602
517,Cybersecurity and Privacy,Jonathan Ullman,"January 1st, 2025",Private Mean Estimation with Person-Level Differential Privacy,https://doi.org/10.1137/1.9781611978322.92," Sushant Agarwal, Gautam Kamath , Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan R. Ullman. (2025). Private Mean Estimation with Person-Level Differential Privacy SODA, 2819-2880. https://doi.org/10.1137/1.9781611978322.92","We study person-level differentially private (DP) mean estimation in the case where each person holds multiple samples. DP here requires the usual notion of distributional stability when all of a person‚Äôs datapoints can be modified. Informally, if n people each have m samples from an unknown d -dimensional distribution with bounded k -th moments, we show that people are necessary and sufficient to estimate the mean up to distance Œ± in ‚Ñì 2 -norm under Œµ -differential privacy (and its common relaxations). In the multivariate setting, we give computationally efficient algorithms under approximate DP and computationally inefficient algorithms under pure DP, and our nearly matching lower bounds hold for the most permissive case of approximate DP. Our computationally efficient estimators are based on the standard clip-and-noise framework, but the analysis for our setting requires both new algorithmic techniques and new analyses. In particular, our new bounds on the tails of sums of independent, vector-valued, bounded-moments random variables may be of interest. * Authors are listed in alphabetical order.",603
518,Cybersecurity and Privacy,Jonathan Ullman,"June 20th, 2024",Program Analysis for Adaptive Data Analysis,https://doi.org/10.1145/3656414," Jiawen Liu, Weihao Qu, Marco Gaboardi, Deepak Garg , Jonathan R. Ullman. (2024). Program Analysis for Adaptive Data Analysis Proc. ACM Program. Lang., 8, 914-938. https://doi.org/10.1145/3656414","An adaptive data analysis can be seen as a process composed by multiple queries interrogating some data. The choice of which query to run next may rely on the results of previous queries. The generalization error of each individual query/analysis can be controlled by using an array of well-established statistical techniques. In this work, we consider adaptive data analyses implemented as while-like programs and we design a program analysis which can help with identifying which technique to use.",604
519,Cybersecurity and Privacy,Jonathan Ullman,"May 1st, 2024",How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization,https://openreview.net/forum?id=XoSF46Pc2e," Andrew Lowy, Jonathan R. Ullman, Stephen J. Wright . (2024). How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization ICML. https://openreview.net/forum?id=XoSF46Pc2e","We provide a simple and flexible framework for designing differentially private algorithms to find approximate stationary points of non-convex loss functions. Our framework is based on using a private approximate risk minimizer to ""warm start"" another private algorithm for finding stationary points. We use this framework to obtain improved, and sometimes optimal, rates for several classes of non-convex loss functions. First, we obtain improved rates for finding stationary points of smooth non-convex empirical loss functions. Second, we specialize to quasar-convex functions, which generalize star-convex functions and arise in learning dynamical systems and training some neural nets. We achieve the optimal rate for this class. Third, we give an optimal algorithm for finding stationary points of functions satisfying the Kurdyka-Lojasiewicz (KL) condition. For example, over-parameterized neural networks often satisfy this condition. Fourth, we provide new state-of-the-art rates for stationary points of non-convex population loss functions. Fifth, we obtain improved rates for non-convex generalized linear models. A modification of our algorithm achieves nearly the same rates for second-order stationary points of functions with Lipschitz Hessian, improving over the previous state-of-the-art for each of the above problems. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",605
520,Cybersecurity and Privacy,Jonathan Ullman,"January 16th, 2024",Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning,https://openreview.net/forum?id=4DoSULcfG6," Harsh Chaudhari, Giorgio Severi, Alina Oprea, Jonathan R. Ullman. (2024). Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning ICLR. https://openreview.net/forum?id=4DoSULcfG6","The integration of Machine Learning in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for ML training purposes. One such privacy risk is Membership Inference (MI), in which an adversary seeks to determine whether a particular data point was included in the training dataset of a model. Current state-of-the-art MI approaches capitalize on access to the model‚Äôs predicted confidence scores to successfully perform membership inference.",606
521,Cybersecurity and Privacy,Jonathan Ullman,"July 5th, 2023",Investigating the Visual Utility of Differentially Private Scatterplots,https://doi.org/10.1109/TVCG.2023.3292391," Liudas Panavas, Tarik Crnovrsanin, Jane Lydia Adams, Jonathan R. Ullman, Ali Sarvghad, Melanie Tory, Cody Dunne. (2024). Investigating the Visual Utility of Differentially Private Scatterplots IEEE Trans. Vis. Comput. Graph., 30, 5370-5385. https://doi.org/10.1109/TVCG.2023.3292391","Increasingly, visualization practitioners are working with, using, and studying private data. Differential privacy algorithms do this by aggregating data statistics with noise. This now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.",607
522,Cybersecurity and Privacy,Jonathan Ullman,"June 22nd, 2020",The power of factorization mechanisms in local and central differential privacy,https://doi.org/10.1145/3357713.3384297," Alexander Edmonds, Aleksandar Nikolov, Jonathan R. Ullman. (2020). The power of factorization mechanisms in local and central differential privacy STOC, 425-438. https://doi.org/10.1145/3357713.3384297","We give new characterizations of the sample complexity of answering linear queries (statistical queries) in the local and central models of differential privacy: (1) In the non-interactive local model, we give the first approximate characterization of the sample complexity. Informally our bounds are tight to within polylogarithmic factors in the number of queries and desired accuracy. Our characterization extends to agnostic learning in the local model. (2) In the central model, we give a characterization of the sample complexity in the high-accuracy regime that is analogous to that of Nikolov, Talwar, and Zhang (STOC 2013), but is both quantitatively tighter and has a dramatically simpler proof. Our lower bounds apply equally to the empirical and population estimation problems. In both cases, our characterizations show that a particular factorization mechanism is approximately optimal, and the optimal sample complexity is bounded from above and below by well studied factorization norms of a matrix associated with the queries.",608
523,Cybersecurity and Privacy,Jonathan Ullman,"January 1st, 2020",Private Query Release Assisted by Public Data,http://proceedings.mlr.press/v119/bassily20a.html," Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan R. Ullman, Zhiwei Steven Wu. (2020). Private Query Release Assisted by Public Data ICML, 695-703. http://proceedings.mlr.press/v119/bassily20a.html","We study the problem of differentially private query release assisted by access to public data. In this problem, the goal is to answer a large class H H of statistical queries with error no more than Œ± Œ± using a combination of public and private samples. The algorithm is required to satisfy differential privacy only with respect to the private samples. We study the limits of this task in terms of the private and public sample complexities. Our upper and lower bounds on the private sample complexity have matching dependence on the dual VC-dimension of H H . For a large category of query classes, our bounds on the public sample complexity have matching dependence on Œ± Œ± .",609
524,Cybersecurity and Privacy,Jonathan Ullman,"December 6th, 2018",Differentially Private Fair Learning,https://arxiv.org/abs/1812.02696," Jagielski, Matthew, Kearns, Michael, Mao, Jieming, Oprea, Alina, Roth, Aaron, Sharifi, Saeed, & Ullman, Jonathan. (2019). Differentially Private Fair Learning. Proceedings of the 36 Th International Conference on Machine Learning.","Motivated by settings in which predictive models may be required to be non-discriminatory with respect to certain attributes (such as race), but even collecting the sensitive attribute may be forbidden or restricted, we initiate the study of fair learning under the constraint of differential privacy. We design two learning algorithms that simultaneously promise differential privacy and equalized odds, a 'fairness' condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a private implementation of the equalized odds post-processing approach of [Hardt et al., 2016]. This algorithm is appealingly simple, but must be able to use protected group membership explicitly at test time, which can be viewed as a form of 'disparate treatment'. Our second algorithm is a differentially private version of the oracle-efficient in-processing approach of [Agarwal et al., 2018] that can be used to find the optimal fair classifier, given access to a subroutine that can solve the original (not necessarily fair) learning problem. This algorithm is more complex but need not have access to protected group membership at test time. We identify new tradeoffs between fairness, accuracy, and privacy that emerge only when requiring all three properties, and show that these tradeoffs can be milder if group membership may be used at test time. We conclude with a brief experimental evaluation.",610
525,Cybersecurity and Privacy,Jonathan Ullman,"November 27th, 2018",The Structure of Optimal Private Tests for Simple Hypotheses,https://arxiv.org/abs/1811.11148," Canonne, C.L., Kamath, G., McMillan, A., Smith, A.D., & Ullman, J. (2018). The structure of optimal private tests for simple hypotheses. ArXiv, abs/1811.11148.","Hypothesis testing plays a central role in statistical inference, and is used in many settings where privacy concerns are paramount. This work answers a basic question about privately testing simple hypotheses: given two distributionsPandQ, and a privacy levelŒµ, how many i.i.d. samples are needed to distinguishPfromQsubject toŒµ-differential privacy, and what sort of tests have optimal sample complexity? Specifically, we characterize this sample complexity up to constant factors in terms of the structure ofPandQand the privacy levelŒµ, and show that this sample complexity is achieved by a certain randomized and clamped variant of the log-likelihood ratio test. Our result is an analogue of the classical Neyman-Pearson lemma in the setting of private hypothesis testing. We also give an application of our result to the private change-point detection. Our characterization applies more generally to hypothesis tests satisfying essentially any notion of algorithmic stability, which is known to imply strong generalization bounds in adaptive data analysis, and thus our results have applications even when privacy is not a primary concern.",611
526,Cybersecurity and Privacy,Jonathan Ullman,"August 4th, 2018",Distributed Differential Privacy via Shuffling,https://arxiv.org/abs/1808.01394," Cheu A., Smith A., Ullman J., Zeber D., Zhilyaev M. (2019) Distributed Differential Privacy via Shuffling. In: Ishai Y., Rijmen V. (eds) Advances in Cryptology ‚Äì EUROCRYPT 2019. EUROCRYPT 2019. Lecture Notes in Computer Science, vol 11476. Springer, Cham","We consider the problem of designing scalable, robust protocols for computing statistics about sensitive data. Specifically, we look at how best to design differentially private protocols in a distributed setting, where each user holds a private datum. The literature has mostly considered two models: the ""central"" model, in which a trusted server collects users' data in the clear, which allows greater accuracy; and the ""local"" model, in which users individually randomize their data, and need not trust the server, but accuracy is limited. Attempts to achieve the accuracy of the central model without a trusted server have so far focused on variants of cryptographic MPC, which limits scalability.In this paper, we initiate the analytic study of a shuffled model for distributed differentially private algorithms, which lies between the local and central models. This simple-to-implement model, a special case of the ESA framework of [Bittau et al., '17], augments the local model with an anonymous channel that randomly permutes a set of user-supplied messages. For sum queries, we show that this model provides the power of the central model while avoiding the need to trust a central server and the complexity of cryptographic secure function evaluation. More generally, we give evidence that the power of the shuffled model lies strictly between those of the central and local models: for a natural restriction of the model, we show that shuffled protocols for a widely studied selection problem require exponentially higher sample complexity than do central-model protocols.",612
527,Cybersecurity and Privacy,Jonathan Ullman,"May 1st, 2018",Privately Learning High-Dimensional Distributions,https://arxiv.org/abs/1805.00216," Kamath, G., Li, J., Singhal, V., & Ullman, J. (2018). Privately Learning High-Dimensional Distributions. COLT.","We present novel, computationally efficient, and differentially private algorithms for two fundamental high-dimensional learning problems: learning a multivariate Gaussian and learning a product distribution over the Boolean hypercube in total variation distance. The sample complexity of our algorithms nearly matches the sample complexity of the optimal non-private learners for these tasks in a wide range of parameters, showing that privacy comes essentially for free for these problems. In particular, in contrast to previous approaches, our algorithm for learning Gaussians does not require strong a priori bounds on the range of the parameters. Our algorithms introduce a novel technical approach to reducing the sensitivity of the estimation procedure that we call recursive private preconditioning.",613
528,Cybersecurity and Privacy,Jonathan Ullman,"April 10th, 2017",Tight lower bounds for differentially private selection,https://arxiv.org/abs/1704.03024," Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. In IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS‚Äô17), 2017.","A pervasive task in the differential privacy literature is to select thekitems of ""highest quality"" out of a set ofditems, where the quality of each item depends on a sensitive dataset that must be protected. Variants of this task arise naturally in fundamental problems like feature selection and hypothesis testing, and also as subroutines for many sophisticated differentially private algorithms.The standard approaches to these tasks---repeated use of the exponential mechanism or the sparse vector technique---approximately solve this problem given a dataset ofn=O(k‚àí‚àí‚àölogd)samples. We provide a tight lower bound for some very simple variants of the private selection problem. Our lower bound shows that a sample of sizen=Œ©(k‚àí‚àí‚àölogd)is required even to achieve a very minimal accuracy guarantee.Our results are based on an extension of the fingerprinting method to sparse selection problems. Previously, the fingerprinting method has been used to provide tight lower bounds for answering an entire set ofdqueries, but often only some much smaller set ofkqueries are relevant. Our extension allows us to prove lower bounds that depend on both the number of relevant queries and the total number of queries.",614
529,Cybersecurity and Privacy,Jonathan Ullman,"June 19th, 2016",Algorithmic stability for adaptive data analysis,https://dl.acm.org/citation.cfm?id=2897566," Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Symposium on Theory of Computing (STOC‚Äô16), 2016","We prove the first upper bounds on the number of samples required to answer more general families of queries. We also show that weaker stability guarantees such as bounded KL divergence and total variation distance lead to correspondingly weaker generalization guarantees. The bounds improve and simplify the work of Dwork et al. (STOC, 2015) and have been applied in subsequent work by those authors.",615
530,Cybersecurity and Privacy,Jonathan Ullman,"October 20th, 2015",Interactive fingerprinting codes and the hardness of preventing false discovery,https://arxiv.org/abs/1410.1228," Thomas Steinke and Jonathan Ullman. Interactive fingerprinting codes and the hardness of preventing false discovery. In Proceedings of The 28th Conference on Learning Theory (COLT‚Äô15), 2015","We show an essentially tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately givennsamples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is ""close"" to the correct expectation over the distribution. This question was recently studied by Dwork et al., who showed how to answerŒ©~(n2)queries efficiently, and also by Hardt and Ullman, who showed that answeringO~(n3)queries is hard. We close the gap between the two bounds and show that, under a standard hardness assumption, there is no computationally efficient algorithm that, givennsamples from an unknown distribution, can give valid answers toO(n2)adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private.We obtain our results using a new connection between the problem of answering adaptively chosen statistical queries and a combinatorial object called an interactive fingerprinting code. In order to optimize our hardness result, we give a new Fourier-analytic approach to analyzing fingerprinting codes that is simpler, more flexible, and yields better parameters than previous constructions.",616
531,Cybersecurity and Privacy,Jonathan Ullman,"October 17th, 2015",Robust traceability from trace amounts,http://ieeexplore.ieee.org/document/7354420/," Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. In IEEE 56th Annual Symposium on Foundations of Computer Science (FOCS‚Äô15), 2015.","The privacy risks inherent in the release of a large number of summary statistics were illustrated by Homer et al. (PLoS Genetics, 2008) In this work we describe and analyze a simple attack that succeeds even if the summary statistics are significantly distorted. The attack only requires that the vector of distorted summary statistics is close to the vector. of true marginals in ‚Ñì 1 norm. The new attack, which is not specific to genomics and which handles Gaussian as well as Bernouilli data, significantly generalizes recent lower bounds on the noise needed to ensure differential privacy (Bun, Ullman, and Vadhan, STOC 2014, Steinke and Ullmann, 2015)",617
532,Cybersecurity and Privacy,Daniel Wichs,"November 29th, 2024",How to Simulate Random Oracles with Auxiliary Input,https://doi.org/10.1109/FOCS61266.2024.00080," Yevgeniy Dodis, Aayush Jain, Huijia Lin, Ji Luo , Daniel Wichs. (2024). How to Simulate Random Oracles with Auxiliary Input FOCS, 1207-1230. https://doi.org/10.1109/FOCS61266.2024.00080","The random oracle model (ROM) allows us to opti-mistically reason about security properties of cryptographic hash functions. It is overly optimistic against non-uniform adversaries, and often suggests security levels unachievable by any real hash function. This work shows how to efficiently simulate the AI-ROM. The simulation has low concrete overhead, leading to small losses in exact security. We present our results at the IEEE 65th Annual Symposium on Foundations of Computer Science (FOCS) in Chicago, IL, on 27-30 October 2024.",618
533,Cybersecurity and Privacy,Daniel Wichs,"August 16th, 2024",Laconic Function Evaluation and ABE for RAMs from (Ring-)LWE,https://doi.org/10.1007/978-3-031-68382-4_4," Fangqi Dong, Zihan Hao, Ethan Mook, Hoeteck Wee, Daniel Wichs. (2024). Laconic Function Evaluation and ABE for RAMs from (Ring-)LWE CRYPTO (3), 107-142. https://doi.org/10.1007/978-3-031-68382-4_4","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",619
534,Cybersecurity and Privacy,Daniel Wichs,"May 8th, 2024","Laconic Function Evaluation, Functional Encryption and Obfuscation for RAMs with Sublinear Computation",https://doi.org/10.1007/978-3-031-58723-8_7," Fangqi Dong, Zihan Hao, Ethan Mook, Daniel Wichs. (2024). Laconic Function Evaluation, Functional Encryption and Obfuscation for RAMs with Sublinear Computation EUROCRYPT (2), 190-218. https://doi.org/10.1007/978-3-031-58723-8_7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",620
535,Cybersecurity and Privacy,Daniel Wichs,"August 9th, 2023",Universal Amplification of KDM Security: From 1-Key Circular to Multi-Key KDM,https://doi.org/10.1007/978-3-031-38545-2_22," Brent Waters, Daniel Wichs. (2023). Universal Amplification of KDM Security: From 1-Key Circular to Multi-Key KDM CRYPTO (2), 674-693. https://doi.org/10.1007/978-3-031-38545-2_22","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",621
536,Cybersecurity and Privacy,Daniel Wichs,"August 9th, 2023",The Pseudorandom Oracle Model and Ideal Obfuscation,https://doi.org/10.1007/978-3-031-38551-3_8," Aayush Jain, Huijia Lin, Ji Luo , Daniel Wichs. (2023). The Pseudorandom Oracle Model and Ideal Obfuscation CRYPTO (4), 233-262. https://doi.org/10.1007/978-3-031-38551-3_8","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",622
537,Cybersecurity and Privacy,Daniel Wichs,"June 2nd, 2023",Doubly Efficient Private Information Retrieval and Fully Homomorphic RAM Computation from Ring LWE,https://doi.org/10.1145/3564246.3585175," Wei-Kai Lin, Ethan Mook, Daniel Wichs. (2023). Doubly Efficient Private Information Retrieval and Fully Homomorphic RAM Computation from Ring LWE STOC, 595-608. https://doi.org/10.1145/3564246.3585175","A (single server) private information retrieval (PIR) allows a client to read data from a public database held on a remote server. In a doubly efficient PIR (DEPIR) the database is first preprocessed, but the server can subsequently answer any client‚Äôs query in time that is sub-linear in the database size. Building on top of our DEPIR, we construct general fully homomorphic encryption for random-access machines (RAM-FHE) This allows a server to homomorphically evaluate an arbitrary RAM program P over a",623
538,Cybersecurity and Privacy,Daniel Wichs,"June 2nd, 2023",Boosting Batch Arguments and RAM Delegation,https://doi.org/10.1145/3564246.3585200," Yael Kalai, Alex Lombardi, Vinod Vaikuntanathan, Daniel Wichs. (2023). Boosting Batch Arguments and RAM Delegation STOC, 1545-1552. https://doi.org/10.1145/3564246.3585200","We show how to generically improve the succinctness of non-interactive publicly verifiable batch argument ( BARG ) systems. In particular, we show (under a mild additional assumption) how to convert a BARG that generates proofs of length poly ( m )¬∑ k 1‚àí—î , where m is the length of a single instance and k is the number of instances being batched, into one that generates proofs of length poly ( m , log k ), which is the gold standard for succinctness of BARG s. By prior work, such BARG s imply the existence of SNARG s for deterministic time T computation with succinctness poly (log T ). Our result reduces the long-standing challenge of building publicly-verifiable delegation schemes to a much easier problem: building a batch argument system that beats the trivial construction. It also immediately implies new constructions of BARG s and SNARG s with polylogarithmic succinctness based on either bilinear maps or a combination of the DDH and QR assumptions. Along the way, we prove an equivalence between BARG s and a new notion of SNARG s for (deterministic) RAM computations that we call ‚Äú flexible RAM SNARG s with partial input soundness .‚Äù This is the first demonstration that SNARG s for deterministic computation (of any kind) imply BARG s. Our RAM SNARG notion is of independent interest and has already been used in a recent work on constructing rate-1 BARG s (Devadas et.‚ÄÑ‚Äçal. FOCS 2022).",624
539,Cybersecurity and Privacy,Daniel Wichs,"April 16th, 2023","Speak Much, Remember Little: Cryptography in the Bounded Storage Model, Revisited",https://doi.org/10.1007/978-3-031-30545-0_4," Yevgeniy Dodis, Willy Quach, Daniel Wichs. (2023). Speak Much, Remember Little: Cryptography in the Bounded Storage Model, Revisited EUROCRYPT (1), 86-116. https://doi.org/10.1007/978-3-031-30545-0_4","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",625
540,Cybersecurity and Privacy,Daniel Wichs,"October 12th, 2022",Nearly Optimal Property Preserving Hashing,https://doi.org/10.1007/978-3-031-15982-4_16," Justin Holmgren, Minghao Liu , LaKyah Tyner, Daniel Wichs. (2022). Nearly Optimal Property Preserving Hashing CRYPTO (3), 473-502. https://doi.org/10.1007/978-3-031-15982-4_16","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",626
541,Cybersecurity and Privacy,Daniel Wichs,"August 11th, 2021",Limits on the Adaptive Security of Yao‚Äôs Garbling,https://doi.org/10.1007/978-3-030-84245-1_17," Chethan Kamath, Karen Klein, Krzysztof Pietrzak, Daniel Wichs. (2021). Limits on the Adaptive Security of Yao's Garbling CRYPTO (2), 486-515. https://doi.org/10.1007/978-3-030-84245-1_17","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",627
542,Cybersecurity and Privacy,Daniel Wichs,"August 11th, 2021",Targeted Lossy Functions and Applications,https://doi.org/10.1007/978-3-030-84259-8_15," Willy Quach, Brent Waters, Daniel Wichs. (2021). Targeted Lossy Functions and Applications CRYPTO (4), 424-453. https://doi.org/10.1007/978-3-030-84259-8_15","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",628
543,Cybersecurity and Privacy,Christo Wilson,"May 13th, 2024",Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results,https://doi.org/10.1145/3589334.3645666," Jeffrey L. Gleason, Avijit Ghosh, Ronald E. Robertson, Christo Wilson. (2024). Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results WWW, 1249-1259. https://doi.org/10.1145/3589334.3645666","The results returned by image search engines have the power to shape peoples' perceptions about social groups. Existing work on image search engines leverages hand-selected queries for occupations like ""doctor"" and ""engineer"" to quantify racial and gender bias in search results. We complement this work by analyzing peoples' real-world image search queries and measuring the distributions of perceived gender, skin tone, and age in their results. We collect 54,070 unique image search queries and analyze 1,481 open-ended people queries (i.e. not queries for named entities) from a representative sample of 643 US residents. For each query, we analyze the top 15 results returned on both Google and Bing Images. Analysis of real-world image search queries produces multiple insights. First, less than 5% of unique queries are open-ended people queries. Second, fashion queries are, by far, the most common category of open-ended people queries, accounting for over 30% of the total. Third, the modal skin tone on the Monk Skin Tone scale is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US.",629
544,Cybersecurity and Privacy,Christo Wilson,"November 7th, 2022","Hammurabi: A Framework for Pluggable, Logic-based X.509 Certificate Validation Policies",https://doi.org/10.1145/3548606.3560594," James Larisch, Waqar Aqeel, Michael Lum, Yaelle Goldschlag, Kasra Torshizi, Leah Kannan, Yujie Wang, Taejoong Chung, Dave Levin, Bruce M. Maggs, Alan Mislove, Bryan Parno, and Christo Wilson. (2022). ""Hammurabi: A Framework for Pluggable, Logic-Based X.509 Certificate Validation Policies"". In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS ‚Äô22), November 7‚Äì11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA, 15 pages. DOI: 10.1145/3548606.3560594","This paper proposes using a logic programming language to disentangle X.509 certificate validation policy from mechanism. Expressing validation policies in a logic programming language provides multiple benefits. First, policy and mechanism can be more independently written, augmented, and analyzed compared to the current practice of interweaving them within a C or C++ implementation. Once written, these policies can be easily shared and modified for use in different TLS clients. Further, logic programming allows us to determine when clients differ in their policies and use the power of imputation to automatically generate interesting certificates, e.g., a certificate that will be accepted by one browser but not by another. We present a new framework called Hammurabi for expressing validation policies, and we demonstrate that we can express the complex policies of the Google Chrome and Mozilla Firefox web browsers in this framework. We confirm the fidelity of the Hammurabi policies by comparing the validation decisions they make with those made by the browsers themselves on over ten million certificate chains derived from Certificate Transparency logs, as well as 100K synthetic chains. We also use imputation to discover nine validation differences between the two browsers' policies. Finally, we demonstrate the feasibility of integrating Hammurabi into Firefox and the Go language in less than 100 lines of code each.",630
545,Cybersecurity and Privacy,Christo Wilson,"January 1st, 2022",Setting the Bar Low: Are Websites Complying With the Minimum Requirements of the CCPA?,https://doi.org/10.2478/popets-2022-0030," Maggie Van Nortwick and Christo Wilson. ""Setting the Bar Low: Are Websites Complying With the Minimum Requirements of the CCPA?"". Proceedings on Privacy Enhancing Technologies (PoPETS), 2022(1), January, 2022.","Authors: Maggie Van Nortwick (Northeastern University), Christo Wilson (Northeastern University) Volume: 2022 Issue: 1 Pages: 608‚Äì628 DOI: https://doi.org/10.2478/popets-2022-0030 Download PDF Abstract: On June 28, 2018, the California State Legislature passed the California Consumer Privacy Act (CCPA), arguably the most comprehensive piece of online privacy legislation in the United States. Online services covered by the CCPA are required to provide a hyperlink on their homepage with the text ‚ÄúDo Not Sell My Personal Information‚Äù (DNSMPI). The CCPA went into effect on January 1, 2020, a date that was chosen to give data collectors time to study the new law and bring themselves into compliance. In this study, we begin the process of investigating whether websites are complying with the CCPA by focusing on DNSMPI links. Using longitudinal data crawled from the top 1M websites in the Tranco ranking, we examine which websites are including DNSMPI links, whether the websites without DNSMPI links are out of compliance with the law, whether websites are using geofences to dynamically hide DNSMPI links from nonCalifornians, how DNSMPI adoption has changed over time, and how websites are choosing to present DNSMPI links (e.g., in terms of font size, color, and placement). We argue that the answers to these questions are critical for spurring enforcement actions under the law, and helping to shape future privacy laws and regulations, e.g., rule making that will soon commence around the successor to the CCPA, known as the CPRA.",631
546,Cybersecurity and Privacy,Christo Wilson,"October 1st, 2021",A Comparative Study of Dark Patterns Across Mobile and Web Modalities,https://doi.org/10.1145/3479521," Johanna Gunawan, Amogh Pradeep, David Choffnes, Woodrow Hartzog, and Christo Wilson. ""A Comparative Study of Dark Patterns Across Mobile and Web Modalities"". Proceedings of the ACM: Human-Computer Interaction, 5(CSCW2), October, 2021. DOI: 10.1145/3479521","Dark patterns are user interface elements that can influence a person's behavior against their intentions or best interests. Prior work identified these patterns in websites and mobile apps, but little is known about how the design of platforms might impact dark pattern manifestations and related human vulnerabilities. In this paper, we conduct a comparative study of mobile application, mobile browser, and web browser versions of 105 popular services to investigate variations in dark patterns across modalities. We perform manual tests, identify dark patterns in each service, and examine how they persist or differ by modality. Our findings show that while services can employ some dark patterns equally across modalities, many dark patterns vary between platforms, and that these differences saddle people with inconsistent experiences of autonomy, privacy, and control. We conclude by discussing broader implications for policymakers and practitioners, and provide suggestions for furthering dark patterns research.",632
547,Cybersecurity and Privacy,Christo Wilson,"July 1st, 2021",When Fair Ranking Meets Uncertain Inference,https://doi.org/10.1145/3506803," Avijit Ghosh, Ritam Dutt, and Christo Wilson. ""When Fair Ranking Meets Uncertain Inference"". In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021). Virtual Event, Canada, July, 2021. DOI: 10.1145/3506803","We occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you‚Äôve provided to them or that they‚Äôve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device. Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. These cookies do not gather information about you that could be used for marketing purposes and do not remember where you have been on the internet. Preference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in. Statistic cookies help website owners understand how visitors interact with websites by collecting and reporting information anonymously. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.",633
548,Cybersecurity and Privacy,Christo Wilson,"March 1st, 2021",Building and Auditing Fair Algorithms: A Case Study in Candidate Screening,https://doi.org/10.1145/3442188.3445928," Christo Wilson, Avijit Ghosh, Shan Jiang, Alan Mislove, Lewis Baker, Janelle Szary, Kelly Trindel, and Frida Polli. ""Building and Auditing Fair Algorithms: A Case Study in Candidate Screening."" In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2021). Virtual Event, Canada, March, 2021. DOI: 10.1145/3442188.3445928","Academics, activists, and regulators are increasingly urging companies to develop and deploy sociotechnical systems that are fair and unbiased. Achieving this goal, however, is complex: the developer must (1) deeply engage with social and legal facets of ""fairness"" in a given context, (2) develop software that concretizes these values, and (3) undergo an independent algorithm audit to ensure technical correctness and social accountability of their algorithms. To date, there are few examples of companies that have transparently undertaken all three steps. In this paper we outline a framework for algorithmic auditing by way of a case-study of pymetrics, a startup that uses machine learning to recommend job candidates to their clients. We discuss how pymetrics approaches the question of fairness given the constraints of ethical, regulatory, and client demands, and how pymetrics' software implements adverse impact testing. We also present the results of an independent audit of pymetrics' candidate screening tool. We conclude with recommendations on how to structure audits to be practical, independent, and constructive, so that companies have better incentive to participate in third party audits, and that watchdog groups can be better prepared to investigate companies.",634
549,Cybersecurity and Privacy,Christo Wilson,"January 1st, 2021",Structurizing Misinformation Stories via Rationalizing Fact-Checks,https://doi.org/10.18653/v1/2021.acl-long.51," Shan Jiang , Christo Wilson. (2021). Structurizing Misinformation Stories via Rationalizing Fact-Checks ACL/IJCNLP (1), 617-631. https://doi.org/10.18653/v1/2021.acl-long.51","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Misinformation has recently become a well-documented matter of public concern. Existing studies on this topic have hitherto adopted a coarse concept of misinformation, which incorporates a broad spectrum of story types ranging from political conspiracies to misinterpreted pranks. This paper aims to structurize these misinformation stories by leveraging fact-check articles. Our intuition is that key phrases in a fact-check article that identify the misinformation type(s) (e.g., doctored images, urban legends) also act as rationales that determine the verdict of the fact-check (e.g., false). We experiment on rationalized models with domain knowledge as weak supervision to extract these phrases as rationales, and then cluster semantically similar rationales to summarize prevalent misinformation types. Using archived fact-checks from Snopes.com, we identify ten types of misinformation stories. We discuss how these types have evolved over the last ten years and compare their prevalence between the 2016/2020 US presidential elections and the H1N1/COVID-19 pandemics.",635
550,Cybersecurity and Privacy,Christo Wilson,"June 1st, 2020",Modeling and Measuring Expressed (Dis)belief in (Mis)information,https://doi.org/10.1609/icwsm.v14i1.7302," Shan Jiang, Miriam Metzger, Andrew Flanagin, and Christo Wilson. ""Modeling and Measuring Expressed (Dis)belief in (Mis)information"". In Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM 2020). Atlanta, Georgia, June, 2020.","Abstract The proliferation of online misinformation has been raising increasing societal concerns about its potential consequences, e.g., polarizing the public and eroding trust in institutions. These consequences are framed under the public's susceptibility to such misinformation ‚Äî a narrative that needs further investigation and quantification. To this end, our paper proposes an observational approach to model and measure expressed (dis)beliefs in (mis)information by leveraging social media comments as a proxy. We collect a sample of tweets in response to (mis)information and annotate them with (dis)belief labels, explore the dataset using lexicon-based methods, and finally build classifiers based on the state-of-the-art neural transfer-learning models (BERT, XLNet, and RoBERTa). Under a domain-specific thresholding strategy for unbiasedness, the best-performing classifier archives macro-F 1 scores around 0.86 for disbelief and 0.80 for belief. Applying the classifier, we conduct a large-scale measurement study and show that, for true/mixed/false claims on social media, 12%/14%/15% of comments express disbelief and 26%/21%/20% of comments express belief. In addition, our results suggest an extremely slight time effect of falsehood awareness, a positive effect of fact-checks to false claims, and differences in (dis)belief across social media platforms.",636
551,Cybersecurity and Privacy,Christo Wilson,"October 21st, 2019",A Longitudinal Analysis of the ads.txt Standard,https://doi.org/10.1145/3355369.3355603," Muhammad Ahmad Bashir, Sajjad Arshad, Engin Kirda, William K. Robertson, Christo Wilson. (2019). A Longitudinal Analysis of the ads.txt Standard Internet Measurement Conference, 294-307. https://doi.org/10.1145/3355369.3355603","Programmatic advertising provides digital ad buyers with the convenience of purchasing ad impressions through Real Time Bidding (RTB) auctions. However, programmatic advertising has also given rise to a novel form of ad fraud known as domain spoofing, in which attackers sell counterfeit impressions that claim to be from high-value publishers. To mitigate domain spoofing, the Interactive Advertising Bureau (IAB) Tech Lab introduced the ads.txt standard in May 2017 to help ad buyers verify authorized digital ad sellers, as well as to promote overall transparency in programmatic advertising. In this work, we present a 15-month longitudinal, observational study of the ads.txt standard. We do this to understand (1) if it is helping ad buyers to combat domain spoofing and (2) whether the transparency offered by the standard can provide useful data to researchers and privacy advocates. With respect to halting domain spoofing, we observe that over 60% of Alexa Top-100K publishers that run RTB ads have adopted ads.txt, and that ad exchanges and advertisers appear to be honoring the standard. With respect to transparency, the widespread adoption of ads.txt allows us to explicitly identify over 1,000 domains belonging to ad exchanges, without having to rely on crowdsourcing or heuristic methods. However, we also find that ads.txt is still a long way from reaching its full potential. Many publishers have yet to adopt the standard, and we observe major ad exchanges purchasing unauthorized impressions that violate the standard. This opens the door to domain spoofing attacks. Further, ads.txt data often include errors that must be cleaned and mitigated before the data is practically useful.",637
552,Cybersecurity and Privacy,Christo Wilson,"April 23rd, 2018",Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages,https://doi.org/10.1145/3178876.3186143," Ronald E. Robertson, David Lazer, and Christo Wilson. 2018. Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages. In Proceedings of the 2018 World Wide Web Conference (WWW '18). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 955‚Äì965. DOI: 10.1145/3178876.3186143","Search engines are a primary means through which people obtain information in today¬ªs connected world. Yet, apart from the search engine companies themselves, little is known about how their algorithms filter, rank, and present the web to users. This question is especially pertinent with respect to political queries, given growing concerns about filter bubbles, and the recent finding that bias or favoritism in search rankings can influence voting behavior. In this study, we conduct a targeted algorithm audit of Google Search using a dynamic set of political queries. We designed a Chrome extension to survey participants and collect the Search Engine Results Pages (SERPs) and autocomplete suggestions that they would have been exposed to while searching our set of political queries during the month after Donald Trump¬ªs Presidential inauguration. Using this data, we found significant differences in the composition and personalization of politically-related SERPs by query type, subjects¬ª characteristics, and date.",638
553,Cybersecurity and Privacy,Cheng Tan,"December 27th, 2024",Instance-Optimized Mapping with Portfolio Methods,https://doi.org/10.1145/3704742.3704963," Yibo Zhao, Panagiotis Manolios, Cheng Tan . (2024). Instance-Optimized Mapping with Portfolio Methods PACMI@SOSP, 11-16. https://doi.org/10.1145/3704742.3704963","Mappings are ubiquitous in computer systems, such as translating virtual memory to physical memory, file paths to inode numbers, database keys to data locations. Traditional system mappings are often hand-crafted and data-agnostic. In this paper, we explore the use of neural networks as learned mappings that are automatically generated and data-dependent, optimizing performance for specific workloads and scenarios. Unlike prior learned structures, we employ a portfolio method consisting of a set of independent neural networks, each responsible for making sole decisions. Our preliminary results indicate that these portfolio mappings can generalize across multiple applications.",639
554,Cybersecurity and Privacy,Cheng Tan,"September 16th, 2024",Scheduling Splittable Jobs on Configurable Machines,https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22," Matthew Casey, Rajmohan Rajaraman, David Stalfa, Cheng Tan . (2024). Scheduling Splittable Jobs on Configurable Machines APPROX/RANDOM, 22:1-22:20. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22","Abstract Motivated by modern architectures allowing for the partitioning of a GPU into hardware separated instances, we initiate the study of scheduling splittable jobs on configurable machines. We consider machines that can be configured into smaller instances, which we call blocks, in multiple ways, each of which is referred to as a configuration. We introduce the Configurable Machine Scheduling (cms) problem, where we are given n jobs and a set C of configurations. A schedule consists of a set of machines, each assigned some configuration in C with each block in the configuration assigned to process one job. The amount of a job‚Äôs demand that is satisfied by a block is given by an arbitrary function of the job and block. The objective is to construct a schedule using as few machines as possible. We provide a tight logarithmic factor approximation algorithm for this problem in the general setting, a factor (3 + Œµ) approximation algorithm for arbitrary Œµ > 0 when there are O(1) input configurations, and a polynomial time approximation scheme when both the number and size of configurations are O(1). Finally, we utilize a technique for finding conic integer combinations in fixed dimension to develop an optimal polynomial time algorithm in the case with O(1) jobs, O(1) blocks, and every configuration up to a given size.",640
555,Cybersecurity and Privacy,Cheng Tan,"July 10th, 2023",Encrypted Databases Made Secure Yet Maintainable,https://www.usenix.org/conference/osdi23/presentation/li-mingyu," Mingyu Li, Xuyang Zhao, Le Chen, Cheng Tan , Huorong Li, Sheng Wang , Zeyu Mi, Yubin Xia, Feifei Li , Haibo Chen . (2023). Encrypted Databases Made Secure Yet Maintainable OSDI, 117-133. https://www.usenix.org/conference/osdi23/presentation/li-mingyu",HEDB uses a dual-mode EDB design based on our analysis of DBA maintenance tasks. Execution Mode handles user queries by isolating DBAs from operators to prevent smuggle attacks. Maintenance Mode enables DBMS maintenance and operator troubleshooting through authenticated replay and anonymized replay.,641
556,Cybersecurity and Privacy,Cheng Tan,"January 30th, 2023",NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers,https://doi.org/10.1145/3575693.3575707," Jiawei Liu , Jinkun Lin, Fabian Ruffy, Cheng Tan , Jinyang Li , Aurojit Panda, Lingming Zhang . (2023). NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers ASPLOS (2), 530-543. https://doi.org/10.1145/3575693.3575707","Deep-learning (DL) compilers such as TVM and TensorRT are increasingly being used to optimize deep neural network (DNN) models to meet performance, resource utilization and other requirements. Bugs in these compilers can result in models whose semantics differ from the original ones, producing incorrect results that corrupt the correctness of downstream applications. However, finding bugs in these compilers is challenging due to their complexity. In this work, we propose a new fuzz testing approach for finding bugs in deep-learning compilers. Our core approach consists of (i) generating diverse yet valid DNN test models that can exercise a large part of the compiler's transformation logic using light-weight operator specifications; (ii) performing gradient-based search to find model inputs that avoid any floating-point exceptional values during model execution, reducing the chance of missed bugs or false alarms; and (iii) using differential testing to identify bugs. We implemented this approach in NNSmith which has found 72 new bugs for TVM, TensorRT, ONNXRuntime, and PyTorch to date. Of these 58 have been confirmed and 51 have been fixed by their respective project maintainers.",642
557,Cybersecurity and Privacy,Cheng Tan,"August 24th, 2021",Building verified neural networks with specifications for systems,https://dl.acm.org/doi/10.1145/3476886.3477508," Cheng Tan, Yibo Zhu, and Chuanxiong Guo. 2021. Building verified neural networks with specifications for systems. Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on Systems. Association for Computing Machinery, New York, NY, USA, 42‚Äì47. DOI:https://doi.org/10.1145/3476886.3477508","Neural networks (NNs) are beneficial to many services, and we believe systems‚Äîsuch as OSes, databases, networked systems‚Äîare not an exception. But applying NNs in these critical systems is challenging: people have to risk getting unexpected outcomes from NNs because NN behaviors are not well-defined. To tame these undefined behaviors, we introduce a framework ouroboros, which builds verified NNs that follow user-defined specifications. These specifications comprise input and output constraints which characterize the behaviors of a NN. We do a case study on database learned indexes to demonstrate that training verified NN models is possible. Though many challenges remain, ouroboros enables us, for the first time, to apply NNs in critical systems with _confidence_.",643
558,Cybersecurity and Privacy,Cheng Tan,"July 1st, 2021",Bringing Decentralized Search to Decentralized Services,https://www.usenix.org/conference/osdi21/presentation/li," Mingyu Li and Jinhao Zhu and Tianxu Zhang and Cheng Tan and Yubin Xia and Sebastian Angel and Haibo Chen, ""Bringing Decentralized Search to Decentralized Services"", 15th {USENIX} Symposium on Operating Systems Design and Implementation , 2021, i USENIX Association",DeSearch uses trusted hardware to build a network of workers that execute a pipeline of small search engine tasks. DeSearch then introduces a witness mechanism to make sure the completed tasks can be reused across different pipelines. We implement DeSearch for two existing decentralized services that handle over 80 million records and 240 GBs of data. We show that DeSearch can scale horizontally with the number of workers and can process 128 million search queries per day.,644
559,Cybersecurity and Privacy,Cheng Tan,"November 4th, 2020",Cobra: Making transactional key-value stores verifiably serializable,https://dl.acm.org/doi/abs/10.5555/3488766.3488770," Cheng Tan, Changgeng Zhao, Shuai Mu, and Michael Walfish. 2020. COBRA: making transactional key-value stores verifiably serializable. Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation. Article 4, 63‚Äì80.","Today's cloud databases offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud databases are complicated black boxes, running in a different administrative domain from their clients. Thus, clients might like to know whether the databases are meeting their contract. To that end, we introduce cobra; cobra applies to transactional key-value stores. It is the first system that combines (a) black-box checking, of (b) serializability, while (c) scaling to real-world online transactional processing workloads. The core technical challenge is that the underlying search problem is computationally expensive. COBRA tames that problem by starting with a suitable SMT solver. COBRA then introduces several new techniques, including a new encoding of the validity condition; hardware acceleration to prune inputs to the solver; and a transaction segmentation mechanism that enables scaling and garbage collection. Cobra imposes modest overhead on clients, improves over baselines by 10√ó in verification cost, and (unlike the baselines) supports continuous verification. Our artifact can handle 2000 transactions/sec, equivalent to 170M/day.",645
560,Cybersecurity and Privacy,Cheng Tan,"December 19th, 2019",Detecting Incorrect Behavior of Cloud Databases as an Outsider,http://arxiv.org/abs/1912.09018," Cheng Tan , Changgeng Zhao, Shuai Mu , Michael Walfish. (2019). Detecting Incorrect Behavior of Cloud Databases as an Outsider CoRR, abs/1912.09018. http://arxiv.org/abs/1912.09018","Cloud DBs offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud DBs are complicated black boxes, running in a different administrative domain from their clients; thus, clients might like to know whether the DBs are meeting their contract. A core difficulty is that the underlying problem here, namely verifying serializability, is NP-complete. Nevertheless, we hypothesize that on real-world workloads, verifying serializability is tractable, and we treat the question as a systems problem, for the first time. We build Cobra, which tames the underlying search problem by blending a new encoding of the problem, hardware acceleration, and a careful choice of a suitable SMT solver. cobra also introduces a technique to address the challenge of garbage collection in this context. cobra improves over natural baselines by at least 10x in the problem size it can handle, while imposing modest overhead on clients.",646
561,Cybersecurity and Privacy,Cheng Tan,"February 26th, 2019",Netbouncer: Active device and link failure localization in data center networks,https://dl.acm.org/doi/10.5555/3323234.3323283," Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng, Dongming Bi, and Dong Xiang. 2019. Netbouncer: active device and link failure localization in data center networks. In Proceedings of the 16th USENIX Conference on Networked Systems Design and Implementation (NSDI'19). USENIX Association, USA, 599‚Äì613.","The availability of data center services is jeopardized by various network incidents. One of the biggest challenges for network incident handling is to accurately localize the failures, among millions of servers and tens of thousands of network devices. In this paper, we propose NetBouncer, a failure localization system that leverages the IP-in-IP technique to actively probe paths in a data center network. NetBouncer provides a complete failure localization framework which is capable of detecting both device and link failures. It further introduces an algorithm for high accuracy link failure inference that is resilient to real-world data inconsistency by integrating both our troubleshooting domain knowledge and machine learning techniques. NetBouncer has been deployed in Microsoft Azure's data centers for three years. And in practice, it produced no false positives and only a few false negatives so far.",647
562,Cybersecurity and Privacy,Cheng Tan,"January 1st, 2019",Taming Distrust in the Decentralized Internet with PIXIU,http://arxiv.org/abs/1901.06095," Yubin Xia, Qingyuan Liu, Cheng Tan , Jing Leng, Shangning Xu, Binyu Zang, Haibo Chen . (2019). Taming Distrust in the Decentralized Internet with PIXIU CoRR, abs/1901.06095. http://arxiv.org/abs/1901.06095","Decentralized Internet is booming. People are fascinated by its promise that users can truly own their data. However, in a decentralized Internet, completing a task usually involves multiple nodes with mutual distrust. Such distrust might eventually become a major obstacle for the growth of the decentralized Internet. In this paper, we analyze the distrust using a simple model and highlight the properties required to faithfully accomplish one task in a decentralized Internet. We also introduce our draft solution -- PIXIU, a framework to mitigate the distrust among different nodes. In PIXIU, we design and utilize trust-{\lambda} and decentralized executor to achieve the above-needed properties.",648
563,Cybersecurity and Privacy,Cheng Tan,"October 14th, 2017","The efficient server audit problem, deduplicated re-execution, and the web",https://dl.acm.org/doi/10.1145/3132747.3132760," Cheng Tan, Lingfan Yu, Joshua B. Leners, and Michael Walfish. 2017. The Efficient Server Audit Problem, Deduplicated Re-execution, and the Web. In Proceedings of the 26th Symposium on Operating Systems Principles (SOSP '17). Association for Computing Machinery, New York, NY, USA, 546‚Äì564. DOI:https://doi.org/10.1145/3132747.3132760","You put a program on a concurrent server, but you don't trust the server; later, you get a trace of the actual requests that the server received from its clients and the responses that it delivered. You separately get logs from the server; these are untrusted. How can you use the logs to efficiently verify that the responses were derived from running the program on the requests? This is the Efficient Server Audit Problem, which abstracts real-world scenarios, including running a web application on an untrusted provider. We give a solution based on several new techniques, including simultaneous replay and efficient verification of concurrent executions. We implement the solution for PHP web applications. For several applications, our verifier achieves 5.6-10.9x speedup versus simply re-executing, with <10% overhead for the server.",649
564,Cybersecurity and Privacy,Maryam Tanha,"September 12th, 2024",Revisiting Temporal Inconsistency and Feature Extraction for Android Malware Detection,https://doi.org/10.1109/CCECE59415.2024.10667123," Maryam Tanha, Arunab Singh, Gavin Knoke. (2024). Revisiting Temporal Inconsistency and Feature Extraction for Android Malware Detection CCECE, 301-306. https://doi.org/10.1109/CCECE59415.2024.10667123","Machine learning has become an essential instrument for conducting Android malware detection and analysis. We demonstrate the unreliability of the commonly used dex_date as the release time of an app. We propose a more accurate approach for creating temporally-consistent datasets based on an app‚Äôs upload year. We have open-sourced our data and feature extraction process for Android malware analysis, supporting both server-side and on-device extraction, to enhance research reproducibility and facilitate community access. The paper was published in the IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)",650
565,Cybersecurity and Privacy,Maryam Tanha,"February 26th, 2024",Interpretable Android Malware Detection Based on Dynamic Analysis,https://doi.org/10.5220/0012415800003648," Arunab Singh, Maryam Tanha, Yashsvi Girdhar, Aaron Hunter . (2024). Interpretable Android Malware Detection Based on Dynamic Analysis ICISSP, 195-202. https://doi.org/10.5220/0012415800003648","The paper was published in the Journal of Applied Machine Learning and is available to download now. Android has emerged as the dominant operating system for smart devices, which has led to the proliferation of Android malware. Our approach provides explanations for the classification results by indicating the features that are contributing the most to the detection result. The quality of explanations are assessed using stability metrics.",651
566,Cybersecurity and Privacy,Ziming Zhao,"December 1st, 2024",TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning,https://doi.org/10.1145/3658644.3690234," Cong Wu , Jing Chen , Ziming Zhao , Kun He , Guowen Xu, Yueming Wu , Haijun Wang, Hongwei Li , Yang Liu , Yang Xiang . (2024). TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning CCS, 956-970. https://doi.org/10.1145/3658644.3690234","Decentralized finance has experienced phenomenal growth, revolutionizing the landscape of financial transactions and asset management via blockchain. Yet, this swift growth brings with it substantial challenges, notably the surge in scam tokens, imposing significant security threats on cryptocurrency investments and trading. Existing detection methods of scam token, primarily relying on analyzing contract codes or transaction patterns, struggle to catch increasingly sophisticated tactics employed by scammers. For example, contract-based analysis are unable to identify scams lacking overt malicious code, e.g., most rugpulls, while transaction-based methods generally lack the foresight to early-detect potential risks. In this paper, we present TokenScout, the first temporal temporal graph neural network-based framework for scam token early detection. TokenScout formulates token transfer data as a dynamic temporal attributed multigraph and leverages the temporal graph learning model to learn graph representations. It also builds a graph representation refining model based on contrastive learning to learn a more discriminative representation space for risk identification. We evaluated TokenScout using a comprehensive dataset of 214,084 standard ERC20 tokens from 2015 to February 2023. TokenScout achieves a balanced accuracy of 98.41%. Additionally, from March to May 2023, deploying TokenScout on Ethereum effectively identified 706 rugpulls, 174 honeypots, and 90 Ponzi schemes, thereby alerting to potential risks exceeding 240 million.",652
567,Cybersecurity and Privacy,Ziming Zhao,"June 26th, 2024",InsectACIDE: Debugger-Based Holistic Asynchronous CFI for Embedded System,https://doi.org/10.1109/RTAS61025.2024.00036," Yujie Wang, Cailani Lemieux Mack, Xi Tan , Ning Zhang , Ziming Zhao , Sanjoy K. Baruah, Bryan C. Ward. (2024). InsectACIDE: Debugger-Based Holistic Asynchronous CFI for Embedded System RTAS, 360-372. https://doi.org/10.1109/RTAS61025.2024.00036","Real-time and embedded systems are predominantly written in C, a language that is notoriously not memory safe. This has led to widespread memory-corruption vulnerabilities in real-time embedded cyber-physical systems (CPS) This is concerning, as such devices are becoming increasingly networked with the Internet of Things (IoT) and other communication technologies (e.g., 5G) This paper presents InsectACIDE, the first holistic CFI for embedded and real- time systems that does not require binary instrumentation. It checks that the sequence of control-flow transitions taken is valid, not just individual transitions, thereby detecting such attacks.",653
568,Cybersecurity and Privacy,Ziming Zhao,"November 21st, 2023",SHERLOC: Secure and Holistic Control-Flow Violation Detection on Embedded Systems,https://doi.org/10.1145/3576915.3623077," Xi Tan , Ziming Zhao . (2023). SHERLOC: Secure and Holistic Control-Flow Violation Detection on Embedded Systems CCS, 1332-1346. https://doi.org/10.1145/3576915.3623077","Microcontroller-based embedded systems are often programmed in low-level languages and are vulnerable to control-flow hijacking attacks. One approach to prevent such attacks is to enforce control-flow integrity (CFI), but inlined CFI enforcement can pose challenges in embedded systems. For example, it increases binary size and changes memory layout. Trace-based control-flow violation detection (CFVD) offers an alternative that doesn't require instrumentation of the protected software or changes to its memory layout. However, existing CFVD methods used in desktop systems require kernel modifications to store and analyze the trace, which limits their use to monitoring unprivileged applications. But, embedded systems are interrupt-driven, with the majority of processing taking place in the privileged mode. Therefore, it is critical to provide a holistic and system-oriented CFVD solution that can monitor control-flow transfers both within and among privileged and unprivileged components. In this paper, we present SHERLOC, a Secure and Holistic Control-Flow Violation Detection mechanism designed for microcontroller-based embedded systems. SHERLOC ensures security by configuring the hardware tracing unit, storing trace records, and executing the violation detection algorithm in a trusted execution environment, which prevents privileged programs from bypassing monitoring or tampering with the trace. We address the challenges of achieving holistic and system-oriented CFVD by formalizing the problem and monitoring forward and backward edges of unprivileged and privileged programs, as well as control-flow transfers among unprivileged and privileged components. Specifically, SHERLOC overcomes the challenges of identifying legitimate asynchronous interrupts and context switches at run-time by using an interrupt- and scheduling-aware violation detection algorithm. Our evaluations on the ARMv8-M architecture demonstrate the effectiveness and efficiency of SHERLOC.",654
569,Cybersecurity and Privacy,Ziming Zhao,"September 15th, 2023",Return-to-Non-Secure Vulnerabilities on ARM Cortex-M TrustZone: Attack and Defense,https://doi.org/10.1109/DAC56929.2023.10247972," Zheyuan Ma, Xi Tan , Lukasz Ziarek, Ning Zhang , Hongxin Hu, Ziming Zhao . (2023). Return-to-Non-Secure Vulnerabilities on ARM Cortex-M TrustZone: Attack and Defense DAC, 1-6. https://doi.org/10.1109/DAC56929.2023.10247972"," ARM Cortex-M is one of the most popular microcontroller architectures designed for embedded and Internet of Things (IoT) applications. To facilitate efficient execution, it has some unique hardware optimization. This fast state switch mechanism can be exploited for arbitrary code execution. The study was published in the 60th ACM/IEEE Design Automation Conference.",655
570,Data Management,Ricardo Baeza-Yates,"February 17th, 2025",A Comparison of Human and Machine Learning Errors in Face Recognition,https://doi.org/10.48550/arXiv.2502.11337," Marina Est√©vez-Almenzar, Ricardo Baeza-Yates, Carlos Castillo . (2025). A Comparison of Human and Machine Learning Errors in Face Recognition CoRR, abs/2502.11337. https://doi.org/10.48550/arXiv.2502.11337","Machine learning applications in high-stakes scenarios should always operate under human oversight. Developing an optimal combination of human and machine intelligence requires an understanding of their complementarities, particularly regarding the similarities and differences in the way they make mistakes. We perform extensive experiments in the area of face recognition and compare two automated face recognition systems against human annotators through a demographically balanced user study. Our research uncovers important ways in which machine learning errors and human errors differ from each other, and suggests potential strategies in which human-machine collaboration can improve accuracy in face recognition.",656
571,Data Management,Ricardo Baeza-Yates,"February 7th, 2025",Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning,https://doi.org/10.1109/ACCESS.2025.3539719," Maria Rauschenberger, Ricardo Baeza-Yates, Luz Rello. (2025). Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning IEEE Access, 13, 29541-29553. https://doi.org/10.1109/ACCESS.2025.3539719",Dyslexia is a type of neuro-developmental disorder that affects the ability to learn how to read and write. We present an approach for screening dyslexic using language-independent games in combination with machine learning models. Our results open the possibility of inexpensive online early screening of dyslexy for young children using non-linguistic elements. The study was published in IEEE Access ( Volume: 13 ) Page(s): 29541 - 29553 Date of Publication: 07 February 2025 Electronic ISSN: 2169-3536. DOI: 10.1109/ACCESS.2025.3539719 Publisher: IEEE Funding Agency.,657
572,Data Management,Ricardo Baeza-Yates,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",658
573,Data Management,Ricardo Baeza-Yates,"September 21st, 2024",AI content detection in the emerging information ecosystem: new obligations for media and tech companies,https://doi.org/10.1007/s10676-024-09795-1," Alistair Knott, Dino Pedreschi, Toshiya Jitsuzumi, Susan Leavy, David M. Eyers, Tapabrata Chakraborti, Andrew Trotman, Sundar Sundareswaran, Ricardo Baeza-Yates, Przemyslaw Biecek, Adrian Weller, Paul D. Teal, Subhadip Basu, Mehmet Haklidir, Virginia Morini, Stuart Russell , Yoshua Bengio. (2024). AI content detection in the emerging information ecosystem: new obligations for media and tech companies Ethics Inf. Technol., 26, 63. https://doi.org/10.1007/s10676-024-09795-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",659
574,Data Management,Ricardo Baeza-Yates,"August 4th, 2023",Fair Multilingual Vandalism Detection System for Wikipedia,https://doi.org/10.1145/3580305.3599823," Mykola Trokhymovych, Muniza Aslam, Ai-Jou Chou, Ricardo Baeza-Yates, Diego S√°ez-Trumper. (2023). Fair Multilingual Vandalism Detection System for Wikipedia KDD, 4981-4990. https://doi.org/10.1145/3580305.3599823","This paper presents a novel design of the system aimed at supporting the Wikipedia community in addressing vandalism on the platform. To achieve this, we collected a massive dataset of 47 languages, and applied advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data. The performance of the system was evaluated through comparison with the one used in production in Wikipedia, known as ORES. Our research results in a significant increase in the number of languages covered, making Wikipedia patrolling more efficient to a wider range of communities. Furthermore, our model outperforms ORES, ensuring that the results provided are not only more accurate but also less biased against certain groups of contributors.",660
575,Data Management,Ricardo Baeza-Yates,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",661
576,Data Management,Ricardo Baeza-Yates,"May 14th, 2018",Bias on the Web,https://dl.acm.org/citation.cfm?id=2908135," Ricardo Baeza-Yates. Bias on the Web. Communications of ACM, June 2018.","The Web is the largest public big data repository that humankind has created. In this overwhelming data ocean we need to be aware of the quality of data extracted from it. One important quality issue is data bias, which appears in different forms. These biases affect the (machine learning) algorithms that we design to improve the user experience. This problem is further exacerbated by biases that are added by these algorithms, especially in the context of recommendation and personalization systems. We give several examples, stressing the importance of the user context to avoid these biases.",662
577,Data Management,Ricardo Baeza-Yates,"December 14th, 2017",Quality-efficiency trade-offs in machine learning for text processing,https://arxiv.org/abs/1711.02295," Ricardo A. Baeza-Yates, Zeinab Liaghat:Quality-efficiency trade-offs in machine learning for text processing. IEEE BigData 2017: 897-904.",Are quality gains worth it when the rate of data processing diminishes? Can we trade quality for time efficiency and recover the quality loss by just being able to process more data? We propose a performance trade-off framework and apply it to three important text processing problems. We find that the results do not change significantly and that most of the time the best algorithms is the fastest.,663
578,Data Management,Mario Nascimento,"November 21st, 2024",An Experimental Study on Data Augmentation Techniques for Named Entity Recognition on Low-Resource Domains,https://doi.org/10.48550/arXiv.2411.14551," Arthur Elwing Torres, Edleno Silva de Moura, Altigran Soares da Silva, Mario A. Nascimento, Filipe de S√° Mesquita. (2024). An Experimental Study on Data Augmentation Techniques for Named Entity Recognition on Low-Resource Domains CoRR, abs/2411.14551. https://doi.org/10.48550/arXiv.2411.14551","Named Entity Recognition (NER) is a machine learning task that traditionally relies on supervised learning and annotated data. Acquiring such data is often a challenge, particularly in specialized fields like medical, legal, and financial sectors. Those are commonly referred to as low-resource domains, which comprise long-tail entities, due to the scarcity of available data. To address this, data augmentation techniques are increasingly being employed to generate additional training instances from the original dataset. In this study, we evaluate the effectiveness of two prominent text augmentation techniques, Mention Replacement and Contextual Word Replacement, on two widely-used NER models, Bi-LSTM+CRF and BERT. We conduct experiments on four datasets from low-resource domains, and we explore the impact of various combinations of training subset sizes and number of augmented examples. We not only confirm that data augmentation is particularly beneficial for smaller datasets, but we also demonstrate that there is no universally optimal number of augmented examples, i.e., NER practitioners must experiment with different quantities in order to fine-tune their projects.",664
579,Data Management,Mario Nascimento,"July 17th, 2024",Effective Trajectory Imputation using Simple Probabilistic Language Models,https://doi.org/10.1109/MDM61037.2024.00027," Hayat Sultan Mohammed, Mario A. Nascimento, Denilson Barbosa . (2024). Effective Trajectory Imputation using Simple Probabilistic Language Models MDM, 51-60. https://doi.org/10.1109/MDM61037.2024.00027","Trajectory imputation is the task of filling in the gaps in actual trajectories by computing points that fit ""naturally"" within existing trajectories. Using a grid-based representation of the space, and not considering the underlying road network, we convert trajectory points into tokens corresponding to the grid cell where they appear. We report experiments on a real dataset of over 500,000 taxi trips, showing that we can accurately fill gaps of up to 2km between GPS observations with 83% precision. These results are comparable to approaches using much more computationally demanding Large Language Models based on transformers.",665
580,Data Management,Mario Nascimento,"July 1st, 2024",Mobility Data Science: Perspectives and Challenges,https://doi.org/10.1145/3652158," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Seok Kim , Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Cyrus Shahabi, Bettina Speckmann, Egemen Tanin, Xu Teng, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2024). Mobility Data Science: Perspectives and Challenges ACM Trans. Spatial Algorithms Syst., 10, 10. https://doi.org/10.1145/3652158","Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)‚Äìequipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years.",666
581,Data Management,Mario Nascimento,"November 7th, 2023","Conference Report: The 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022) Seattle, Washington, USA November 1-4, 2022",https://doi.org/10.1145/3632268.3632270," Matthias Renz, Mohamed Sarwat, Mario A. Nascimento, Shashi Shekar, Xing Xie . (2022). Conference Report: The 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022) Seattle, Washington, USA November 1-4, 2022 ACM SIGSPATIAL Special, 14, 2-6. https://doi.org/10.1145/3632268.3632270","This report presents the development and finalization of the 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022), which was held in Seattle, Washington, USA, November 1--4, 2022.",667
582,Data Management,Mario Nascimento,"June 21st, 2023",Towards Mobility Data Science (Vision Paper),https://doi.org/10.48550/arXiv.2307.05717," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Sook Kim, Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Cyrus Shahabi, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Bettina Speckmann, Egemen Tanin, Xu Teng, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2023). Towards Mobility Data Science (Vision Paper) CoRR, abs/2307.05717. https://doi.org/10.48550/arXiv.2307.05717","Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years.",668
583,Data Management,Mario Nascimento,"November 30th, 2022",Asymmetric Action Abstractions for Planning in Real-Time Strategy Games,https://doi.org/10.1613/jair.1.13769," Rubens O. Moraes, Mario A. Nascimento, Levi H. S. Lelis. (2022). Asymmetric Action Abstractions for Planning in Real-Time Strategy Games J. Artif. Intell. Res., 75, 1103-1137. https://doi.org/10.1613/jair.1.13769","Action abstractions restrict the number of legal actions available for real-time planning in zero-sum extensive-form games, thus allowing algorithms to focus their search on a set of promising actions. Even though unabstracted game trees can lead to optimal policies, due to real-time constraints and the tree size, they are not a practical choice. In this context, we introduce an action abstraction scheme which we call asymmetric action abstraction. Asymmetric abstractions allow search algorithms to ‚Äúpay more attention‚Äù to some aspects of the game by unevenly dividing the algorithm‚Äôs search effort amongst different aspects of the game. We also introduce four algorithms that search in asymmetrically abstracted game trees to evaluate the effectiveness of our abstraction schemes. Two of our algorithms are adaptations of algorithms developed for searching in action-abstracted spaces, Portfolio Greedy Search and Stratified Strategy Selection, and the other two are adaptations of an algorithm developed for searching in unabstracted spaces, Na√ØveMCTS. An extensive set of experiments in a real-time strategy game shows that search algorithms using asymmetric abstractions are able to outperform all other search algorithms tested.",669
584,Data Management,Mario Nascimento,"August 23rd, 2022",Mobility Data Science (Dagstuhl Seminar 22021),https://doi.org/10.4230/DagRep.12.1.1," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Sook Kim, Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Cyrus Shahabi, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Bettina Speckmann, Egemen Tanin, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2022). Mobility Data Science (Dagstuhl Seminar 22021) Dagstuhl Reports, 12, 1-34. https://doi.org/10.4230/DagRep.12.1.1","Abstract This report documents the program and the outcomes of Dagstuhl Seminar 22021 ""Mobility Data Science"". This seminar was held January 9-14, 2022, including 47 participants from industry and academia. The goal of this Dagstuhl Seminar was to create a new research community of mobility data science in which the whole is greater than the sum of its parts by bringing together established leaders as well as promising young researchers from all fields related to mobility data science. Specifically, this report summarizes the main results of the seminar by (1) defining Mobility Data Science as a research domain, (2) by sketching its agenda in the coming years, and by (3) building a mobility data science community. (1) Mobility data science is defined as spatiotemporal data that additionally captures the behavior of moving entities (human, vehicle, animal, etc.). To understand, explain, and predict behavior, we note that a strong collaboration with research in behavioral and social sciences is needed. (2) Future research directions for mobility data science described in this report include a) mobility data acquisition and privacy, b) mobility data management and analysis, and c) applications of mobility data science. (3) We identify opportunities towards building a mobility data science community, towards collaborations between academic and industry, and towards a mobility data science curriculum.",670
585,Data Management,Mirek Riedewald,"June 17th, 2024",Finding Linear Explanations for a Given Ranking,https://doi.org/10.48550/arXiv.2406.11797," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2024). Finding Linear Explanations for a Given Ranking CoRR, abs/2406.11797. https://doi.org/10.48550/arXiv.2406.11797","Given a relation and a ranking of its tuples, but no information about the ranking function, we propose RankExplain to solve 2 types of problems: SAT asks if any linear scoring function can exactly reproduce the given ranking. OPT identifies the linear scoring function that minimizes position-based error, i.e., the total of the ranking-position differences over all tuples in the top-k. Our solution consists of linear programs that solve the problems exactly and can be implemented using MILP solvers. These solvers also support additional constraints on the scoring function, allowing the user to explore competing hypotheses through alternative scoring functions. We also discuss techniques for dealing with numerical imprecision and for improving performance and scalability. Experiments demonstrate that RankExplain can solve realistic problems. It is the first technique to provide exact solutions for OPT; and it is the fastest in producing exact solutions for SAT.",671
586,Data Management,Mirek Riedewald,"June 18th, 2023",Efficient Computation of Quantiles over Joins,https://doi.org/10.1145/3584372.3588670," Nikolaos Tziavelis, Nofar Carmeli, Wolfgang Gatterbauer, Benny Kimelfeld, Mirek Riedewald. (2023). Efficient Computation of Quantiles over Joins PODS, 303-315. https://doi.org/10.1145/3584372.3588670","Quantile Join Queries, abbreviated as %JQ, ask for the answer at a specified relative position. A recent dichotomy result rules out the existence of such an algorithm for a general family of queries and orders. We handle the intractable cases of sum by devising a deterministic approximation scheme that applies to every acyclic JQ.",672
587,Data Management,Mirek Riedewald,"October 1st, 2021",STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,https://doi.org/10.1109/TVCG.2021.3114756," S. di Bartolomeo, M. Riedewald, W. Gatterbauer and C. Dunne, ""STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,"" in IEEE Transactions on Visualization and Computer Graphics, vol. 28, no. 1, pp. 324-334, Jan. 2022, DOI: 10.1109/TVCG.2021.3114756.","Stratisfimal Layout is a modular integer-linear-programming formulation that can consider several important readability criteria simultaneously. It can be adapted to diverse use cases through its modularity. Individual features can be enabled and customized depending on the application. We provide open-source and documented implementations of the layout, both for web-based and desktop visualizations. The paper is published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 28 , Issue: 1 , January 2022 ) The full paper with all appendices, data, and source code is available at o.sf.io/qdyt9 with live examples at https://visdunneright. io/stratisfimal/.",673
588,Data Management,Mirek Riedewald,"June 20th, 2021",Tractable Orders for Direct Access to Ranked Answers of Conjunctive Queries,https://doi.org/10.1145/3452021.3458331," Carmeli, Nofar and Tziavelis, Nikolaos and Gatterbauer, Wolfgang and Kimelfeld, Benny and Riedewald, Mirek. ‚ÄúTractable Orders for Direct Access to Ranked Answers of Conjunctive Queries‚Äù. PODS 2021 , 2021. DOI: 10.1145/3452021.3458331","We study the question of when we can provide logarithmic-time direct access to the k-th answer to a Conjunctive Query (CQ) with a specified ordering over the answers, following a preprocessing step that constructs a data structure in time quasilinear in the size of the database. Specifically, we embark on the challenge of identifying the tractable answer orderings that allow for ranked direct access with such complexity guarantees. We begin with lexicographic orderings and give a decidable characterization (under conventional complexity assumptions) of the class of tractable lexicographic orderings for every CQ without self-joins. We then continue to the more general orderings by the sum of attribute weights and show for it that ranked direct access is tractable only in trivial cases. Hence, to better understand the computational challenge at hand, we consider the more modest task of providing access to only a single answer (i.e., finding the answer at a given position) - a task that we refer to as the selection problem. We indeed achieve a quasilinear-time algorithm for a subset of the class of full CQs without self-joins, by adopting a solution of Frederickson and Johnson to the classic problem of selection over sorted matrices. We further prove that none of the other queries in this class admit such an algorithm.",674
589,Data Management,Mirek Riedewald,"May 1st, 2020",Optimal Algorithms for Ranked Enumeration of Answers to Full Conjunctive Queries,https://doi.org/10.14778/3397230.3397250," Nikolaos Tziavelis, Deepak Ajwani, Wolfgang Gatterbauer, Mirek Riedewald, Xiaofeng Yang. PVLDB 13(9):1582-1597, 2020","We study ranked enumeration of join-query results according to very general orders defined by selective dioids. Our main contribution is a framework for ranked enumeration over a class of dynamic programming problems that generalizes seemingly different problems that had been studied in isolation. To this end, we extend classic algorithms that find the k -shortest paths in a weighted graph. For full conjunctive queries, including cyclic ones, our approach is optimal in terms of the time to return the top result and the delay between results. These optimality properties are derived for the widely used notion of data complexity, which treats query size as a constant. By performing a careful cost analysis, we are able to uncover a previously unknown tradeoff between two incomparable enumeration approaches: one has lower complexity when the number of returned results is small, the other when the number is very large. We theoretically and empirically demonstrate the superiority of our techniques over batch algorithms, which produce the full result and then sort it. Our technique is not only faster for returning the first few results, but on some inputs beats the batch algorithm even when all results are produced.",675
590,Data Management,Cheng Tan,"September 16th, 2024",Scheduling Splittable Jobs on Configurable Machines,https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22," Matthew Casey, Rajmohan Rajaraman, David Stalfa, Cheng Tan . (2024). Scheduling Splittable Jobs on Configurable Machines APPROX/RANDOM, 22:1-22:20. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22","Abstract Motivated by modern architectures allowing for the partitioning of a GPU into hardware separated instances, we initiate the study of scheduling splittable jobs on configurable machines. We consider machines that can be configured into smaller instances, which we call blocks, in multiple ways, each of which is referred to as a configuration. We introduce the Configurable Machine Scheduling (cms) problem, where we are given n jobs and a set C of configurations. A schedule consists of a set of machines, each assigned some configuration in C with each block in the configuration assigned to process one job. The amount of a job‚Äôs demand that is satisfied by a block is given by an arbitrary function of the job and block. The objective is to construct a schedule using as few machines as possible. We provide a tight logarithmic factor approximation algorithm for this problem in the general setting, a factor (3 + Œµ) approximation algorithm for arbitrary Œµ > 0 when there are O(1) input configurations, and a polynomial time approximation scheme when both the number and size of configurations are O(1). Finally, we utilize a technique for finding conic integer combinations in fixed dimension to develop an optimal polynomial time algorithm in the case with O(1) jobs, O(1) blocks, and every configuration up to a given size.",676
591,Data Management,Cheng Tan,"July 10th, 2023",Encrypted Databases Made Secure Yet Maintainable,https://www.usenix.org/conference/osdi23/presentation/li-mingyu," Mingyu Li, Xuyang Zhao, Le Chen, Cheng Tan , Huorong Li, Sheng Wang , Zeyu Mi, Yubin Xia, Feifei Li , Haibo Chen . (2023). Encrypted Databases Made Secure Yet Maintainable OSDI, 117-133. https://www.usenix.org/conference/osdi23/presentation/li-mingyu",HEDB uses a dual-mode EDB design based on our analysis of DBA maintenance tasks. Execution Mode handles user queries by isolating DBAs from operators to prevent smuggle attacks. Maintenance Mode enables DBMS maintenance and operator troubleshooting through authenticated replay and anonymized replay.,677
592,Data Management,Cheng Tan,"January 30th, 2023",NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers,https://doi.org/10.1145/3575693.3575707," Jiawei Liu , Jinkun Lin, Fabian Ruffy, Cheng Tan , Jinyang Li , Aurojit Panda, Lingming Zhang . (2023). NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers ASPLOS (2), 530-543. https://doi.org/10.1145/3575693.3575707","Deep-learning (DL) compilers such as TVM and TensorRT are increasingly being used to optimize deep neural network (DNN) models to meet performance, resource utilization and other requirements. Bugs in these compilers can result in models whose semantics differ from the original ones, producing incorrect results that corrupt the correctness of downstream applications. However, finding bugs in these compilers is challenging due to their complexity. In this work, we propose a new fuzz testing approach for finding bugs in deep-learning compilers. Our core approach consists of (i) generating diverse yet valid DNN test models that can exercise a large part of the compiler's transformation logic using light-weight operator specifications; (ii) performing gradient-based search to find model inputs that avoid any floating-point exceptional values during model execution, reducing the chance of missed bugs or false alarms; and (iii) using differential testing to identify bugs. We implemented this approach in NNSmith which has found 72 new bugs for TVM, TensorRT, ONNXRuntime, and PyTorch to date. Of these 58 have been confirmed and 51 have been fixed by their respective project maintainers.",678
593,Data Management,Cheng Tan,"August 24th, 2021",Building verified neural networks with specifications for systems,https://dl.acm.org/doi/10.1145/3476886.3477508," Cheng Tan, Yibo Zhu, and Chuanxiong Guo. 2021. Building verified neural networks with specifications for systems. Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on Systems. Association for Computing Machinery, New York, NY, USA, 42‚Äì47. DOI:https://doi.org/10.1145/3476886.3477508","Neural networks (NNs) are beneficial to many services, and we believe systems‚Äîsuch as OSes, databases, networked systems‚Äîare not an exception. But applying NNs in these critical systems is challenging: people have to risk getting unexpected outcomes from NNs because NN behaviors are not well-defined. To tame these undefined behaviors, we introduce a framework ouroboros, which builds verified NNs that follow user-defined specifications. These specifications comprise input and output constraints which characterize the behaviors of a NN. We do a case study on database learned indexes to demonstrate that training verified NN models is possible. Though many challenges remain, ouroboros enables us, for the first time, to apply NNs in critical systems with _confidence_.",679
594,Data Management,Cheng Tan,"July 1st, 2021",Bringing Decentralized Search to Decentralized Services,https://www.usenix.org/conference/osdi21/presentation/li," Mingyu Li and Jinhao Zhu and Tianxu Zhang and Cheng Tan and Yubin Xia and Sebastian Angel and Haibo Chen, ""Bringing Decentralized Search to Decentralized Services"", 15th {USENIX} Symposium on Operating Systems Design and Implementation , 2021, i USENIX Association",DeSearch uses trusted hardware to build a network of workers that execute a pipeline of small search engine tasks. DeSearch then introduces a witness mechanism to make sure the completed tasks can be reused across different pipelines. We implement DeSearch for two existing decentralized services that handle over 80 million records and 240 GBs of data. We show that DeSearch can scale horizontally with the number of workers and can process 128 million search queries per day.,680
595,Data Management,Cheng Tan,"November 4th, 2020",Cobra: Making transactional key-value stores verifiably serializable,https://dl.acm.org/doi/abs/10.5555/3488766.3488770," Cheng Tan, Changgeng Zhao, Shuai Mu, and Michael Walfish. 2020. COBRA: making transactional key-value stores verifiably serializable. Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation. Article 4, 63‚Äì80.","Today's cloud databases offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud databases are complicated black boxes, running in a different administrative domain from their clients. Thus, clients might like to know whether the databases are meeting their contract. To that end, we introduce cobra; cobra applies to transactional key-value stores. It is the first system that combines (a) black-box checking, of (b) serializability, while (c) scaling to real-world online transactional processing workloads. The core technical challenge is that the underlying search problem is computationally expensive. COBRA tames that problem by starting with a suitable SMT solver. COBRA then introduces several new techniques, including a new encoding of the validity condition; hardware acceleration to prune inputs to the solver; and a transaction segmentation mechanism that enables scaling and garbage collection. Cobra imposes modest overhead on clients, improves over baselines by 10√ó in verification cost, and (unlike the baselines) supports continuous verification. Our artifact can handle 2000 transactions/sec, equivalent to 170M/day.",681
596,Data Management,Cheng Tan,"December 19th, 2019",Detecting Incorrect Behavior of Cloud Databases as an Outsider,http://arxiv.org/abs/1912.09018," Cheng Tan , Changgeng Zhao, Shuai Mu , Michael Walfish. (2019). Detecting Incorrect Behavior of Cloud Databases as an Outsider CoRR, abs/1912.09018. http://arxiv.org/abs/1912.09018","Cloud DBs offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud DBs are complicated black boxes, running in a different administrative domain from their clients; thus, clients might like to know whether the DBs are meeting their contract. A core difficulty is that the underlying problem here, namely verifying serializability, is NP-complete. Nevertheless, we hypothesize that on real-world workloads, verifying serializability is tractable, and we treat the question as a systems problem, for the first time. We build Cobra, which tames the underlying search problem by blending a new encoding of the problem, hardware acceleration, and a careful choice of a suitable SMT solver. cobra also introduces a technique to address the challenge of garbage collection in this context. cobra improves over natural baselines by at least 10x in the problem size it can handle, while imposing modest overhead on clients.",682
597,Data Management,Cheng Tan,"February 26th, 2019",Netbouncer: Active device and link failure localization in data center networks,https://dl.acm.org/doi/10.5555/3323234.3323283," Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng, Dongming Bi, and Dong Xiang. 2019. Netbouncer: active device and link failure localization in data center networks. In Proceedings of the 16th USENIX Conference on Networked Systems Design and Implementation (NSDI'19). USENIX Association, USA, 599‚Äì613.","The availability of data center services is jeopardized by various network incidents. One of the biggest challenges for network incident handling is to accurately localize the failures, among millions of servers and tens of thousands of network devices. In this paper, we propose NetBouncer, a failure localization system that leverages the IP-in-IP technique to actively probe paths in a data center network. NetBouncer provides a complete failure localization framework which is capable of detecting both device and link failures. It further introduces an algorithm for high accuracy link failure inference that is resilient to real-world data inconsistency by integrating both our troubleshooting domain knowledge and machine learning techniques. NetBouncer has been deployed in Microsoft Azure's data centers for three years. And in practice, it produced no false positives and only a few false negatives so far.",683
598,Data Management,Cheng Tan,"January 1st, 2019",Taming Distrust in the Decentralized Internet with PIXIU,http://arxiv.org/abs/1901.06095," Yubin Xia, Qingyuan Liu, Cheng Tan , Jing Leng, Shangning Xu, Binyu Zang, Haibo Chen . (2019). Taming Distrust in the Decentralized Internet with PIXIU CoRR, abs/1901.06095. http://arxiv.org/abs/1901.06095","Decentralized Internet is booming. People are fascinated by its promise that users can truly own their data. However, in a decentralized Internet, completing a task usually involves multiple nodes with mutual distrust. Such distrust might eventually become a major obstacle for the growth of the decentralized Internet. In this paper, we analyze the distrust using a simple model and highlight the properties required to faithfully accomplish one task in a decentralized Internet. We also introduce our draft solution -- PIXIU, a framework to mitigate the distrust among different nodes. In PIXIU, we design and utilize trust-{\lambda} and decentralized executor to achieve the above-needed properties.",684
599,Data Management,Cheng Tan,"October 14th, 2017","The efficient server audit problem, deduplicated re-execution, and the web",https://dl.acm.org/doi/10.1145/3132747.3132760," Cheng Tan, Lingfan Yu, Joshua B. Leners, and Michael Walfish. 2017. The Efficient Server Audit Problem, Deduplicated Re-execution, and the Web. In Proceedings of the 26th Symposium on Operating Systems Principles (SOSP '17). Association for Computing Machinery, New York, NY, USA, 546‚Äì564. DOI:https://doi.org/10.1145/3132747.3132760","You put a program on a concurrent server, but you don't trust the server; later, you get a trace of the actual requests that the server received from its clients and the responses that it delivered. You separately get logs from the server; these are untrusted. How can you use the logs to efficiently verify that the responses were derived from running the program on the requests? This is the Efficient Server Audit Problem, which abstracts real-world scenarios, including running a web application on an untrusted provider. We give a solution based on several new techniques, including simultaneous replay and efficient verification of concurrent executions. We implement the solution for PHP web applications. For several applications, our verifier achieves 5.6-10.9x speedup versus simply re-executing, with <10% overhead for the server.",685
600,Data Science,Javed Aslam,"October 30th, 2024","Don‚Äôt Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification",https://doi.org/10.48550/arXiv.2410.23066," Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu. (2024). Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification CoRR, abs/2410.23066. https://doi.org/10.48550/arXiv.2410.23066","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely heavily on multi-label attention layers to focus on key tokens in input text, but obtaining optimal attention weights is challenging and resource-intensive. To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses existing state-of-the-art methods across all metrics on mimicfull, mimicfifty, mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot scenarios, outperforming previous models specifically designed for few-shot scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36 percentage points on mimicfew, demonstrating its superior capability in handling rare codes. PLANT also shows remarkable data efficiency in few-shot scenarios, achieving precision comparable to traditional models with significantly less data. These results are achieved through key technical innovations: leveraging a pretrained Learning-to-Rank model as the planted attention layer, integrating mutual-information gain to enhance attention, introducing an inattention mechanism, and implementing a stateful-decoder to maintain context. Comprehensive ablation studies validate the importance of these contributions in realizing the performance gains.",686
601,Data Science,Javed Aslam,"August 2nd, 2024",Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy,https://doi.org/10.1145/3626324," Maryam Aziz, Jesse Anderton, Kevin G. Jamieson, Alice Wang, Hugues Bouchard, Javed A. Aslam. (2025). Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy Trans. Recomm. Syst., 3, 4:1-4:22. https://doi.org/10.1145/3626324","Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely armed pure-exploration setting. We demonstrate that our algorithm is well suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches. Finally, we study a setting in which users are more likely to stream more-streamed podcasts independent of their general appeal and find that our proposed algorithm is robust to this type of popularity bias.",687
602,Data Science,Javed Aslam,"January 1st, 2021",Improving Query Graph Generation for Complex Question Answering over Knowledge Base,https://doi.org/10.18653/v1/2021.emnlp-main.346," Kechen Qin, Cheng Li, Virgil Pavlu, Javed A. Aslam. (2021). Improving Query Graph Generation for Complex Question Answering over Knowledge Base EMNLP (1), 4201-4207. https://doi.org/10.18653/v1/2021.emnlp-main.346","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Most of the existing Knowledge-based Question Answering (KBQA) methods first learn to map the given question to a query graph, and then convert the graph to an executable query to find the answer. The query graph is typically expanded progressively from the topic entity based on a sequence prediction model. In this paper, we propose a new solution to query graph generation that works in the opposite manner: we start with the entire knowledge base and gradually shrink it to the desired query graph. This approach improves both the efficiency and the accuracy of query graph generation, especially for complex multi-hop questions. Experimental results show that our method achieves state-of-the-art performance on ComplexWebQuestion (CWQ) dataset.",688
603,Data Science,Javed Aslam,"June 23rd, 2019",Adapting RNN Sequence Prediction Model to Multi-label Set Prediction,https://www.aclweb.org/anthology/N19-1321/," Conference Proceedings Adapting RNN Sequence Prediction Model to Multi-label Set Prediction. Qin, Kechen; Li, Cheng; Pavlu, Virgil; Aslam, Javed. Proceedings of the 2019 NAACL-HLT, Volume 1 (Long and Short Papers), 2019 8 jun I Association for Computational Linguistics, Minneapolis, Minnesota","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present an adaptation of RNN sequence models to the problem of multi-label classification for text, where the target is a set of labels, not a sequence. Previous such RNN models define probabilities for sequences but not for sets; attempts to obtain a set probability are after-thoughts of the network design, including pre-specifying the label order, or relating the sequence probability to the set probability in ad hoc ways. Our formulation is derived from a principled notion of set probability, as the sum of probabilities of corresponding permutation sequences for the set. We provide a new training objective that maximizes this set probability, and a new prediction objective that finds the most probable set on a test document. These new objectives are theoretically appealing because they give the RNN model freedom to discover the best label order, which often is the natural one (but different among documents). We develop efficient procedures to tackle the computation difficulties involved in training and prediction. Experiments on benchmark datasets demonstrate that we outperform state-of-the-art methods for this task.",689
604,Data Science,Javed Aslam,"June 15th, 2019",Scaling Up Ordinal Embedding: A Landmark Approach,http://proceedings.mlr.press/v97/anderton19a.html," Anderton, J. & Aslam, J.. (2019). Scaling Up Ordinal Embedding: A Landmark Approach. Proceedings of the 36th International Conference on Machine Learning, in PMLR 97:282-290","Ordinal Embedding is the problem of placing n objects into R^d to satisfy constraints like ""object a is closer to b than to c."" It can accommodate data that embeddings from features or distances cannot, but is a more difficult problem. We propose a novel landmark-based method as a partial solution. At small to medium scales, we present a novel combination of existing methods with some new theoretical justification. For very large values of n optimizing over an entire embedding breaks down, so we propose a novel method which first embeds a subset of m << n objects and then embeds the remaining objects independently and in parallel. We prove a distance error bound for our method in terms of m and that it has O(dn log m) time complexity, and show empirically that it is able to produce high quality embeddings in a fraction of the time needed for any published method.",690
605,Data Science,Javed Aslam,"March 24th, 2018",Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence,https://doi.org/10.48550/arXiv.1803.04665," Aziz, M., Anderton, J., Kaufmann, E. and Aslam, J.. (2018). ""Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence."" Proceedings of Algorithmic Learning Theory, in PMLR 83:3-24. DOI: 0.48550/arXiv.1803.04665","We consider the problem of near-optimal arm identification in the fixed confidence setting of the infinitely armed bandit problem when nothing is known about the arm reservoir distribution. We (1) introduce a PAC-like framework within which to derive and cast results; (2) derive a sample complexity lower bound for near-optimal arm identification; (3) propose an algorithm that identifies a nearly-optimal arm with high probability and derive an upper bound on its sample complexity which is within a log factor of our lower bound; and (4) discuss whether our log^2(1/delta) dependence is inescapable for ""two-phase"" (select arms first, identify the best later) algorithms in the infinite setting. This work permits the application of bandit models to a broader class of problems where fewer assumptions hold.",691
606,Data Science,Javed Aslam,"January 17th, 2018",A Pipeline for Optimizing F1-Measure in Multi-label Text Classification,https://ieeexplore.ieee.org/abstract/document/8614173," B. Wang, C. Li, V. Pavlu, J. Aslam, ""A Pipeline for Optimizing F1-Measure in Multi-label Text Classification ,"" ICMLA, 2018.",Multi-label text classification is the machine learning task wherein each document is tagged with multiple labels. This task is uniquely challenging due to high dimensional features and correlated labels. Such text classifiers need to be regularized to prevent severe over-fitting in the high dimensional space. We propose a new pipeline which takes such algorithms and improves their F1-performance with careful training regularization and a new prediction strategy. We further demonstrate that support inference acts as a strong regularizer on the label prediction structure.,692
607,Data Science,Javed Aslam,"October 23rd, 2015",Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model,https://doi.org/10.1145/2806416.2806492," P. Metrikov, V. Pavlu, J. A. Aslam. ""Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model"". Proceedings of the 24th ACM Conference on Information and Knowledge Management, Melbourne, Australia (2015). DOI: 10.1145/2806416.2806492","Existing approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors. A document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.",693
608,Data Science,Javed Aslam,"September 29th, 2013",A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments,http://dx.doi.org/10.1145/2499178.2499198," Pavel Metrikov, Jie Wu, Jesse Anderton, Virgil Pavlu, and Javed A. Aslam. 2013. A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments. In Proceedings of the 2013 Conference on the Theory of Information Retrieval (ICTIR '13). Association for Computing Machinery, New York, NY, USA, 133‚Äì134. https://doi.org/10.1145/2499178.2499198","We consider noisy crowdsourced assessments and their impact on learning-to-rank algorithms. Starting with EM-weighted assessments, we modify LambdaMART in order to use smoothed probabilistic preferences over pairs of documents, directly as input to the ranking algorithm.",694
609,Data Science,Javed Aslam,"March 24th, 2013",Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency,http://link.springer.com/chapter/10.1007/978-3-642-36973-5_78," P. Metrikov, V. Pavlu, J. A. Aslam, ""Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency"", Advances in Information Retrieval: 35th European Conference on IR Research (ECIR), Moscow, Russia (2013).  Best Poster Paper Award","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",695
610,Data Science,Ricardo Baeza-Yates,"February 17th, 2025",A Comparison of Human and Machine Learning Errors in Face Recognition,https://doi.org/10.48550/arXiv.2502.11337," Marina Est√©vez-Almenzar, Ricardo Baeza-Yates, Carlos Castillo . (2025). A Comparison of Human and Machine Learning Errors in Face Recognition CoRR, abs/2502.11337. https://doi.org/10.48550/arXiv.2502.11337","Machine learning applications in high-stakes scenarios should always operate under human oversight. Developing an optimal combination of human and machine intelligence requires an understanding of their complementarities, particularly regarding the similarities and differences in the way they make mistakes. We perform extensive experiments in the area of face recognition and compare two automated face recognition systems against human annotators through a demographically balanced user study. Our research uncovers important ways in which machine learning errors and human errors differ from each other, and suggests potential strategies in which human-machine collaboration can improve accuracy in face recognition.",696
611,Data Science,Ricardo Baeza-Yates,"February 7th, 2025",Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning,https://doi.org/10.1109/ACCESS.2025.3539719," Maria Rauschenberger, Ricardo Baeza-Yates, Luz Rello. (2025). Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning IEEE Access, 13, 29541-29553. https://doi.org/10.1109/ACCESS.2025.3539719",Dyslexia is a type of neuro-developmental disorder that affects the ability to learn how to read and write. We present an approach for screening dyslexic using language-independent games in combination with machine learning models. Our results open the possibility of inexpensive online early screening of dyslexy for young children using non-linguistic elements. The study was published in IEEE Access ( Volume: 13 ) Page(s): 29541 - 29553 Date of Publication: 07 February 2025 Electronic ISSN: 2169-3536. DOI: 10.1109/ACCESS.2025.3539719 Publisher: IEEE Funding Agency.,697
612,Data Science,Ricardo Baeza-Yates,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",698
613,Data Science,Ricardo Baeza-Yates,"September 21st, 2024",AI content detection in the emerging information ecosystem: new obligations for media and tech companies,https://doi.org/10.1007/s10676-024-09795-1," Alistair Knott, Dino Pedreschi, Toshiya Jitsuzumi, Susan Leavy, David M. Eyers, Tapabrata Chakraborti, Andrew Trotman, Sundar Sundareswaran, Ricardo Baeza-Yates, Przemyslaw Biecek, Adrian Weller, Paul D. Teal, Subhadip Basu, Mehmet Haklidir, Virginia Morini, Stuart Russell , Yoshua Bengio. (2024). AI content detection in the emerging information ecosystem: new obligations for media and tech companies Ethics Inf. Technol., 26, 63. https://doi.org/10.1007/s10676-024-09795-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",699
614,Data Science,Ricardo Baeza-Yates,"August 4th, 2023",Fair Multilingual Vandalism Detection System for Wikipedia,https://doi.org/10.1145/3580305.3599823," Mykola Trokhymovych, Muniza Aslam, Ai-Jou Chou, Ricardo Baeza-Yates, Diego S√°ez-Trumper. (2023). Fair Multilingual Vandalism Detection System for Wikipedia KDD, 4981-4990. https://doi.org/10.1145/3580305.3599823","This paper presents a novel design of the system aimed at supporting the Wikipedia community in addressing vandalism on the platform. To achieve this, we collected a massive dataset of 47 languages, and applied advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data. The performance of the system was evaluated through comparison with the one used in production in Wikipedia, known as ORES. Our research results in a significant increase in the number of languages covered, making Wikipedia patrolling more efficient to a wider range of communities. Furthermore, our model outperforms ORES, ensuring that the results provided are not only more accurate but also less biased against certain groups of contributors.",700
615,Data Science,Ricardo Baeza-Yates,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",701
616,Data Science,Ricardo Baeza-Yates,"May 14th, 2018",Bias on the Web,https://dl.acm.org/citation.cfm?id=2908135," Ricardo Baeza-Yates. Bias on the Web. Communications of ACM, June 2018.","The Web is the largest public big data repository that humankind has created. In this overwhelming data ocean we need to be aware of the quality of data extracted from it. One important quality issue is data bias, which appears in different forms. These biases affect the (machine learning) algorithms that we design to improve the user experience. This problem is further exacerbated by biases that are added by these algorithms, especially in the context of recommendation and personalization systems. We give several examples, stressing the importance of the user context to avoid these biases.",702
617,Data Science,Ricardo Baeza-Yates,"December 14th, 2017",Quality-efficiency trade-offs in machine learning for text processing,https://arxiv.org/abs/1711.02295," Ricardo A. Baeza-Yates, Zeinab Liaghat:Quality-efficiency trade-offs in machine learning for text processing. IEEE BigData 2017: 897-904.",Are quality gains worth it when the rate of data processing diminishes? Can we trade quality for time efficiency and recover the quality loss by just being able to process more data? We propose a performance trade-off framework and apply it to three important text processing problems. We find that the results do not change significantly and that most of the time the best algorithms is the fastest.,703
618,Data Science,Albert-L√°szl√≥ Barab√°si,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",704
619,Data Science,Albert-L√°szl√≥ Barab√°si,"October 30th, 2023",iGEM: a model system for team science and innovation,https://doi.org/10.48550/arXiv.2310.19858," Marc Santolini, Leo Blondel, Megan J. Palmer, Robert N. Ward, Rathin Jeyaram, Kathryn R. Brink, Abhijeet Krishna, Albert-L√°szl√≥ Barab√°si. (2023). iGEM: a model system for team science and innovation CoRR, abs/2310.19858. https://doi.org/10.48550/arXiv.2310.19858","Teams are a primary source of innovation in science and technology. Rather than examining the lone genius, scholarly and policy attention has shifted to understanding how team interactions produce new and useful ideas. Yet the organizational roots of innovation remain unclear, in part because of the limitations of current data. This paper introduces the international Genetically Engineered Machine (iGEM) competition, a model system for studying team science and innovation. By combining digital laboratory notebooks with performance data from 2,406 teams over multiple years of participation, we reveal shared dynamical and organizational patterns across teams and identify features associated with team performance and success. This dataset makes visible organizational behavior that is typically hidden, and thus understudied, creating new opportunities for the science of science and innovation.",705
620,Data Science,Albert-L√°szl√≥ Barab√°si,"October 24th, 2023",Hidden Citations Obscure True Impact in Science,https://doi.org/10.48550/arXiv.2310.16181," Xiangyi Meng, Onur Varol, Albert-L√°szl√≥ Barab√°si. (2023). Hidden Citations Obscure True Impact in Science CoRR, abs/2310.16181. https://doi.org/10.48550/arXiv.2310.16181","References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate that bibliometric measures offer a limited perspective on quantifying the true impact of a discovery, raising the need to extract knowledge from the full text of the scientific corpus.",706
621,Data Science,Albert-L√°szl√≥ Barab√°si,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",707
622,Data Science,Albert-L√°szl√≥ Barab√°si,"January 25th, 2023",The Clinical Trials Puzzle: How Network Effects Limit Drug Discovery,https://doi.org/10.48550/arXiv.2301.10709," Kishore Vasan, Deisy Morselli Gysi, Albert-L√°szl√≥ Barab√°si. (2023). The Clinical Trials Puzzle: How Network Effects Limit Drug Discovery CoRR, abs/2301.10709. https://doi.org/10.48550/arXiv.2301.10709","The depth of knowledge offered by post-genomic medicine has carried the promise of new drugs, and cures for multiple diseases. To explore the degree to which this capability has materialized, we extract meta-data from 356,403 clinical trials spanning four decades, aiming to offer mechanistic insights into the innovation practices in drug discovery. We find that convention dominates over innovation, as over 96% of the recorded trials focus on previously tested drug targets, and the tested drugs target only 12% of the human interactome. If current patterns persist, it would take 170 years to target all druggable proteins. We uncover two network-based fundamental mechanisms that currently limit target discovery: preferential attachment, leading to the repeated exploration of previously targeted proteins; and local network effects, limiting exploration to proteins interacting with highly explored proteins. We build on these insights to develop a quantitative network-based model of drug discovery. We demonstrate that the model is able to accurately recreate the exploration patterns observed in clinical trials. Most importantly, we show that a network-based search strategy can widen the scope of drug discovery by guiding exploration to novel proteins that are part of under explored regions in the human interactome.",708
623,Data Science,Albert-L√°szl√≥ Barab√°si,"June 9th, 2022",Mapping Philanthropic Support of Science,https://doi.org/10.48550/arXiv.2206.10661," Louis M. Shekhtman, Alexander J. Gates, Albert-L√°szl√≥ Barab√°si. (2022). Mapping Philanthropic Support of Science CoRR, abs/2206.10661. https://doi.org/10.48550/arXiv.2206.10661","While philanthropic support for science has increased in the past decade, there is limited quantitative knowledge about the patterns that characterize it and the mechanisms that drive its distribution. Here, we map philanthropic funding to universities and research institutions based on IRS tax forms from 685,397 non-profit organizations. We identify nearly one million grants supporting institutions involved in science and higher education, finding that in volume and scope, philanthropic funding has grown to become comparable to federal research funding. Yet, distinct from government support, philanthropic funders tend to focus locally, indicating that criteria beyond research excellence play an important role in funding decisions. We also show evidence of persistence, i.e., once a grant-giving relationship begins, it tends to continue in time. Finally, we leverage the bipartite network of supporters and recipients to help us demonstrate the predictive power of the underlying network in foreseeing future funder-recipient relationships. The developed toolset could offer funding recommendations to organizations and help funders diversify their portfolio. We discuss the policy implications of our findings for philanthropic funders, individual researchers, and quantitative understanding of philanthropy.",709
624,Data Science,Albert-L√°szl√≥ Barab√°si,"December 25th, 2021",AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands,https://arxiv.org/abs/2112.13168," Ayan Chatterjee, Omair Shafi Ahmed, Robin Walters, Zohair Shafi, Deisy Morselli Gysi, Rose Yu, Tina Eliassi-Rad, Albert-L√°szl√≥ Barab√°si, Giulia Menichetti. (2021). AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands CoRR, abs/2112.13168. https://arxiv.org/abs/2112.13168","Identifying novel drug-target interactions (DTI) is a critical and rate limiting step in drug discovery. While deep learning models have been proposed to accelerate the identification process, we show that state-of-the-art models fail to generalize to novel (i.e., never-before-seen) structures. We first unveil the mechanisms responsible for this shortcoming, demonstrating how models rely on shortcuts that leverage the topology of the protein-ligand bipartite network, rather than learning the node features. Then, we introduce AI-Bind, a pipeline that combines network-based sampling strategies with unsupervised pre-training, allowing us to limit the annotation imbalance and improve binding predictions for novel proteins and ligands. We illustrate the value of AI-Bind by predicting drugs and natural compounds with binding affinity to SARS-CoV-2 viral proteins and the associated human proteins. We also validate these predictions via docking simulations and comparison with recent experimental evidence, and step up the process of interpreting machine learning prediction of protein-ligand binding by identifying potential active binding sites on the amino acid sequence. Overall, AI-Bind offers a powerful high-throughput approach to identify drug-target combinations, with the potential of becoming a powerful tool in drug discovery.",710
625,Data Science,Albert-L√°szl√≥ Barab√°si,"January 1st, 2019",Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology,https://proceedings.neurips.cc/paper/2019/hash/73bf6c41e241e28b89d0fb9e0c82f9ce-Abstract.html," Nima Dehmamy, Albert-L√°szl√≥ Barab√°si, Rose Yu. (2019). Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology NeurIPS, 15387-15397. https://proceedings.neurips.cc/paper/2019/hash/73bf6c41e241e28b89d0fb9e0c82f9ce-Abstract.html","Part of Advances in Neural Information Processing Systems 32 (NeurIPS 2019) Nima Dehmamy, Albert-Laszlo Barabasi, Rose Yu To deepen our understanding of graph neural networks, we investigate the representation power of Graph Convolutional Networks (GCN) through the looking glass of graph moments, a key property of graph topology encoding path of various lengths. We find that GCNs are rather restrictive in learning graph moments. Without careful design, GCNs can fail miserably even with multiple layers and nonlinear activation functions. We analyze theoretically the expressiveness of GCNs, arriving at a modular GCN design, using different propagation rules. Our modular design is capable of distinguishing graphs from different graph generation models for surprisingly small graphs, a notoriously difficult problem in network science. Our investigation suggests that, depth is much more influential than width and deeper GCNs are more capable of learning higher order graph moments. Additionally, combining GCN modules with different propagation rules is critical to the representation power of GCNs.",711
626,Data Science,Usama Fayyad,"June 30th, 2020",Toward Foundations for Data Science and Analytics: A Knowledge Framework for Professional Standards,https://hdsr.mitpress.mit.edu/pub/6wx0qmkl/release/3?readingCollection=70ac5c46," ‚ÄúToward Foundations for Data Science and Analytics: A Knowledge Framework for Professional Standards‚Äù, U. Fayyad and H. Hamutcu. Harvard Data Science Review, vol. 2, issue 2, June 2020.",Abstract,712
627,Data Science,Usama Fayyad,"August 1st, 2002",Evolving Data Into Mining Solutions For Insights,https://cacm.acm.org/magazines/2002/8/6991-evolving-data-into-mining-solutions-for-insights," ‚ÄúEvolving data into mining solutions for insights‚Äù, U.Fayyad and R. Uthurusamy, Communications of the ACM, vol. 45, issue 8, p. 28-31, August 2002.","Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Membership in ACM includes a subscription to Communications of the ACM (CACM), the computing industry's most trusted source for staying connected to the world of advanced computing. The capacity of digital data storage worldwide has doubled every nine months for at least a decade, at twice the rate predicted by Moore‚Äôs Law for the growth of computing power during the same period [ 5 ]. This less familiar but noteworthy phenomenon, which we call Storage Law, is among the reasons for the increasing importance and rapid growth of the field of data mining. The aggressive rate of growth of disk storage and the gap between Moore‚Äôs Law and Storage Law growth trends represents a very interesting pattern in the state of technology evolution. Our ability to capture and store data has far outpaced our ability to process and utilize it. This growing challenge has produced a phenomenon we call the data tombs, or data stores that are effectively write-only; data is deposited to merely rest in peace, since in all likelihood it will never be accessed again.",713
628,Data Science,Miguel Fuentes-Cabrera,"May 3rd, 2023",Predicting partner fitness based on spatial structuring in a light-driven microbial community,https://doi.org/10.1371/journal.pcbi.1011045," Jonathan K. Sakkos, Mar√≠a Santos-Merino, Emmanuel J. Kokarakis, Bowen Li , Miguel Fuentes-Cabrera, Paolo Zuliani, Daniel C. Ducat. (2023). Predicting partner fitness based on spatial structuring in a light-driven microbial community PLoS Comput. Biol., 19. https://doi.org/10.1371/journal.pcbi.1011045","Microbial communities have vital roles in systems essential to human health and agriculture, such as gut and soil microbiomes. To better understand how these microbes interact with each other, we want to monitor the exchange of metabolites and the locations of the microbes. We developed a computerized model of a synthetic microbial community of two bacteria, one which performs photosynthesis and supplies sugar and another which consumes the sugar for growth. We showed that the relative level of sugar secretion regulates not only the steady-state support for the consumer partner‚Äôs growth, but also how the community changes with time. We anticipate that the synergy between experimental and computational approaches will improve our ability to design microbial communities with new functions.",714
629,Data Science,Miguel Fuentes-Cabrera,"April 5th, 2023",Inferring assembly-curving trends of bacterial micro-compartment shell hexamers from crystal structure arrangements,https://doi.org/10.1371/journal.pcbi.1011038," Luis F. Garcia-Alles, Miguel Fuentes-Cabrera, Gilles Truan, David Reguera. (2023). Inferring assembly-curving trends of bacterial micro-compartment shell hexamers from crystal structure arrangements PLoS Comput. Biol., 19. https://doi.org/10.1371/journal.pcbi.1011038","BMC-encapsulated enzymatic activities are segregated from other cell contents by means of semipermeable shells. Understanding how such complex objects form is essential, say the authors. They claim that only one of the two possible pathways is ready to curve. They also pinpointed a residue that seems to be pivotal in triggering bending. The study was published in the journal Cell, which was published by the University of California, San Diego, and the journal of the American Chemical Society, which published the study.",715
630,Data Science,Miguel Fuentes-Cabrera,"May 12th, 2022",Performing Video Frame Prediction of Microbial Growth with a Recurrent Neural Network,https://doi.org/10.48550/arXiv.2205.05810," Connor Robertson, Jared L. Wilmoth, Scott Retterer, Miguel Fuentes-Cabrera. (2022). Performing Video Frame Prediction of Microbial Growth with a Recurrent Neural Network CoRR, abs/2205.05810. https://doi.org/10.48550/arXiv.2205.05810","A Recurrent Neural Network (RNN) was used to perform video frame prediction of microbial growth for a population of two mutants of Pseudomonas aeruginosa. The RNN was trained on videos of 20 frames that were acquired using fluorescence microscopy and microfluidics. The network predicted the last 10 frames of each video, and the accuracy's of the predictions was assessed by comparing raw images, population curves, and the number and size of individual colonies. Overall, we found the predictions to be accurate using this approach. The implications this result has on designing autonomous experiments in microbiology, and the steps that can be taken to make the predictions even more accurate, are discussed.",716
631,Data Science,Miguel Fuentes-Cabrera,"February 22nd, 2020",Self-Propulsion Enhances Polymerization,https://doi.org/10.3390/e22020251," Maximino Aldana, Miguel Fuentes-Cabrera, Mart√≠n Zumaya. (2020). Self-Propulsion Enhances Polymerization Entropy, 22, 251. https://doi.org/10.3390/e22020251","Self-Propulsion Enhances Polymerization. The assembly of active molecules might have promoted the formation of large pre-biotic polymers that could be the precursors of the informational polymers we observe nowadays. Numerical simulations clearly show that self-propulsion considerably speeds up the assembly of polymers, somewhat in agreement with previous related studies. We conclude by discussing the differences between self-Assembly and self-Organization and discuss the role of self-propelled particles in the development of the self-organized system. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. We show how a model that borrows some of these ideas can be used to study polymer formation from a collection of self-propelled monomers. We will not attempt to provide a theoretical description of the active self-assembly process presented here. Instead, we will present only numerical results obtained through molecular dynamics simulations. The motivation for studying the channel system is based on the hypothesis that the formation of organic macro-molecules relevant to the origin of life may have occurred in micro-channels formed either in meteorites [ 38 , 39 , 40 , 41 ] or in confined micro-spaces of marine vent chimneys in which molecules are driven by thermal gradients. The results show that the external input of energy, via self-propulsion or other sources (such as ATP), can considerably enhance the assembly of structures. Propulsion considerably improves theassembly of molecules as compared to spontaneous self-assembly. At high temperatures, mostly monomers and dimers coexist, whereas longer polymer appear in negligible amounts. At low temperatures, the average polymer length does not reach a maximum at any value of the self-propulsion force. This is due to the aggregation of molecules and polymers next to the repulsive channel walls, which decreases the rate at which the chains grow. In the high-temperature regime, the system reaches a stationary state within the simulation time. In every case reported in Figure 4 , it can be seen that increasing ùêπ sp F sp increases the growth rate of the polymer chains. The tail of the distribution reveals that much longer polymers are created. The narrower the channel, the less self- Propulsion force is needed to create long polymers. This effect clearly becomes stronger for narrow channels. The aggregation and jammingof active particles next to the confining Walls has been observed in both numerical simulations and experiments. Self-propulsion could have been an important mechanism for the formation of pre-biotic structures or the synthesis of nanometric structures. The model we have introduced takes into account the full geometry of the molecules by discretizing them into subunits. All authors have read and agree to the published version of the manuscript. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; or in the decision to publish the results. This article includes a review of attraction and repulsion models of aggregation. The study of active matter has the potential to provide new insights into the nature of the universe. The author‚Äôs conclusion is that active matter is a form of ‚Äòactive matter‚Äô and should be considered as a type of ‚Äúactive‚Äù matter, rather than as a ‚Äònon-active‚Äô matter. In silico synthesis of microgel particles. The role of clay minerals in chemical evolution and the origins of life. In Clay Minerals in Nature; Valaskova, M., Martynkov√°, G.S., Eds.; IntechOpen: London, UK, 2012; Chapter 10; pp. 191‚Äì208. Figure 6 shows the average chain length in a channel with semi-periodic boundary conditions. Almost all the points fall above the identity line, which means that the polymers formed in the channel are considerably longer than the ones observed in the bulk. All the results presented in this figure were computed at constant temperature ùëá = 0.1 T =0.1 . The histograms also show the probability of the distribution P ( L ) in order to better appreciate the existence of long polymers. The ensemble averages were computed over 20 different realizations for each condition. Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here . Article Metrics Yes Citations Yes Web of Science 3 ads 2 Scopus 3 PubMed 1 PMC 1 Google Scholar",717
632,Data Science,Eric Gerber,"September 29th, 2023",Residuals and diagnostics for multinomial regression models,https://dl.acm.org/doi/abs/10.1002/sam.11645," Eric A. E. Gerber and Bruce A. Craig. 2023. Residuals and diagnostics for multinomial regression models. Stat. Anal. Data Min. 17, 1 (February 2024). https://doi.org/10.1002/sam.11645","In this paper, we extend the concept of a randomized quantile residual to multinomial regression models. Customary diagnostics for these models are limited because they involve difficult‚Äêto‚Äêinterpret residuals and often focus on the fit of one category versus the rest. Our residuals account for associations between categories by using the squared Mahalanobis distances of the observed log‚Äêodds relative to their fitted sampling distributions. Aside from sampling variation, these residuals are exactly normal when the data come from the fitted model. This motivates our use of the residuals to detect model misspecification and overdispersion, in addition to an overall goodness‚Äêof‚Äêfit Kolmogorov‚ÄìSmirnov test. We illustrate the use of the residuals and diagnostics in both simulation and real data studies.",718
633,Data Science,Eric Gerber,"January 6th, 2021",A mixed effects multinomial logistic-normal model for forecasting baseball performance,https://doi.org/10.1515/jqas-2020-0007," Gerber, Eric A. E. and Craig, Bruce A.. ""A mixed effects multinomial logistic-normal model for forecasting baseball performance"". Journal of Quantitative Analysis in Sports, vol. 17, no. 3, 2021, pp. 221-239. DOI: 10.1515/jqas-2020-0007","Abstract Prediction of player performance is a key component in the construction of baseball team rosters. As a result, most prediction models are the proprietary property of team or industrial sports entities, and little is known about them. Of those models that have been published, the main focus has been to separately model each outcome with nearly no emphasis on uncertainty quantification. This research introduces a joint modeling approach to predict seasonal plate appearance outcome vectors using a mixed-effects multinomial logistic-normal model. This model accounts for positive and negative correlations between outcomes, both across and within player seasons, and provides a joint posterior predictive outcome distribution from which uncertainty can be quantified. It is applied to the important, yet unaddressed, problem of predicting performance for players moving between the Japanese (NPB) and American (MLB) major leagues.",719
634,Data Science,Fatemeh Ghoreishi,"September 5th, 2024",Optimal Detection for Bayesian Attack Graphs Under Uncertainty in Monitoring and Reimaging,https://doi.org/10.23919/ACC60939.2024.10644873," Armita Kazeminajafabadi, Seyede Fatemeh Ghoreishi, Mahdi Imani. (2024). Optimal Detection for Bayesian Attack Graphs Under Uncertainty in Monitoring and Reimaging ACC, 3927-3934. https://doi.org/10.23919/ACC60939.2024.10644873","Bayesian attack graphs (BAGs) are powerful models to capture the time-varying progression of attacks in complex interconnected networks. The accuracy and timely detection of attacks are the main objectives in the security analysis of networks modeled by BAGs. This can ensure network safety by identifying network vulnerabilities and designing better defense strategies (e.g., reimaging devices, installing firewalls, changing connections, etc.) This paper presents an optimal minimum mean square error (MMSE) attack detection technique with arbitrary uncertainty in the monitoring and reimaging process. The paper is published in the Proceedings of the 2024 American Control Conference (ACC)",720
635,Data Science,Fatemeh Ghoreishi,"July 7th, 2024",Dynamic Sensor Selection for Efficient Monitoring of Coupled Multidisciplinary Systems,https://doi.org/10.1115/1.4065607," Negar Asadi, Seyede Fatemeh Ghoreishi. (2024). Dynamic Sensor Selection for Efficient Monitoring of Coupled Multidisciplinary Systems J. Comput. Inf. Sci. Eng., 24. https://doi.org/10.1115/1.4065607","Graphical Abstract Figure View large Download slide Graphical Abstract Figure View large Download slide Close modal Coupled multidisciplinary systems involve different disciplines/subsystems with feedback-coupled interactions, illustrating the complex interdependencies inherent in real-world engineering systems. Effective monitoring of a coupled multidisciplinary system is crucial for real-time assessment of the interactions between various disciplines within the system. This monitoring provides the data necessary for detecting and addressing issues in a timely manner and facilitates adaptive decision-making for taking reliable design or control actions. However, processing and analyzing data in real time is computationally intensive, and limited resources, such as computational power, sensor capabilities, and budget, may constrain the extent to which a system can be monitored comprehensively. To address this, this article develops a particle-based approach that dynamically selects a subset of sensors that provides the highest information about the state of the system in real time. The proposed approach first predicts the amount of uncertainty in the estimation of the state of the system given noisy measurements from different subsets of available sensors. Then, it selects the sensors that reduce this uncertainty the most, enhancing the precision and efficiency of the monitoring process. The efficacy of the proposed framework is demonstrated via two coupled multidisciplinary systems in the numerical experiments.",721
636,Data Science,Fatemeh Ghoreishi,"June 14th, 2024",Physics-Informed Particle-Based Reinforcement Learning for Autonomy in Signalized Intersections,https://doi.org/10.1007/s13177-024-00407-2," Mehrnoosh Emamifar, Seyede Fatemeh Ghoreishi. (2024). Physics-Informed Particle-Based Reinforcement Learning for Autonomy in Signalized Intersections Int. J. Intell. Transp. Syst. Res., 22, 416-430. https://doi.org/10.1007/s13177-024-00407-2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",722
637,Data Science,Fatemeh Ghoreishi,"January 24th, 2024",Optimal Inference of Hidden Markov Models Through Expert-Acquired Data,https://doi.org/10.1109/TAI.2024.3358261," Amirhossein Ravari, Seyede Fatemeh Ghoreishi, Mahdi Imani. (2024). Optimal Inference of Hidden Markov Models Through Expert-Acquired Data IEEE Trans. Artif. Intell., 5, 3985-4000. https://doi.org/10.1109/TAI.2024.3358261","Inference is an essential tool for understanding and predicting the behavior of complex systems and processes. Expert knowledge, such as that of scientists, doctors, and engineers, can provide valuable insights into the underlying mechanisms of systems. Incorporating expert knowledge and intention into the inference process allows for constructing/learning models that carry valuable expert perception of complex system. This helps to overcome data limitations, deal with the nonidentifiability of models, and increase the accuracy of the inferenceprocess. The article is published in IEEE Transactions on Artificial Intelligence ( Volume: 5 , Issue: 8 , August 2024 )",723
638,Data Science,Fatemeh Ghoreishi,"July 19th, 2021",Bayesian Optimization for Design of Multi-Actuator Soft Catheter Robots,https://ieeexplore.ieee.org/abstract/document/9490346," S. F. Ghoreishi, R. D. Sochol, D. Gandhi, A. Krieger and M. Fuge, ""Bayesian Optimization for Design of Multi-Actuator Soft Catheter Robots,"" in IEEE Transactions on Medical Robotics and Bionics, vol. 3, no. 3, pp. 725-737, Aug. 2021, doi: 10.1109/TMRB.2021.3098119.","Design of Multi-Actuator Soft Catheters for Treatment of Cerebral Aneurysms. Catheter-based diagnosis and therapy have grown increasingly in recent years. We propose finding the optimal geometric and material properties for a multi-actuator soft catheter robot using a bi-level optimization framework. The paper is published in IEEE Transactions on Medical Robotics and Bionics ( Volume: 3 , Issue: 3 ) The results demonstrate the capability of our proposed multi- actuatorsoft catheter to align with the desired vessel shapes, and show that the proposed framework could expedite the design process.",724
639,Data Science,Fatemeh Ghoreishi,"April 5th, 2021",Two-Stage Bayesian Optimization for Scalable Inference in State-Space Models,https://ieeexplore.ieee.org/abstract/document/9395183," M. Imani and S. F. Ghoreishi, ""Two-Stage Bayesian Optimization for Scalable Inference in State-Space Models,"" in IEEE Transactions on Neural Networks and Learning Systems, doi: 10.1109/TNNLS.2021.3069172.","State-space models (SSMs) are a rich class of dynamical models with a wide range of applications in economics, healthcare, computational biology, robotics, and more. Proper analysis, control, learning, and decision-making in dynamical systems modeled by SSMs depend on the accuracy of the inferred/learned model. Most of the existing inference techniques for SSMs are capable of dealing with very small systems, unable to be applied to most of the large-scale practical problems. This article introduces a two-stage Bayesian optimization (BO) framework for scalable and efficient inference in SSMs.",725
640,Data Science,Fatemeh Ghoreishi,"February 23rd, 2021",Bayesian surrogate learning for uncertainty analysis of coupled multidisciplinary systems,https://asmedigitalcollection.asme.org/computingengineering/article/21/4/041009/1096990/Bayesian-Surrogate-Learning-for-Uncertainty," Ghoreishi, Seyede Fatemeh & Imani, Mahdi. (2021). Bayesian Surrogate Learning for Uncertainty Analysis of Coupled Multidisciplinary Systems. Journal of Computing and Information Science in Engineering. 10.1115/1.4049994.","Engineering systems are often composed of many subsystems that interact with each other. These subsystems, referred to as disciplines, contain many types of uncertainty and in many cases are feedback-coupled with each other. In designing these complex systems, one needs to assess the stationary behavior of these systems for the sake of stability and reliability. This requires the system level uncertainty analysis of the multidisciplinary systems, which is often computationally intractable. To overcome this issue, techniques have been developed for capturing the stationary behavior of the coupled multidisciplinary systems through available data of individual disciplines. The accuracy and convergence of the existing techniques depend on a large amount of data from all disciplines, which are not available in many practical problems. Toward this, we have developed an adaptive methodology that adds the minimum possible number of samples from individual disciplines to achieve an accurate and reliable uncertainty propagation in coupled multidisciplinary systems. The proposed method models each discipline function via Gaussian process (GP) regression to derive a closed-form policy. This policy sequentially selects a new sample point that results in the highest uncertainty reduction over the distribution of the coupling design variables. The effectiveness of the proposed method is demonstrated in the uncertainty analysis of an aerostructural system and a coupled numerical example.",726
641,Data Science,Fatemeh Ghoreishi,"January 22nd, 2021",Scalable inverse reinforcement learning through multifidelity Bayesian optimization,https://ieeexplore.ieee.org/abstract/document/9334410," M. Imani and S. F. Ghoreishi, ""Scalable Inverse Reinforcement Learning Through Multifidelity Bayesian Optimization,"" in IEEE Transactions on Neural Networks and Learning Systems, doi: 10.1109/TNNLS.2021.3051012.","We propose a multifidelity Bayesian optimization (MFBO) framework that significantly scales the learning process of a wide range of existing IRL techniques. The proposed framework enables the incorporation of multiple approximators and efficiently takes their uncertainty and computational costs into account to balance exploration and exploitation. The proposal is published in the IEEE Transactions on Neural Networks and Learning Systems ( Volume: 33 , Issue: 8 , August 2022 ) and is available for download at the following URL: 10.1109/TNNLS.2021.3051012. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",727
642,Data Science,Fatemeh Ghoreishi,"October 25th, 2019",Sequential Information-Theoretic and Reification-Based Approach for Querying Multi-Information Sources,https://arc.aiaa.org/doi/abs/10.2514/1.I010753," Ghoreishi, S.F., Thomison, W.D. and Allaire, D.L., 2019. Sequential Information-Theoretic and Reification-Based Approach for Querying Multi-Information Sources. Journal of Aerospace Information Systems, 16(12), pp.575-587.",The method is based on a model reification approach that eliminates the observational data requirement. The results are published in the open-source edition of the book ‚ÄòDesigning Machine Intelligence‚Äô The correlation is then used in an updating procedure whereby uncertain outputs from multiple models may be fused together to better estimate some quantity or quantities of interest. The result is a fused model with superior predictive capability than any of its constituent models.,728
643,Data Science,Fatemeh Ghoreishi,"July 17th, 2019",MFBO-SSM: Multi-fidelity Bayesian optimization for fast inference in state-space models,https://ojs.aaai.org/index.php/AAAI/article/view/4784," Imani, M., Ghoreishi, S. F., Allaire, D., & Braga-Neto, U. M. (2019). MFBO-SSM: Multi-Fidelity Bayesian Optimization for Fast Inference in State-Space Models. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01), 7858-7865. https://doi.org/10.1609/aaai.v33i01.33017858","Abstract Nonlinear state-space models are ubiquitous in modeling real-world dynamical systems. Sequential Monte Carlo (SMC) techniques, also known as particle methods, are a well-known class of parameter estimation methods for this general class of state-space models. Existing SMC-based techniques rely on excessive sampling of the parameter space, which makes their computation intractable for large systems or tall data sets. Bayesian optimization techniques have been used for fast inference in state-space models with intractable likelihoods. These techniques aim to find the maximum of the likelihood function by sequential sampling of the parameter space through a single SMC approximator. Various SMC approximators with different fidelities and computational costs are often available for sample-based likelihood approximation. In this paper, we propose a multi-fidelity Bayesian optimization algorithm for the inference of general nonlinear state-space models (MFBO-SSM), which enables simultaneous sequential selection of parameters and approximators. The accuracy and speed of the algorithm are demonstrated by numerical experiments using synthetic gene expression data from a gene regulatory network model and real data from the VIX stock price index.",729
644,Data Science,Fatemeh Ghoreishi,"June 20th, 2019",Efficient use of multiple information sources in material design,https://www.sciencedirect.com/science/article/pii/S135964541930597X," Ghoreishi, Seyede Fatemeh and Molkeri, Abhilash and Arroyave, Raymundo and Allaire, Douglas and Srivastava, Ankit, Efficient Use of Multiple Information Sources in Material Design (June 20, 2019). Available at SSRN: https://ssrn.com/abstract=3406949 or http://dx.doi.org/10.2139/ssrn.3406949","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",730
645,Data Science,Fatemeh Ghoreishi,"March 28th, 2019",Adaptive dimensionality reduction for fast sequential optimization with gaussian processes,https://asmedigitalcollection.asme.org/mechanicaldesign/article/141/7/071404/727152/Adaptive-Dimensionality-Reduction-for-Fast," Ghoreishi, S.F., Friedman, S. and Allaire, D.L., 2019. Adaptive dimensionality reduction for fast sequential optimization with gaussian processes. Journal of Mechanical Design","We demonstrate our approach on three benchmark problems and a practical aerostructural wing design problem. Our method performs well against traditional direct application of Bayesian global optimization techniques. We have developed a framework for the optimization of expensive black-box models, which is based on active subspace exploitation and a two-step knowledge gradient policy. This article is published by the Design Automation Committee of ASME for publication in the J ournal of M echanical D esign . Manuscript received July 26, 2018; final manuscript received March 4, 2019; published online March 28, 2019. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch or click here for details. For more information on wing optimization, see the Wings section of the AIAA/USAF/NASA/ISSMO Symposium on Multidisciplinary Analysis and Optimization. This article includes the author‚Äôs comments, as well as the author and author-written versions of the articles. We present our method in the next issue of ASME J. Mech. Des. Use the Daily Discussion to help people with reading comprehension and vocabulary. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch or click here for details. You do not currently have access to this content. The online version of this article includesthe author‚Äùs comments and the author's comments. We have developed a framework for the optimization of expensive black- box models, which is based on active subspace exploitation and a two-step knowledge gradient policy. We demonstrate our approach on three benchmark problems and a practical aerostructural wing design problem. We demonstrate our approach on three benchmark problems and a practical aerostructural wing design problem. Our method performs well against traditional direct application of Bayesian global optimization techniques. We have developed a framework for the optimization of expensive black-box models, which is based on active subspace exploitation and a two-step knowledge gradient policy. We conclude with a discussion of the benefits and drawbacks of using Bayesian optimization techniques to solve aerostructure design problems. We also discuss the potential benefits and challenges of using Python to solve these problems. Back to the page you came from. Click here to visit the ASME website for more about the AIAa/ISSMO Multidisciplinary disciplinary conference, Albany, NY, August 30‚ÄìSept. 1. The ASme conference in the U.S. and the European Conference on",731
646,Data Science,Fatemeh Ghoreishi,"December 3rd, 2018",Bayesian control of large MDPs with unknown dynamics in data-poor environments,https://dl.acm.org/doi/10.5555/3327757.3327909," Mahdi Imani, Seyede Fatemeh Ghoreishi, and Ulisses M. Braga-Neto. 2018. Bayesian control of large MDPs with unknown dynamics in data-poor environments. In Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS'18). Curran Associates Inc., Red Hook, NY, USA, 8157‚Äì8167.","We propose a Bayesian decision making framework for control of Markov Decision Processes (MDPs) with unknown dynamics and large, possibly continuous, state, action, and parameter spaces in data-poor environments. Most of the existing adaptive controllers for MDPs with unknown dynamics are based on the reinforcement learning framework and rely on large data sets acquired by sustained direct interaction with the system or via a simulator. This is not feasible in many applications, due to ethical, economic, and physical constraints. The proposed framework addresses the data poverty issue by decomposing the problem into an offline planning stage that does not rely on sustained direct interaction with the system or simulator and an online execution stage. In the offline process, parallel Gaussian process temporal difference (GPTD) learning techniques are employed for near-optimal Bayesian approximation of the expected discounted reward over a sample drawn from the prior distribution of unknown parameters. In the online stage, the action with the maximum expected return with respect to the posterior distribution of the parameters is selected. This is achieved by an approximation of the posterior distribution using a Markov Chain Monte Carlo (MCMC) algorithm, followed by constructing multiple Gaussian processes over the parameter space for efficient prediction of the means of the expected return at the MCMC sample. The effectiveness of the proposed framework is demonstrated using a simple dynamical system model with continuous state and action spaces, as well as a more complex model for a metastatic melanoma gene regulatory network observed through noisy synthetic gene expression data.",732
647,Data Science,Fatemeh Ghoreishi,"July 12th, 2018",Multi-information source constrained Bayesian optimization,https://link.springer.com/article/10.1007/s00158-018-2115-z," Ghoreishi, S.F., Allaire, D. Multi-information source constrained Bayesian optimization. Struct Multidisc Optim 59, 977‚Äì991 (2019). https://doi.org/10.1007/s00158-018-2115-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 1587 Accesses",733
648,Data Science,Yifan Hu,"November 1st, 2021",BERT-Beta: A Proactive Probabilistic Approach to Text Moderation,https://doi.org/10.18653/v1/2021.emnlp-main.682," Fei Tan, Yifan Hu , Kevin Yen, Changwei Hu. (2021). BERT-Beta: A Proactive Probabilistic Approach to Text Moderation EMNLP (1), 8667-8675. https://doi.org/10.18653/v1/2021.emnlp-main.682","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text moderation for user generated content, which helps to promote healthy interaction among users, has been widely studied and many machine learning models have been proposed. In this work, we explore an alternative perspective by augmenting reactive reviews with proactive forecasting. Specifically, we propose a new concept text toxicity propensity to characterize the extent to which a text tends to attract toxic comments. Beta regression is then introduced to do the probabilistic modeling, which is demonstrated to function well in comprehensive experiments. We also propose an explanation method to communicate the model decision clearly. Both propensity scoring and interpretation benefit text moderation in a novel manner. Finally, the proposed scaling mechanism for the linear model offers useful insights beyond this work.",734
649,Data Science,Yifan Hu,"November 1st, 2020",HABERTOR: An Efficient and Effective Deep Hatespeech Detector,https://doi.org/10.18653/v1/2020.emnlp-main.606," Thanh Tran , Yifan Hu , Changwei Hu, Kevin Yen, Fei Tan, Kyumin Lee, Se Rim Park. (2020). HABERTOR: An Efficient and Effective Deep Hatespeech Detector EMNLP (1), 7486-7502. https://doi.org/10.18653/v1/2020.emnlp-main.606","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present our HABERTOR model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. HABERTOR inherits BERT‚Äôs architecture, but is different in four aspects: (i) it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset; (ii) it consists of Quaternion-based factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage; (iii) it uses our proposed multi-source ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and (iv) it uses a regularized adversarial training with our proposed fine-grained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that HABERTOR works better than 15 state-of-the-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our HABERTOR is 4 5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pre-train it by using less than 1% of the number of words. Our generalizability analysis shows that HABERTOR transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.",735
650,Data Science,Yifan Hu,"November 1st, 2020",Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference,https://doi.org/10.18653/v1/2020.emnlp-main.17," Bang An, Jie Lyu , Zhenyi Wang , Chunyuan Li, Changwei Hu, Fei Tan, Ruiyi Zhang, Yifan Hu , Changyou Chen. (2020). Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference EMNLP (1), 236-255. https://doi.org/10.18653/v1/2020.emnlp-main.17","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The neural attention mechanism plays an important role in many natural language processing applications. In particular, multi-head attention extends single-head attention by allowing a model to jointly attend information from different perspectives. However, without explicit constraining, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the model‚Äôs representation power. In this paper, for the first time, we provide a novel understanding of multi-head attention from a Bayesian perspective. Based on the recently developed particle-optimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens model‚Äôs expressiveness. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions: why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on multiple tasks.",736
651,Data Science,Yifan Hu,"November 1st, 2020",TNT: Text Normalization based Pre-training of Transformers for Content Moderation,https://doi.org/10.18653/v1/2020.emnlp-main.383," Fei Tan, Yifan Hu , Changwei Hu, Keqian Li, Kevin Yen. (2020). TNT: Text Normalization based Pre-training of Transformers for Content Moderation EMNLP (1), 4735-4741. https://doi.org/10.18653/v1/2020.emnlp-main.383","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract In this work, we present a new language pre-training model TNT (Text Normalization based pre-training of Transformers) for content moderation. Inspired by the masking strategy and text normalization, TNT is developed to learn language representation by training transformers to reconstruct text from four operation types typically seen in text manipulation: substitution, transposition, deletion, and insertion. Furthermore, the normalization involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery. As a result, the experiments demonstrate that TNT outperforms strong baselines on the hate speech classification task. Additional text normalization experiments and case studies show that TNT is a new potential approach to misspelling correction.",737
652,Data Science,David Lazer,"January 14th, 2025",DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter,https://doi.org/10.48550/arXiv.2501.09035," Kai-Cheng Yang, Pranav Goel, Alexi Quintana Math√©, Luke Horgan, Stefan D. McCabe, Nir Grinberg, Kenneth Joseph, David Lazer. (2025). DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter CoRR, abs/2501.09035. https://doi.org/10.48550/arXiv.2501.09035","Social media play a pivotal role in disseminating web content, particularly during elections, yet our understanding of the association between demographic factors and political discourse online remains limited. Here, we introduce a unique dataset, DomainDemo, linking domains shared on Twitter (X) with the demographic characteristics of associated users, including age, gender, race, political affiliation, and geolocation, from 2011 to 2022. This new resource was derived from a panel of over 1.5 million Twitter users matched against their U.S. voter registration records, facilitating a better understanding of a decade of information flows on one of the most prominent social media platforms and trends in political and public discourse among registered U.S. voters from different sociodemographic groups. By aggregating user demographic information onto the domains, we derive five metrics that provide critical insights into over 129,000 websites. In particular, the localness and partisan audience metrics quantify the domains' geographical reach and ideological orientation, respectively. These metrics show substantial agreement with existing classifications, suggesting the effectiveness and reliability of DomainDemo's approach.",738
653,Data Science,David Lazer,"November 12th, 2024",When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions,https://doi.org/10.48550/arXiv.2411.07907," Allison Wan, Christoph Riedl, David Lazer. (2024). When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions CoRR, abs/2411.07907. https://doi.org/10.48550/arXiv.2411.07907","How does social network structure amplify or stifle behavior diffusion? Existing theory suggests that when social reinforcement makes the adoption of behavior more likely, it should spread more -- both farther and faster -- on clustered networks with redundant ties. Conversely, if adoption does not benefit from social reinforcement, then it should spread more on random networks without such redundancies. We develop a novel model of behavior diffusion with tunable probabilistic adoption and social reinforcement parameters to systematically evaluate the conditions under which clustered networks better spread a behavior compared to random networks. Using both simulations and analytical techniques we find precise boundaries in the parameter space where either network type outperforms the other or performs equally. We find that in most cases, random networks spread a behavior equally as far or farther compared to clustered networks despite strong social reinforcement. While there are regions in which clustered networks better diffuse contagions with social reinforcement, this only holds when the diffusion process approaches that of a deterministic threshold model and does not hold for all socially reinforced behaviors more generally. At best, clustered networks only outperform random networks by at least a five percent margin in 18\% of the parameter space, and when social reinforcement is large relative to the baseline probability of adoption.",739
654,Data Science,David Lazer,"August 12th, 2023",Mainstream News Articles Co-Shared with Fake News Buttress Misinformation Narratives,https://doi.org/10.48550/arXiv.2308.06459," Pranav Goel, Jon Green, David Lazer, Philip Resnik. (2023). Mainstream News Articles Co-Shared with Fake News Buttress Misinformation Narratives CoRR, abs/2308.06459. https://doi.org/10.48550/arXiv.2308.06459","Most prior and current research examining misinformation spread on social media focuses on reports published by 'fake' news sources. These approaches fail to capture another potential form of misinformation with a much larger audience: factual news from mainstream sources ('real' news) repurposed to promote false or misleading narratives. We operationalize narratives using an existing unsupervised NLP technique and examine the narratives present in misinformation content. We find that certain articles from reliable outlets are shared by a disproportionate number of users who also shared fake news on Twitter. We consider these 'real' news articles to be co-shared with fake news. We show that co-shared articles contain existing misinformation narratives at a significantly higher rate than articles from the same reliable outlets that are not co-shared with fake news. This holds true even when articles are chosen following strict criteria of reliability for the outlets and after accounting for the alternative explanation of partisan curation of articles. For example, we observe that a recent article published by The Washington Post titled ""Vaccinated people now make up a majority of COVID deaths"" was disproportionately shared by Twitter users with a history of sharing anti-vaccine false news reports. Our findings suggest a strategic repurposing of mainstream news by conveyors of misinformation as a way to enhance the reach and persuasiveness of misleading narratives. We also conduct a comprehensive case study to help highlight how such repurposing can happen on Twitter as a consequence of the inclusion of particular narratives in the framing of mainstream news.",740
655,Data Science,David Lazer,"July 27th, 2023",Enhancing the ethics of user-sourced online data collection and sharing,https://doi.org/10.1038/s43588-023-00490-7," Michelle N. Meyer, John Basl, David R. Choffnes, Christo Wilson, David M. J. Lazer. (2023). Enhancing the ethics of user-sourced online data collection and sharing Nat. Comput. Sci., 3, 660-664. https://doi.org/10.1038/s43588-023-00490-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",741
656,Data Science,David Lazer,"July 15th, 2023",The science of fake news,https://doi.org/10.48550/arXiv.2307.07903," David M. J. Lazer, Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan, Gordon Pennycook, David M. Rothschild, Michael Schudson, Steven A. Sloman, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts, Jonathan L. Zittrain. (2023). The science of fake news CoRR, abs/2307.07903. https://doi.org/10.48550/arXiv.2307.07903","Fake news emerged as an apparent global problem during the 2016 U.S. Presidential election. Addressing it requires a multidisciplinary effort to define the nature and extent of the problem, detect fake news in real time, and mitigate its potentially harmful effects. This will require a better understanding of how the Internet spreads content, how people process news, and how the two interact. We review the state of knowledge in these areas and discuss two broad potential mitigation strategies: better enabling individuals to identify fake news, and intervention within the platforms to reduce the attention given to fake news. The cooperation of Internet platforms (especially Facebook, Google, and Twitter) with researchers will be critical to understanding the scale of the issue and the effectiveness of possible interventions.",742
657,Data Science,David Lazer,"December 31st, 2021",Engagement Outweighs Exposure to Partisan and Unreliable News within Google Search,https://arxiv.org/abs/2201.00074," Ronald E. Robertson, Jon Green, Damian Ruck, Katya Ognyanova, Christo Wilson, David Lazer. (2022). Engagement Outweighs Exposure to Partisan and Unreliable News within Google Search CoRR, abs/2201.00074. https://arxiv.org/abs/2201.00074","If popular online platforms systematically expose their users to partisan and unreliable news, they could potentially contribute to societal issues like rising political polarization. This concern is central to the echo chamber and filter bubble debates, which critique the roles that user choice and algorithmic curation play in guiding users to different online information sources. These roles can be measured in terms of exposure, the URLs seen while using an online platform, and engagement, the URLs selected while on that platform or browsing the web more generally. However, due to the challenges of obtaining ecologically valid exposure data--what real users saw during their regular platform use--studies in this vein often only examine engagement data, or estimate exposure via simulated behavior or inference. Despite their centrality to the contemporary information ecosystem, few such studies have focused on web search, and even fewer have examined both exposure and engagement on any platform. To address these gaps, we conducted a two-wave study pairing surveys with ecologically valid measures of exposure and engagement on Google Search during the 2018 and 2020 US elections. We found that participants' partisan identification had a small and inconsistent relationship with the amount of partisan and unreliable news they were exposed to on Google Search, a more consistent relationship with the search results they chose to follow, and the most consistent relationship with their overall engagement. That is, compared to the news sources our participants were exposed to on Google Search, we found more identity-congruent and unreliable news sources in their engagement choices, both within Google Search and overall. These results suggest that exposure and engagement with partisan or unreliable news on Google Search are not primarily driven by algorithmic curation, but by users' own choices.",743
658,Data Science,David Lazer,"September 4th, 2021",(Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys,https://doi.org/10.18653/v1/2021.emnlp-main.27," Kenneth Joseph, Sarah Shugars, Ryan J. Gallagher, Jon Green, Alexi Quintana Math√©, Zijian An, David Lazer. (2021). (Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys EMNLP (1), 312-324. https://doi.org/10.18653/v1/2021.emnlp-main.27","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Stance detection, which aims to determine whether an individual is for or against a target concept, promises to uncover public opinion from large streams of social media data. Yet even human annotation of social media content does not always capture ‚Äústance‚Äù as measured by public opinion polls. We demonstrate this by directly comparing an individual‚Äôs self-reported stance to the stance inferred from their social media data. Leveraging a longitudinal public opinion survey with respondent Twitter handles, we conducted this comparison for 1,129 individuals across four salient targets. We find that recall is high for both ‚ÄúPro‚Äô‚Äô and ‚ÄúAnti‚Äô‚Äô stance classifications but precision is variable in a number of cases. We identify three factors leading to the disconnect between text and author stance: temporal inconsistencies, differences in constructs, and measurement errors from both survey respondents and annotators. By presenting a framework for assessing the limitations of stance detection models, this work provides important insight into what stance detection truly measures.",744
659,Data Science,David Lazer,"June 2nd, 2020","Misinformation in action: Fake news exposure is linked to lower trust in media, higher trust in government when your side is in power",https://doi.org/10.37016/mr-2020-024%20," K. Ognyanova, D. Lazer, R. E. Robertson, and C. Wilson. (2020). ""Misinformation in action: Fake news exposure is linked to lower trust in media, higher trust in government when your side is in power"". Harvard Kennedy School (HKS) Misinformation Review. DOI: 10.37016/mr-2020-024","Peer Reviewed One major concern about fake news is that it could damage the public trust in democratic institutions. We examined this possibility using longitudinal survey data combined with records of online behavior. Our study found that online misinformation was linked to lower trust in mainstream media across party lines. However, for moderates and conservatives, exposure to fake news predicted a higher confidence in political institutions. The mostly right-leaning fake news accessed by our moderate-to-conservative respondents could strengthen their trust in a Republican government. This was not true for liberals who could be biased against such content and less likely to believe its claims. School of Communication & Information, Rutgers University, USA Network Science Institute, Northeastern University, USA Network Science Institute, Northeastern University, USA",745
660,Data Science,David Lazer,"April 23rd, 2018",Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages,https://doi.org/10.1145/3178876.3186143," Ronald E. Robertson, David Lazer, and Christo Wilson. 2018. Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages. In Proceedings of the 2018 World Wide Web Conference (WWW '18). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 955‚Äì965. DOI: 10.1145/3178876.3186143","Search engines are a primary means through which people obtain information in today¬ªs connected world. Yet, apart from the search engine companies themselves, little is known about how their algorithms filter, rank, and present the web to users. This question is especially pertinent with respect to political queries, given growing concerns about filter bubbles, and the recent finding that bias or favoritism in search rankings can influence voting behavior. In this study, we conduct a targeted algorithm audit of Google Search using a dynamic set of political queries. We designed a Chrome extension to survey participants and collect the Search Engine Results Pages (SERPs) and autocomplete suggestions that they would have been exposed to while searching our set of political queries during the month after Donald Trump¬ªs Presidential inauguration. Using this data, we found significant differences in the composition and personalization of politically-related SERPs by query type, subjects¬ª characteristics, and date.",746
661,Data Science,Mario Nascimento,"November 21st, 2024",An Experimental Study on Data Augmentation Techniques for Named Entity Recognition on Low-Resource Domains,https://doi.org/10.48550/arXiv.2411.14551," Arthur Elwing Torres, Edleno Silva de Moura, Altigran Soares da Silva, Mario A. Nascimento, Filipe de S√° Mesquita. (2024). An Experimental Study on Data Augmentation Techniques for Named Entity Recognition on Low-Resource Domains CoRR, abs/2411.14551. https://doi.org/10.48550/arXiv.2411.14551","Named Entity Recognition (NER) is a machine learning task that traditionally relies on supervised learning and annotated data. Acquiring such data is often a challenge, particularly in specialized fields like medical, legal, and financial sectors. Those are commonly referred to as low-resource domains, which comprise long-tail entities, due to the scarcity of available data. To address this, data augmentation techniques are increasingly being employed to generate additional training instances from the original dataset. In this study, we evaluate the effectiveness of two prominent text augmentation techniques, Mention Replacement and Contextual Word Replacement, on two widely-used NER models, Bi-LSTM+CRF and BERT. We conduct experiments on four datasets from low-resource domains, and we explore the impact of various combinations of training subset sizes and number of augmented examples. We not only confirm that data augmentation is particularly beneficial for smaller datasets, but we also demonstrate that there is no universally optimal number of augmented examples, i.e., NER practitioners must experiment with different quantities in order to fine-tune their projects.",747
662,Data Science,Mario Nascimento,"July 17th, 2024",Effective Trajectory Imputation using Simple Probabilistic Language Models,https://doi.org/10.1109/MDM61037.2024.00027," Hayat Sultan Mohammed, Mario A. Nascimento, Denilson Barbosa . (2024). Effective Trajectory Imputation using Simple Probabilistic Language Models MDM, 51-60. https://doi.org/10.1109/MDM61037.2024.00027","Trajectory imputation is the task of filling in the gaps in actual trajectories by computing points that fit ""naturally"" within existing trajectories. Using a grid-based representation of the space, and not considering the underlying road network, we convert trajectory points into tokens corresponding to the grid cell where they appear. We report experiments on a real dataset of over 500,000 taxi trips, showing that we can accurately fill gaps of up to 2km between GPS observations with 83% precision. These results are comparable to approaches using much more computationally demanding Large Language Models based on transformers.",748
663,Data Science,Mario Nascimento,"July 1st, 2024",Mobility Data Science: Perspectives and Challenges,https://doi.org/10.1145/3652158," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Seok Kim , Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Cyrus Shahabi, Bettina Speckmann, Egemen Tanin, Xu Teng, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2024). Mobility Data Science: Perspectives and Challenges ACM Trans. Spatial Algorithms Syst., 10, 10. https://doi.org/10.1145/3652158","Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)‚Äìequipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years.",749
664,Data Science,Mario Nascimento,"June 21st, 2023",Towards Mobility Data Science (Vision Paper),https://doi.org/10.48550/arXiv.2307.05717," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Sook Kim, Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Cyrus Shahabi, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Bettina Speckmann, Egemen Tanin, Xu Teng, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2023). Towards Mobility Data Science (Vision Paper) CoRR, abs/2307.05717. https://doi.org/10.48550/arXiv.2307.05717","Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years.",750
665,Data Science,Mario Nascimento,"November 30th, 2022",Asymmetric Action Abstractions for Planning in Real-Time Strategy Games,https://doi.org/10.1613/jair.1.13769," Rubens O. Moraes, Mario A. Nascimento, Levi H. S. Lelis. (2022). Asymmetric Action Abstractions for Planning in Real-Time Strategy Games J. Artif. Intell. Res., 75, 1103-1137. https://doi.org/10.1613/jair.1.13769","Action abstractions restrict the number of legal actions available for real-time planning in zero-sum extensive-form games, thus allowing algorithms to focus their search on a set of promising actions. Even though unabstracted game trees can lead to optimal policies, due to real-time constraints and the tree size, they are not a practical choice. In this context, we introduce an action abstraction scheme which we call asymmetric action abstraction. Asymmetric abstractions allow search algorithms to ‚Äúpay more attention‚Äù to some aspects of the game by unevenly dividing the algorithm‚Äôs search effort amongst different aspects of the game. We also introduce four algorithms that search in asymmetrically abstracted game trees to evaluate the effectiveness of our abstraction schemes. Two of our algorithms are adaptations of algorithms developed for searching in action-abstracted spaces, Portfolio Greedy Search and Stratified Strategy Selection, and the other two are adaptations of an algorithm developed for searching in unabstracted spaces, Na√ØveMCTS. An extensive set of experiments in a real-time strategy game shows that search algorithms using asymmetric abstractions are able to outperform all other search algorithms tested.",751
666,Data Science,Mario Nascimento,"August 23rd, 2022",Mobility Data Science (Dagstuhl Seminar 22021),https://doi.org/10.4230/DagRep.12.1.1," Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong , Andreas Z√ºfle, Jussara M. Almeida, Taylor Anderson , Walid G. Aref, Gennady L. Andrienko, Natalia V. Andrienko, Yang Cao , Sanjay Chawla, Reynold Cheng, Panos K. Chrysanthis, Xiqi Fei, Gabriel Ghinita, Anita Graser, Dimitrios Gunopulos, Christian S. Jensen, Joon-Sook Kim, Kyoung-Sook Kim, Peer Kr√∂ger, John Krumm, Johannes Lauer, Amr Magdy , Mario A. Nascimento, Siva Ravada, Matthias Renz, Dimitris Sacharidis, Cyrus Shahabi, Flora D. Salim, Mohamed Sarwat, Maxime Schoemans, Bettina Speckmann, Egemen Tanin, Yannis Theodoridis, Kristian Torp, Goce Trajcevski, Marc J. van Kreveld, Carola Wenk, Martin Werner , Raymond Chi-Wing Wong, Song Wu, Jianqiu Xu, Moustafa Youssef , Demetris Zeinalipour, Mengxuan Zhang , Esteban Zim√°nyi. (2022). Mobility Data Science (Dagstuhl Seminar 22021) Dagstuhl Reports, 12, 1-34. https://doi.org/10.4230/DagRep.12.1.1","Abstract This report documents the program and the outcomes of Dagstuhl Seminar 22021 ""Mobility Data Science"". This seminar was held January 9-14, 2022, including 47 participants from industry and academia. The goal of this Dagstuhl Seminar was to create a new research community of mobility data science in which the whole is greater than the sum of its parts by bringing together established leaders as well as promising young researchers from all fields related to mobility data science. Specifically, this report summarizes the main results of the seminar by (1) defining Mobility Data Science as a research domain, (2) by sketching its agenda in the coming years, and by (3) building a mobility data science community. (1) Mobility data science is defined as spatiotemporal data that additionally captures the behavior of moving entities (human, vehicle, animal, etc.). To understand, explain, and predict behavior, we note that a strong collaboration with research in behavioral and social sciences is needed. (2) Future research directions for mobility data science described in this report include a) mobility data acquisition and privacy, b) mobility data management and analysis, and c) applications of mobility data science. (3) We identify opportunities towards building a mobility data science community, towards collaborations between academic and industry, and towards a mobility data science curriculum.",752
667,Data Science,Predrag Radivojac,"June 28th, 2024",An algorithm for decoy-free false discovery rate estimation in XL-MS/MS proteomics,https://doi.org/10.1093/bioinformatics/btae233," Yisu Peng, Shantanu Jain, Predrag Radivojac. (2024). An algorithm for decoy-free false discovery rate estimation in XL-MS/MS proteomics Bioinform., 40, i428-i436. https://doi.org/10.1093/bioinformatics/btae233","Motivation Cross-linking tandem mass spectrometry (XL-MS/MS) is an established analytical platform used to determine distance constraints between residues within a protein or from physically interacting proteins, thus improving our understanding of protein structure and function. To aid biological discovery with XL-MS/MS, it is essential that pairs of chemically linked peptides be accurately identified, a process that requires: (i) database search, that creates a ranked list of candidate peptide pairs for each experimental spectrum and (ii) false discovery rate (FDR) estimation, that determines the probability of a false match in a group of top-ranked peptide pairs with scores above a given threshold. Currently, the only available FDR estimation mechanism in XL-MS/MS is the target-decoy approach (TDA). However, despite its simplicity, TDA has both theoretical and practical limitations that impact the estimation accuracy and increase run time over potential decoy-free approaches (DFAs). Results We introduce a novel decoy-free framework for FDR estimation in XL-MS/MS. Our approach relies on multi-sample mixtures of skew normal distributions, where the latent components correspond to the scores of correct peptide pairs (both peptides identified correctly), partially incorrect peptide pairs (one peptide identified correctly, the other incorrectly), and incorrect peptide pairs (both peptides identified incorrectly). To learn these components, we exploit the score distributions of first- and second-ranked peptide-spectrum matches for each experimental spectrum and subsequently estimate FDR using a novel expectation-maximization algorithm with constraints. We evaluate the method on ten datasets and provide evidence that the proposed DFA is theoretically sound and a viable alternative to TDA owing to its good performance in terms of accuracy, variance of estimation, and run time. Availability and implementation https://github.com/shawn-peng/xlms Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",753
668,Data Science,Predrag Radivojac,"March 4th, 2020",Fast nonparametric estimation of class proportions in the positive-unlabeled classification setting,https://ojs.aaai.org//index.php/AAAI/article/view/6151," Zeiberg, D., Jain, S., & Radivojac, P. (2020). Fast Nonparametric Estimation of Class Proportions in the Positive-Unlabeled Classification Setting. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 6729-6736. https://doi.org/10.1609/aaai.v34i04.6151","Abstract Estimating class proportions has emerged as an important direction in positive-unlabeled learning. Well-estimated class priors are key to accurate approximation of posterior distributions and are necessary for the recovery of true classification performance. While significant progress has been made in the past decade, there remains a need for accurate strategies that scale to big data. Motivated by this need, we propose an intuitive and fast nonparametric algorithm to estimate class proportions. Unlike any of the previous methods, our algorithm uses a sampling strategy to repeatedly (1) draw an example from the set of positives, (2) record the minimum distance to any of the unlabeled examples, and (3) remove the nearest unlabeled example. We show that the point of sharp increase in the recorded distances corresponds to the desired proportion of positives in the unlabeled set and train a deep neural network to identify that point. Our distance-based algorithm is evaluated on forty datasets and compared to all currently available methods. We provide evidence that this new approach results in the most accurate performance and can be readily used on large datasets.",754
669,Data Science,Predrag Radivojac,"July 20th, 2019",A new class of metrics for learning on real-valued and structured data,https://dl.acm.org/doi/abs/10.1007/s10618-019-00622-6," Yang R, Jiang Y, Mathews S, Housworth EA, Hahn MW, Radivojac P. A new class of metrics for learning on real-valued and structured data. Data Min. Knowl. Disc. (2019) 33(4): 995-1016.","We propose a new class of metrics on sets, vectors, and functions that can be used in various stages of data mining, including exploratory data analysis, learning, and result interpretation. These new distance functions unify and generalize some of the popular metrics, such as the Jaccard and bag distances on sets, Manhattan distance on vector spaces, and Marczewski-Steinhaus distance on integrable functions. We prove that the new metrics are complete and show useful relationships with f-divergences for probability distributions. To further extend our approach to structured objects such as ontologies, we introduce information-theoretic metrics on directed acyclic graphs drawn according to a fixed probability distribution. We conduct empirical investigation to demonstrate the effectiveness on real-valued, high-dimensional, and structured data. Overall, the new metrics compare favorably to multiple similarity and dissimilarity functions traditionally used in data mining, including the Minkowski ($$L^p$$Lp) family, the fractional $$L^p$$Lp family, two f-divergences, cosine distance, and two correlation coefficients. We provide evidence that they are particularly appropriate for rapid processing of high-dimensional and structured data in distance-based learning.",755
670,Data Science,Predrag Radivojac,"June 14th, 2019",Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007112," Pagel KA, Antaki D, Lian A, Mort M, Cooper DN, Sebat J, Iakoucheva LM, Mooney SD, Radivojac P. Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome. PLoS Comput. Biol. (2019) 15(6): e1007112.","Machine learning method, MutPred-Indel, predicts pathogenicity and identifies types of functional residues impacted by non-frameshifting insertion/deletion variation. The model shows good predictive performance as well as the ability to identify impacted structural and functional residues including secondary structure, intrinsic disorder, metal and macromolecular binding, post-translational modifications and allosteric sites.",756
671,Data Science,Predrag Radivojac,"March 14th, 2019",Estimating classification accuracy in positive-unlabeled learning: characterization and correction strategies,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6417800/," Ramola R, Jain S, Radivojac P. Estimating classification accuracy in positive-unlabeled learning: characterization and correction strategies. Pac. Symp. Biocomput. (2019) 24: 124-135.","Abstract Accurately estimating performance accuracy of machine learning classifiers is of fundamental importance in biomedical research with potentially societal consequences upon the deployment of best-performing tools in everyday life. Although classification has been extensively studied over the past decades, there remain understudied problems when the training data violate the main statistical assumptions relied upon for accurate learning and model characterization. This particularly holds true in the open world setting where observations of a phenomenon generally guarantee its presence but the absence of such evidence cannot be interpreted as the evidence of its absence. Learning from such data is often referred to as positive-unlabeled learning, a form of semi-supervised learning where all labeled data belong to one (say, positive) class. To improve the best practices in the field, we here study the quality of estimated performance in positive-unlabeled learning in the biomedical domain. We provide evidence that such estimates can be wildly inaccurate, depending on the fraction of positive examples in the unlabeled data and the fraction of negative examples mislabeled as positives in the labeled data. We then present correction methods for four such measures and demonstrate that the knowledge or accurate estimates of class priors in the unlabeled data and noise in the labeled data are sufficient for the recovery of true classification performance. We provide theoretical support as well as empirical evidence for the efficacy of the new performance estimation methods. Keywords: Positive-unlabeled learning, AlphaMax, Matthews correlation, accuracy estimation",757
672,Data Science,Predrag Radivojac,"July 20th, 2018",On whom should I perform this lab test next? An active feature elicitation approach,https://www.ijcai.org/proceedings/2018/486," Natarajan S, Das S, Ramanan N, Kunapuli G, Radivojac P. On whom should I perform this lab test next? An active feature elicitation approach. Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 3498-3505, Stockholm, Sweden, July 2018.","Copyright ¬© 2025,",758
673,Data Science,Predrag Radivojac,"July 20th, 2018",Enumerating consistent sub-graphs of directed acyclic graphs: an insight into biomedical ontologies,https://www.ncbi.nlm.nih.gov/pubmed/29949985," Peng Y, Jiang Y, Radivojac P. Enumerating consistent sub-graphs of directed acyclic graphs: an insight into biomedical ontologies. Bioinformatics (2018) 34(13): i313-i322.","Abstract Motivation: Modern problems of concept annotation associate an object of interest (gene, individual, text document) with a set of interrelated textual descriptors (functions, diseases, topics), often organized in concept hierarchies or ontologies. Most ontology can be seen as directed acyclic graphs (DAGs), where nodes represent concepts and edges represent relational ties between these concepts. Given an ontology graph, each object can only be annotated by a consistent sub-graph; that is, a sub-graph such that if an object is annotated by a particular concept, it must also be annotated by all other concepts that generalize it. Ontologies therefore provide a compact representation of a large space of possible consistent sub-graphs; however, until now we have not been aware of a practical algorithm that can enumerate such annotation spaces for a given ontology. Results: We propose an algorithm for enumerating consistent sub-graphs of DAGs. The algorithm recursively partitions the graph into strictly smaller graphs until the resulting graph becomes a rooted tree (forest), for which a linear-time solution is computed. It then combines the tallies from graphs created in the recursion to obtain the final count. We prove the correctness of this algorithm, propose several practical accelerations, evaluate it on random graphs and then apply it to characterize four major biomedical ontologies. We believe this work provides valuable insights into the complexity of concept annotation spaces and its potential influence on the predictability of ontological annotation. Availability and implementation: https://github.com/shawn-peng/counting-consistent-sub-DAG. Supplementary information: Supplementary data are available at Bioinformatics online.",759
674,Data Science,Predrag Radivojac,"July 15th, 2017",When loss-of-function is loss of function: assessing mutational signatures and impact of loss-of-function genetic variants,https://www.ncbi.nlm.nih.gov/pubmed/28882004," Pagel KA, Pejaver V, Lin GN, Nam H, Mort M, Cooper DN, Sebat J, Iakoucheva LM, Mooney SD, Radivojac P. When loss-of-function is loss of function: assessing mutational signatures and impact of loss-of-function genetic variants. Bioinformatics (2017) 33(14): i389-i398.","Abstract Motivation: Loss-of-function genetic variants are frequently associated with severe clinical phenotypes, yet many are present in the genomes of healthy individuals. The available methods to assess the impact of these variants rely primarily upon evolutionary conservation with little to no consideration of the structural and functional implications for the protein. They further do not provide information to the user regarding specific molecular alterations potentially causative of disease. Results: To address this, we investigate protein features underlying loss-of-function genetic variation and develop a machine learning method, MutPred-LOF, for the discrimination of pathogenic and tolerated variants that can also generate hypotheses on specific molecular events disrupted by the variant. We investigate a large set of human variants derived from the Human Gene Mutation Database, ClinVar and the Exome Aggregation Consortium. Our prediction method shows an area under the Receiver Operating Characteristic curve of 0.85 for all loss-of-function variants and 0.75 for proteins in which both pathogenic and neutral variants have been observed. We applied MutPred-LOF to a set of 1142 de novo vari3ants from neurodevelopmental disorders and find enrichment of pathogenic variants in affected individuals. Overall, our results highlight the potential of computational tools to elucidate causal mechanisms underlying loss of protein function in loss-of-function variants. Availability and implementation: http://mutpred.mutdb.org. Contact: predrag@indiana.edu.",760
675,Data Science,Predrag Radivojac,"February 20th, 2017",Recovering true classifier performance in positive-unlabeled learning,https://arxiv.org/abs/1702.00518," Jain S, White M, Radivojac P. Recovering true classifier performance in positive-unlabeled learning. AAAI Conference on Artificial Intelligence, AAAI 2017, pp. 2066-2072, San Francisco, California, U.S.A., February 2017.","A common approach in positive-unlabeled learning is to train a classification model between labeled and unlabeled data. This strategy is in fact known to give an optimal classifier under mild conditions; however, it results in biased empirical estimates of the classifier performance. In this work, we show that the typically used performance measures such as the receiver operating characteristic curve, or the precision-recall curve obtained on such data can be corrected with the knowledge of class priors; i.e., the proportions of the positive and negative examples in the unlabeled data. We extend the results to a noisy setting where some of the examples labeled positive are in fact negative and show that the correction also requires the knowledge of the proportion of noisy examples in the labeled positives. Using state-of-the-art algorithms to estimate the positive class prior and the proportion of noise, we experimentally evaluate two correction approaches and demonstrate their efficacy on real-life data.",761
676,Data Science,Predrag Radivojac,"December 1st, 2016",Estimating the class prior and posterior from noisy positives and unlabeled data,https://papers.nips.cc/paper/6168-estimating-the-class-prior-and-posterior-from-noisy-positives-and-unlabeled-data," Jain S, White M, Radivojac P. Estimating the class prior and posterior from noisy positives and unlabeled data. Advances in Neural Information Processing Systems, NIPS 2016, pp. 2693-2701, Barcelona, Spain, December 2016.","Part of Advances in Neural Information Processing Systems 29 (NIPS 2016) Shantanu Jain, Martha White, Predrag Radivojac We develop a classification algorithm for estimating posterior distributions from positive-unlabeled data, that is robust to noise in the positive labels and effective for high-dimensional data. In recent years, several algorithms have been proposed to learn from positive-unlabeled data; however, many of these contributions remain theoretical, performing poorly on real high-dimensional data that is typically contaminated with noise. We build on this previous work to develop two practical classification algorithms that explicitly model the noise in the positive labels and utilize univariate transforms built on discriminative classifiers. We prove that these univariate transforms preserve the class prior, enabling estimation in the univariate space and avoiding kernel density estimation for high-dimensional data. The theoretical development and parametric and nonparametric algorithms proposed here constitute an important step towards wide-spread use of robust classification algorithms for positive-unlabeled data.",762
677,Data Science,Predrag Radivojac,"August 26th, 2016",The loss and gain of functional amino acid residues is a common mechanism causing human inherited disease.,https://www.ncbi.nlm.nih.gov/pubmed/27564311," Lugo-Martinez J, Pejaver V, Pagel KA, Jain S, Mort M, Cooper DN, Mooney SD, Radivojac P. The loss and gain of functional amino acid residues is a common mechanism causing human inherited disease. PLoS Comput. Biol. (2016) 12(8): e1005091.","Abstract Elucidating the precise molecular events altered by disease-causing genetic variants represents a major challenge in translational bioinformatics. To this end, many studies have investigated the structural and functional impact of amino acid substitutions. Most of these studies were however limited in scope to either individual molecular functions or were concerned with functional effects (e.g. deleterious vs. neutral) without specifically considering possible molecular alterations. The recent growth of structural, molecular and genetic data presents an opportunity for more comprehensive studies to consider the structural environment of a residue of interest, to hypothesize specific molecular effects of sequence variants and to statistically associate these effects with genetic disease. In this study, we analyzed data sets of disease-causing and putatively neutral human variants mapped to protein 3D structures as part of a systematic study of the loss and gain of various types of functional attribute potentially underlying pathogenic molecular alterations. We first propose a formal model to assess probabilistically function-impacting variants. We then develop an array of structure-based functional residue predictors, evaluate their performance, and use them to quantify the impact of disease-causing amino acid substitutions on catalytic activity, metal binding, macromolecular binding, ligand binding, allosteric regulation and post-translational modifications. We show that our methodology generates actionable biological hypotheses for up to 41% of disease-causing genetic variants mapped to protein structures suggesting that it can be reliably used to guide experimental validation. Our results suggest that a significant fraction of disease-causing human variants mapping to protein structures are function-altering both in the presence and absence of stability disruption.",763
678,Data Science,Mirek Riedewald,"June 17th, 2024",Finding Linear Explanations for a Given Ranking,https://doi.org/10.48550/arXiv.2406.11797," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2024). Finding Linear Explanations for a Given Ranking CoRR, abs/2406.11797. https://doi.org/10.48550/arXiv.2406.11797","Given a relation and a ranking of its tuples, but no information about the ranking function, we propose RankExplain to solve 2 types of problems: SAT asks if any linear scoring function can exactly reproduce the given ranking. OPT identifies the linear scoring function that minimizes position-based error, i.e., the total of the ranking-position differences over all tuples in the top-k. Our solution consists of linear programs that solve the problems exactly and can be implemented using MILP solvers. These solvers also support additional constraints on the scoring function, allowing the user to explore competing hypotheses through alternative scoring functions. We also discuss techniques for dealing with numerical imprecision and for improving performance and scalability. Experiments demonstrate that RankExplain can solve realistic problems. It is the first technique to provide exact solutions for OPT; and it is the fastest in producing exact solutions for SAT.",764
679,Data Science,Mirek Riedewald,"June 18th, 2023",Efficient Computation of Quantiles over Joins,https://doi.org/10.1145/3584372.3588670," Nikolaos Tziavelis, Nofar Carmeli, Wolfgang Gatterbauer, Benny Kimelfeld, Mirek Riedewald. (2023). Efficient Computation of Quantiles over Joins PODS, 303-315. https://doi.org/10.1145/3584372.3588670","Quantile Join Queries, abbreviated as %JQ, ask for the answer at a specified relative position. A recent dichotomy result rules out the existence of such an algorithm for a general family of queries and orders. We handle the intractable cases of sum by devising a deterministic approximation scheme that applies to every acyclic JQ.",765
680,Data Science,Mirek Riedewald,"October 1st, 2021",STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,https://doi.org/10.1109/TVCG.2021.3114756," S. di Bartolomeo, M. Riedewald, W. Gatterbauer and C. Dunne, ""STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,"" in IEEE Transactions on Visualization and Computer Graphics, vol. 28, no. 1, pp. 324-334, Jan. 2022, DOI: 10.1109/TVCG.2021.3114756.","Stratisfimal Layout is a modular integer-linear-programming formulation that can consider several important readability criteria simultaneously. It can be adapted to diverse use cases through its modularity. Individual features can be enabled and customized depending on the application. We provide open-source and documented implementations of the layout, both for web-based and desktop visualizations. The paper is published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 28 , Issue: 1 , January 2022 ) The full paper with all appendices, data, and source code is available at o.sf.io/qdyt9 with live examples at https://visdunneright. io/stratisfimal/.",766
681,Data Science,Mirek Riedewald,"June 20th, 2021",Tractable Orders for Direct Access to Ranked Answers of Conjunctive Queries,https://doi.org/10.1145/3452021.3458331," Carmeli, Nofar and Tziavelis, Nikolaos and Gatterbauer, Wolfgang and Kimelfeld, Benny and Riedewald, Mirek. ‚ÄúTractable Orders for Direct Access to Ranked Answers of Conjunctive Queries‚Äù. PODS 2021 , 2021. DOI: 10.1145/3452021.3458331","We study the question of when we can provide logarithmic-time direct access to the k-th answer to a Conjunctive Query (CQ) with a specified ordering over the answers, following a preprocessing step that constructs a data structure in time quasilinear in the size of the database. Specifically, we embark on the challenge of identifying the tractable answer orderings that allow for ranked direct access with such complexity guarantees. We begin with lexicographic orderings and give a decidable characterization (under conventional complexity assumptions) of the class of tractable lexicographic orderings for every CQ without self-joins. We then continue to the more general orderings by the sum of attribute weights and show for it that ranked direct access is tractable only in trivial cases. Hence, to better understand the computational challenge at hand, we consider the more modest task of providing access to only a single answer (i.e., finding the answer at a given position) - a task that we refer to as the selection problem. We indeed achieve a quasilinear-time algorithm for a subset of the class of full CQs without self-joins, by adopting a solution of Frederickson and Johnson to the classic problem of selection over sorted matrices. We further prove that none of the other queries in this class admit such an algorithm.",767
682,Data Science,Mirek Riedewald,"June 1st, 2020",QueryVis: Logic-based diagrams help users understand complicated SQL queries faster,https://doi.org/10.1145/3318464.3389767," Aristotelis Leventidis, Jiahui Zhang, Cody Dunne, Wolfgang Gatterbauer, H. V. Jagadish, and Mirek Ridewald. ‚ÄúQueryVis: Logic-based diagrams help users understand complicated SQL queries faster‚Äù. In: Proc. 2020 ACM SIGMOD International Conference on Management of  Data. SIGMOD. Preprint & supplemental material: osf.io/btszh. SIGMOD 2021 Most Reproducible Paper Award. 2020, pp. 2303‚Äì2318. doi: 10.1145/3318464.3389767.","Understanding the meaning of existing SQL queries is critical for code maintenance and reuse. Yet SQL can be hard to read, even for expert users or the original creator of a query. We conjecture that it is possible to capture the logical intent of queries in automatically-generated visual diagrams that can help users understand the meaning of queries faster and more accurately than SQL text alone. We present initial steps in that direction with visual diagrams that are based on the first-order logic foundation of SQL and can capture the meaning of deeply nested queries. Our diagrams build upon a rich history of diagrammatic reasoning systems in logic and were designed using a large body of human-computer interaction best practices: they are minimal in that no visual element is superfluous; they are unambiguous in that no two queries with different semantics map to the same visualization; and they extend previously existing visual representations of relational schemata and conjunctive queries in a natural way. An experimental evaluation involving 42 users on Amazon Mechanical Turk shows that with only a 2--3 minute static tutorial, participants could interpret queries meaningfully faster with our diagrams than when reading SQL alone. Moreover, we have evidence that our visual diagrams result in participants making fewer errors than with SQL. We believe that more regular exposure to diagrammatic representations of SQL can give rise to a pattern-based and thus more intuitive use and re-use of SQL. A full version of this paper with all appendices and supplemental material for the experimental study (stimuli, raw data, and analysis code) are available at https://osf.io/btszh.",768
683,Data Science,Christoph Riedl,"November 12th, 2024",When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions,https://doi.org/10.48550/arXiv.2411.07907," Allison Wan, Christoph Riedl, David Lazer. (2024). When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions CoRR, abs/2411.07907. https://doi.org/10.48550/arXiv.2411.07907","How does social network structure amplify or stifle behavior diffusion? Existing theory suggests that when social reinforcement makes the adoption of behavior more likely, it should spread more -- both farther and faster -- on clustered networks with redundant ties. Conversely, if adoption does not benefit from social reinforcement, then it should spread more on random networks without such redundancies. We develop a novel model of behavior diffusion with tunable probabilistic adoption and social reinforcement parameters to systematically evaluate the conditions under which clustered networks better spread a behavior compared to random networks. Using both simulations and analytical techniques we find precise boundaries in the parameter space where either network type outperforms the other or performs equally. We find that in most cases, random networks spread a behavior equally as far or farther compared to clustered networks despite strong social reinforcement. While there are regions in which clustered networks better diffuse contagions with social reinforcement, this only holds when the diffusion process approaches that of a deterministic threshold model and does not hold for all socially reinforced behaviors more generally. At best, clustered networks only outperform random networks by at least a five percent margin in 18\% of the parameter space, and when social reinforcement is large relative to the baseline probability of adoption.",769
684,Data Science,Christoph Riedl,"April 26th, 2024",Cooperation in the Gig Economy: Insights from Upwork Freelancers,https://doi.org/10.1145/3637314," Zachary Fulker, Christoph Riedl. (2024). Cooperation in the Gig Economy: Insights from Upwork Freelancers Proc. ACM Hum. Comput. Interact., 8, 1-20. https://doi.org/10.1145/3637314","Existing literature on online labor markets predominantly focuses on how freelancers individually complete tasks and projects. Our study examines freelancers' willingness to work collaboratively. We report results from a survey of 122 freelancers on a leading online labor market platform (Upwork) that examine freelancers' preferences for collaborative work arrangements, and that explore several antecedents of cooperative behaviors. We then test if actual cooperative behavior matches with freelancers' stated preferences through an incentivized social dilemma experiment. We find that respondents cooperate at a higher rate (85%) than reported in previous comparable studies (between 50-75%). This high rate of cooperation may be explained by an ingroup bias. Using a sequential mediation model, we demonstrate the importance of a sense of shared expectations and accountability for cooperation. We contribute to a better understanding of the potential for collaborative work on online labor market platforms by assessing if and what social factors and collective culture exist among freelancers. We discuss the implications of our results for platform designers by highlighting the importance of platform features that promote shared expectations and improve accountability. Overall, contrary to existing literature and predictions, our results suggest that freelancers in our sample display traits that are more consistent with belonging to a coherent group with a shared collective culture, rather than being anonymous actors in a transaction-based market.",770
685,Data Science,Christoph Riedl,"April 22nd, 2024",Competition and Collaboration in Crowdsourcing Communities: What happens when peers evaluate each other?,https://doi.org/10.48550/arXiv.2404.14141," Christoph Riedl, Tom Grad, Christopher Lettl. (2024). Competition and Collaboration in Crowdsourcing Communities: What happens when peers evaluate each other? CoRR, abs/2404.14141. https://doi.org/10.48550/arXiv.2404.14141","Crowdsourcing has evolved as an organizational approach to distributed problem solving and innovation. As contests are embedded in online communities and evaluation rights are assigned to the crowd, community members face a tension: they find themselves exposed to both competitive motives to win the contest prize and collaborative participation motives in the community. The competitive motive suggests they may evaluate rivals strategically according to their self-interest, the collaborative motive suggests they may evaluate their peers truthfully according to mutual interest. Using field data from Threadless on 38 million peer evaluations of more than 150,000 submissions across 75,000 individuals over 10 years and two natural experiments to rule out alternative explanations, we answer the question of how community members resolve this tension. We show that as their skill level increases, they become increasingly competitive and shift from using self-promotion to sabotaging their closest competitors. However, we also find signs of collaborative behavior when high-skilled members show leniency toward those community members who do not directly threaten their chance of winning. We explain how the individual-level use of strategic evaluations translates into important organizational-level outcomes by affecting the community structure through individuals' long-term participation. While low-skill targets of sabotage are less likely to participate in future contests, high-skill targets are more likely. This suggests a feedback loop between competitive evaluation behavior and future participation. These findings have important implications for the literature on crowdsourcing design, and the evolution and sustainability of crowdsourcing communities.",771
686,Data Science,Christoph Riedl,"April 2nd, 2024",Cash or Non-Cash? Unveiling Ideators‚Äô Incentive Preferences in Crowdsourcing Contests,https://doi.org/10.48550/arXiv.2404.01997," Christoph Riedl, Johann F√ºller, Katja Hutter, Gerard J. Tellis. (2024). Cash or Non-Cash? Unveiling Ideators' Incentive Preferences in Crowdsourcing Contests CoRR, abs/2404.01997. https://doi.org/10.48550/arXiv.2404.01997","Even though research has repeatedly shown that non-cash incentives can be effective, cash incentives are the de facto standard in crowdsourcing contests. In this multi-study research, we quantify ideators' preferences for non-cash incentives and investigate how allowing ideators to self-select their preferred incentive -- offering ideators a choice between cash and non-cash incentives -- affects their creative performance. We further explore whether the market context of the organization hosting the contest -- social (non-profit) or monetary (for-profit) -- moderates incentive preferences and their effectiveness. We find that individuals exhibit heterogeneous incentive preferences and often prefer non-cash incentives, even in for-profit contexts. Offering ideators a choice of incentives can enhance creative performance. Market context moderates the effect of incentives, such that ideators who receive non-cash incentives in for-profit contexts tend to exert less effort. We show that heterogeneity of ideators' preferences (and the ability to satisfy diverse preferences with suitably diverse incentive options) is a critical boundary condition to realizing benefits from offering ideators a choice of incentives. We provide managers with guidance to design effective incentives by improving incentive-preference fit for ideators.",772
687,Data Science,Christoph Riedl,"January 26th, 2024",Multimodality in Group Communication Research,https://doi.org/10.48550/arXiv.2401.15194," Robin Lange, Brooke Foucault Welles, Gyanendra Sharma, Richard J. Radke, Javier O. Garcia, Christoph Riedl. (2024). Multimodality in Group Communication Research CoRR, abs/2401.15194. https://doi.org/10.48550/arXiv.2401.15194","Team interactions are often multisensory, requiring members to pick up on verbal, visual, spatial and body language cues. Multimodal research, research that captures multiple modes of communication such as audio and visual signals, is therefore integral to understanding these multisensory group communication processes. This type of research has gained traction in biomedical engineering and neuroscience, but it is unclear the extent to which communication and management researchers conduct multimodal research. Our study finds that despite its' utility, multimodal research is underutilized in the communication and management literature's. This paper then covers introductory guidelines for creating new multimodal research including considerations for sensors, data integration and ethical considerations.",773
688,Data Science,Christoph Riedl,"August 22nd, 2023",Building Better Human-Agent Teams: Tradeoffs in Helpfulness and Humanness in Voice,https://doi.org/10.48550/arXiv.2308.11786," Samuel Westby, Richard J. Radke, Christoph Riedl, Brooke Foucault Welles. (2023). Building Better Human-Agent Teams: Tradeoffs in Helpfulness and Humanness in Voice CoRR, abs/2308.11786. https://doi.org/10.48550/arXiv.2308.11786","Voice assistants are increasingly prevalent, from personal devices to team environments. This study explores how voice type and contribution quality influence human-agent team performance and perceptions of anthropomorphism, animacy, intelligence, and trustworthiness. By manipulating both, we reveal mechanisms of perception and clarify ambiguity in previous work. Our results show that the human resemblance of a voice assistant's voice negatively interacts with the helpfulness of an agent's contribution to flip its effect on perceived anthropomorphism and perceived animacy. This means human teammates interpret the agent's contributions differently depending on its voice. Our study found no significant effect of voice on perceived intelligence, trustworthiness, or team performance. We find differences in these measures are caused by manipulating the helpfulness of an agent. These findings suggest that function matters more than form when designing agents for high-performing human-agent teams, but controlling perceptions of anthropomorphism and animacy can be unpredictable even with high human resemblance.",774
689,Data Science,Christoph Riedl,"March 27th, 2023",How creative versus technical constraints affect individual learning in an online innovation community,https://doi.org/10.48550/arXiv.2303.15163," Victor P. Seidel, Christoph Riedl. (2023). How creative versus technical constraints affect individual learning in an online innovation community CoRR, abs/2303.15163. https://doi.org/10.48550/arXiv.2303.15163","Online innovation communities allow for a search for novel solutions within a design space bounded by constraints. Past research has focused on the effect of creative constraints on individual projects, but less is known about how constraints affect learning from repeated design submissions and the effect of the technical constraints that are integral to online platforms. How do creative versus technical constraints affect individual learning in exploring a design space in online communities? We analyzed ten years of data from an online innovation community that crowdsourced 136,989 design submissions from 33,813 individuals. We leveraged data from two types of design contests-creatively constrained and unconstrained-running in parallel on the platform, and we evaluated a natural experiment where a platform change reduced technical constraints. We find that creative constraints lead to high rates of learning only if technical constraints are sufficiently relaxed. Our findings have implications for the management of creative design work and the downstream effects of the technical constraints of the information systems that support online innovation communities.",775
690,Data Science,Christoph Riedl,"January 20th, 2023",Who wants to cooperate-and why? Attitude and perception of crowd workers in online labor markets,https://doi.org/10.48550/arXiv.2301.08808," Zachary Fulker, Christoph Riedl. (2023). Who wants to cooperate-and why? Attitude and perception of crowd workers in online labor markets CoRR, abs/2301.08808. https://doi.org/10.48550/arXiv.2301.08808","Existing literature predominantly focuses on how freelancers individually complete tasks and projects. Our study examines freelancers' willingness to work collaboratively. We report results from a survey of 122 freelancers on a leading online labor market platform (Upwork) and examine freelancers' preferences for collaboration and explore several antecedents of cooperative behaviors. We then test if actual cooperative behavior matches with freelancers' stated preferences through an incentivized social dilemma experiment. We find that respondents cooperate at a higher rate (85%) than reported in previous comparable studies (between 50-75%). This high rate of cooperation may be explained by an ingroup bias. Using a sequential mediation model we demonstrate the importance of a sense of shared expectations and accountability for cooperation. We contribute to a better understanding of the potential for collaborative work on online labor market platforms by assessing if and what social factors and collective culture exist among freelancers. We discuss the implications of our results for platform designers by highlighting the importance of platform features that promote shared expectations and improve accountability. Overall, contrary to existing literature and predictions, our results suggest that freelancers in our sample display traits that are more consistent with belonging to a coherent group with a shared collective culture, rather than being anonymous actors in a transaction-based market.",776
691,Data Science,Christoph Riedl,"October 22nd, 2022",Spontaneous emergence of groups and signaling diversity in dynamic networks,https://doi.org/10.48550/arXiv.2210.17309," Zachary Fulker, Patrick Forber, Rory Smead, Christoph Riedl. (2022). Spontaneous emergence of groups and signaling diversity in dynamic networks CoRR, abs/2210.17309. https://doi.org/10.48550/arXiv.2210.17309","We study the coevolution of network structure and signaling behavior. We model agents who can preferentially associate with others in a dynamic network while they also learn to play a simple sender-receiver game. We have four major findings. First, signaling interactions in dynamic networks are sufficient to cause the endogenous formation of distinct signaling groups, even in an initially homogeneous population. Second, dynamic networks allow the emergence of novel {\em hybrid} signaling groups that do not converge on a single common signaling system but are instead composed of different yet complementary signaling strategies. We show that the presence of these hybrid groups promotes stable diversity in signaling among other groups in the population. Third, we find important distinctions in information processing capacity of different groups: hybrid groups diffuse information more quickly initially but at the cost of taking longer to reach all group members. Fourth, our findings pertain to all common interest signaling games, are robust across many parameters, and mitigate known problems of inefficient communication.",777
692,Data Science,Christoph Riedl,"August 24th, 2022",Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach,https://doi.org/10.48550/arXiv.2208.11660," Samuel Westby, Christoph Riedl. (2022). Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach CoRR, abs/2208.11660. https://doi.org/10.48550/arXiv.2208.11660","We develop a network of Bayesian agents that collectively model the mental states of teammates from the observed communication. Using a generative computational approach to cognition, we make two contributions. First, we show that our agent could generate interventions that improve the collective intelligence of a human-AI team beyond what humans alone would achieve. Second, we develop a real-time measure of human's theory of mind ability and test theories about human cognition. We use data collected from an online experiment in which 145 individuals in 29 human-only teams of five communicate through a chat-based system to solve a cognitive task. We find that humans (a) struggle to fully integrate information from teammates into their decisions, especially when communication load is high, and (b) have cognitive biases which lead them to underweight certain useful, but ambiguous, information. Our theory of mind ability measure predicts both individual- and team-level performance. Observing teams' first 25% of messages explains about 8% of the variation in final team performance, a 170% improvement compared to the current state of the art.",778
693,Data Science,Christoph Riedl,"May 7th, 2021","Online Mingling: Supporting Ad Hoc, Private Conversations at Virtual Conferences",https://doi.org/10.1145/3411764.3445776," Jaeyoon Song , Christoph Riedl, Thomas W. Malone. (2021). Online Mingling: Supporting Ad Hoc, Private Conversations at Virtual Conferences CHI, 340:1-340:10. https://doi.org/10.1145/3411764.3445776","Even though today‚Äôs videoconferencing systems are often very useful, these systems do not provide support for one of the most important aspects of in-person meetings: the ad hoc, private conversations that happen before, after, and during the breaks of scheduled events‚Äìthe proverbial hallway conversations. Here we describe our design of a simple system, called Minglr, which supports this kind of interaction by facilitating the matching of conversational partners. We describe two studies of this system‚Äôs use at two virtual conferences with over 450 total participants. Our results provide evidence for the usefulness of this capability, showing that, for example, 81% of people who used the system successfully thought that future virtual conferences should include a tool with similar functionality. We believe that similar functionality is likely to be widely implemented in many videoconferencing systems and to increase the feasibility and desirability of many kinds of remote work and socializing.",779
694,Data Science,Christoph Riedl,"April 7th, 2021",Avoiding the bullies: the resilience of cooperation among unequals,https://doi.org/10.1371/journal.pcbi.1008847," M. Foley, R. Smead, P. Forber, C. Riedl. (2021). ‚ÄúAvoiding the Bullies: Resilience of Cooperation among Unequals,‚Äù PLoS Computational Biology, 17(4): e1008847.","Can egalitarian norms or conventions survive the presence of dominant individuals who are ensured of victory in conflicts? We investigate the interaction of power asymmetry and partner choice in games of conflict over a contested resource. Partner choice counteracts the hyper dominance of bullies who are isolated in the network and eliminate the need for others to coordinate in a coalition. Our results have important implications: in our modeled scenario the rich do notalways get richer, the dominance of bullying individuals can be broken, and inequality in accrued resources can be eliminated. The study was published in the Journal of Game Theory and Behavior. The work provides new insight into potential sources of, and strategies for avoiding, resource inequality.",780
695,Data Science,Christoph Riedl,"January 11th, 2021",Spite is contagious in dynamic networks,https://doi.org/10.1038/s41467-020-20436-1," Z Fulker, P Forber, R Smead, C Riedl. ""Spite is contagious in dynamic networks"". Nature Communications 12, 260 (2021). DOI: 10.1038/s41467-020-20436-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",781
696,Data Science,Christoph Riedl,"March 21st, 2018",Conflict and convention in dynamic networks,http://rsif.royalsocietypublishing.org/content/15/140/20170835," Foley, M., Forber, P., Smead, R., Riedl, C. Journal of the Royal Society Interface, 15(140), 20170835, 2018","An important way to resolve games of conflict (snowdrift, hawk‚Äìdove, chicken) involves adopting a convention. We model the emergence of conventions as correlated equilibria in dynamic networks. Our results show that networks have the tendency to break the symmetry between the two conventional solutions in a strongly biased way.",782
697,Data Science,Cheng Tan,"September 16th, 2024",Scheduling Splittable Jobs on Configurable Machines,https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22," Matthew Casey, Rajmohan Rajaraman, David Stalfa, Cheng Tan . (2024). Scheduling Splittable Jobs on Configurable Machines APPROX/RANDOM, 22:1-22:20. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22","Abstract Motivated by modern architectures allowing for the partitioning of a GPU into hardware separated instances, we initiate the study of scheduling splittable jobs on configurable machines. We consider machines that can be configured into smaller instances, which we call blocks, in multiple ways, each of which is referred to as a configuration. We introduce the Configurable Machine Scheduling (cms) problem, where we are given n jobs and a set C of configurations. A schedule consists of a set of machines, each assigned some configuration in C with each block in the configuration assigned to process one job. The amount of a job‚Äôs demand that is satisfied by a block is given by an arbitrary function of the job and block. The objective is to construct a schedule using as few machines as possible. We provide a tight logarithmic factor approximation algorithm for this problem in the general setting, a factor (3 + Œµ) approximation algorithm for arbitrary Œµ > 0 when there are O(1) input configurations, and a polynomial time approximation scheme when both the number and size of configurations are O(1). Finally, we utilize a technique for finding conic integer combinations in fixed dimension to develop an optimal polynomial time algorithm in the case with O(1) jobs, O(1) blocks, and every configuration up to a given size.",783
698,Data Science,Cheng Tan,"July 10th, 2023",Encrypted Databases Made Secure Yet Maintainable,https://www.usenix.org/conference/osdi23/presentation/li-mingyu," Mingyu Li, Xuyang Zhao, Le Chen, Cheng Tan , Huorong Li, Sheng Wang , Zeyu Mi, Yubin Xia, Feifei Li , Haibo Chen . (2023). Encrypted Databases Made Secure Yet Maintainable OSDI, 117-133. https://www.usenix.org/conference/osdi23/presentation/li-mingyu",HEDB uses a dual-mode EDB design based on our analysis of DBA maintenance tasks. Execution Mode handles user queries by isolating DBAs from operators to prevent smuggle attacks. Maintenance Mode enables DBMS maintenance and operator troubleshooting through authenticated replay and anonymized replay.,784
699,Data Science,Cheng Tan,"August 24th, 2021",Building verified neural networks with specifications for systems,https://dl.acm.org/doi/10.1145/3476886.3477508," Cheng Tan, Yibo Zhu, and Chuanxiong Guo. 2021. Building verified neural networks with specifications for systems. Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on Systems. Association for Computing Machinery, New York, NY, USA, 42‚Äì47. DOI:https://doi.org/10.1145/3476886.3477508","Neural networks (NNs) are beneficial to many services, and we believe systems‚Äîsuch as OSes, databases, networked systems‚Äîare not an exception. But applying NNs in these critical systems is challenging: people have to risk getting unexpected outcomes from NNs because NN behaviors are not well-defined. To tame these undefined behaviors, we introduce a framework ouroboros, which builds verified NNs that follow user-defined specifications. These specifications comprise input and output constraints which characterize the behaviors of a NN. We do a case study on database learned indexes to demonstrate that training verified NN models is possible. Though many challenges remain, ouroboros enables us, for the first time, to apply NNs in critical systems with _confidence_.",785
700,Data Science,Cheng Tan,"July 1st, 2021",Bringing Decentralized Search to Decentralized Services,https://www.usenix.org/conference/osdi21/presentation/li," Mingyu Li and Jinhao Zhu and Tianxu Zhang and Cheng Tan and Yubin Xia and Sebastian Angel and Haibo Chen, ""Bringing Decentralized Search to Decentralized Services"", 15th {USENIX} Symposium on Operating Systems Design and Implementation , 2021, i USENIX Association",DeSearch uses trusted hardware to build a network of workers that execute a pipeline of small search engine tasks. DeSearch then introduces a witness mechanism to make sure the completed tasks can be reused across different pipelines. We implement DeSearch for two existing decentralized services that handle over 80 million records and 240 GBs of data. We show that DeSearch can scale horizontally with the number of workers and can process 128 million search queries per day.,786
701,Data Science,Cheng Tan,"November 4th, 2020",Cobra: Making transactional key-value stores verifiably serializable,https://dl.acm.org/doi/abs/10.5555/3488766.3488770," Cheng Tan, Changgeng Zhao, Shuai Mu, and Michael Walfish. 2020. COBRA: making transactional key-value stores verifiably serializable. Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation. Article 4, 63‚Äì80.","Today's cloud databases offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud databases are complicated black boxes, running in a different administrative domain from their clients. Thus, clients might like to know whether the databases are meeting their contract. To that end, we introduce cobra; cobra applies to transactional key-value stores. It is the first system that combines (a) black-box checking, of (b) serializability, while (c) scaling to real-world online transactional processing workloads. The core technical challenge is that the underlying search problem is computationally expensive. COBRA tames that problem by starting with a suitable SMT solver. COBRA then introduces several new techniques, including a new encoding of the validity condition; hardware acceleration to prune inputs to the solver; and a transaction segmentation mechanism that enables scaling and garbage collection. Cobra imposes modest overhead on clients, improves over baselines by 10√ó in verification cost, and (unlike the baselines) supports continuous verification. Our artifact can handle 2000 transactions/sec, equivalent to 170M/day.",787
702,Data Science,Cheng Tan,"December 19th, 2019",Detecting Incorrect Behavior of Cloud Databases as an Outsider,http://arxiv.org/abs/1912.09018," Cheng Tan , Changgeng Zhao, Shuai Mu , Michael Walfish. (2019). Detecting Incorrect Behavior of Cloud Databases as an Outsider CoRR, abs/1912.09018. http://arxiv.org/abs/1912.09018","Cloud DBs offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud DBs are complicated black boxes, running in a different administrative domain from their clients; thus, clients might like to know whether the DBs are meeting their contract. A core difficulty is that the underlying problem here, namely verifying serializability, is NP-complete. Nevertheless, we hypothesize that on real-world workloads, verifying serializability is tractable, and we treat the question as a systems problem, for the first time. We build Cobra, which tames the underlying search problem by blending a new encoding of the problem, hardware acceleration, and a careful choice of a suitable SMT solver. cobra also introduces a technique to address the challenge of garbage collection in this context. cobra improves over natural baselines by at least 10x in the problem size it can handle, while imposing modest overhead on clients.",788
703,Data Science,Cheng Tan,"February 26th, 2019",Netbouncer: Active device and link failure localization in data center networks,https://dl.acm.org/doi/10.5555/3323234.3323283," Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng, Dongming Bi, and Dong Xiang. 2019. Netbouncer: active device and link failure localization in data center networks. In Proceedings of the 16th USENIX Conference on Networked Systems Design and Implementation (NSDI'19). USENIX Association, USA, 599‚Äì613.","The availability of data center services is jeopardized by various network incidents. One of the biggest challenges for network incident handling is to accurately localize the failures, among millions of servers and tens of thousands of network devices. In this paper, we propose NetBouncer, a failure localization system that leverages the IP-in-IP technique to actively probe paths in a data center network. NetBouncer provides a complete failure localization framework which is capable of detecting both device and link failures. It further introduces an algorithm for high accuracy link failure inference that is resilient to real-world data inconsistency by integrating both our troubleshooting domain knowledge and machine learning techniques. NetBouncer has been deployed in Microsoft Azure's data centers for three years. And in practice, it produced no false positives and only a few false negatives so far.",789
704,Data Science,Cheng Tan,"January 1st, 2019",Taming Distrust in the Decentralized Internet with PIXIU,http://arxiv.org/abs/1901.06095," Yubin Xia, Qingyuan Liu, Cheng Tan , Jing Leng, Shangning Xu, Binyu Zang, Haibo Chen . (2019). Taming Distrust in the Decentralized Internet with PIXIU CoRR, abs/1901.06095. http://arxiv.org/abs/1901.06095","Decentralized Internet is booming. People are fascinated by its promise that users can truly own their data. However, in a decentralized Internet, completing a task usually involves multiple nodes with mutual distrust. Such distrust might eventually become a major obstacle for the growth of the decentralized Internet. In this paper, we analyze the distrust using a simple model and highlight the properties required to faithfully accomplish one task in a decentralized Internet. We also introduce our draft solution -- PIXIU, a framework to mitigate the distrust among different nodes. In PIXIU, we design and utilize trust-{\lambda} and decentralized executor to achieve the above-needed properties.",790
705,Data Science,Cheng Tan,"October 14th, 2017","The efficient server audit problem, deduplicated re-execution, and the web",https://dl.acm.org/doi/10.1145/3132747.3132760," Cheng Tan, Lingfan Yu, Joshua B. Leners, and Michael Walfish. 2017. The Efficient Server Audit Problem, Deduplicated Re-execution, and the Web. In Proceedings of the 26th Symposium on Operating Systems Principles (SOSP '17). Association for Computing Machinery, New York, NY, USA, 546‚Äì564. DOI:https://doi.org/10.1145/3132747.3132760","You put a program on a concurrent server, but you don't trust the server; later, you get a trace of the actual requests that the server received from its clients and the responses that it delivered. You separately get logs from the server; these are untrusted. How can you use the logs to efficiently verify that the responses were derived from running the program on the requests? This is the Efficient Server Audit Problem, which abstracts real-world scenarios, including running a web application on an untrusted provider. We give a solution based on several new techniques, including simultaneous replay and efficient verification of concurrent executions. We implement the solution for PHP web applications. For several applications, our verifier achieves 5.6-10.9x speedup versus simply re-executing, with <10% overhead for the server.",791
706,Data Science,Olga Vitek,"June 30th, 2023",Optimal adjustment sets for causal query estimation in partially observed biomolecular networks,https://doi.org/10.1093/bioinformatics/btad270," Sara Mohammad Taheri, Vartika Tewari, Rohan Kapre, Ehsan Rahiminasab, Karen Sachs, Charles Tapley Hoyt, Jeremy Zucker, Olga Vitek. (2023). Optimal adjustment sets for causal query estimation in partially observed biomolecular networks Bioinform., 39, 494-503. https://doi.org/10.1093/bioinformatics/btad270","Causal query estimation in biomolecular networks commonly selects a ‚Äòvalid adjustment set‚Äô, i.e. a subset of network variables that eliminates the bias of the estimator. A same query may have multiple valid adjustment sets, each with a different variance. When networks are partially observed, current methods use graph-based criteria to find an adjustment set that minimizes asymptotic variance. Unfortunately, many models that share the same graph topology, and therefore same functional dependencies, may differ in the processes that generate the observational data. In these cases, the topology-based criteria fail to distinguish the variances of the adjustment sets. This deficiency can lead to sub-optimal adjustment sets, and to miss-characterization of the effect of the intervention. We propose an approach for deriving ‚Äòoptimal adjustment sets‚Äô that takes into account the nature of the data, bias and finite-sample variance of the estimator, and cost. It empirically learns the data generating processes from historical experimental data, and characterizes the properties of the estimators by simulation. We demonstrate the utility of the proposed approach in four biomolecular Case studies with different topologies and different data generation processes. The implementation and reproducible Case studies are at https://github.com/srtaheri/OptimalAdjustmentSet . Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",792
707,Data Science,Olga Vitek,"February 6th, 2023",A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images,https://doi.org/10.1093/bioinformatics/btad067," Dan Guo, Melanie Christine F√∂ll, Kylie A. Bemis, Olga Vitek. (2023). A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images Bioinform., 39. https://doi.org/10.1093/bioinformatics/btad067","Motivation Mass Spectrometry Imaging (MSI) analyzes complex biological samples such as tissues. It simultaneously characterizes the ions present in the tissue in the form of mass spectra, and the spatial distribution of the ions across the tissue in the form of ion images. Unsupervised clustering of ion images facilitates the interpretation in the spectral domain, by identifying groups of ions with similar spatial distributions. Unfortunately, many current methods for clustering ion images ignore the spatial features of the images, and are therefore unable to learn these features for clustering purposes. Alternative methods extract spatial features using deep neural networks pre-trained on natural image tasks; however, this is often inadequate since ion images are substantially noisier than natural images. Results We contribute a deep clustering approach for ion images that accounts for both spatial contextual features and noise. In evaluations on a simulated dataset and on four experimental datasets of different tissue types, the proposed method grouped ions from the same source into a same cluster more frequently than existing methods. We further demonstrated that using ion image clustering as a pre-processing step facilitated the interpretation of a subsequent spatial segmentation as compared to using either all the ions or one ion at a time. As a result, the proposed approach facilitated the interpretability of MSI data in both the spectral domain and the spatial domain. Availabilityand implementation The data and code are available at https://github.com/DanGuo1223/mzClustering . Supplementary information Supplementary data are available at Bioinformatics online. Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide Open in new tab Download slide",793
708,Data Science,Olga Vitek,"August 12th, 2022",Effective Use of Likert Scales in Visualization Evaluations: A Systematic Review,https://doi.org/10.1111/cgf.14521," Laura South, David Saffo, Olga Vitek, Cody Dunne, Michelle A. Borkin. (2022). Effective Use of Likert Scales in Visualization Evaluations: A Systematic Review Comput. Graph. Forum, 41, 43-55. https://doi.org/10.1111/cgf.14521","Abstract Likert scales are often used in visualization evaluations to produce quantitative estimates of subjective attributes, such as ease of use or aesthetic appeal. However, the methods used to collect, analyze, and visualize data collected with Likert scales are inconsistent among evaluations in visualization papers. In this paper, we examine the use of Likert scales as a tool for measuring subjective response in a systematic review of 134 visualization evaluations published between 2009 and 2019. We find that papers with both objective and subjective measures do not hold the same reporting and analysis standards for both aspects of their evaluation, producing less rigorous work for the subjective qualities measured by Likert scales. Additionally, we demonstrate that many papers are inconsistent in their interpretations of Likert data as discrete or continuous and may even sacrifice statistical power by applying nonparametric tests unnecessarily. Finally, we identify instances where key details about Likert item construction with the potential to bias participant responses are omitted from evaluation methodology reporting, inhibiting the feasibility and reliability of future replication studies. We summarize recommendations from other fields for best practices with Likert data in visualization evaluations, based on the results of our survey. A full copy of this paper and all supplementary material are available at https://osf.io/exbz8/ .",794
709,Data Science,Alessandro Vespignani,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",795
710,Data Science,Alessandro Vespignani,"August 4th, 2023",Deep Bayesian Active Learning for Accelerating Stochastic Simulation,https://doi.org/10.1145/3580305.3599300," Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An Ma, Rose Yu. (2023). Deep Bayesian Active Learning for Accelerating Stochastic Simulation KDD, 2559-2569. https://doi.org/10.1145/3580305.3599300","Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic models are computationally expensive at fine-grained resolution. While deep surrogate models can speed up the simulations, doing so for stochastic simulations and with active learning approaches is an underexplored area. We propose Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP consists of two components, a spatiotemporal surrogate model built upon Neural Process (NP) family and an acquisition function for active learning. For surrogate modeling, we develop Spatiotemporal Neural Process (STNP) to mimic the simulator dynamics. For active learning, we propose a novel acquisition function, Latent Information Gain (LIG), calculated in the latent space of NP based models. We perform a theoretical analysis and demonstrate that LIG reduces sample complexity compared with random sampling in high dimensions. We also conduct empirical studies on three complex spatiotemporal simulators for reaction diffusion, heat flow, and infectious disease. The results demonstrate that STNP outperforms the baselines in the offline learning setting and LIG achieves the state-of-the-art for Bayesian active learning.",796
711,Data Science,Alessandro Vespignani,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",797
712,Data Visualization,Enrico Bertini,"February 1st, 2024",Visual Exploration of Machine Learning Model Behavior With Hierarchical Surrogate Rule Sets,https://doi.org/10.1109/TVCG.2022.3219232," Jun Yuan, Brian Barr, Kyle Overton, Enrico Bertini. (2024). Visual Exploration of Machine Learning Model Behavior With Hierarchical Surrogate Rule Sets IEEE Trans. Vis. Comput. Graph., 30, 1470-1488. https://doi.org/10.1109/TVCG.2022.3219232","Hierarchical Surrogate Rules (HSR) is an algorithm that generates hierarchical rules based on user-defined parameters. We also contribute SuRE, a visual analytics (VA) system that integrates HSR and an interactive surrogate rule visualization, the Feature-Aligned Tree. We evaluate the algorithm in terms of parameter sensitivity, time performance, and comparison with surrogate decision trees and find that it scales reasonably well and overcomes the shortcomings of surrogate decision Trees. We discuss many interesting findings, including a rule analysis task characterization, that can be used for visualization design and future research. The paper is published in: IEEE Transactions on Visualization and Computer Graphics ( Volume: 30 , Issue: 2 , February 2024 )",798
713,Data Visualization,Enrico Bertini,"August 25th, 2023","The Arrangement of Marks Impacts Afforded Messages: Ordering, Partitioning, Spacing, and Coloring in Bar Charts",https://doi.org/10.48550/arXiv.2308.13321," Racquel Fygenson, Steven Franconeri, Enrico Bertini. (2023). The Arrangement of Marks Impacts Afforded Messages: Ordering, Partitioning, Spacing, and Coloring in Bar Charts CoRR, abs/2308.13321. https://doi.org/10.48550/arXiv.2308.13321","Data visualizations present a massive number of potential messages to an observer. One might notice that one group's average is larger than another's, or that a difference in values is smaller than a difference between two others, or any of a combinatorial explosion of other possibilities. The message that a viewer tends to notice--the message that a visualization 'affords'--is strongly affected by how values are arranged in a chart, e.g., how the values are colored or positioned. Although understanding the mapping between a chart's arrangement and what viewers tend to notice is critical for creating guidelines and recommendation systems, current empirical work is insufficient to lay out clear rules. We present a set of empirical evaluations of how different messages--including ranking, grouping, and part-to-whole relationships--are afforded by variations in ordering, partitioning, spacing, and coloring of values, within the ubiquitous case study of bar graphs. In doing so, we introduce a quantitative method that is easily scalable, reviewable, and replicable, laying groundwork for further investigation of the effects of arrangement on message affordances across other visualizations and tasks. Pre-registration and all supplemental materials are available atthis https URLandthis https URL.",799
714,Data Visualization,Enrico Bertini,"July 21st, 2023",SliceLens: Guided Exploration of Machine Learning Datasets,https://doi.org/10.1145/3597465.3605217," Daniel Kerrigan, Enrico Bertini. (2023). SliceLens: Guided Exploration of Machine Learning Datasets HILDA@SIGMOD, 1:1-1:7. https://doi.org/10.1145/3597465.3605217","SliceLens is a tool for exploring labeled, tabular, machine learning datasets. To explore a dataset, the user selects combinations of features in the dataset that they are interested in. The tool splits those features into bins and then visualizes the label distributions for the subsets of data created by the intersections of the bins. SliceLens guides the user in determining which feature combinations to explore. Guidance is based on a user-selected rating metric, which assigns a score to the subsets created by a given combination of features. The purpose of the metrics are to detect interesting patterns in the subsets, such as subsets that have high label purity or an uneven distribution of errors. SliceLens uses the metrics to guide the user towards combinations of features that create potentially interesting subsets in two ways. First, SliceLens assigns a rating to each feature based on the subsets that would be created by selecting that feature. This incremental guidance can help the user determine which feature to select next. Second, SliceLens can suggest combinations of features ranked according to the chosen metric, which the user can then cycle through.",800
715,Data Visualization,Michelle Borkin,"October 27th, 2024",Design considerations for photosensitivity warnings in visual media,https://doi.org/10.1145/3663548.3675643," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Design considerations for photosensitivity warnings in visual media ASSETS, 68:1-68:12. https://doi.org/10.1145/3663548.3675643","When digital content is tested for photosensitive safety and is found to contain seizure-inducing strobes or flashing lights, warnings about photosensitive risk are usually shown to the user prior to viewing the content. These photosensitivity warnings are an important accessibility feature for people with photosensitive epilepsy, allowing them to avoid interacting with content that may trigger seizures. However, little is known about how these warnings should be structured to maximize effectiveness in helping with people PSE navigate visual media safely. The design space for photosensitivity warnings is vast and includes questions such as what details to include about strobing light sequences or the content itself, where to place warnings within an interface, and what methods to use to extract information about the strobing light sequences (e.g., crowdsourced or automated methods). In this work, we contribute a thematic analysis of crowdsourced warnings drawn from the DoesTheDogDie online forum and an interview study with five people who have been diagnosed with photosensitive epilepsy about design considerations for photosensitivity warnings on digital platforms. To guide our interviews, we assembled examples of both crowdsourced and automated warnings about seizure-inducing content in films. Automated warnings were presented in the form of a high fidelity sketch demonstrating what an automated system for photosensitivity warnings might look like when deployed by a film streaming platform. We contribute design suggestions for the structure, content, and data sourcing of photosensitivity warnings for visual media based on the findings of our interviews. The results of this work will enable more effective and informative photosensitivity warnings across all forms of digital visual media.",801
716,Data Visualization,Michelle Borkin,"May 11th, 2024",Barriers to Photosensitive Accessibility in Virtual Reality,https://doi.org/10.1145/3613904.3642635," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Barriers to Photosensitive Accessibility in Virtual Reality CHI, 58:1-58:13. https://doi.org/10.1145/3613904.3642635","Virtual reality (VR) systems have grown in popularity as an immersive modality for daily activities such as gaming, socializing, and working. However, this technology is not always accessible for people with photosensitive epilepsy (PSE) who may experience seizures or other adverse symptoms when exposed to certain light stimuli (e.g., flashes or strobes). How can VR be made more inclusive and safer for people with PSE? In this paper, we report on a series of semi-structured interviews about current perceptions of accessibility in VR among people with PSE. We identify 12 barriers to accessibility that fall into four categories: physical VR equipment, VR interfaces and content, specific VR applications, and individual differences in sensitivity. Our findings allow researchers and practitioners to better understand the meaning of photosensitive accessibility in the context of VR, and provide a step towards enabling people with PSE to enjoy the benefits offered by immersive technology.",802
717,Data Visualization,Michelle Borkin,"December 20th, 2023",Augmented Reality as a Visualization Technique for Scholarly Publications in Astronomy: An Empirical Evaluation,https://doi.org/10.1109/VIS54172.2023.00016," Jane L. Adams, Laura South, Arzu √á√∂ltekin, Alyssa A. Goodman, Michelle A. Borkin. (2023). Augmented Reality as a Visualization Technique for Scholarly Publications in Astronomy: An Empirical Evaluation IEEE VIS (Short Papers), 36-40. https://doi.org/10.1109/VIS54172.2023.00016","We present a mixed methods user study evaluating augmented reality (AR) as a visualization technique for use in astronomy journal publications. We evaluate two AR approaches (one traditional tabletop projection and the other with a ‚Äòtangible‚Äô aid) as spatial 3D visualization techniques, as compared to a baseline 3D rendering on a phone. We identify a significant difference in mental and physical workload between the two AR conditions in men and women. The confluence of quantitative and qualitative results suggest a tension between workload and engagement when comparing non-AR and AR technologies.",803
718,Data Visualization,Michelle Borkin,"April 19th, 2023",Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings,https://doi.org/10.1145/3544549.3585649," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2023). Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings CHI Extended Abstracts, 111:1-111:7. https://doi.org/10.1145/3544549.3585649","Films often include sequences of flashing lights for visual effect that may inadvertently trigger seizures when viewed by individuals with photosensitive epilepsy (PSE). Warnings about photosensitive risk in films can help people with PSE make informed decisions about their personal safety, but little is known about how to design such warnings and what information to include. To better understand the design space for photosensitive risk warnings, we conducted a qualitative analysis of 265 crowdsourced warnings about flashing lights in films. We find that the crowdsourced warnings were tightly coupled to the scenic and temporal contexts of the films being described, unlike current practices for labeling media with potentially seizure-inducing sequences using general warnings that are not specific to the media at hand. As technological capabilities for detecting seizure-inducing sequences continue to improve, understanding how to effectively communicate this information to individuals with photosensitive epilepsy is critical for ensuring accessibility.",804
719,Data Visualization,Michelle Borkin,"January 1st, 2023",GenoREC: A Recommendation System for Interactive Genomics Data Visualization,https://doi.org/10.1109/TVCG.2022.3209407," Aditeya Pandey, Sehi L'Yi, Qianwen Wang, Michelle A. Borkin, Nils Gehlenborg. (2023). GenoREC: A Recommendation System for Interactive Genomics Data Visualization IEEE Trans. Vis. Comput. Graph., 29, 570-580. https://doi.org/10.1109/TVCG.2022.3209407","GenoREC enables genomics analysts to select effective visualizations based on a description of their data and analysis tasks. We present the recommendation model that uses a knowledge-based method for choosing appropriate visualizations. We also present the results of two user studies demonstrating that GenoREC recommends visualizations that are both accepted by domain experts and suited to address the given genomics analysis problem. The study was published in the IEEE Transactions on Visualization and Computer Graphics ( Volume: 29 , Issue: 1 , January 2023) and is available for download at: http://www.IEEE.org/tv CG/vcs/article/29/1/29.3209407.",805
720,Data Visualization,Michelle Borkin,"January 1st, 2023",Photosensitive Accessibility for Interactive Data Visualizations,https://doi.org/10.1109/TVCG.2022.3209359," Laura South, Michelle A. Borkin. (2023). Photosensitive Accessibility for Interactive Data Visualizations IEEE Trans. Vis. Comput. Graph., 29, 374-384. https://doi.org/10.1109/TVCG.2022.3209359","Accessibility guidelines place restrictions on the use of animations and interactivity on webpages to lessen the likelihood of webpages inadvertently producing sequences with flashes, patterns, or color changes. The impact of animation and interaction in visualizations on users with photosensitivity, who may experience seizures in response to certain visual stimuli, has not been considered. We introduce a theoretical model defining the degree of control visualization designers have over three determinants of photosensitive risk in potentially seizure-inducing sequences. We then use this model to propose a new method of testing for photossensitive risk that focuses on elements of visualizations that are subject to greater authorial control - and are therefore more robust to variations in the individual user.",806
721,Data Visualization,Michelle Borkin,"March 5th, 2021",A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset,https://doi.org/10.1109/TVCG.2021.3064037," Aditeya Pandey, Uzma Haque Syeda, Chaitya Shah, John A. Guerra-Gomez, Michelle A. Borkin. (2022). A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset IEEE Trans. Vis. Comput. Graph., 28, 3563-3584. https://doi.org/10.1109/TVCG.2021.3064037",No prior efforts exist to collect and abstractly define tree visualization tasks. We present a literature review of tree visualization articles and generate a curated dataset of over 200 tasks. All tasks in the dataset were abstracted with the novel typology extension and analyzed to gain a better understanding of the state of tree visualizations. We also contribute a novel extension of the Multi-Level Task Typology to include more specificity to support tree-specific tasks. The Supplemental Material can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2021.,807
722,Data Visualization,Michelle Borkin,"November 18th, 2020",Scalable Scalable Vector Graphics: Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering,https://osf.io/ypxz2/," Schwab, M., Saffo, D., Dunne, C., Tompkin, J., & Borkin, M. (2020, November 18). Scalable Scalable Vector Graphics: Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering. https://doi.org/10.31219/osf.io/ypxz2",For full functionality of this site it is necessary to enable JavaScript. Here are instructions for enabling JavaScript in your web browser . Copyright ¬© 2011-2025 Center for Open Science | Terms¬†of¬†Use | Privacy¬†Policy | Status | API TOP Guidelines | Reproducibility¬†Project: Psychology | Reproducibility¬†Project: Cancer Biology,808
723,Data Visualization,Michelle Borkin,"July 8th, 2020",Data Comets: Designing a Visualization Tool for Analyzing Autonomous Aerial Vehicle Logs with Grounded Evaluation,https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.13994," Saffo, David, et al. ""Data Comets: Designing a Visualization Tool for Analyzing Autonomous Aerial Vehicle Logs with Grounded Evaluation."" Computer Graphics Forum. Vol. 39. No. 3. 2020.","Abstract Autonomous unmanned aerial vehicles are complex systems of hardware, software, and human input. Understanding this complexity is key to their development and operation. Information visualizations already exist for exploring flight logs but comprehensive analyses currently require several disparate and custom tools. This design study helps address the pain points faced by autonomous unmanned aerial vehicle developers and operators. We contribute: a spiral development process model for grounded evaluation visualization development focused on progressively broadening target user involvement and refining user goals; a demonstration of the model as part of developing a deployed and adopted visualization system; a data and task abstraction for developers and operators performing post-flight analysis of autonomous unmanned aerial vehicle logs; the design and implementation of D ata C omets , an open-source and web-based interactive visualization tool for post-flight log analysis incorporating temporal, geospatial, and multivariate data; and the results of a summative evaluation of the visualization system and our abstractions based on in-the-wild usage. A free copy of this paper and source code are available at osf.io/h4p7g",809
724,Data Visualization,Michelle Borkin,"May 9th, 2019",Evaluating Pan and Zoom Timelines and Sliders,https://dl.acm.org/citation.cfm?id=3300786," Michail Schwab, Sicheng Hao, Olga Vitek, James Tompkin, Jeff Huang, and Michelle A. Borkin. 2019. Evaluating Pan and Zoom Timelines and Sliders. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19). ACM, New York, NY, USA, Paper 556, 12 pages. DOI: https://doi.org/10.1145/3290605.3300786","Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source.",810
725,Data Visualization,Michael Correll,"January 24th, 2025",The Many Tendrils of the Octopus Map,https://doi.org/10.48550/arXiv.2501.14903," Eduardo Puerta, Shani Spivak, Michael Correll. (2025). The Many Tendrils of the Octopus Map CoRR, abs/2501.14903. https://doi.org/10.48550/arXiv.2501.14903","Conspiratorial thinking can connect many distinct or distant ills to a central cause. This belief has visual form in the octopus map: a map where a central force (for instance a nation, an ideology, or an ethnicity) is depicted as a literal or figurative octopus, with extending tendrils. In this paper, we explore how octopus maps function as visual arguments through an analysis of historical examples as well as a through a crowd-sourced study on how the underlying data and the use of visual metaphors contribute to specific negative or conspiratorial interpretations. We find that many features of the data or visual style can lead to ""octopus-like"" thinking in visualizations, even without the use of an explicit octopus motif. We conclude with a call for a deeper analysis of visual rhetoric, and an acknowledgment of the potential for the design of data visualizations to contribute to harmful or conspiratorial thinking.",811
726,Data Visualization,Michael Correll,"November 25th, 2024",Tasks and Telephones: Threats to Experimental Validity due to Misunderstandings of Visualisation Tasks and Strategies Position Paper,https://doi.org/10.1109/BELIV64461.2024.00009," Abhraneel Sarma, Sheng Long, Michael Correll, Matthew Kay . (2024). Tasks and Telephones: Threats to Experimental Validity due to Misunderstandings of Visualisation Tasks and Strategies Position Paper BELIV, 33-40. https://doi.org/10.1109/BELIV64461.2024.00009","The effectiveness of a visualisation may be intrinsically related to, and difficult to distinguish from, individual-level factors such as visualisation literacy. We argue that aspects of the study design that are often neglected or overlooked can have a big role in the results of a study. We describe how such challenges apply to experiments that we use to evaluate visualisations, and discuss a set of considerations for designing studies in the future. We also argue that onboarding of participants, tutorials, training, etc. can potentially impact the conclusions that the researchers can draw from the study.",812
727,Data Visualization,Michael Correll,"October 26th, 2023",Heuristics for Supporting Cooperative Dashboard Design,https://doi.org/10.1109/TVCG.2023.3327158," Vidya Setlur, Michael Correll, Arvind Satyanarayan, Melanie Tory. (2024). Heuristics for Supporting Cooperative Dashboard Design IEEE Trans. Vis. Comput. Graph., 30, 370-380. https://doi.org/10.1109/TVCG.2023.3327158","Dashboards are no longer mere static displays of metrics. Through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines are often unable to account for this expanded scope as they largely focus on best practices for visual design. Our approach suggests several compelling directions for future work. including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement. and extending cooperative principles to other analytical workflows. The study was published in the IEEE Transactions on Visualization and Computer Graphics ( Volume: 30 , Issue: 1 , January 2024 ) and is available online at: 10.1109/TVCG.2023.",813
728,Data Visualization,Michael Correll,"July 18th, 2020",VisuaLint: Sketchy In Situ Annotations of Chart Construction Errors,https://doi.org/10.1111/cgf.13975," Aspen K. Hopkins, Michael Correll, Arvind Satyanarayan. (2020). VisuaLint: Sketchy In Situ Annotations of Chart Construction Errors Comput. Graph. Forum, 39, 219-228. https://doi.org/10.1111/cgf.13975","Abstract Chart construction errors, such as truncated axes or inexpressive visual encodings, can hinder reading a visualization, or worse, imply misleading facts about the underlying data. These errors can be caught by critical readings of visualizations, but readers must have a high level of data and design literacy and must be paying close attention. To address this issue, we introduce VisuaLint: a technique for surfacing chart construction errors in situ. Inspired by the ubiquitous red wavy underline that indicates spelling mistakes, visualization elements that contain errors (e.g., axes and legends) are sketchily rendered and accompanied by a concise annotation. VisuaLint is unobtrusive ‚Äî it does not interfere with reading a visualization ‚Äî and its direct display establishes a close mapping between erroneous elements and the expression of error. We demonstrate five examples of VisualLint and present the results of a crowdsourced evaluation (N = 62) of its efficacy. These results contribute an empirical baseline proficiency for recognizing chart construction errors, and indicate near-universal difficulty in error identification. We find that people more reliably identify chart construction errors after being shown examples of VisuaLint, and prefer more verbose explanations for unfamiliar or less obvious flaws.",814
729,Data Visualization,Cody Dunne,"May 3rd, 2024",Evaluating Graph Layout Algorithms: A Systematic Review of Methods and Best Practices,https://doi.org/10.1111/cgf.15073," Sara Di Bartolomeo, Tarik Crnovrsanin, David Saffo, Eduardo Puerta, Connor Wilson, Cody Dunne. (2024). Evaluating Graph Layout Algorithms: A Systematic Review of Methods and Best Practices Comput. Graph. Forum, 43. https://doi.org/10.1111/cgf.15073",Evaluations are essential tools for validating the performance and applicability of graph and network layout algorithms. It is often difficult to compare layout algorithms without first implementing them and then running your own evaluation. The paper's objective is to provide a valuable resource for readers to understand and effectively apply various evaluation methods.,815
730,Data Visualization,Cody Dunne,"July 5th, 2023",Investigating the Visual Utility of Differentially Private Scatterplots,https://doi.org/10.1109/TVCG.2023.3292391," Liudas Panavas, Tarik Crnovrsanin, Jane Lydia Adams, Jonathan R. Ullman, Ali Sarvghad, Melanie Tory, Cody Dunne. (2024). Investigating the Visual Utility of Differentially Private Scatterplots IEEE Trans. Vis. Comput. Graph., 30, 5370-5385. https://doi.org/10.1109/TVCG.2023.3292391","Increasingly, visualization practitioners are working with, using, and studying private data. Differential privacy algorithms do this by aggregating data statistics with noise. This now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.",816
731,Data Visualization,Cody Dunne,"August 12th, 2022",Six methods for transforming layered hypergraphs to apply layered graph layout algorithms,https://doi.org/10.1111/cgf.14538," Sara Di Bartolomeo, Alexis Pister, Paolo Buono, Catherine Plaisant, Cody Dunne, Jean-Daniel Fekete. (2022). Six methods for transforming layered hypergraphs to apply layered graph layout algorithms Comput. Graph. Forum, 41, 259-270. https://doi.org/10.1111/cgf.14538","Abstract Hypergraphs are a generalization of graphs in which edges (hyperedges) can connect more than two vertices‚Äîas opposed to ordinary graphs where edges involve only two vertices. Hypergraphs are a fairly common data structure but there is little consensus on how to visualize them. To optimize a hypergraph drawing for readability, we need a layout algorithm. Common graph layout algorithms only consider ordinary graphs and do not take hyperedges into account. We focus on layered hypergraphs, a particular class of hypergraphs that, like layered graphs, assigns every vertex to a layer, and the vertices in a layer are drawn aligned on a linear axis with the axes arranged in parallel. In this paper, we propose a general method to apply layered graph layout algorithms to layered hypergraphs. We introduce six different transformations for layered hypergraphs. The choice of transformation affects the subsequent graph layout algorithm in terms of computational performance and readability of the results. Thus, we perform a comparative evaluation of these transformations in terms of number of crossings, edge length, and impact on performance. We also provide two case studies showing how our transformations can be applied to real-life use cases. A copy of this paper with all appendices and supplemental material is available at osf.io/grvwu.",817
732,Data Visualization,Cody Dunne,"October 1st, 2021",STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,https://doi.org/10.1109/TVCG.2021.3114756," S. di Bartolomeo, M. Riedewald, W. Gatterbauer and C. Dunne, ""STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations,"" in IEEE Transactions on Visualization and Computer Graphics, vol. 28, no. 1, pp. 324-334, Jan. 2022, DOI: 10.1109/TVCG.2021.3114756.","Stratisfimal Layout is a modular integer-linear-programming formulation that can consider several important readability criteria simultaneously. It can be adapted to diverse use cases through its modularity. Individual features can be enabled and customized depending on the application. We provide open-source and documented implementations of the layout, both for web-based and desktop visualizations. The paper is published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 28 , Issue: 1 , January 2022 ) The full paper with all appendices, data, and source code is available at o.sf.io/qdyt9 with live examples at https://visdunneright. io/stratisfimal/.",818
733,Data Visualization,Cody Dunne,"August 23rd, 2021",Sequence Braiding: Visual Overviews of Temporal Event Sequences and Attributes,https://ieeexplore.ieee.org/abstract/document/9231271," S. D. Bartolomeo, Y. Zhang, F. Sheng and C. Dunne, ""Sequence Braiding: Visual Overviews of Temporal Event Sequences and Attributes,"" in IEEE Transactions on Visualization and Computer Graphics, vol. 27, no. 2, pp. 1353-1363, Feb. 2021, doi: 10.1109/TVCG.2020.3030442.","Temporal event sequence alignment has been used in many domains to visualize nuanced changes and interactions overtime. Existing approaches align one or two sentinel events. We present SEQUENCE BRAIDING, a novel overview visualization for temporal event sequences and attributes using a layered directed acyclic network. In a controlled experiment we compare SEquENCE BRAIDS and IDMVis on user task completion time, correctness, error, and confidence.",819
734,Data Visualization,Cody Dunne,"June 1st, 2020",QueryVis: Logic-based diagrams help users understand complicated SQL queries faster,https://doi.org/10.1145/3318464.3389767," Aristotelis Leventidis, Jiahui Zhang, Cody Dunne, Wolfgang Gatterbauer, H. V. Jagadish, and Mirek Ridewald. ‚ÄúQueryVis: Logic-based diagrams help users understand complicated SQL queries faster‚Äù. In: Proc. 2020 ACM SIGMOD International Conference on Management of  Data. SIGMOD. Preprint & supplemental material: osf.io/btszh. SIGMOD 2021 Most Reproducible Paper Award. 2020, pp. 2303‚Äì2318. doi: 10.1145/3318464.3389767.","Understanding the meaning of existing SQL queries is critical for code maintenance and reuse. Yet SQL can be hard to read, even for expert users or the original creator of a query. We conjecture that it is possible to capture the logical intent of queries in automatically-generated visual diagrams that can help users understand the meaning of queries faster and more accurately than SQL text alone. We present initial steps in that direction with visual diagrams that are based on the first-order logic foundation of SQL and can capture the meaning of deeply nested queries. Our diagrams build upon a rich history of diagrammatic reasoning systems in logic and were designed using a large body of human-computer interaction best practices: they are minimal in that no visual element is superfluous; they are unambiguous in that no two queries with different semantics map to the same visualization; and they extend previously existing visual representations of relational schemata and conjunctive queries in a natural way. An experimental evaluation involving 42 users on Amazon Mechanical Turk shows that with only a 2--3 minute static tutorial, participants could interpret queries meaningfully faster with our diagrams than when reading SQL alone. Moreover, we have evidence that our visual diagrams result in participants making fewer errors than with SQL. We believe that more regular exposure to diagrammatic representations of SQL can give rise to a pattern-based and thus more intuitive use and re-use of SQL. A full version of this paper with all appendices and supplemental material for the experimental study (stimuli, raw data, and analysis code) are available at https://osf.io/btszh.",820
735,Data Visualization,Cliff Forlines,"June 21st, 2023",Cognitive and Emotional Monitoring with Inexpensive Wrist-Worn Consumer-Grade Wearables,https://doi.org/10.1109/PerComWorkshops56833.2023.10150338," Yunan Wu, Roxana Valdez, Clifton Forlines. (2023). Cognitive and Emotional Monitoring with Inexpensive Wrist-Worn Consumer-Grade Wearables PerCom Workshops, 665-670. https://doi.org/10.1109/PerComWorkshops56833.2023.10150338","High-cost and physical-limitations limit the use of Electroencephalogram sensing (EEG) with respect to Affective Computing. Wearable health devices, an intriguing alternative, are becoming cheap, inconspicuous, and common-place.",821
736,Data Visualization,John Alexis Guerra Gomez,"December 2nd, 2024",Towards Reusable and Reactive Widgets for Information Visualization Research and Dissemination,https://doi.org/10.1109/VIS55277.2024.00071," John A. Guerra-Gomez. (2024). Towards Reusable and Reactive Widgets for Information Visualization Research and Dissemination IEEE VIS, 316-320. https://doi.org/10.1109/VIS55277.2024.00071","This paper presents a design pattern for facilitating the creation, dissemination, and re-utilization of visualization techniques using reactive widgets. The design pattern features basic concepts that leverage modern front-end development best practices and standards. The paper presents several usage examples of the pattern, templates for implementation, and even a wrapper for. facilitating the conversion of any Vega [27], [28] specification into a reactive widget.",822
737,Data Visualization,John Alexis Guerra Gomez,"March 21st, 2024",Guitar Improvisation Preparation and Practice: A Digital-Assisted Approach Integrating Set Theory and Mechanical Gesture Exploration,https://doi.org/10.1007/978-3-031-55319-6_12," Leon Salcedo, Maria Fernanda Zuniga-Zabala, John A. Guerra-Gomez. (2023). Guitar Improvisation Preparation and Practice: A Digital-Assisted Approach Integrating Set Theory and Mechanical Gesture Exploration ArtsIT (1), 166-185. https://doi.org/10.1007/978-3-031-55319-6_12","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",823
738,Data Visualization,John Alexis Guerra Gomez,"January 29th, 2024",Extracting and visualizing a new classification system for Colombia‚Äôs National Administrative Department of Statistics. A visual analytics framework case study,https://doi.org/10.48550/arXiv.2401.15994," Pierre Raimbaud, Jaime Camilo Espitia Castillo, John A. Guerra-Gomez. (2024). Extracting and visualizing a new classification system for Colombia's National Administrative Department of Statistics. A visual analytics framework case study CoRR, abs/2401.15994. https://doi.org/10.48550/arXiv.2401.15994","In a world filled with data, it is expected for a nation to take decisions informed by data. However, countries need to first collect and publish such data in a way meaningful for both citizens and policy makers. A good thematic classification could be instrumental in helping users navigate and find the right resources on a rich data repository as the one collected by Colombia's National Administrative Department of Statistics (DANE). The Visual Analytics Framework is a methodology for conducting visual analysis developed by T. Munzner et al. [T. Munzner, Visualization Analysis and Design, A K Peters Visualization Series, 1, 2014] that could help with this task. This paper presents a case study applying such framework conducted to help the DANE better visualize their data repository, and present a more understandable classification of it. It describes three main analysis tasks identified, the proposed solutions and the collection of insights generated from them.",824
739,Data Visualization,John Alexis Guerra Gomez,"April 29th, 2022",Digital Proxemics: Designing Social and Collaborative Interaction in Virtual Environments,https://doi.org/10.1145/3491102.3517594," Julie R. Williamson, Joseph O'Hagan, John Alexis Guerra G√≥mez, John H. Williamson, Pablo C√©sar, David A. Shamma. (2022). Digital Proxemics: Designing Social and Collaborative Interaction in Virtual Environments CHI, 423:1-423:12. https://doi.org/10.1145/3491102.3517594","Behaviour in virtual environments might be informed by our experiences in physical environments, but virtual environments are not constrained by the same physical, perceptual, or social cues. Instead of replicating the properties of physical spaces, one can create virtual experiences that diverge from reality by dynamically manipulating environmental, aural, and social properties. This paper explores digital proxemics, which describe how we use space in virtual environments and how the presence of others influences our behaviours, interactions, and movements. First, we frame the open challenges of digital proxemics in terms of activity, social signals, audio design, and environment. We explore a subset of these challenges through an evaluation that compares two audio designs and two displays with different social signal affordances: head-mounted display (HMD) versus desktop PC. We use quantitative methods using instrumented tracking to analyse behaviour, demonstrating how personal space, proximity, and attention compare between desktop PC and HMDs.",825
740,Data Visualization,John Alexis Guerra Gomez,"April 28th, 2022",Lessons Learned Building Low-Cost DIY Tactile Graphics and Conducting a Tactile Drawing Club in Colombia During COVID-19,https://doi.org/10.1145/3491101.3503559," Maria Fernanda Zuniga-Zabala, John Alexis Guerra G√≥mez. (2022). Lessons Learned Building Low-Cost DIY Tactile Graphics and Conducting a Tactile Drawing Club in Colombia During COVID-19 CHI Extended Abstracts, 30:1-30:10. https://doi.org/10.1145/3491101.3503559","Perceiving images and drawing are fundamental parts of human life, and thus access to them should be a universal right. However, there is a large breach for people with visual impairments to access diverse graphics, let alone drawing. There are several techniques of tactile graphics, such as swell paper, Braille embossing, and thermoform that help to alleviate this gap. However, in developing countries, the high cost and lack of access make them impractical. In this work, we describe our experience improving access to tactile graphics and drawing in Colombia. We created low-cost, effective and efficient, tactile graphics and drawing techniques that improve on current solutions. These techniques were created from the best practices of two projects adapting pieces from the Colombian art heritage¬†[52, 53] for blind and visually impaired people. They were then applied to a third project: running a virtual tactile drawing club with blind and visually impaired participants in the middle of the COVID-19 pandemic. The lessons learned from these experiences are presented in this paper with the hope they can help the community democratize access to tactile graphics.",826
741,Data Visualization,John Alexis Guerra Gomez,"March 5th, 2021",A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset,https://doi.org/10.1109/TVCG.2021.3064037," Aditeya Pandey, Uzma Haque Syeda, Chaitya Shah, John A. Guerra-Gomez, Michelle A. Borkin. (2022). A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset IEEE Trans. Vis. Comput. Graph., 28, 3563-3584. https://doi.org/10.1109/TVCG.2021.3064037",No prior efforts exist to collect and abstractly define tree visualization tasks. We present a literature review of tree visualization articles and generate a curated dataset of over 200 tasks. All tasks in the dataset were abstracted with the novel typology extension and analyzed to gain a better understanding of the state of tree visualizations. We also contribute a novel extension of the Multi-Level Task Typology to include more specificity to support tree-specific tasks. The Supplemental Material can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2021.,827
742,Data Visualization,Mahsan Nourani,"December 8th, 2023",Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models,https://doi.org/10.1145/3626961," Chiradeep Roy, Mahsan Nourani, Shivvrat Arya, Mahesh Shanbhag, Tahrima Rahman, Eric D. Ragan, Nicholas Ruozzi, Vibhav Gogate. (2023). Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models ACM Trans. Interact. Intell. Syst., 13, 29:1-29:32. https://doi.org/10.1145/3626961","We consider the following video activity recognition (VAR) task: given a video, infer the set of activities being performed in the video and assign each frame to an activity. Although VAR can be solved accurately using existing deep learning techniques, deep networks are neither interpretable nor explainable and as a result their use is problematic in high stakes decision-making applications (in healthcare, experimental Biology, aviation, law, etc.). In such applications, failure may lead to disastrous consequences and therefore it is necessary that the user is able to either understand the inner workings of the model or probe it to understand its reasoning patterns for a given decision. We address these limitations of deep networks by proposing a new approach that feeds the output of a deep model into a tractable, interpretable probabilistic model called a dynamic conditional cutset network that is defined over the explanatory and output variables and then performing joint inference over the combined model. The two key benefits of using cutset networks are: (a) they explicitly model the relationship between the output and explanatory variables and as a result, the combined model is likely to be more accurate than the vanilla deep model and (b) they can answer reasoning queries in polynomial time and as a result, they can derive meaningful explanations by efficiently answering explanation queries. We demonstrate the efficacy of our approach on two datasets, Textually Annotated Cooking Scenes (TACoS), and wet lab, using conventional evaluation measures such as the Jaccard Index and Hamming Loss, as well as a human-subjects study.",828
743,Data Visualization,Mahsan Nourani,"March 17th, 2023",An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality,https://doi.org/10.1109/TVCG.2023.3258693," Brett Benda, Shyam Prathish Sargunam, Mahsan Nourani, Eric D. Ragan. (2024). An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality IEEE Trans. Vis. Comput. Graph., 30, 4257-4270. https://doi.org/10.1109/TVCG.2023.3258693","Head tracking is commonly used in VR applications to allow users to naturally view 3D content using physical head movement. Controller and joystick controls are convenient for practical settings where full 360-degree physical rotation is not possible, such as when the user is sitting at a desk. Previous research has demonstrated that virtual or joystick-controlled view rotation to have drawbacks of sickness and disorientation compared to physical turning. Our findings indicate a preference by users towards directly-manipulated joystick-based rotations compared to user-initiated resetting and minimal effects of technique on spatial awareness.",829
744,Data Visualization,Mahsan Nourani,"December 12th, 2022",On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications,https://doi.org/10.1145/3531066," Mahsan Nourani, Chiradeep Roy, Jeremy E. Block, Donald R. Honeycutt, Tahrima Rahman, Eric D. Ragan, Vibhav Gogate. (2022). On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications ACM Trans. Interact. Intell. Syst., 12, 28:1-28:29. https://doi.org/10.1145/3531066","While EXplainable Artificial Intelligence (XAI) approaches aim to improve human-AI collaborative decision-making by improving model transparency and mental model formations, experiential factors associated with human users can cause challenges in ways system designers do not anticipate. In this article, we first showcase a user study on how anchoring bias can potentially affect mental model formations when users initially interact with an intelligent system and the role of explanations in addressing this bias. Using a video activity recognition tool in cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. However, those who encountered weaknesses earlier made significantly fewer errors, since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Motivated by these findings and similar existing work, we formalize and present a conceptual model of user‚Äôs past experiences that examine the relations between user‚Äôs backgrounds, experiences, and human factors in XAI systems based on usage time. Our work presents strong findings and implications, aiming to raise the awareness of AI designers toward biases associated with user impressions and backgrounds.",830
745,Data Visualization,Mahsan Nourani,"August 24th, 2022",DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification,https://doi.org/10.1109/MCG.2022.3201465," Mahsan Nourani, Chiradeep Roy, Donald R. Honeycutt, Eric D. Ragan, Vibhav Gogate. (2022). DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification IEEE Computer Graphics and Applications, 42, 37-46. https://doi.org/10.1109/MCG.2022.3201465"," Debugging some models, such as temporal multilabel classification (TMLC), can be especially more challenging due to the complexity of the analysis. We propose DETOXER, an interactive visual debugging system to support finding different error types and scopes through providing multiscope explanations.",831
746,Data Visualization,Lace Padilla,"September 10th, 2024",Impact of Vertical Scaling on Normal Probability Density Function Plots,https://doi.org/10.1109/TVCG.2024.3456396," Racquel Fygenson, Lace M. K. Padilla. (2025). Impact of Vertical Scaling on Normal Probability Density Function Plots IEEE Trans. Vis. Comput. Graph., 31, 984-994. https://doi.org/10.1109/TVCG.2024.3456396","Keeping vertical scaling consistent, and therefore maintaining equal pixel areas under PDF curves, results in the highest likelihood of accurate comparisons. Findings provide insights into the impact of vertical scaled on PDFs, and reveal the complicated nature of proportional area comparisons. In some contexts, we find including a y-axis can help reduce this effect. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the paper, you can download your copy of the IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 1 , January 2025 ) for free. The paper is available to download now for free by clicking here.",832
747,Data Visualization,Lace Padilla,"September 9th, 2024","Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations",https://doi.org/10.1109/TVCG.2024.3456344," Anjana Arunkumar, Lace M. K. Padilla, Chris Bryan. (2025). Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations IEEE Trans. Vis. Comput. Graph., 31, 1169-1179. https://doi.org/10.1109/TVCG.2024.3456344","Mind wandering is a phenomenon where attention spontaneously shifts from a primary task to internal, task-related thoughts or unrelated distractions. Results show that mind wandering negatively affects short-term visualization recall, particularly for visualizations with little text annotation. Mind wandering also functions as an intermediate process linking visualization design elements to post-viewing measures, influencing how viewers engage with and interpret visual information over time. Overall, this research underscores the importance of incorporating mind wandering as aynamic measure in visualization design and evaluation, offering novel avenues for enhancing user engagement and comprehension.",833
748,Data Visualization,Lace Padilla,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",834
749,Data Visualization,Lace Padilla,"March 4th, 2024",Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs,https://doi.org/10.1109/TVCG.2024.3372620," Helia Hosseinpour, Laura E. Matzen, Kristin M. Divis, Spencer C. Castro, Lace M. K. Padilla. (2025). Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs IEEE Trans. Vis. Comput. Graph., 31, 1875-1887. https://doi.org/10.1109/TVCG.2024.3372620","Small multiples are a popular visualization method, displaying different views of a dataset using multiple frames, often with the same scale and axes. We found a linear decline in accuracy with increasing frames across seven tasks, which was not fully explained by differences in frame size. highlighting specific frames can mitigate some visual search difficulties but, surprisingly, not eliminate them. This research offers insights into optimizing the utility of small multiples by aligning them with human limitations. It was published in: IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 3 , March 2025 ) and will be published in the next issue of the journal.",835
750,Data Visualization,Lace Padilla,"October 23rd, 2023",Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,https://doi.org/10.1109/TVCG.2023.3326589," Dominik Moritz, Lace M. K. Padilla, Francis Nguyen, Steven L. Franconeri. (2024). Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability IEEE Trans. Vis. Comput. Graph., 30, 306-315. https://doi.org/10.1109/TVCG.2023.3326589","Bias might arise because higher variability leads to stronger weighting in the average calculation. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders. The study was published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 30, Issue: 1, January 2024) We found this effect across two preregistered experiments with 140 and 420 participants. We can model the bias with the average of the data series and theAverage of the points drawn along the line.",836
751,Data Visualization,Lace Padilla,"January 1st, 2023",Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations,https://doi.org/10.1109/TVCG.2022.3209457," Lace M. K. Padilla, Racquel Fygenson, Spencer C. Castro, Enrico Bertini. (2023). Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations IEEE Trans. Vis. Comput. Graph., 29, 12-22. https://doi.org/10.1109/TVCG.2022.3209457","The prevalence of inadequate SARS-COV-2 (COVID-19) responses may indicate a lack of trust in forecasts and risk communication. No work has empirically tested how multiple forecast visualization choices impact trust and task-based performance. The studies reveal that trust in. CO VID-19 forecast visualizations initially increases with the number of forecasts and then plateaus after. 6‚Äì9 forecasts. Participants were most trusting of visualizations that showed less visual information, including a 95% confidence. interval, single forecast, and grayscale encoded forecasts. was the most likely to evoke predictions that did not correspond with the actual CO VID -19 trend.",837
752,Data Visualization,Melanie Tory,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",838
753,Data Visualization,Melanie Tory,"April 15th, 2024",Struggles and Strategies in Understanding Information Visualizations,https://doi.org/10.1109/TVCG.2024.3388560," Maryam Rezaie, Melanie Tory, Sheelagh Carpendale. (2024). Struggles and Strategies in Understanding Information Visualizations IEEE Trans. Vis. Comput. Graph., 30, 3035-3048. https://doi.org/10.1109/TVCG.2024.3388560","Empirical studies are needed to tease apart the details of what makes the process of understanding difficult for visualization viewers. We conducted a qualitative study with 14 participants, observing them as they described how they were trying to make sense of 20 information visualizations. We identified the challenges participants faced throughout their sensemaking process and the strategies they employed to help themselves in overcoming the challenges. Our findings show how details and nuances within visualizations can impact comprehensibility and offer research suggestions to help us move toward more understandable visualizations, the authors say.",839
754,Data Visualization,Melanie Tory,"October 26th, 2023",Heuristics for Supporting Cooperative Dashboard Design,https://doi.org/10.1109/TVCG.2023.3327158," Vidya Setlur, Michael Correll, Arvind Satyanarayan, Melanie Tory. (2024). Heuristics for Supporting Cooperative Dashboard Design IEEE Trans. Vis. Comput. Graph., 30, 370-380. https://doi.org/10.1109/TVCG.2023.3327158","Dashboards are no longer mere static displays of metrics. Through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines are often unable to account for this expanded scope as they largely focus on best practices for visual design. Our approach suggests several compelling directions for future work. including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement. and extending cooperative principles to other analytical workflows. The study was published in the IEEE Transactions on Visualization and Computer Graphics ( Volume: 30 , Issue: 1 , January 2024 ) and is available online at: 10.1109/TVCG.2023.",840
755,Data Visualization,Melanie Tory,"July 5th, 2023",Investigating the Visual Utility of Differentially Private Scatterplots,https://doi.org/10.1109/TVCG.2023.3292391," Liudas Panavas, Tarik Crnovrsanin, Jane Lydia Adams, Jonathan R. Ullman, Ali Sarvghad, Melanie Tory, Cody Dunne. (2024). Investigating the Visual Utility of Differentially Private Scatterplots IEEE Trans. Vis. Comput. Graph., 30, 5370-5385. https://doi.org/10.1109/TVCG.2023.3292391","Increasingly, visualization practitioners are working with, using, and studying private data. Differential privacy algorithms do this by aggregating data statistics with noise. This now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.",841
756,Data Visualization,Melanie Tory,"June 28th, 2021",Untidy Data: The Unreasonable Effectiveness of Tables,https://arxiv.org/abs/2106.15005," Bartram, Lyn, Michael Correll, and Melanie Tory. ""Untidy data: The unreasonable effectiveness of tables."" IEEE Computer Graphics and Applications, (2021).","Working with data in table form is usually considered a preparatory and tedious step in the sensemaking pipeline; a way of getting the data ready for more sophisticated visualization and analytical tools. But for many people, spreadsheets -- the quintessential table tool -- remain a critical part of their information ecosystem, allowing them to interact with their data in ways that are hidden or abstracted in more complex tools. This is particularly true for data workers: people who work with data as part of their job but do not identify as professional analysts or data scientists. We report on a qualitative study of how these workers interact with and reason about their data. Our findings show that data tables serve a broader purpose beyond data cleanup at the initial stage of a linear analytic flow: users want to see and ""get their hands on"" the underlying data throughout the analytics process, reshaping and augmenting it to support sensemaking. They reorganize, mark up, layer on levels of detail, and spawn alternatives within the context of the base data. These direct interactions and human-readable table representations form a rich and cognitively important part of building understanding of what the data mean and what they can do with it. We argue that interactive tables are an important visualization idiom in their own right; that the direct data interaction they afford offers a fertile design space for visual analytics; and that sense making can be enriched by more flexible human-data interaction than is currently supported in visual analytics tools.",842
757,Data Visualization,Melanie Tory,"April 15th, 2021",The Unmet Data Visualization Needs of Decision Makers within Organizations,https://research.tableau.com/paper/unmet-data-visualization-needs-decision-makers-within-organizations," Evanthia Dimara, Harry Zhang, Melanie Tory, and Steven Franconeri, The Unmet Data Visualization Needs of Decision Makers within Organizations, IEEE Transactions on Visualization and Computer Graphics, 2021.","Tableau Research is an industrial research team focused on Tableau‚Äôs mission of helping people see and understand data. We actively work to be a source of new and inspiring product and technology directions, generating ideas that influence, drive, or significantly change what Tableau delivers to customers. We are also active members of the academic community, where we regularly publish and participate in top-tier conferences and journals. Tableau Research‚Äôs charter is to explore ways in which a computer can support humans when they are exploring, interacting, or presenting data. Be it new ML models that can provide reasonable defaults, support data augmentation, better search algorithms for helping people discover content and answer their questions, tools for better supporting data presentations, or figuring out how new channels can support new experiences for seeing and understanding data. Dennis Bromley Principal Research Scientist",843
758,Data Visualization,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",844
759,Data Visualization,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",845
760,Data Visualization,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",846
761,Data Visualization,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",847
762,Data Visualization,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",848
763,Data Visualization,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",849
764,Data Visualization,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",850
765,Data Visualization,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",851
766,Data Visualization,Caglar Yildirim,"November 4th, 2024",Poke Typing: Effects of Hand-Tracking Input and Key Representation on Mid-Air Text Entry Performance in Virtual Reality,https://doi.org/10.1145/3678957.3685734," Mehmet Akhoroz, Caglar Yildirim. (2024). Poke Typing: Effects of Hand-Tracking Input and Key Representation on Mid-Air Text Entry Performance in Virtual Reality ICMI, 293-301. https://doi.org/10.1145/3678957.3685734","In this paper, we investigated the effects of hand-tracking input on mid-air text entry performance in virtual reality as a function of the key representations used in the virtual keyboard, i.e., flat 2D keys vs. protruded 3D keys. This led to a comparison among four conditions: controller input using 2D keys, controller input using 3D keys, hand-tracking input using 2D keys, hand-tracking input using 3D keys. Results from our user study (n = 28) revealed that controller input (15.3 WPM) outperformed hand-tracking input (13.8 WPM) in terms of text entry rates and that protruded 3D keys (15.6 WPM) led to faster text entry performance than did flat 2D keys (13.4 WPM). While the four conditions did not differ in error rates, flat 2D keys led to a greater number of character corrections. In addition, results showed that compared to flat 2D keys, protruded 3D keys lowered the perceived mental workload of the text entry task. These results indicate that despite the technological advances in hand-tracking technology, controller input is still more performant than hand-tracking input for VR text entry tasks and that protruded 3D keys afford faster text entry and better user experience than do flat 2D keys. That said, hand-tracking input can still be used for mid-air text entry without extreme performance losses.",852
767,Data Visualization,Caglar Yildirim,"October 27th, 2024",Design considerations for photosensitivity warnings in visual media,https://doi.org/10.1145/3663548.3675643," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Design considerations for photosensitivity warnings in visual media ASSETS, 68:1-68:12. https://doi.org/10.1145/3663548.3675643","When digital content is tested for photosensitive safety and is found to contain seizure-inducing strobes or flashing lights, warnings about photosensitive risk are usually shown to the user prior to viewing the content. These photosensitivity warnings are an important accessibility feature for people with photosensitive epilepsy, allowing them to avoid interacting with content that may trigger seizures. However, little is known about how these warnings should be structured to maximize effectiveness in helping with people PSE navigate visual media safely. The design space for photosensitivity warnings is vast and includes questions such as what details to include about strobing light sequences or the content itself, where to place warnings within an interface, and what methods to use to extract information about the strobing light sequences (e.g., crowdsourced or automated methods). In this work, we contribute a thematic analysis of crowdsourced warnings drawn from the DoesTheDogDie online forum and an interview study with five people who have been diagnosed with photosensitive epilepsy about design considerations for photosensitivity warnings on digital platforms. To guide our interviews, we assembled examples of both crowdsourced and automated warnings about seizure-inducing content in films. Automated warnings were presented in the form of a high fidelity sketch demonstrating what an automated system for photosensitivity warnings might look like when deployed by a film streaming platform. We contribute design suggestions for the structure, content, and data sourcing of photosensitivity warnings for visual media based on the findings of our interviews. The results of this work will enable more effective and informative photosensitivity warnings across all forms of digital visual media.",853
768,Data Visualization,Caglar Yildirim,"May 11th, 2024",Barriers to Photosensitive Accessibility in Virtual Reality,https://doi.org/10.1145/3613904.3642635," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Barriers to Photosensitive Accessibility in Virtual Reality CHI, 58:1-58:13. https://doi.org/10.1145/3613904.3642635","Virtual reality (VR) systems have grown in popularity as an immersive modality for daily activities such as gaming, socializing, and working. However, this technology is not always accessible for people with photosensitive epilepsy (PSE) who may experience seizures or other adverse symptoms when exposed to certain light stimuli (e.g., flashes or strobes). How can VR be made more inclusive and safer for people with PSE? In this paper, we report on a series of semi-structured interviews about current perceptions of accessibility in VR among people with PSE. We identify 12 barriers to accessibility that fall into four categories: physical VR equipment, VR interfaces and content, specific VR applications, and individual differences in sensitivity. Our findings allow researchers and practitioners to better understand the meaning of photosensitive accessibility in the context of VR, and provide a step towards enabling people with PSE to enjoy the benefits offered by immersive technology.",854
769,Data Visualization,Caglar Yildirim,"January 30th, 2024",On the Plane: A Roleplaying Game for Simulating Ingroup-Outgroup Biases in Virtual Reality,https://doi.org/10.1109/AIVR56993.2022.00041," Caglar Yildirim, D. Fox Harrell. (2022). On the Plane: A Roleplaying Game for Simulating Ingroup-Outgroup Biases in Virtual Reality AIVR, 207-209. https://doi.org/10.1109/AIVR56993.2022.00041","On the Plane is a roleplaying game aimed at simulating ingroup-outgroup biases with the goal of supporting positive perspective taking in virtual reality. The game presents players with a simulation of air travel experience, from airport security screening to in-flight events. On the Plane affords the ability to experience the simulation as different characters, supporting both ingroup and outgroup perspectives. We describe how the game is structured to simulate and challenge ingroup outgroup biases within the context of xenophobia.",855
770,Data Visualization,Caglar Yildirim,"October 29th, 2023",E4UnityIntegration-MIT: An Open-Source Unity Plug-in for Collecting Physiological Data using Empatica E4 during Gameplay,https://doi.org/10.1145/3586182.3616627," Eduard De Vidal Flores, Caglar Yildirim, D. Fox Harrell. (2023). E4UnityIntegration-MIT: An Open-Source Unity Plug-in for Collecting Physiological Data using Empatica E4 during Gameplay UIST (Adjunct Volume), 49:1-49:3. https://doi.org/10.1145/3586182.3616627","Physiological measurement of player experience (PX) during gameplay has been of increasing interest within game research circles. A commonly-used non-invasive wearable device for physiological measurement is the Empatica E4 wristband, which offers multiple physiological metrics, ranging from electrodermal activity to heart rate. That said, the E4‚Äôs integration with popular game engines such as Unity 3D presents certain challenges due to non-obvious critical bugs in the library and limited documentation applicability within the Unity context. In this paper, we present an open-source Unity plug-in designed to mitigate the challenges associated with integrating the E4 into Unity projects: E4UnityIntegration-MIT. The plug-in exposes the E4‚Äôs API for interfacing with Unity C# scripts, thereby enabling realtime data collection and monitoring. E4UnityIntegration-MIT also provides the affordance of saving the E4 data into an external file for data analysis purposes.",856
771,Data Visualization,Caglar Yildirim,"July 9th, 2023",Toward Computationally-Supported Roleplaying for Perspective-Taking,https://doi.org/10.1007/978-3-031-35930-9_11," Caglar Yildirim, Sercan Seng√ºn, Pakinam Amer, JJ Hawke, D. Fox Harrell. (2023). Toward Computationally-Supported Roleplaying for Perspective-Taking HCI (36), 154-171. https://doi.org/10.1007/978-3-031-35930-9_11","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",857
772,Data Visualization,Caglar Yildirim,"April 19th, 2023",Is ‚ÄúCategorical Imperative‚Äù Metaversal?: A Kantian Ethical Framework for Social Virtual Reality,https://doi.org/10.1145/3544549.3585911," Eyup Engin Kucuk, Caglar Yildirim. (2023). Is ""Categorical Imperative"" Metaversal?: A Kantian Ethical Framework for Social Virtual Reality CHI Extended Abstracts, 193:1-193:7. https://doi.org/10.1145/3544549.3585911","The increasing adoption of social virtual reality (VR) environments for socializing and collaborating with others has led to a growing concern about ethical issues in these immersive environments. Beyond the introduction of some practical guidelines, theoretical work on this topic has been scant. In this paper, we propose an ethical framework for social VR based on Kant‚Äôs Theory of Morality. In so doing, we argue that the Kantian concept of categorical imperative does apply to social VR, that the reality of VR is not different from the reality of real life, and that what is morally unacceptable in real life is and should be unacceptable in social VR. In our framework, we provide three principles that can aid users and developers of social VR environments in reasoning about ethical issues in social VR, while advocating for more theoretical approaches to addressing the issue of VR ethics in human-computer interaction circles.",858
773,Data Visualization,Caglar Yildirim,"April 19th, 2023",Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings,https://doi.org/10.1145/3544549.3585649," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2023). Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings CHI Extended Abstracts, 111:1-111:7. https://doi.org/10.1145/3544549.3585649","Films often include sequences of flashing lights for visual effect that may inadvertently trigger seizures when viewed by individuals with photosensitive epilepsy (PSE). Warnings about photosensitive risk in films can help people with PSE make informed decisions about their personal safety, but little is known about how to design such warnings and what information to include. To better understand the design space for photosensitive risk warnings, we conducted a qualitative analysis of 265 crowdsourced warnings about flashing lights in films. We find that the crowdsourced warnings were tightly coupled to the scenic and temporal contexts of the films being described, unlike current practices for labeling media with potentially seizure-inducing sequences using general warnings that are not specific to the media at hand. As technological capabilities for detecting seizure-inducing sequences continue to improve, understanding how to effectively communicate this information to individuals with photosensitive epilepsy is critical for ensuring accessibility.",859
774,Data Visualization,Caglar Yildirim,"September 20th, 2022",Co-located Immersive Gaming: A Comparison between Augmented and Virtual Reality,https://doi.org/10.1109/CoG51982.2022.9893708," Moinak Ghoshal, Juan Ong, Hearan Won, Dimitrios Koutsonikolas, Caglar Yildirim. (2022). Co-located Immersive Gaming: A Comparison between Augmented and Virtual Reality CoG, 594-597. https://doi.org/10.1109/CoG51982.2022.9893708","Escape from Kyle-Earth is a co-located, multiplayer XR game that can be played in both AR and VR using a head-mounted display. Results indicate that VR evoked a stronger sense of presence while its AR counterpart increased co-presence between players. There was no significant difference in game enjoyment between the two platforms.",860
775,Data Visualization,Caglar Yildirim,"November 15th, 2021",Detecting Mental Workload in Virtual Reality Using EEG Spectral Data: A Deep Learning Approach,https://doi.org/10.1109/AIVR52153.2021.00039," H. Ved and C. Yildirim, ""Detecting Mental Workload in Virtual Reality Using EEG Spectral Data: A Deep Learning Approach,"" 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR), 2021, pp. 173-178, doi: 10.1109/AIVR52153.2021.00039.","Mental workload is the amount of mental effort a task requires users to exert. It is a critical consideration in various human-computer interaction scenarios, including virtual reality (VR) interactions. Automatic detection of mental workload as users are completing their tasks in interactive systems is crucial in terms of avoiding the possibility of overwhelming users and negatively affecting their task performance. This study investigated the possibility. of classifying mental workload levels in VR from electroencephalogram (EEG) signals through. the application of deep learning models.",861
776,Data Visualization,Caglar Yildirim,"July 3rd, 2021",The Effect of Body-Based Haptic Feedback on Player Experience During VR Gaming,https://doi.org/10.1007/978-3-030-77599-5_13," Michael Carroll, Caglar Yildirim. (2021). The Effect of Body-Based Haptic Feedback on Player Experience During VR Gaming HCI (9), 163-171. https://doi.org/10.1007/978-3-030-77599-5_13","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",862
777,Data Visualization,Caglar Yildirim,"May 7th, 2021",Remote and Collaborative Virtual Reality Experiments via Social VR Platforms,https://doi.org/10.1145/3411764.3445426," David Saffo, Sara Di Bartolomeo, Caglar Yildirim, and Cody Dunne. 2021. Remote and Collaborative Virtual Reality Experiments via Social VR Platforms. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 523, 1‚Äì15. DOI:https://doi.org/10.1145/3411764.3445426","Virtual reality (VR) researchers struggle to conduct remote studies. Previous work has focused on working around limitations imposed by traditional crowdsourcing methods. However, the potential for leveraging social VR platforms for HCI evaluations is largely unexplored. These platforms have large VR-ready user populations, distributed synchronous virtual environments, and support for user-generated content. We demonstrate how social VR platforms can be used to practically and ethically produce valid research results by replicating two studies using one such platform (VRChat): a quantitative study on Fitts‚Äô Law and a qualitative study on tabletop collaboration. Our replication studies exhibited analogous results to the originals, indicating the research validity of this approach. Moreover, we easily recruited experienced VR users with their own hardware for synchronous, remote, and collaborative participation. We further provide lessons learned for future researchers experimenting using social VR platforms. This paper and all supplemental materials are available at osf.io/c2amz.",863
778,Data Visualization,Caglar Yildirim,"July 24th, 2019",Cybersickness during VR gaming undermines game enjoyment: A mediation model,https://doi.org/10.1016/j.displa.2019.07.002," Yildirim, Caglar. ""Cybersickness during VR gaming undermines game enjoyment: a mediation model."" Displays 59 (2019): 35-43.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",864
779,Formal Methods,Gene Cooperman,"August 5th, 2024",Enabling Practical Transparent Checkpointing for MPI: A Topological Sort Approach,https://doi.org/10.48550/arXiv.2408.02218," Yao Xu, Gene Cooperman. (2024). Enabling Practical Transparent Checkpointing for MPI: A Topological Sort Approach CoRR, abs/2408.02218. https://doi.org/10.48550/arXiv.2408.02218","MPI is the de facto standard for parallel computing on a cluster of computers. Checkpointing is an important component in any strategy for software resilience and for long-running jobs that must be executed by chaining together time-bounded resource allocations. This work solves an old problem: a practical and general algorithm for transparent checkpointing of MPI that is both efficient and compatible with most of the latest network software. Transparent checkpointing is attractive due to its generality and ease of use for most MPI application developers. Earlier efforts at transparent checkpointing for MPI, one decade ago, had two difficult problems: (i) by relying on a specific MPI implementation tied to a specific network technology; and (ii) by failing to demonstrate sufficiently low runtime overhead.Problem (i) (network dependence) was already solved in 2019 by MANA's introduction of split processes. Problem (ii) (efficient runtime overhead) is solved in this work. This paper introduces an approach that avoids these limitations, employing a novel topological sort to algorithmically determine a safe future synchronization point. The algorithm is valid for both blocking and non-blocking collective communication in MPI. We demonstrate the efficacy and scalability of our approach through both micro-benchmarks and a set of five real-world MPI applications, notably including the widely used VASP (Vienna Ab Initio Simulation Package), which is responsible for 11% of the workload on the Perlmutter supercomputer at Lawrence Berkley National Laboratory. VASP was previously cited as a special challenge for checkpointing, in part due to its multi-algorithm codes.",865
780,Formal Methods,Gene Cooperman,"September 26th, 2023",Implementation-Oblivious Transparent Checkpoint-Restart for MPI,https://doi.org/10.48550/arXiv.2309.14996," Yao Xu, Leonid Belyaev, Twinkle Jain, Derek Schafer, Anthony Skjellum, Gene Cooperman. (2023). Implementation-Oblivious Transparent Checkpoint-Restart for MPI CoRR, abs/2309.14996. https://doi.org/10.48550/arXiv.2309.14996","This work presents experience with traditional use cases of checkpointing on a novel platform. A single codebase (MANA) transparently checkpoints production workloads for major available MPI implementations: ""develop once, run everywhere"". The new platform enables application developers to compile their application against any of the available standards-compliant MPI implementations, and test each MPI implementation according to performance or other features.",866
781,Formal Methods,Gene Cooperman,"December 12th, 2022",Collective Vector Clocks: Low-Overhead Transparent Checkpointing for MPI,https://doi.org/10.48550/arXiv.2212.05701," Yao Xu, Gene Cooperman. (2022). Collective Vector Clocks: Low-Overhead Transparent Checkpointing for MPI CoRR, abs/2212.05701. https://doi.org/10.48550/arXiv.2212.05701","Taking snapshots of the state of a distributed computation is useful for off-line analysis of the computational state, for later restarting from the saved snapshot, for cloning a copy of the computation, and for migration to a new cluster. The problem is made more difficult when supporting collective operations across processes, such as barrier, reduce operations, scatter and gather, etc. Some processes may have reached the barrier or other collective operation, while other processes wait a long time to reach that same barrier or collective operation. At least two solutions are well-known in the literature: (I) draining in-flight network messages and then freezing the network at checkpoint time; and (ii) adding a barrier prior to the collective operation, and either completing the operation or aborting the barrier if not all processes are present. Both solutions suffer important drawbacks. The code in the first solution must be updated whenever one ports to a newer network. The second solution implies additional barrier-related network traffic prior to each collective operation. This work presents a third solution that avoids both drawbacks. There is no additional barrier-related traffic, and the solution is implemented entirely above the network layer. The work is demonstrated in the context of transparent checkpointing of MPI libraries for parallel computation, where each of the first two solutions have already been used in prior systems, and then abandoned due to the aforementioned drawbacks. Experiments demonstrate the low runtime overhead of this new, network-agnostic approach. The approach is also extended to non-blocking, collective operations in order to handle overlapping of computation and communication.",867
782,Formal Methods,Gene Cooperman,"December 11th, 2022",McMini: A Programmable DPOR-based Model Checker for Multithreaded Programs,https://doi.org/10.48550/arXiv.2212.05468," Maxwell Pirtle, Luka Jovanovic, Gene Cooperman. (2022). McMini: A Programmable DPOR-based Model Checker for Multithreaded Programs CoRR, abs/2212.05468. https://doi.org/10.48550/arXiv.2212.05468",Model checking has become a key tool for gaining confidence in correctness of multi-threaded programs. A simple model checker is useful for detecting race conditions prior to production. Current model checkers hardwire the behavior of common thread operations. McMini is an **extensible** modelChecker based on DPOR (Dynamic Partial Order Reduction),868
783,Formal Methods,Gene Cooperman,"November 9th, 2020",CRAC: Checkpoint-Restart Architecture for CUDA with Streams and UVM,https://dl.acm.org/doi/10.5555/3433701.3433803," Twinkle Jain and Gene Cooperman, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC'20), pp. 1083‚Äì1097, Nov., 2020, IEEE Computer Society","The share of the top 500 supercomputers with NVIDIA GPUs is now over 25% and continues to grow. While fault tolerance is a critical issue for supercomputing, there does not currently exist an efficient, scalable solution for CUDA applications on NVIDIA GPUs. CRAC (Checkpoint-Restart Architecture for CUDA) is a new checkpoint-restart solution for fault tolerance that supports the full range of CUDA applications. CRAC combines: low runtime overhead (approximately 1% or less); fast checkpoint-restart; support for scalable CUDA streams (for efficient usage of all of the thousands of GPU cores); and support for the full features of Unified Virtual Memory (eliminating the programmer's burden of migrating memory between device and host). CRAC achieves its flexible architecture by segregating application code (checkpointed) and its external GPU communication via non-reentrant CUDA libraries (not checkpointed) within a single process's memory. This eliminates the high overhead of inter-process communication in earlier approaches, and has fewer limitations.",869
784,Formal Methods,Gene Cooperman,"June 27th, 2018",Functional Classification of Protein Structures by Local Structure Matching in Graph Representation,https://www.ncbi.nlm.nih.gov/pubmed/29604149," ""Functional Classification of Protein Structures by Local Structure Matching in Graph Representation"", Caitlyn L. Mills, Rohan Garg, Joslynn S. Lee, Liang Tian, Alexandru Suciu, Gene Cooperman, Penny J. Beuning, Mary Jo Ondrechen, Protein Science¬†27(6), pp. 1125--1135, 2018,","Abstract As a result of high-throughput protein structure initiatives, over 14,400 protein structures have been solved by Structural Genomics (SG) centers and participating research groups. While the totality of SG data represents a tremendous contribution to genomics and structural biology, reliable functional information for these proteins is generally lacking. Better functional predictions for SG proteins will add substantial value to the structural information already obtained. Our method described herein, Graph Representation of Active Sites for Prediction of Function (GRASP-Func), predicts quickly and accurately the biochemical function of proteins by representing residues at the predicted local active site as graphs rather than in Cartesian coordinates. We compare the GRASP-Func method to our previously reported method, Structurally Aligned Local Sites of Activity (SALSA), using the Ribulose Phosphate Binding Barrel (RPBB), 6-Hairpin Glycosidase (6-HG), and Concanavalin A-like Lectins/Glucanase (CAL/G) superfamilies as test cases. In each of the superfamilies, SALSA and the much faster method GRASP-Func yield similar correct classification of previously characterized proteins, providing a validated benchmark for the new method. In addition, we analyzed SG proteins using our SALSA and GRASP-Func methods to predict function. Forty-one SG proteins in the RPBB superfamily, nine SG proteins in the 6-HG superfamily, and one SG protein in the CAL/G superfamily were successfully classified into one of the functional families in their respective superfamily by both methods. This improved, faster, validated computational method can yield more reliable predictions of function that can be used for a wide variety of applications by the community. Keywords: 6-Hairpin Glycosidase (6-HG) superfamily; Concanavalin A-like Lectins/Glucanase (CAL/G) superfamily; Graph Representation of Active Sites for Prediction of Function (GRASP-Func); Ribulose Phosphate Binding Barrel (RPBB) superfamily; Structurally Aligned Local Sites of Activity (SALSA); protein function annotation.",870
785,Formal Methods,Joshua Gancher,"October 8th, 2024",FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions,https://doi.org/10.1145/3689729," Zhengyao Lin, Joshua Gancher, Bryan Parno. (2024). FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions Proc. ACM Program. Lang., 8, 499-526. https://doi.org/10.1145/3689729","Coarse-grained reconfigurable arrays (CGRAs) have gained attention in recent years due to their promising power efficiency compared to traditional von Neumann architectures. To program these architectures using ordinary languages such as C, a dataflow compiler must transform the original sequential, imperative program into an equivalent dataflow graph, composed of dataflow operators running in parallel. This transformation is challenging since the asynchronous nature of dataflow graphs allows out-of-order execution of operators, leading to behaviors not present in the original imperative programs. We address this challenge by developing a translation validation technique for dataflow compilers to ensure that the dataflow program has the same behavior as the original imperative program on all possible inputs and schedules of execution. We apply this method to a state-of-the-art dataflow compiler targeting the RipTide CGRA architecture. Our tool uncovers 8 compiler bugs where the compiler outputs incorrect dataflow graphs, including a data race that is otherwise hard to discover via testing. After repairing these bugs, our tool verifies the correct compilation of all programs in the RipTide benchmark suite.",871
786,Formal Methods,Joshua Gancher,"September 20th, 2024",Secure Synthesis of Distributed Cryptographic Applications,https://doi.org/10.1109/CSF61375.2024.00021," Cosku Acay, Joshua Gancher, Rolph Recto, Andrew C. Myers. (2024). Secure Synthesis of Distributed Cryptographic Applications CSF, 433-448. https://doi.org/10.1109/CSF61375.2024.00021","Developing secure distributed systems is difficult, and even harder when advanced cryptography must be used to achieve security goals. We advocate using secure program partitioning to synthesize cryptographic applications. Instead of implementing a system of communicating processes, the programmer implements a centralized, sequential program, which is automatically compiled into a secure distributed version that uses cryptography. We prove that our result guarantees robust hyperproperty preservation, an important criterion for compiler correctness that preserves all source-level security properties in target programs. The proof targets hybrid protocols, which abstract cryptographic mechanisms as idealized functionalities. It relies on a novel unification of simulation-based security, information-flow control, choreographic programming, and sequentialization techniques for concurrent programs.",872
787,Formal Methods,Joshua Gancher,"January 11th, 2023",A Core Calculus for Equational Proofs of Cryptographic Protocols,https://doi.org/10.1145/3571223," Joshua Gancher, Kristina Sojakova, Xiong Fan, Elaine Shi, Greg Morrisett. (2023). A Core Calculus for Equational Proofs of Cryptographic Protocols Proc. ACM Program. Lang., 7, 866-892. https://doi.org/10.1145/3571223","Many proofs of interactive cryptographic protocols (e.g., as in Universal Composability) operate by proving the protocol at hand to be observationally equivalent to an idealized specification. While pervasive, formal tool support for observational equivalence of cryptographic protocols is still a nascent area of research. Current mechanization efforts tend to either focus on diff-equivalence, which establishes observational equivalence between protocols with identical control structures, or require an explicit witness for the observational equivalence in the form of a bisimulation relation. Our goal is to simplify proofs for cryptographic protocols by introducing a core calculus, IPDL, for cryptographic observational equivalences. Via IPDL, we aim to address a number of theoretical issues for cryptographic proofs in a simple manner, including probabilistic behaviors, distributed message-passing, and resource-bounded adversaries and simulators. We demonstrate IPDL on a number of case studies, including a distributed coin toss protocol, Oblivious Transfer, and the GMW multi-party computation protocol. All proofs of case studies are mechanized via an embedding of IPDL into the Coq proof assistant.",873
788,Formal Methods,Joshua Gancher,"June 18th, 2021","Viaduct: an extensible, optimizing compiler for secure distributed programs",https://doi.org/10.1145/3453483.3454074," Cosku Acay, Rolph Recto, Joshua Gancher, Andrew C. Myers, Elaine Shi. (2021). Viaduct: an extensible, optimizing compiler for secure distributed programs PLDI, 740-755. https://doi.org/10.1145/3453483.3454074","Modern distributed systems involve interactions between principals with limited trust, so cryptographic mechanisms are needed to protect confidentiality and integrity. At the same time, most developers lack the training to securely employ cryptography. We present Viaduct, a compiler that transforms high-level programs into secure, efficient distributed realizations. Viaduct's source language allows developers to declaratively specify security policies by annotating their programs with information flow labels. The compiler uses these labels to synthesize distributed programs that use cryptography efficiently while still defending the source-level security policy. The Viaduct approach is general, and can be easily extended with new security mechanisms. Our implementation of the Viaduct compiler comes with an extensible runtime system that includes plug-in support for multiparty computation, commitments, and zero-knowledge proofs. We have evaluated the system on a set of benchmarks, and the results indicate that our approach is feasible and can use cryptography in efficient, nontrivial ways.",874
789,Formal Methods,Steve Holtzen,"July 8th, 2024",A Nominal Approach to Probabilistic Separation Logic,https://doi.org/10.1145/3661814.3662135," John M. Li, Jon Aytac, Philip Johnson-Freyd, Amal Ahmed , Steven Holtzen. (2024). A Nominal Approach to Probabilistic Separation Logic LICS, 55:1-55:14. https://doi.org/10.1145/3661814.3662135","Currently, there is a gap between the tools used by probability theorists and those used in formal reasoning about probabilistic programs. On the one hand, a probability theorist decomposes probabilistic state along the simple and natural product of probability spaces. On the other hand, recently developed probabilistic separation logics decompose state via relatively unfamiliar measure-theoretic constructions for computing unions of sigma-algebras and probability measures. We bridge the gap between these two perspectives by showing that these two methods of decomposition are equivalent up to a suitable equivalence of categories. Our main result is a probabilistic analog of the classic equivalence between the category of nominal sets and the Schanuel topos. Through this equivalence, we validate design decisions in prior work on probabilistic separation logic and create new connections to nominal-setlike models of probability.",875
790,Formal Methods,Steve Holtzen,"July 5th, 2024",Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces,https://doi.org/10.1145/3649921.3656986," Abdelrahman Madkour, Ross Mawhorter, Stacy Marsella, Adam M. Smith , Steven Holtzen. (2024). Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces FDG, 54. https://doi.org/10.1145/3649921.3656986","We introduce a new approach to deploying constraint-based content generators that better supports online generation. Constraint-based generators ensure that certain properties hold in each design they output. However, when deployed a general-purpose solver is often required, thus guarantees come with unpredictable search times and little control over sequentially-generated outputs. In this paper, we outline how we can encode design constraints into a compact circuit representation that affords generation without search. These generators yield samples that are distributed uniformly over the space of valid designs. We illustrate our approach with binary decision diagrams (BDDs) in comparison to the traditional approach with answer-set programming (ASP) in two scenarios: a grid-based tile placement scenario inspired by WaveFunctionCollapse, and a playable platformer level design scenario. These compiled design-space models make constraint-based methods easier to deploy by improving on both the running time and diversity of previous constraint-based methods.",876
791,Formal Methods,Steve Holtzen,"October 6th, 2023",Probabilistic Logic Programming Semantics For Procedural Content Generation,https://doi.org/10.1609/aiide.v19i1.27525," Abdelrahman Madkour, Chris Martens , Steven Holtzen, Casper Harteveld, Stacy Marsella. (2023). Probabilistic Logic Programming Semantics For Procedural Content Generation AIIDE, 295-305. https://doi.org/10.1609/aiide.v19i1.27525","Abstract Research in procedural content generation (PCG) has recently heralded two major methodologies: machine learning (PCGML) and declarative programming. The former shows promise by automating the specification of quality criteria through latent patterns in data, while the latter offers significant advantages for authorial control. In this paper we propose the use of probabilistic logic as a unifying framework that combines the benefits of both methodologies. We propose a Bayesian formalization of content generators as probability distributions and show how common PCG tasks map naturally to operations on the distribution. Further, through a series of experiments with maze generation, we demonstrate how probabilistic logic semantics allows us to leverage the authorial control of declarative programming and the flexibility of learning from data.",877
792,Formal Methods,Steve Holtzen,"July 25th, 2023",Scaling integer arithmetic in probabilistic programs,https://proceedings.mlr.press/v216/cao23b.html," William X. Cao, Poorva Garg, Ryan Tjoa, Steven Holtzen, Todd D. Millstein, Guy Van den Broeck. (2023). Scaling integer arithmetic in probabilistic programs UAI, 260-270. https://proceedings.mlr.press/v216/cao23b.html","Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today‚Äôs probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today‚Äôs PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.",878
793,Formal Methods,Steve Holtzen,"April 3rd, 2023",Lilac: a Modal Separation Logic for Conditional Probability,https://doi.org/10.48550/arXiv.2304.01339," John M. Li, Amal Ahmed , Steven Holtzen. (2023). Lilac: a Modal Separation Logic for Conditional Probability CoRR, abs/2304.01339. https://doi.org/10.48550/arXiv.2304.01339","We present Lilac, a separation logic for reasoning about probabilistic programs where separating conjunction captures probabilistic independence. Inspired by an analogy with mutable state where sampling corresponds to dynamic allocation, we show how probability spaces over a fixed, ambient sample space appear to be the natural analogue of heap fragments, and present a new combining operation on them such that probability spaces behave like heaps and measurability of random variables behaves like ownership. This combining operation forms the basis for our model of separation, and produces a logic with many pleasant properties. In particular, Lilac has a frame rule identical to the ordinary one, and naturally accommodates advanced features like continuous random variables and reasoning about quantitative properties of programs. Then we propose a new modality based on disintegration theory for reasoning about conditional probability. We show how the resulting modal logic validates examples from prior work, and give a formal verification of an intricate weighted sampling algorithm whose correctness depends crucially on conditional independence structure.",879
794,Formal Methods,Steve Holtzen,"June 30th, 2021",Model Checking Finite-Horizon Markov Chains with Probabilistic Inference,https://arxiv.org/abs/2105.12326," Model Checking Finite-Horizon Markov Chains with Probabilistic Inference. Steven Holtzen, Sebastian Junges, Marcell Vazquez-Chanlatte, Todd Millstein, Sanjit A. Seshia, and Guy Van den Broeck. In International Conference on Computer-Aided Verification (CAV), 2021.","We revisit the symbolic verification of Markov chains with respect to finite horizon reachability properties. The prevalent approach iteratively computes step-bounded state reachability probabilities. By contrast, recent advances in probabilistic inference suggest symbolically representing all horizon-length paths through the Markov chain. We ask whether this perspective advances the state-of-the-art in probabilistic model checking. First, we formally describe both approaches in order to highlight their key differences. Then, using these insights we develop Rubicon, a tool that transpiles Prism models to the probabilistic inference tool Dice. Finally, we demonstrate better scalability compared to probabilistic model checkers on selected benchmarks. All together, our results suggest that probabilistic inference is a valuable addition to the probabilistic model checking portfolio -- with Rubicon as a first step towards integrating both perspectives.",880
795,Formal Methods,Steve Holtzen,"March 31st, 2021",Logical Abstractions for Noisy Variational Quantum Algorithm Simulation,https://arxiv.org/abs/2103.17226," Yipeng Huang , Steven Holtzen, Todd D. Millstein, Guy Van den Broeck, Margaret Martonosi. (2021). Logical Abstractions for Noisy Variational Quantum Algorithm Simulation CoRR, abs/2103.17226. https://arxiv.org/abs/2103.17226","Due to the unreliability and limited capacity of existing quantum computer prototypes, quantum circuit simulation continues to be a vital tool for validating next generation quantum computers and for studying variational quantum algorithms, which are among the leading candidates for useful quantum computation. Existing quantum circuit simulators do not address the common traits of variational algorithms, namely: 1) their ability to work with noisy qubits and operations, 2) their repeated execution of the same circuits but with different parameters, and 3) the fact that they sample from circuit final wavefunctions to drive a classical optimization routine. We present a quantum circuit simulation toolchain based on logical abstractions targeted for simulating variational algorithms. Our proposed toolchain encodes quantum amplitudes and noise probabilities in a probabilistic graphical model, and it compiles the circuits to logical formulas that support efficient repeated simulation of and sampling from quantum circuits for different parameters. Compared to state-of-the-art state vector and density matrix quantum circuit simulators, our simulation approach offers greater performance when sampling from noisy circuits with at least eight to 20 qubits and with around 12 operations on each qubit, making the approach ideal for simulating near-term variational quantum algorithms. And for simulating noise-free shallow quantum circuits with 32 qubits, our simulation approach offers a66√óreduction in sampling cost versus quantum circuit simulation techniques based on tensor network contraction.",881
796,Formal Methods,Steve Holtzen,"November 13th, 2020",Scaling Exact Inference for Discrete Probabilistic Programs,https://dl.acm.org/doi/10.1145/3428208," Steven Holtzen, Guy Van den Broeck, and Todd Millstein. 2020. Scaling exact inference for discrete probabilistic programs. Proc. ACM Program. Lang. 4, OOPSLA, Article 140 (November 2020), 31 pages. DOI:https://doi.org/10.1145/3428208","Probabilistic programming languages (PPLs) are an expressive means of representing and reasoning about probabilistic models. The computational challenge of probabilistic inference remains the primary roadblock for applying PPLs in practice. Inference is fundamentally hard, so there is no one-size-fits all solution. In this work, we target scalable inference for an important class of probabilistic programs: those whose probability distributions are discrete . Discrete distributions are common in many fields, including text analysis, network verification, artificial intelligence, and graph analysis, but they prove to be challenging for existing PPLs. We develop a domain-specific probabilistic programming language called Dice that features a new approach to exact discrete probabilistic program inference. Dice exploits program structure in order to factorize inference, enabling us to perform exact inference on probabilistic programs with hundreds of thousands of random variables. Our key technical contribution is a new reduction from discrete probabilistic programs to weighted model counting (WMC). This reduction separates the structure of the distribution from its parameters, enabling logical reasoning tools to exploit that structure for probabilistic inference. We (1) show how to compositionally reduce Dice inference to WMC, (2) prove this compilation correct with respect to a denotational semantics, (3) empirically demonstrate the performance benefits over prior approaches, and (4) analyze the types of structure that allow Dice to scale to large probabilistic programs.",882
797,Formal Methods,Steve Holtzen,"June 30th, 2019",Generating and Sampling Orbits for Lifted Probabilistic Inference,http://proceedings.mlr.press/v115/holtzen20a.html," Generating and Sampling Orbits for Lifted Probabilistic Inference Steven Holtzen, Todd Millstein, Guy Van den Broeck Proceedings of The 35th Uncertainty in Artificial Intelligence Conference, PMLR 115:985-994, 2020.",A key goal in the design of probabilistic inference algorithms is identifying and exploit- ing properties of the distribution that make inference tractable. Lifted inference algorithms identify symmetry as a property that enables efficient inference and seek to scale with the degree of symmetry of a probability model. A limitation of existing exact lifted inference techniques is that they do not apply to non- relational representations like factor graphs. In this work we provide the first example of an exact lifted inference algorithm for arbitrary discrete factor graphs. In addition we describe a lifted Markov-Chain Monte-Carlo algorithm that provably mixes rapidly in the degree of symmetry of the distribution.,883
798,Formal Methods,Steve Holtzen,"June 6th, 2018",Sound Abstraction and Decomposition of Probabilistic Programs,http://proceedings.mlr.press/v80/holtzen18a.html," Sound Abstraction and Decomposition of Probabilistic Programs. Steven Holtzen, Guy Van den Broeck, and Todd Millstein. In International Conference on Machine Learning (ICML), 2018.","Probabilistic programming languages are a flexible tool for specifying statistical models, but this flexibility comes at the cost of efficient analysis. It is currently difficult to compactly represent the subtle independence properties of a probabilistic program, and exploit independence properties to decompose inference. Classical graphical model abstractions do capture some properties of the underlying distribution, enabling inference algorithms to operate at the level of the graph topology. However, we observe that graph-based abstractions are often too coarse to capture interesting properties of programs. We propose a form of sound abstraction for probabilistic programs wherein the abstractions are themselves simplified programs. We provide a theoretical foundation for these abstractions, as well as an algorithm to generate them. Experimentally, we also illustrate the practical benefits of our framework as a tool to decompose probabilistic program inference.",884
799,Formal Methods,Panagiotis (Pete) Manolios,"December 27th, 2024",Instance-Optimized Mapping with Portfolio Methods,https://doi.org/10.1145/3704742.3704963," Yibo Zhao, Panagiotis Manolios, Cheng Tan . (2024). Instance-Optimized Mapping with Portfolio Methods PACMI@SOSP, 11-16. https://doi.org/10.1145/3704742.3704963","Mappings are ubiquitous in computer systems, such as translating virtual memory to physical memory, file paths to inode numbers, database keys to data locations. Traditional system mappings are often hand-crafted and data-agnostic. In this paper, we explore the use of neural networks as learned mappings that are automatically generated and data-dependent, optimizing performance for specific workloads and scenarios. Unlike prior learned structures, we employ a portfolio method consisting of a set of independent neural networks, each responsible for making sole decisions. Our preliminary results indicate that these portfolio mappings can generalize across multiple applications.",885
800,Formal Methods,Panagiotis (Pete) Manolios,"June 17th, 2024",Finding Linear Explanations for a Given Ranking,https://doi.org/10.48550/arXiv.2406.11797," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2024). Finding Linear Explanations for a Given Ranking CoRR, abs/2406.11797. https://doi.org/10.48550/arXiv.2406.11797","Given a relation and a ranking of its tuples, but no information about the ranking function, we propose RankExplain to solve 2 types of problems: SAT asks if any linear scoring function can exactly reproduce the given ranking. OPT identifies the linear scoring function that minimizes position-based error, i.e., the total of the ranking-position differences over all tuples in the top-k. Our solution consists of linear programs that solve the problems exactly and can be implemented using MILP solvers. These solvers also support additional constraints on the scoring function, allowing the user to explore competing hypotheses through alternative scoring functions. We also discuss techniques for dealing with numerical imprecision and for improving performance and scalability. Experiments demonstrate that RankExplain can solve realistic problems. It is the first technique to provide exact solutions for OPT; and it is the fastest in producing exact solutions for SAT.",886
801,Formal Methods,Panagiotis (Pete) Manolios,"March 10th, 2023",Automated Grading of Automata with ACL2s,https://doi.org/10.48550/arXiv.2303.05867," Ankit Kumar, Andrew T. Walter, Panagiotis Manolios. (2023). Automated Grading of Automata with ACL2s CoRR, abs/2303.05867. https://doi.org/10.48550/arXiv.2303.05867","Almost all Computer Science programs require students to take a course on the Theory of Computation (ToC) which covers various models of computation such as finite automata, push-down automata and Turing machines. ToC courses tend to give assignments that require paper-and-pencil solutions. Grading such assignments takes time, so students typically receive feedback for their solutions more than a week after they complete them. We present the Automatic Automata Checker (A2C), an open source library that enables one to construct executable automata using definitions that mimic those found in standard textbooks. Such constructions are easy to reason about using semantic equivalence checks, properties and test cases. Instructors can conveniently specify solutions in the form of their own constructions. A2C can check for semantic equivalence between student and instructor solutions and can immediately generate actionable feedback, which helps students better understand the material. A2C can be downloaded and used locally by students as well as integrated into Learning Management Systems (LMS) like Gradescope to automatically grade student submissions and generate feedback. A2C is based on the ACL2s interactive theorem prover, which provides advanced methods for stating, proving and disproving properties. Since feedback is automatic, A2C can be deployed at scale and integrated into massively open online courses.",887
802,Formal Methods,Panagiotis (Pete) Manolios,"December 10th, 2022",Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from Misbehaving Peers,https://doi.org/10.48550/arXiv.2212.05197," Ankit Kumar, Max von Hippel, Pete Manolios, Cristina Nita-Rotaru. (2022). Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from Misbehaving Peers CoRR, abs/2212.05197. https://doi.org/10.48550/arXiv.2212.05197","GossipSub is a new peer-to-peer communication protocol designed to counter attacks from misbehaving peers by controlling what information is sent and to whom, via a score function computed by each peer that captures positive and negative behaviors of its neighbors. The score function depends on several parameters (weights, caps, thresholds) that can be configured by applications using GossipSub. The specification for GossipSub is written in English and its resilience to attacks from misbehaving peers is supported empirically by emulation testing using an implementation in Golang.In this work we take a foundational approach to understanding the resilience of GossipSub to attacks from misbehaving peers. We build the first formal model of GossipSub, using the ACL2s theorem prover. Our model is officially endorsed by the GossipSub developers. It can simulate GossipSub networks of arbitrary size and topology, with arbitrarily configured peers, and can be used to prove and disprove theorems about the protocol. We formalize fundamental security properties stating that the score function is fair, penalizes bad behavior, and rewards good behavior. We prove that the score function is always fair, but can be configured in ways that either penalize good behavior or ignore bad behavior. Using our model, we run GossipSub with the specific configurations for two popular real-world applications: the FileCoin and Eth2.0 blockchains. We show that all properties hold for FileCoin. However, given any Eth2.0 network (of any topology and size) with any number of potentially misbehaving peers, we can synthesize attacks where these peers are able to continuously misbehave by never forwarding topic messages, while maintaining positive scores so that they are never pruned from the network by GossipSub.",888
803,Formal Methods,Panagiotis (Pete) Manolios,"October 1st, 2022",Enumerative Data Types with Constraints,https://doi.org/10.34727/2022/isbn.978-3-85448-053-2_25," Andrew T. Walter, David A. Greve, Panagiotis Manolios. (2022). Enumerative Data Types with Constraints FMCAD, 189-198. https://doi.org/10.34727/2022/isbn.978-3-85448-053-2_25",¬© 2025 TU Wien Data Protection Declaration Support Policies Legal Notice,889
804,Formal Methods,Panagiotis (Pete) Manolios,"May 24th, 2022",ACL2s Systems Programming,https://doi.org/10.4204/EPTCS.359.12," Andrew T. Walter, Panagiotis Manolios. (2022). ACL2s Systems Programming ACL2, 134-150. https://doi.org/10.4204/EPTCS.359.12","ACL2 provides a systems programming capability that allows one to write code that uses and extends ACL2 inside of ACL2. However, for soundness reasons, ACL2 bars the unrestricted use of certain kinds of programming constructs, like destructive updates, higher-order functions, eval, and arbitrary macros. We devised a methodology for writing code in Common Lisp that allows one to access ACL2, ACL2s, and Common Lisp functionality in a unified way. We arrived at this methodology in the process of developing the ACL2 Sedan (ACL2s) and using it as a key component in formal-methods-enabled projects relating to gamified verification, education, proof checking, interfacing with external theorem provers and security. The methodology includes a library for performing ACL2 queries from Common Lisp, as well as guidelines and utilities that help address common needs. We call this methodology ""ACL2s systems programming,"" to distinguish it from ACL2 systems programming. We show how our methodology makes it possible to easily develop tools that interface with ACL2 and ACL2s, and describe our experience using it in our research.",890
805,Formal Methods,Panagiotis (Pete) Manolios,"October 1st, 2021",Mathematical Programming Modulo Strings,https://doi.org/10.34727/2021/isbn.978-3-85448-046-4_36," Ankit Kumar, Panagiotis Manolios. (2021). Mathematical Programming Modulo Strings FMCAD, 261-270. https://doi.org/10.34727/2021/isbn.978-3-85448-046-4_36",¬© 2025 TU Wien Data Protection Declaration Support Policies Legal Notice,891
806,Formal Methods,Panagiotis (Pete) Manolios,"July 12th, 2019",Local and Compositional Reasoning for Optimized Reactive Systems,https://doi.org/10.1007/978-3-030-25540-4_32," Mitesh Jain, Panagiotis Manolios. (2019). Local and Compositional Reasoning for Optimized Reactive Systems CAV (1), 553-571. https://doi.org/10.1007/978-3-030-25540-4_32","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",892
807,Formal Methods,Panagiotis (Pete) Manolios,"September 17th, 2017",Flight critical software and systems development using ASSERT,http://ieeexplore.ieee.org/document/8102059/," Kit Siu, Abha Moitra, Panagiotis Manolios, Michael Durling, Andrew Crapo, Meng Li, Han Yu, Craig McMillan, Heber Herencia-Zapana, Mauricio Castillo-Effen, Shiraj Sen, Daniel Russell and Sundeep Roy.","The size and complexity associated with software that monitors, controls, and protects flight critical products continues to grow. This is compounded by an increased use of autonomous systems which are just as complex, if not more so. General Electric has devoted a team to research and develop a new suite of tools to address the challenges with design, development, and verification of these software-intensive products. The goals are to develop technology, processes, and tools that result in more efficient software and system development as measured by cost and cycle time. We will introduce the ASSERT‚Ñ¢ tool chain (Analysis of Semantic Specifications and Efficient generation of Requirements-based Tests) and demonstrate aspects of the tool on an autonomous aerial inspection system.",893
808,Formal Methods,Panagiotis (Pete) Manolios,"July 16th, 2015",Skipping Refinement,https://link.springer.com/chapter/10.1007/978-3-319-21690-4_7," Mitesh Jain and Panagiotis Manolios. Skipping Refinement. CAV, Computer-Aided Verification (CAV 2015) July 2015.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",894
809,Formal Methods,Ji-Yong Shin,"June 20th, 2024",LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs,https://doi.org/10.1145/3656423," Longfei Qiu, Yoonseung Kim, Ji-Yong Shin, Jieung Kim, Wolf Honor√©, Zhong Shao. (2024). LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs Proc. ACM Program. Lang., 8, 1140-1164. https://doi.org/10.1145/3656423","Byzantine fault-tolerant state machine replication (SMR) protocols, such as PBFT, HotStuff, and Jolteon, are essential for modern blockchain technologies. However, they are challenging to implement correctly because they have to deal with any unexpected message from byzantine peers and ensure safety and liveness at all times. Many formal frameworks have been developed to verify the safety of SMR implementations, but there is still a gap in the verification of their liveness. Existing liveness proofs are either limited to the network level or do not cover popular partially synchronous protocols. We introduce LiDO, a consensus model that enables the verification of both safety and liveness of implementations through refinement. We observe that current consensus models cannot handle liveness because they do not include a pacemaker state. We show that by adding a pacemaker state to the LiDO model, we can express the liveness properties of SMR protocols as a few safety properties that can be easily verified by refinement proofs. Based on our LiDO model, we provide mechanized safety and liveness proofs for both unpipelined and pipelined Jolteon in Coq. This is the first mechanized liveness proof for a byzantine consensus protocol with non-trivial optimizations such as pipelining.",895
810,Formal Methods,Ji-Yong Shin,"April 29th, 2024",AdoB: Bridging Benign and Byzantine Consensus with Atomic Distributed Objects,https://doi.org/10.1145/3649826," Wolf Honor√©, Longfei Qiu, Yoonseung Kim, Ji-Yong Shin, Jieung Kim, Zhong Shao. (2024). AdoB: Bridging Benign and Byzantine Consensus with Atomic Distributed Objects Proc. ACM Program. Lang., 8, 419-448. https://doi.org/10.1145/3649826","Achieving consensus is a challenging and ubiquitous problem in distributed systems that is only made harder by the introduction of malicious byzantine servers. While significant effort has been devoted to the benign and byzantine failure models individually, no prior work has considered the mechanized verification of both in a generic way. We claim this is due to the lack of an appropriate abstraction that is capable of representing both benign and byzantine consensus without either losing too much detail or becoming impractically complex. We build on recent work on the atomic distributed object model to fill this void with a novel abstraction called AdoB. In addition to revealing important insights into the essence of consensus, this abstraction has practical benefits for easing distributed system verification. As a case study, we proved safety and liveness properties for AdoB in Coq, which are the first such mechanized proofs to handle benign and byzantine consensus in a unified manner. We also demonstrate that AdoB faithfully models real consensus protocols by proving it is refined by standard network-level specifications of Fast Paxos and a variant of Jolteon.",896
811,Formal Methods,Ji-Yong Shin,"June 9th, 2022",Adore: atomic distributed objects with certified reconfiguration,https://doi.org/10.1145/3519939.3523444," Wolf Honor√©, Ji-Yong Shin, Jieung Kim, Zhong Shao. (2022). Adore: atomic distributed objects with certified reconfiguration PLDI, 379-394. https://doi.org/10.1145/3519939.3523444","Finding the right abstraction is critical for reasoning about complex systems such as distributed protocols like Paxos and Raft. Despite a recent abundance of impressive verification work in this area, we claim the ways that past efforts model distributed state are not ideal for protocol-level reasoning: they either hide important details, or leak too much complexity from the network. As evidence we observe that nearly all of them avoid the complex, but important issue of reconfiguration. Reconfiguration's primary challenge lies in how it interacts with a protocol's core safety invariants. To handle this increased complexity, we introduce the Adore model, whose novel abstract state hides network-level communications while capturing dependencies between committed and uncommitted states, as well as metadata like election quorums. It includes first-class support for a generic reconfiguration command that can be instantiated with a variety of implementations. Under this model, the subtle interactions between reconfiguration and the core protocol become clear, and with this insight we completed the first mechanized proof of safety of a reconfigurable consensus protocol.",897
812,Formal Methods,Ji-Yong Shin,"October 15th, 2021",Much ADO about failures: a fault-aware model for compositional verification of strongly consistent distributed systems,https://doi.org/10.1145/3485474," Wolf Honor√©, Jieung Kim, Ji-Yong Shin, and Zhong Shao. 2021. ""Much ADO about failures: a fault-aware model for compositional verification of strongly consistent distributed systems."" Proc. ACM Program. Lang. 5, OOPSLA, Article 97 (October 2021), 31 pages. DOI: 10.1145/3485474","Despite recent advances, guaranteeing the correctness of large-scale distributed applications without compromising performance remains a challenging problem. Network and node failures are inevitable and, for some applications, careful control over how they are handled is essential. Unfortunately, existing approaches either completely hide these failures behind an atomic state machine replication (SMR) interface, or expose all of the network-level details, sacrificing atomicity. We propose a novel, compositional, atomic distributed object (ADO) model for strongly consistent distributed systems that combines the best of both options. The object-oriented API abstracts over protocol-specific details and decouples high-level correctness reasoning from implementation choices. At the same time, it intentionally exposes an abstract view of certain key distributed failure cases, thus allowing for more fine-grained control over them than SMR-like models. We demonstrate that proving properties even of composite distributed systems can be straightforward with our Coq verification framework, Advert, thanks to the ADO model. We also show that a variety of common protocols including multi-Paxos and Chain Replication refine the ADO semantics, which allows one to freely choose among them for an application's implementation without modifying ADO-level correctness proofs.",898
813,Formal Methods,Ji-Yong Shin,"November 1st, 2019","WormSpace: A Modular Foundation for Simple, Verifiable Distributed Systems",https://dl.acm.org/doi/10.1145/3357223.3362739," ""WormSpace: A Modular Foundation for Simple, Verifiable Distributed Systems,‚Äù Ji-Yong Shin, Jieung Kim, Wolf Honor√©, Hern√°n Vanzetto, Srihari Radhakrishnan, Mahesh Balakrishnan, and Zhong Shao, In Proceedings of the ACM Symposium on Cloud Computing (SoCC), Santa Cruz, CA, U.S.A., Nov 2019.","We propose the Write-Once Register (WOR) as an abstraction for building and verifying distributed systems. A WOR exposes a simple, data-centric API: clients can capture, write, and read it. Applications can use a sequence or a set of WORs to obtain properties such as durability, concurrency control, and failure atomicity. By hiding the logic for distributed coordination underneath a data-centric API, the WOR abstraction enables easy, incremental, and extensible implementation and verification of applications built above it. We present the design, implementation, and verification of a system called WormSpace that provides developers with an address space of WORs, implementing each WOR via a Paxos instance. We describe three applications built over WormSpace: a flexible, efficient Multi-Paxos implementation; a shared log implementation with lower append latency than the state-of-the-art; and a fault-tolerant transaction coordinator that uses an optimal number of round-trips. We show that these applications are simple, easy to verify, and match the performance of unverified monolithic implementations. We use a modular layered verification approach to link the proofs for WormSpace, its applications, and a verified operating system to produce the first verified distributed system stack from the application to the operating system.",899
814,Formal Methods,Ji-Yong Shin,"October 1st, 2016",Towards Weakly Consistent Local Storage Systems,https://dl.acm.org/doi/10.1145/2987550.2987579," ""Towards Weakly Consistent Local Storage Systems,"" Ji-Yong Shin, Mahesh Balakrishnan, Tudor Marian, Jakub Szefer and Hakim Weatherspoon, In Proceedings of the ACM Symposium on Cloud Computing (SoCC), Santa Clara, CA, U.S.A., Oct 2016.","Heterogeneity is a fact of life for modern storage servers. For example, a server may spread terabytes of data across many different storage media, ranging from magnetic disks, DRAM, NAND-based solid state drives (SSDs), as well as hybrid drives that package various combinations of these technologies. It follows that access latencies to data can vary hugely depending on which media the data resides on. At the same time, modern storage systems naturally retain older versions of data due to the prevalence of log-structured designs and caches in software and hardware layers. In a sense, a contemporary storage system is very similar to a small-scale distributed system, opening the door to consistency/performance trade-offs. In this paper, we propose a class of local storage systems called StaleStores that support relaxed consistency, returning stale data for better performance. We describe several examples of StaleStores, and show via emulations that serving stale data can improve access latency by between 35% and 20X. We describe a particular StaleStore called Yogurt, a weakly consistent local block storage system. Depending on the application's consistency requirements (e.g. bounded staleness, mono-tonic reads, read-my-writes, etc.), Yogurt queries the access costs for different versions of data within tolerable staleness bounds and returns the fastest version. We show that a distributed key-value store running on top of Yogurt obtains a 6X speed-up for access latency by trading off consistency and performance within individual storage servers.",900
815,Formal Methods,Ji-Yong Shin,"February 22nd, 2016",Isotope: Transactional Isolation for Block Storage,https://www.usenix.org/conference/fast16/technical-sessions/presentation/shin," ""Isotope: Transactional Isolation for Block Storage,"" Ji-Yong Shin, Mahesh Balakrishnan, Tudor Marian, and Hakim Weatherspoon, In Proceedings of the USENIX Conference on File and Storage Technologies (FAST), Santa Clara, CA, U.S.A., Feb 2016.","Ji-Yong Shin, Cornell University; Mahesh Balakrishnan, Yale University; Tudor Marian, Google; Hakim Weatherspoon, Cornell University Existing storage stacks are top-heavy and expect little from block storage. As a result, new high-level storage abstractions‚Äîand new designs for existing abstractions‚Äîare difficult to realize, requiring developers to implement from scratch complex functionality such as failure atomicity and fine-grained concurrency control. In this paper, we argue that pushing transactional isolation into the block store (in addition to atomicity and durability) is both viable and broadly useful, resulting in simpler high-level storage systems that provide strong semantics without sacrificing performance. We present Isotope, a new block store that supports ACID transactions over block reads and writes. Internally, Isotope uses a new multi-version concurrency control protocol that exploits fine-grained, sub-block parallelism in workloads and offers both strict serializability and snapshot isolation guarantees. We implemented several high-level storage systems over Isotope, including two key-value stores that implement the LevelDB API over a hashtable and B-tree, respectively, and a POSIX filesystem. We show that Isotope‚Äôs block-level transactions enable systems that are simple (100s of lines of code), robust (i.e., providing ACID guarantees), and fast (e.g., 415 MB/s for random file writes). We also show that these systems can be composed using Isotope, providing applications with transactions across different high-level constructs such as files, directories and key-value pairs. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. Download Audio ¬© USENIX 2025 EIN 13-3055038",901
816,Formal Methods,Stavros Tripakis,"January 24th, 2025",Accelerating Protocol Synthesis and Detecting Unrealizability with Interpretation Reduction,https://doi.org/10.48550/arXiv.2501.14585," Derek Egolf, Stavros Tripakis. (2025). Accelerating Protocol Synthesis and Detecting Unrealizability with Interpretation Reduction CoRR, abs/2501.14585. https://doi.org/10.48550/arXiv.2501.14585","We present a novel counterexample-guided, sketch-based method for the synthesis of symbolic distributed protocols in TLA+. Our method's chief novelty lies in a new search space reduction technique called interpretation reduction, which allows to not only eliminate incorrect candidate protocols before they are sent to the verifier, but also to avoid enumerating redundant candidates in the first place. Further performance improvements are achieved by an advanced technique for exact generalization of counterexamples. Experiments on a set of established benchmarks show that our tool is almost always faster than the state of the art, often by orders of magnitude, and was also able to synthesize an entire TLA+ protocol ""from scratch"" in less than 3 minutes where the state of the art timed out after an hour. Our method is sound, complete, and guaranteed to terminate on unrealizable synthesis instances under common assumptions which hold in all our benchmarks.",902
817,Formal Methods,Stavros Tripakis,"July 26th, 2023",Counterexample classification,https://doi.org/10.1007/s10270-023-01118-0," Cole Vick, Eunsuk Kang, Stavros Tripakis. (2024). Counterexample classification Softw. Syst. Model., 23, 455-472. https://doi.org/10.1007/s10270-023-01118-0","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 188 Accesses",903
818,Formal Methods,Stavros Tripakis,"June 5th, 2023",Synthesis of Distributed Protocols by Enumeration Modulo Isomorphisms,https://doi.org/10.48550/arXiv.2306.02967," Derek Egolf, Stavros Tripakis. (2023). Synthesis of Distributed Protocols by Enumeration Modulo Isomorphisms CoRR, abs/2306.02967. https://doi.org/10.48550/arXiv.2306.02967","Synthesis of distributed protocols is a hard, often undecidable, problem. Completion techniques provide partial remedy by turning the problem into a search problem. However, the space of candidate completions is still massive. In this paper, we propose optimization techniques to reduce the size of the search space by a factorial factor by exploiting symmetries (isomorphisms) in functionally equivalent solutions. We present both a theoretical analysis of this optimization as well as empirical results that demonstrate its effectiveness in synthesizing both the Alternating Bit Protocol and Two Phase Commit. Our experiments show that the optimized tool achieves a speedup of approximately 2 to 10 times compared to its unoptimized counterpart.",904
819,Formal Methods,Stavros Tripakis,"June 1st, 2023",Safe Environmental Envelopes of Discrete Systems,https://doi.org/10.48550/arXiv.2306.01025," R√¥mulo Meira-G√≥es, Ian Dardik, Eunsuk Kang, St√©phane Lafortune, Stavros Tripakis. (2023). Safe Environmental Envelopes of Discrete Systems CoRR, abs/2306.01025. https://doi.org/10.48550/arXiv.2306.01025","A safety verification task involves verifying a system against a desired safety property under certain assumptions about the environment. However, these environmental assumptions may occasionally be violated due to modeling errors or faults. Ideally, the system guarantees its critical properties even under some of these violations, i.e., the system is \emph{robust} against environmental deviations. This paper proposes a notion of \emph{robustness} as an explicit, first-class property of a transition system that captures how robust it is against possible \emph{deviations} in the environment. We modeled deviations as a set of \emph{transitions} that may be added to the original environment. Our robustness notion then describes the safety envelope of this system, i.e., it captures all sets of extra environment transitions for which the system still guarantees a desired property. We show that being able to explicitly reason about robustness enables new types of system analysis and design tasks beyond the common verification problem stated above. We demonstrate the application of our framework on case studies involving a radiation therapy interface, an electronic voting machine, a fare collection protocol, and a medical pump device.",905
820,Formal Methods,Stavros Tripakis,"January 11th, 2022",Formal verification of a distributed dynamic reconfiguration protocol,https://doi.org/10.1145/3497775.3503688," William Schultz, Ian Dardik, Stavros Tripakis. (2022). Formal verification of a distributed dynamic reconfiguration protocol CPP, 143-152. https://doi.org/10.1145/3497775.3503688","We present a formal, machine checked TLA+ safety proof of MongoRaftReconfig , a distributed dynamic reconfiguration protocol. MongoRaftReconfig was designed for and implemented in MongoDB, a distributed database whose replication protocol is derived from the Raft consensus algorithm. We present an inductive invariant for MongoRaftReconfig that is formalized in TLA+ and formally proved using the TLA+ proof system (TLAPS). We also present a formal TLAPS proof of two key safety properties of MongoRaftReconfig , LeaderCompleteness and StateMachineSafety . To our knowledge, these are the first machine checked inductive invariant and safety proof of a dynamic reconfiguration protocol for a Raft based replication system.",906
821,Formal Methods,Stavros Tripakis,"November 25th, 2021",Decentralized Observation of Discrete-Event Systems: At Least One Can Tell,https://doi.org/10.1109/LCSYS.2021.3130887," Stavros Tripakis, Karen Rudie. (2022). Decentralized Observation of Discrete-Event Systems: At Least One Can Tell IEEE Control. Syst. Lett., 6, 1652-1657. https://doi.org/10.1109/LCSYS.2021.3130887","In a truly decentralized system, agents must be able to make decisions based on their observations, without reliance on a centralized coordinator or fusion rule. A condition, called at least one can tell , is developed that characterizes when decentralized agents can determine whether behavior generated by a system is good (i.e., legal) or bad ( i.e. illegal)",907
822,Formal Methods,Stavros Tripakis,"July 31st, 2021",Automated Attacker Synthesis for Distributed Protocols,https://doi.org/10.1007/978-3-030-54549-9_9," Max von Hippel, Cole Vick, Stavros Tripakis, and Cristina Nita-Rotaru. Automated Attacker Synthesis for Distributed Protocols. In 39th International Conference on Computer Safety, Reliability and Security (SAFECOMP), 2020.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",908
823,Formal Methods,Stavros Tripakis,"July 26th, 2021",Metrics and methods for robustness evaluation of neural networks with generative models,https://doi.org/10.1007/s10994-021-05994-9," Buzhinsky, I., Nerinovsky, A. & Tripakis, S. Metrics and methods for robustness evaluation of neural networks with generative models. Machine Learning (2021).","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 6608 Accesses",909
824,Formal Methods,Stavros Tripakis,"January 11th, 2021",The refinement calculus of reactive systems,https://doi.org/10.1016/j.ic.2021.104819," Viorel Preoteasa, Iulia Dragomir, Stavros Tripakis. (2022). The refinement calculus of reactive systems Inf. Comput., 285, 104819. https://doi.org/10.1016/j.ic.2021.104819","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",910
825,Formal Methods,Stavros Tripakis,"April 7th, 2020",The Refinement Calculus of Reactive Systems Toolset,https://doi.org/10.1007/s10009-020-00561-4," Iulia Dragomir, Viorel Preoteasa, and Stavros Tripakis. The Refinement Calculus of Reactive Systems Toolset. International Journal on Software Tools for Technology Transfer, pages 1‚Äì20, 2020.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 253 Accesses",911
826,Formal Methods,Stavros Tripakis,"November 6th, 2019",Learning Moore Machines from Input-Output Traces,https://doi.org/10.1007/s10009-019-00544-0," Giantamidis, G., Tripakis, S. & Basagiannis, S. Learning Moore machines from input‚Äìoutput traces. Int J Softw Tools Technol Transfer 23, 1‚Äì29 (2021).","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 1381 Accesses",912
827,Formal Methods,Stavros Tripakis,"August 26th, 2019",Automated Synthesis of Secure Platform Mappings,https://doi.org/10.1007/978-3-030-25540-4_12," Kang E., Lafortune S., Tripakis S. (2019) Automated Synthesis of Secure Platform Mappings. In: Dillig I., Tasiran S. (eds) Computer Aided Verification. CAV 2019. Lecture Notes in Computer Science, vol 11561. Springer, Cham","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",913
828,Games,Seth Cooper,"November 15th, 2024",Toward Space-Time WaveFunctionCollapse for Level and Solution Generation,https://doi.org/10.1609/aiide.v20i1.31863," Kaylah Facey, Seth Cooper. (2024). Toward Space-Time WaveFunctionCollapse for Level and Solution Generation AIIDE, 25-34. https://doi.org/10.1609/aiide.v20i1.31863","Abstract WaveFunctionCollapse (WFC) is a constraint-satisfaction-based approach to procedural content generation via machine learning (PCGML). It is relatively easy to implement and requires very little training data, making it a popular approach. Generated game levels are guaranteed to look locally similar totheir example tilemaps; however, local adjacency rules often fail to capture global solvability rules, potentially making many such levels unplayable. Existing approaches to improving the solvability of WFC-generated levels typically require adding additional game-specific information in the form of global constraints, substantially increasing the complexity and time required for setup. The purpose of this work is to explore whether using level solutions as training data can allow WFC to learn solvability constraints and game mechanics. We have implemented a novel space-time approach that uses three-dimensional space-time blocks representing solutions to 2D levels as both input and output. Experiments using this method show that space-time WFC is capable of demonstrating localized game mechanics and creating small playable levels with given solutions. However, levels are slow to generate, and some high-level constraints are still not captured.",914
829,Games,Seth Cooper,"November 15th, 2024",Procedurally Puzzling: On Algorithmic Difficulty and Player Experience in QD-Generated Logic Grid Puzzles,https://doi.org/10.1609/aiide.v20i1.31873," Fiona Shyne, Kaylah Facey, Seth Cooper. (2024). Procedurally Puzzling: On Algorithmic Difficulty and Player Experience in QD-Generated Logic Grid Puzzles AIIDE, 127-137. https://doi.org/10.1609/aiide.v20i1.31873","Abstract Determining if and how the difficulty of algorithmic puzzle solvers is related to the difficulty and enjoyment for human players is a challenging task. In this work, we explored this relationship using logic grid puzzles. We used an algorithmic solver to estimate the difficulty of the puzzles by capturing the number of ``solver loops'' through the algorithm. This characteristic was used to generate and evaluate a set of puzzles of varying algorithmic difficulty using constrained MAP-Elites. Then, we ran a user study to gather information on the player experience of these puzzles. We tested the relationship between solver loops and player experience on generated puzzles and found that the number of solver loops is statistically significantly correlated with subjective perception of difficulty and borderline statistically significantly correlated with puzzle correctness.",915
830,Games,Seth Cooper,"November 15th, 2024",Sturgeon-MKIV: Constraint-Based Level and Playthrough Generation with Graph Label Rewrite Rules,https://doi.org/10.1609/aiide.v20i1.31862," Seth Cooper, Mahsa Bazzaz. (2024). Sturgeon-MKIV: Constraint-Based Level and Playthrough Generation with Graph Label Rewrite Rules AIIDE, 13-24. https://doi.org/10.1609/aiide.v20i1.31862","Abstract Procedurally generated game levels should be completable. The representation used for levels and game mechanics impacts the types of games for which different techniques can be applied. Previous work used a constraint solving approach to simultaneously generate levels with example playthroughs, showing they can be completed using the game's mechanics. However, that work used 2D grid-based rewrite rules. In this work, we extend previous approaches by representing levels as more general graphs, and game mechanics as rewrites on node and edge labels of subgraphs. Using this approach, graph-based levels with playthroughs are generated. We describe the approach and demonstrate its application in some games with graph-based levels.",916
831,Games,Seth Cooper,"July 5th, 2024",Asynchronous Collaboration with Quality-Diversity Search in Human Computation Games,https://doi.org/10.1145/3649921.3656977," Nicholas Osborn, Seth Cooper. (2024). Asynchronous Collaboration with Quality-Diversity Search in Human Computation Games FDG, 45. https://doi.org/10.1145/3649921.3656977","Human computation games can crowdsource human intuition and reasoning for complex problems. Collaboration on these problems may help players build on each others‚Äô work, but may also reduce the variety of solutions due to convergence. Previous work has found that applying quality-diversity approaches to crowdsourced human computation can encourage individuals to discover a wider variety of solutions. Thus, we investigate if quality-diversity approaches can similarly improve solution variety while also benefiting from collaboration. We ran a crowdsourced study in which two factors were varied: whether participants could asynchronously collaborate via access to solutions previously provided by other participants, and whether participants had access to quality-diversity search tools. We evaluated on two human computation puzzle tasks, and found the impact varied based on task; the quality-diversity tools appeared to help more in the travelling salesperson task, while collaboration appeared to help more in the knapsack task.",917
832,Games,Seth Cooper,"July 5th, 2024",Authoring Games with Tile Rewrite Rule Behavior Trees,https://doi.org/10.1145/3649921.3656979," Jiayi Zhou, Chris Martens , Seth Cooper. (2024). Authoring Games with Tile Rewrite Rule Behavior Trees FDG, 47. https://doi.org/10.1145/3649921.3656979","Game authoring can be a difficult, technical process; exploring new ways to describe games and game mechanics may help make game authoring more accessible. In this work, we present Tile Rewrite Rule Behavior Trees (TRRBTs): a concept for a domain-specific language for authoring tile-based, turn-based games. The approach combines tile rewrite rules and behavior trees. Using TRRBTs, a game‚Äôs state is represented as a grid of tiles, the behavior trees describe the overall flow of the game, and the rewrite rules at leaf nodes describe changes in game state. We include transform nodes, which apply transformations to other nodes in the behavior tree, allowing more complex mechanics to be expressed in a compact way. We demonstrate a text-based approach to using TRRBTs to create several simple games, show how the approach allows re-use of trees to build on existing games, and show how they can provide a unified representation for procedural content generation and enemy AI along with game mechanics.",918
833,Games,Seth Cooper,"May 11th, 2024",A Design Framework for Reflective Play,https://doi.org/10.1145/3613904.3642455," Josh Aaron Miller, Kutub Gandhi, Matthew Alexander Whitby, Mehmet Kosa, Seth Cooper, Elisa D. Mekler, Ioanna Iacovides. (2024). A Design Framework for Reflective Play CHI, 519:1-519:21. https://doi.org/10.1145/3613904.3642455","Recent research has begun exploring games as a medium for reflection due to their affordances as interactive systems of challenge. However, little effort has been put into (1) synthesizing insights across studies and disciplines and (2) translating the academic work on reflective play into practical takeaways for game developers. This article takes the first steps toward summarizing existing work on reflective play and translating insights for practical implementation by identifying key game elements present in games that evoke reflection. We divide these elements into five approaches: Disruptions, Slowdowns, Questioning, Revisiting, and Enhancers. Finally, we provide an actionable supplement for practicing game developers to apply these concepts to their games.",919
834,Games,Seth Cooper,"December 25th, 2023",Latent Combinational Game Design,," Anurag Sarkar, Seth Cooper. (2024). Latent Combinational Game Design IEEE Trans. Games, 16, 659-669. https://doi.org/10.1109/TG.2023.3346331",Invalid URL,920
835,Games,Seth Cooper,"December 4th, 2023",Game Level Blending using a Learned Level Representation,https://doi.org/10.1109/CoG57401.2023.10333227," Venkata Sai Revanth Atmakuri, Seth Cooper, Matthew Guzdial. (2023). Game Level Blending using a Learned Level Representation CoG, 1-8. https://doi.org/10.1109/CoG57401.2023.10333227","Clustering-based Tile Embeddings (CTE) can serve as a level representation for unannotated games and a unified level representation across games. CTE represents game level tiles as a continuous vector representation, unifying their visual, contextual, and behavioral information. We find that CTE has comparable or better performance without the need for human annotation. The study was published in the 2023 IEEE Conference on Games (CoG) and is available on the IEEE Xplore website.",921
836,Games,Seth Cooper,"December 4th, 2023",Active Learning for Classifying 2D Grid-Based Level Completability,https://doi.org/10.1109/CoG57401.2023.10333212," Mahsa Bazzaz, Seth Cooper. (2023). Active Learning for Classifying 2D Grid-Based Level Completability CoG, 1-4. https://doi.org/10.1109/CoG57401.2023.10333212","Active learning is not yet widely adopted in game evaluations. It has been used successfully in natural language processing, image and speech recognition, and computer vision. We train deep-learning models to classify levels for Super Mario Bros., Kid Icarus, and a Zelda-like game. Our results show using an activelearning approach to label levels results in better classifier performance with the same amount of labeled data. The results will be presented at the 2023 IEEE Conference on Games (CoG)",922
837,Games,Seth Cooper,"December 4th, 2023",Segment-wise Level Generation using Iterative Constrained Extension,https://doi.org/10.1109/CoG57401.2023.10333222," Hao Mao, Seth Cooper. (2023). Segment-wise Level Generation using Iterative Constrained Extension CoG, 1-7. https://doi.org/10.1109/CoG57401.2023.10333222","Generating game levels via constraint satisfaction can become slow as levels grow large. We explore constraint-based generation of large levels by iteratively extending smaller intermediate levels. We found that generating a level using more segments improves performance up to a point, and then decreases performance. Later segments usually took more time to generate than earlier segments. We evaluated our approach using three games and two low-level solvers. IEEE Conference on Games (CoG) will be held 21-24 August 2023 in Boston, MA, USA.",923
838,Games,Seth Cooper,"December 4th, 2023",path2level: Constraint-Based Level Generation from Paths,https://doi.org/10.1109/CoG57401.2023.10333205," Seth Cooper, Matthew Guzdial. (2023). path2level: Constraint-Based Level Generation from Paths CoG, 1-4. https://doi.org/10.1109/CoG57401.2023.10333205",Player paths are an important consideration when procedurally generating levels. Here we present a constraint-based level generation approach that takes a path through the level as input. We describe an interactive level generation tool where the generator creates levels based on paths the user draws. We characterize the types of paths and levels generated by the approach.,924
839,Games,Seth Cooper,"October 6th, 2023",Mechanic Maker 2.0: Reinforcement Learning for Evaluating Generated Rules,https://doi.org/10.1609/aiide.v19i1.27522," Johor Jara Gonzalez, Seth Cooper, Matthew Guzdial. (2023). Mechanic Maker 2.0: Reinforcement Learning for Evaluating Generated Rules AIIDE, 266-275. https://doi.org/10.1609/aiide.v19i1.27522","Abstract Automated game design (AGD), the study of automatically generating game rules, has a long history in technical games research. AGD approaches generally rely on approximations of human play, either objective functions or AI agents. Despite this, the majority of these approximators are static, meaning they do not reflect human player's ability to learn and improve in a game. In this paper, we investigate the application of Reinforcement Learning (RL) as an approximator for human play for rule generation. We recreate the classic AGD environment Mechanic Maker in Unity as a new, open-source rule generation framework. Our results demonstrate that RL produces distinct sets of rules from an A* agent baseline, which may be more usable by humans.",925
840,Games,Seth Cooper,"April 12th, 2023",Re-trainable Procedural Level Generation via Machine Learning (RT-PLGML) as Game Mechanic,https://doi.org/10.1145/3582437.3587210," Seth Cooper, Emily Halina, Jichen Zhu, Matthew Guzdial. (2023). Re-trainable Procedural Level Generation via Machine Learning (RT-PLGML) as Game Mechanic FDG, 69:1-69:3. https://doi.org/10.1145/3582437.3587210","We present re-trainable procedural level generation via machine learning (RT-PLGML), a game mechanic of providing in-game training examples for a PLGML system. We discuss opportunities and challenges, along with concept RT-PLGML games.",926
841,Games,Seth Cooper,"April 12th, 2023",Wrapped in Story: The Affordances of Narrative for Citizen Science Games,https://doi.org/10.1145/3582437.3582443," Josh Aaron Miller, Katherine Buse, Ranjodh Singh Dhaliwal, Justin B. Siegel, Seth Cooper, Colin Milburn. (2023). Wrapped in Story: The Affordances of Narrative for Citizen Science Games FDG, 33:1-33:11. https://doi.org/10.1145/3582437.3582443","Citizen science games enable public participation in scientific research, yet these games often struggle to engage wide audiences. As a potential solution, some game developers look to narrative as an experience-enhancing feature. Yet the impacts and affordances of narrative in citizen science games remain understudied, especially for games that require significant onboarding. Therefore, we investigated the effects of wrapping a story around the tutorial puzzles of the citizen science game Foldit. We found that the narrative increased the time players spent engaging with the game‚Äôs tutorial and its scientific puzzles but did not substantially affect their progress through the tutorial. This article provides two major contributions: (1) empirical evidence detailing the impact of narrative on gameplay metrics in a citizen science game, including the relevant effects of genre preferences on engagement; and (2) recommendations on the use of narrative and its capacities in citizen science games. We conclude that the inclusion of a narrative can add valuable depth to the experience when designed thoughtfully and intentionally.",927
842,Games,Seth Cooper,"April 12th, 2023",Sturgeon-MKIII: Simultaneous Level and Example Playthrough Generation via Constraint Satisfaction with Tile Rewrite Rules,https://doi.org/10.1145/3582437.3587205," Seth Cooper. (2023). Sturgeon-MKIII: Simultaneous Level and Example Playthrough Generation via Constraint Satisfaction with Tile Rewrite Rules FDG, 64:1-64:9. https://doi.org/10.1145/3582437.3587205","Completability is a key aspect of procedural level generation. In this work, we present a constraint-based approach to level generation for 2D tile-based games that simultaneously generates a level and an example playthrough of the level demonstrating its completability. The approach represents game mechanics as tile rewrite rules, which allows a variety of games and mechanics (beyond simple pathfinding) to be incorporated. The mechanics are represented as constraints in the same problem along with the constraints used to generate the level itself. Thus, the solution to the constraint problem contains both a level and a playthrough of the level. We demonstrate the flexibilty of the system and of tile rewrite rules in several applications, including lock-and-key dungeons, platformers, puzzles, and match-three style games.",928
843,Games,Seth Cooper,"April 12th, 2023",Sturgeon-GRAPH: Constrained Graph Generation from Examples,https://doi.org/10.1145/3582437.3582465," Seth Cooper. (2023). Sturgeon-GRAPH: Constrained Graph Generation from Examples FDG, 23:1-23:9. https://doi.org/10.1145/3582437.3582465","Procedural level generation techniques that learn local neighborhoods from example levels (such as WaveFunctionCollapse) have risen in popularity. Usually the neighborhood structure (such as a regular grid) onto which a level is generated is fixed in advance and not generated. In this work, we present a constraint-based approach for graph generation that learns local neighborhood patterns (in the form of labeled nodes and edges) from example graphs. This allows the approach to generate graphs with varying structures that are still locally similar to the examples. We demonstrate the approach on several applications, such as abstract graphs describing Legend of Zelda dungeons. Additionally, using Super Mario Bros. levels, we show how techniques that run on a grid may be considered a special case of graph generation where each tile is a node connecting to its neighboring tiles‚Äô nodes.",929
844,Games,Bob De Schutter,"July 5th, 2024",Cardistry: Exploring a GPT Model Workflow as an Adapted Method of Gaminiscing,https://doi.org/10.1145/3649921.3656984," Brandon Lyman, Ala Ebrahimi, James Cox, Szeyi Chan, Christopher Barney, Bob De Schutter. (2024). Cardistry: Exploring a GPT Model Workflow as an Adapted Method of Gaminiscing FDG, 52. https://doi.org/10.1145/3649921.3656984","Cardistry is an application that enables users to create their own playing cards for use in evocative storytelling games. It is driven by OpenAI‚Äôs Generative Pre-trained Transformer (GPT) models that generate unique card titles, cards suits, imagery, and poetry based on the user‚Äôs input. It allows the user to preserve their digital cards in an online repository and print them for tabletop game play use. Cardistry was designed to begin exploring the question of whether widely available GPT models could be used to adapt the process of gaminiscing to make it more accessible to designers and players alike. This short paper details the concept, design, and implementation of Cardistry as a first step in exploring this research question. It explains how the adapted gaminiscing process is different from the original process, discusses the limitations of the implementation, and expresses what future research would be required to answer the research question.",930
845,Games,Bob De Schutter,"July 5th, 2024",Hidden Heroes: A thematic analysis of a game jam designed around authentic stories,https://doi.org/10.1145/3649921.3656981," Ala Ebrahimi, James Cox, Erica Kleinman, Bob De Schutter. (2024). Hidden Heroes: A thematic analysis of a game jam designed around authentic stories FDG, 49. https://doi.org/10.1145/3649921.3656981","In 2023, the Hidden Heroes game jam allowed game developers to share untold stories of individuals who had a significant impact on their lives. As a result, 33 games were created embracing the stories of real people. Interviews were conducted with 12 of these developers to understand their experiences of creating games about authentic personal stories. Thematic analysis revealed eight themes and three categories that captured the experiences and challenges of making such personal narrative games. Based on these findings, we reflected on the future of authentic personal narrative games.",931
846,Games,Bob De Schutter,"December 4th, 2023",Brukel vs Brukel: Impact of Game Fidelity on Player Experience In Gaminiscing Games,https://doi.org/10.1109/CoG57401.2023.10333250," Szeyi Chan, James Cox, Ala Ebrahimi, Brandon Lyman, Bob De Schutter. (2023). Brukel vs Brukel: Impact of Game Fidelity on Player Experience In Gaminiscing Games CoG, 1-4. https://doi.org/10.1109/CoG57401.2023.10333250","Gaminiscing games are designed in a narrative way to archive and recreate personal oral history. Results show that it is not the case that both fidelity and scene would always significantly affect the overall experience of the game. This finding could shed light on practical game design, where game designers can choose the level of production that best aligns with their game's objectives. The study aims to explore the potential possibility of low-fidelity game design but without sacrificing the player experience. It was published in the 2023 IEEE Conference on Games (CoG)",932
847,Games,Bob De Schutter,"December 4th, 2023",Catch The Butterfly: Using Gaminiscing to Design a Serious Game about Immigrants,https://doi.org/10.1109/CoG57401.2023.10333237," Ala Ebrahimi, Brandon Lyman, James Earl Cox, Szeyi Chan, Bob De Schutter. (2023). Catch The Butterfly: Using Gaminiscing to Design a Serious Game about Immigrants CoG, 1-4. https://doi.org/10.1109/CoG57401.2023.10333237",This short paper explores the utilization of the gaminiscing method in the design of a narrative-driven game. Every game mechanic is derived from the authentic stories of an immigrant. The aim is to provide valuable insights to game designers interested in employing the gammisces method for the development of storytelling games.,933
848,Games,Bob De Schutter,"August 21st, 2023",Catch The Butterfly: A Gaminiscing Game about Immigration,https://doi.org/10.1109/CoG57401.2023.10333172," Ala Ebrahimi, Brandon Lyman, James Earl Cox, Szeyi Chan, Bob De Schutter. (2023). Catch The Butterfly: A Gaminiscing Game about Immigration CoG, 1-2. https://doi.org/10.1109/CoG57401.2023.10333172","Catch The Butterfly is a narrative game exploring the real, lived experiences of an immigrant. It was created using the gaminiscing method. In Catch The Butterfly, every mechanic and representation is derived from the authentic stories of the subject. The aim is twofold: to provide insights to game designers. and to promote empathy and understanding of immigrants.",934
849,Games,Bob De Schutter,"September 25th, 2020",The Relationship Between the Seniors‚Äô Appraisal of Cognitive-Training Games and Game-Related Stress Is Complex: A Mixed-Methods Study,https://doi.org/10.1007/978-3-030-60149-2_45," Najmeh Khalili-Mahani, Bob De Schutter, Kim Sawchuk. (2020). The Relationship Between the Seniors' Appraisal of Cognitive-Training Games and Game-Related Stress Is Complex: A Mixed-Methods Study HCI (44), 586-607. https://doi.org/10.1007/978-3-030-60149-2_45","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",935
850,Games,Bob De Schutter,"March 11th, 2020",For Whom the Games Toll: A Qualitative and Intergenerational Evaluation of What is Serious in Games for Older Adults,https://doi.org/10.1007/s40869-020-00103-7," Najmeh Khalili-Mahani, Bob De Schutter, Mahsa Mirgholami, Eileen Mary Holowka, Rebecca Goodine, Scott DeJong, Roseleen McGaw, Sue Meyer, Kim Sawchuk. (2020). For Whom the Games Toll: A Qualitative and Intergenerational Evaluation of What is Serious in Games for Older Adults Comput. Games J., 9, 221-244. https://doi.org/10.1007/s40869-020-00103-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",936
851,Games,Brianna Dym,"October 4th, 2023",Competing Imaginaries and Partisan Divides in the Data Rhetoric of Advocacy Organizations,https://doi.org/10.1145/3610050," Shiva Darian, Brianna Dym, Amy Voida. (2023). Competing Imaginaries and Partisan Divides in the Data Rhetoric of Advocacy Organizations Proc. ACM Hum. Comput. Interact., 7, 1-29. https://doi.org/10.1145/3610050","Data are wielded to shape public opinion, particularly in electoral contexts where the role and veracity of information is questioned. This post-truth era is characterized by world events in which facts too often are obfuscated and evidential standards are abandoned. To study how data are used to influence pressing and divisive contemporary issues, this paper explores the rhetorical work that quantitative data are doing through the blogging practices of advocacy organizations during the highly-polarized month preceding the 2016 United States elections. We present results of a qualitative content analysis of the quantitative data used in 337 blog posts published by five pairs of conservative and liberal advocacy organizations over the course of the month leading up to the 2016 US elections. We identify key data rhetoric practices along partisan lines and contribute an analytic framework-evaluating ethos, pathos, and logos- that can be used to analyze the rhetorical use of data in other contexts. We then characterize two different imaginaries that come into conflict in this research: 1) the political imaginaries being promoted through organizational blogging and 2) the sociotechnical imaginary of the data economy, foregrounding differences in the epistemic value of data in each. We conclude by outlining research challenges and trajectories for future research within each of the two imaginaries of data.",937
852,Games,Brianna Dym,"March 3rd, 2023","Gaming Together, Coding Together: Collaborative Pathways to Computational Learning",https://doi.org/10.1145/3545945.3569833," Brianna Dym, Cole Rockwood, Casey Fiesler. (2023). Gaming Together, Coding Together: Collaborative Pathways to Computational Learning SIGCSE (1), 1035-1041. https://doi.org/10.1145/3545945.3569833","Collaborative, playful learning represents an important avenue to mastering a range of skills within computer science education. This research presents findings from interviews with 9 members of an online community that started out as a gaming league and transitioned into a game development team. Community members learned programming skills to contribute their ideas to the game and participate in activities based around game development. Drawing on these experiences, we identify key elements from informal learning that can improve computer science education: 1) playful projects can help learners overcome barriers to participating in computer science; 2) community closeness facilitates a collaborative learning environment to support developing expertise in specific computational skills. We consider these findings in the context of learning as an everyday social practice, and discuss means of developing playful learning communities in computer science classrooms.",938
853,Games,Brianna Dym,"January 14th, 2022",Building a Pillowfort: Political Tensions in Platform Design and Policy,https://doi.org/10.1145/3492835," Brianna Dym, Namita Pasupuleti, Casey Fiesler. (2022). Building a Pillowfort: Political Tensions in Platform Design and Policy Proc. ACM Hum. Comput. Interact., 6, 16:1-16:23. https://doi.org/10.1145/3492835","Social media platforms make trade-offs in their design and policy decisions to attract users and stand out from other platforms. These decisions are influenced by a number of considerations, e.g. what kinds of content moderation to deploy or what kinds of resources a platform has access to. Their choices play into broader political tensions; social media platforms are situated within a social context that frames their impact, and they can have politics through their design that enforce power structures and serve existing authorities. We turn to Pillowfort, a small social media platform, to examine these political tensions as a case study. Using a discourse analysis, we examine public discussion posts between staff and users as they negotiate the site's development over a period of two years. Our findings illustrate the tensions in navigating the politics that users bring with them from previous platforms, the difficulty of building a site's unique identity and encouraging commitment, and examples of how design decisions can both foster and break trust with users. Drawing from these findings, we discuss how the success and failure of new social media platforms are impacted by political influences on design and policy decisions.",939
854,Games,Brianna Dym,"May 8th, 2021",Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research,https://doi.org/10.1145/3411763.3450403," Michael Ann DeVito, Caitlin Lustig, Ellen Simpson, Kimberley R. Allison, Tya S. Chuanromanee, Katta Spiel, Amy J. Ko, Jennifer Ann Rode, Brianna Dym, Michael J. Muller, Morgan Klaus Scheuerman, Ashley Marie Walker, Jed R. Brubaker, Alex A. Ahmed. (2021). Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research CHI Extended Abstracts, 159:1-159:3. https://doi.org/10.1145/3411763.3450403","As Queer Human-Computer Interaction (HCI) becomes an established part of the larger field, both in terms of research on and with queer populations and in terms of employing queering theories and methods, the role of queer researchers has become a timely topic of discussion. However, these discussions have largely centered around member-researcher status and positionality when working with queer populations. Based on insights gathered at multiple ACM events over the past two years, we identified two pressing issues: (1) we need to better support queer people doing HCI research not specific to queer populations, and (2) we need to identify how to best support member-researchers in leading Queer HCI while including collaborators beyond the queer community. This Special Interest Group (SIG) aims to directly address these challenges by convening a broad community of queer researchers and allies, working not only on explicitly-queer topics but across a broad range of HCI topics.",940
855,Games,Wallace Lages,"November 1st, 2024",Audio augmented reality using sonification to enhance visual art experiences: Lessons learned,https://doi.org/10.1016/j.ijhcs.2024.103329," Abhraneil Dam, Yeaji Lee, Arsh Siddiqui, Wallace Santos Lages, Myounghoon Jeon . (2024). Audio augmented reality using sonification to enhance visual art experiences: Lessons learned Int. J. Hum. Comput. Stud., 191, 103329. https://doi.org/10.1016/j.ijhcs.2024.103329","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",941
856,Games,Wallace Lages,"October 29th, 2024","Breaking Barriers in Immersive Stories: Empathy, Representation, and Access",https://doi.org/10.1145/3698391," Tyechia L. Thompson, Eric Lyon, Wallace Lages. (2024). Breaking Barriers in Immersive Stories: Empathy, Representation, and Access Interactions, 31, 6-7. https://doi.org/10.1145/3698391","The Interactions website (interactions.acm.org) hosts a stable of bloggers who share insights and observations on HCI, often challenging current practices. Each issue we'll publish selected posts from some of the leading and emerging voices in the field.",942
857,Games,Wallace Lages,"October 7th, 2024","Examining Pair Dynamics in Shared, Co-located Augmented Reality Narratives",https://doi.org/10.1145/3677386.3682091," Cherelle Connor, Eric Cade Schoenborn, Sathaporn Hu, Thiago Malheiros Porcino, Cameron Moore, Derek Reilly, Wallace Santos Lages. (2024). Examining Pair Dynamics in Shared, Co-located Augmented Reality Narratives SUI, 17:1-17:11. https://doi.org/10.1145/3677386.3682091","Augmented reality (AR) allows users to experience stories together in the same physical space. However, little is known about the experience of sharing AR narratives with others. Much of our current understanding is derived from multi-user VR applications, which can differ significantly in presence, social interaction, and spatial awareness from narratives and other entertainment content designed for AR head-worn displays. To understand the dynamics of multi-user, co-located, AR storytelling, we conducted an exploratory study involving three original AR narratives. Participants experienced each narrative alone or in pairs via the Microsoft Hololens 2. We collected qualitative and quantitative data from 42 participants through questionnaires and post-experience semi-structured interviews. Results indicate participants enjoyed experiencing AR narratives together and revealed five themes relevant to the design of multi-user, co-located AR narratives. We discuss the implications of these themes and provide design recommendations for AR experience designers and storytellers regarding the impact of interaction, physical space, spatial coherence, and narrative timing. Our findings highlight the importance of exploring both user interactions and pair interactions as factors in AR storytelling research.",943
858,Games,Wallace Lages,"May 11th, 2020",Where to display? How Interface Position Affects Comfort and Task Switching Time on Glanceable Interfaces,https://doi.org/10.1109/VR46266.2020.1581435674325," Samat Imamov, Daniel Monzel, Wallace Santos Lages. (2020). Where to display? How Interface Position Affects Comfort and Task Switching Time on Glanceable Interfaces VR, 851-858. https://doi.org/10.1109/VR46266.2020.1581435674325","A critical decision when designing glanceable information displays is where to place the content. Since blocking the center of the field of view with virtual information is not desirable, designers often opt for placement in the visual periphery. No study has been made to systematically evaluate world-locked content position, considering both cognitive and physiological constraints. We found participants preferred content at medium distances, although they were also faster with content at far distances. The same happens with discomfort: content placed at eye level, or below, was faster and more comfortable than in other positions.",944
859,Games,Chris Martens,"July 5th, 2024",Authoring Games with Tile Rewrite Rule Behavior Trees,https://doi.org/10.1145/3649921.3656979," Jiayi Zhou, Chris Martens , Seth Cooper. (2024). Authoring Games with Tile Rewrite Rule Behavior Trees FDG, 47. https://doi.org/10.1145/3649921.3656979","Game authoring can be a difficult, technical process; exploring new ways to describe games and game mechanics may help make game authoring more accessible. In this work, we present Tile Rewrite Rule Behavior Trees (TRRBTs): a concept for a domain-specific language for authoring tile-based, turn-based games. The approach combines tile rewrite rules and behavior trees. Using TRRBTs, a game‚Äôs state is represented as a grid of tiles, the behavior trees describe the overall flow of the game, and the rewrite rules at leaf nodes describe changes in game state. We include transform nodes, which apply transformations to other nodes in the behavior tree, allowing more complex mechanics to be expressed in a compact way. We demonstrate a text-based approach to using TRRBTs to create several simple games, show how the approach allows re-use of trees to build on existing games, and show how they can provide a unified representation for procedural content generation and enemy AI along with game mechanics.",945
860,Games,Chris Martens,"October 6th, 2023",Probabilistic Logic Programming Semantics For Procedural Content Generation,https://doi.org/10.1609/aiide.v19i1.27525," Abdelrahman Madkour, Chris Martens , Steven Holtzen, Casper Harteveld, Stacy Marsella. (2023). Probabilistic Logic Programming Semantics For Procedural Content Generation AIIDE, 295-305. https://doi.org/10.1609/aiide.v19i1.27525","Abstract Research in procedural content generation (PCG) has recently heralded two major methodologies: machine learning (PCGML) and declarative programming. The former shows promise by automating the specification of quality criteria through latent patterns in data, while the latter offers significant advantages for authorial control. In this paper we propose the use of probabilistic logic as a unifying framework that combines the benefits of both methodologies. We propose a Bayesian formalization of content generators as probability distributions and show how common PCG tasks map naturally to operations on the distribution. Further, through a series of experiments with maze generation, we demonstrate how probabilistic logic semantics allows us to leverage the authorial control of declarative programming and the flexibility of learning from data.",946
861,Games,Alexandra To,"January 13th, 2025",Data Enrichment Work and AI Labor in Latin America and the Caribbean,https://doi.org/10.48550/arXiv.2501.06981," Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage. (2025). Data Enrichment Work and AI Labor in Latin America and the Caribbean CoRR, abs/2501.06981. https://doi.org/10.48550/arXiv.2501.06981","The global AI surge demands crowdworkers from diverse languages and cultures. They are pivotal in labeling data for enabling global AI systems. Despite global significance, research has primarily focused on understanding the perspectives and experiences of US and India crowdworkers, leaving a notable gap. To bridge this, we conducted a survey with 100 crowdworkers across 16 Latin American and Caribbean countries. We discovered that these workers exhibited pride and respect for their digital labor, with strong support and admiration from their families. Notably, crowd work was also seen as a stepping stone to financial and professional independence. Surprisingly, despite wanting more connection, these workers also felt isolated from peers and doubtful of others' labor quality. They resisted collaboration and gender-based tools, valuing gender-neutrality. Our work advances HCI understanding of Latin American and Caribbean crowdwork, offering insights for digital resistance tools for the region.",947
862,Games,Alexandra To,"July 24th, 2024","Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing",https://doi.org/10.48550/arXiv.2407.17579," JaeWon Kim, Lindsay Popowski, Anna Fang, Cassidy Pyle, Guo Freeman, Ryan M. Kelly, Angela Y. Lee, Fannie Liu, Angela D. R. Smith, Alexandra To, Amy X. Zhang. (2024). Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing CoRR, abs/2407.17579. https://doi.org/10.48550/arXiv.2407.17579","Social technology research today largely focuses on mitigating the negative impacts of technology and, therefore, often misses the potential of technology to enhance human connections and well-being. However, we see a potential to shift towards a holistic view of social technology's impact on human flourishing. We introduce Positive Social Technology (Positech), a framework that shifts emphasis toward leveraging social technologies to support and augment human flourishing. This workshop is organized around three themes relevant to Positech: 1) ""Exploring Relevant and Adjacent Research"" to define and widen the Positech scope with insights from related fields, 2) ""Projecting the Landscape of Positech"" for participants to outline the domain's key aspects and 3) ""Envisioning the Future of Positech,"" anchored around strategic planning towards a sustainable research community. Ultimately, this workshop will serve as a platform to shift the narrative of social technology research towards a more positive, human-centric approach. It will foster research that goes beyond fixing technologies to protect humans from harm, to also pursue enriching human experiences and connections through technology.",948
863,Games,Alexandra To,"July 5th, 2024","Queer TTRPGs‚Äô Visibility, Safety, and Allegory as Resistance",https://doi.org/10.1145/3649921.3650022," Jailyn Zabala, Josie Zvelebilova, Alexandra To. (2024). Queer TTRPGs' Visibility, Safety, and Allegory as Resistance FDG, 30. https://doi.org/10.1145/3649921.3650022","Responding to Ruberg‚Äôs notion of the ‚Äúqueer games avant-garde‚Äù where games are made by, for, and about queer gamers [23], we sought out ‚Äúqueer TTRPGs‚Äù where queerness is centered in the design of a given tabletop roleplaying game (TTRPG) system and/or setting. In this study, we curated a ludography of seven queer TTRPGs that support the exploration of queer identity: Thirsty Sword Lesbians [36], Monsterhearts 2 [2], Dream Askew [1], Alice is Missing [29], Sleepaway [8], Lichcraft [19], and Wanderhome [9]. In our content analysis of the game guidebooks, we found that the games guide players through queer play experiences through tenets of queer theory, while using visibility and direct disclosure of the game‚Äôs themes to resist the status-quo of erasing queerness in traditional media. We close with reflections on how other game designers can leverage these strategies to support and uplift queer gamers.",949
864,Games,Alexandra To,"May 11th, 2024",An Exploration of Learned Values Through Lived Experiences to Design for BIPOC Students‚Äô Flourishing,https://doi.org/10.1145/3613905.3650899," Laveda Chan, Dilruba Showkat, Alexandra To. (2024). An Exploration of Learned Values Through Lived Experiences to Design for BIPOC Students' Flourishing CHI Extended Abstracts, 43:1-43:7. https://doi.org/10.1145/3613905.3650899","Prior research has primarily focused on the negative experiences faced by BIPOC students and sought to identify ways to counter harms. In contrast, our work seeks to characterize and support the positive, valuable, and meaningful experiences of BIPOC to support their holistic thriving at predominantly white institutions (PWIs). Experiences where students can share their stories and engage with racial identity development, are paramount to their flourishing. However, these stories and connections are not widely accessible. In this work, we gathered stories of meaningful experiences by conducting a qualitative semi-structured interview with 17 BIPOC students from diverse races and ethnic backgrounds, all studying across various PWIs. Our preliminary findings revealed that students derive meaningful experiences by engaging in activities that lead to the cultivation of learned values and personal growth. We discuss and situate our findings within a positive design framework to support BIPOC students‚Äô sustained well-being and flourishing.",950
865,Games,Alexandra To,"October 31st, 2022",Alienated Serendipity and Reflective Failure: Exploring Queer Game Mechanics and Queerness in Games via Queer Temporality,https://doi.org/10.1145/3549484," Matthew Hantsbarger, Giovanni Maria Troiano, Alexandra To, Casper Harteveld. (2022). Alienated Serendipity and Reflective Failure: Exploring Queer Game Mechanics and Queerness in Games via Queer Temporality Proc. ACM Hum. Comput. Interact., 6, 1-27. https://doi.org/10.1145/3549484","Queerness can help redefine interactive technologies and re-conceptualize their design beyond cisheteronormativity. Recently, games have emerged as promising avenues for exploring queerness. In this research-through-design (RtD) effort, we advance queer explorations in games by leveraging queer temporality to evoke and explore feelings of alienation and isolation in a horror game called You're Going To Be Late. We further engage with queer individuals who playtest our game and participate in focus groups to discuss how queer they felt our game was and what they regard as queer game mechanics. Participants had varying experiences while playing our game, ranging from serendipity and wonder to alienation and confusion. The focus groups described queer game mechanics as queer modes of play and often tapped into gender representation. Finally, we show how including and amplifying queer voices in discursive efforts around interactive technology design has implications for transformative and critical reflections that can broadly benefit game design and HCI research.",951
866,Games,Alexandra To,"April 29th, 2022",Interactive Fiction Provotypes for Coping with Interpersonal Racism,https://doi.org/10.1145/3491102.3502044," Alexandra To, Hillary Carey, Riya Shrivastava, Jessica Hammer, Geoff Kaufman. (2022). Interactive Fiction Provotypes for Coping with Interpersonal Racism CHI, 453:1-453:14. https://doi.org/10.1145/3491102.3502044","Reducing uncertainty around the nature of racist interactions is one of the key motivations driving individual behaviors for coping with those incidents. However, there are few appropriate technologies to support BIPOC (Black, Indigenous, People of Color) in engaging in social uncertainty reduction around this vulnerable, sensitive topic. This paper reports on an exploratory design study investigating how social technology might facilitate uncertainty reduction through three ‚Äúprovotypes‚Äù - provocative prototypes of user-generated speculative design concepts. U.S.-based participants engaged with the provotypes through an interactive fiction to explore their usefulness in the context of a racist microaggression. Results showed that engaging the provotypes through interactive fiction facilitated complex and productive interactions and critiques. This work contributes a novel method for conducting exploratory design, remote user studies using interactive fiction as well as priorities, tensions, and further information what role, if any, technology might play in managing racist interactions.",952
867,Games,Alexandra To,"April 28th, 2022",Collecting and Reporting Race and Ethnicity Data in HCI,https://doi.org/10.1145/3491101.3519685," Yiqun T. Chen, Angela D. R. Smith, Katharina Reinecke, Alexandra To. (2022). Collecting and Reporting Race and Ethnicity Data in HCI CHI Extended Abstracts, 327:1-327:8. https://doi.org/10.1145/3491101.3519685","Engaging racially and ethnically diverse participants in Human-Computer Interaction (HCI) research is critical for creating safe, inclusive, and equitable technology. However, it remains unclear why and how HCI researchers collect study participants‚Äô race and ethnicity. Through a systematic literature analysis of 2016‚Äì2021 CHI proceedings and a survey with 15 authors who published in these proceedings, we found that reporting race and ethnicity of participants is uncommon and that HCI researchers are far from consensus on the collection and analysis of this data. Because a majority (>90%) of the articles that report participants‚Äô race and ethnicity are conducted in the United States, we focused our discussion on race and ethnicity accordingly. In future work, we plan to investigate considerations and best practices for collecting and analyzing race and ethnicity data in a global context.",953
868,Games,Alexandra To,"June 30th, 2021",Discovering intersectionality: part 2: reclaiming our time,https://doi.org/10.1145/3468783," Jakita Owensby Thomas, Neha Kumar, Alexandra To, Quincy Brown, Yolanda A. Rankin. (2021). Discovering intersectionality: part 2: reclaiming our time Interactions, 28, 72-75. https://doi.org/10.1145/3468783","In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors",954
869,Games,Alexandra To,"April 27th, 2021",Discovering intersectionality part I: researcher interrupted,https://doi.org/10.1145/3457869," Quincy Brown, Neha Kumar, Jakita Owensby Thomas, Alexandra To, Yolanda A. Rankin. (2021). Discovering intersectionality part I: researcher interrupted Interactions, 28, 73-77. https://doi.org/10.1145/3457869","In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors",955
870,Games,Alexandra To,"May 1st, 2020",‚ÄúThey Just Don‚Äôt Get It‚Äù: Towards Social Technologies for Coping with Interpersonal Racism,https://dl.acm.org/doi/abs/10.1145/3392828," To, A., Sweeney, W., Hammer, J., & Kaufman, G. (2020). "" They Just Don't Get It"": Towards Social Technologies for Coping with Interpersonal Racism. Proceedings of the ACM on Human-Computer Interaction, 4(CSCW1), 1-29.","Over 35% of Americans belong to racial minority groups. Racism targeting these individuals results in a range of harmful physical, psychological, and practical consequences. The present work aims to shed light on the current sense-making and support-seeking practices exhibited by targets of racism, as well as to identify the core needs and barriers that future socio-technical interventions could potentially address. The long-term goal of this work is to understand how CSCW researchers and designers could best support members of marginalized groups to make sense of and to seek support for experiences with racism. Narrative episode interviews with targets of racism revealed a number of key entry points for intervention. For example, participants' personal stories confirmed that uncertainty, both about the nature and consequences of the experience of racism, is a key motivator for support-seeking. In addition, despite the need for support, participants largely do not trust public forms of social media for support-seeking. We discuss how participants' accounts of the complex labor involved in determining who ""gets it"" in identifying potential supporters, and in navigating the complexities of trust and agency in sharing their experiences, present clear implications for the design of new socio-technical platforms for members of racial minority groups.",956
871,Games,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",957
872,Games,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",958
873,Games,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",959
874,Games,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",960
875,Games,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",961
876,Games,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",962
877,Games,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",963
878,Games,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",964
879,Human-Centered Computing,Timothy W. Bickmore,"February 25th, 2025",Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations,https://doi.org/10.48550/arXiv.2502.18673," Ian Steenstra, Farnaz Nouraei, Timothy W. Bickmore. (2025). Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations CoRR, abs/2502.18673. https://doi.org/10.48550/arXiv.2502.18673","Learning therapeutic counseling involves significant role-play experience with mock patients, with current manual training methods providing only intermittent granular feedback. We seek to accelerate and optimize counselor training by providing frequent, detailed feedback to trainees as they interact with a simulated patient. Our first application domain involves training motivational interviewing skills for counselors. Motivational interviewing is a collaborative counseling style in which patients are guided to talk about changing their behavior, with empathetic counseling an essential ingredient. We developed and evaluated an LLM-powered training system that features a simulated patient and visualizations of turn-by-turn performance feedback tailored to the needs of counselors learning motivational interviewing. We conducted an evaluation study with professional and student counselors, demonstrating high usability and satisfaction with the system. We present design implications for the development of automated systems that train users in counseling skills and their generalizability to other types of social skills training.",965
880,Human-Centered Computing,Timothy W. Bickmore,"December 26th, 2024",Exploring the Potential of Virtual Agents in Atrial Fibrillation Management: Insights from a Randomized Trial,https://doi.org/10.1145/3652988.3673955," Mina Fallah, Timothy W. Bickmore, Stefan Olafsson, Michael K. Paasche-Orlow, Andrew Joseph Mrkva, Jared W. Magnani. (2024). Exploring the Potential of Virtual Agents in Atrial Fibrillation Management: Insights from a Randomized Trial IVA, 8:1-8:9. https://doi.org/10.1145/3652988.3673955","Smartphone-based conversational agents offer a convenient way to deliver health education, particularly for managing complex health conditions such as chronic diseases. The present study explores using a smartphone-based virtual agent system to aid patients with a chronic heart condition‚Äîatrial fibrillation‚Äîto manage their health by encouraging the use of a heart rhythm sensor integrated with their smartphones. We report the results of a randomized clinical trial with 240 patients experiencing atrial fibrillation who were provided with smartphones and heart rhythm sensors for 4 months. Participants in the intervention group interacted with a virtual agent, while the control group received general health education via the WebMD app. Intervention participants completed a median 91 interactions with the agent over the 4 months of the study period, and agent features designed to increase engagement‚Äìsuch as storytelling‚Äìwere effective at increasing use. The agent‚Äôs promotion of heart rhythm sensor use was effective, with intervention participants taking significantly more heart rhythm readings compared to those in the control group. Participants were followed for 8 months thereafter to assess the sustainability of the effects, specifically focusing on medication adherence.",966
881,Human-Centered Computing,Timothy W. Bickmore,"July 8th, 2024",Investigating User Perceptions of Collaborative Agenda Setting in Virtual Health Counseling Session,https://doi.org/10.48550/arXiv.2407.06123," Mina Fallah, Farnaz Nouraei, Hye Sun Yun, Timothy W. Bickmore. (2024). Investigating User Perceptions of Collaborative Agenda Setting in Virtual Health Counseling Session CoRR, abs/2407.06123. https://doi.org/10.48550/arXiv.2407.06123","Virtual health counselors offer the potential to provide users with information and counseling in complex areas such as disease management and health education. However, ensuring user engagement is challenging, particularly when the volume of information and length of counseling sessions increase. Agenda setting a clinical counseling technique where a patient and clinician collaboratively decide on session topics is an effective approach to tailoring discussions for individual patient needs and sustaining engagement. We explore the effectiveness of agenda setting in a virtual counselor system designed to counsel women for breast cancer genetic testing. In a between subjects study, we assessed three versions of the system with varying levels of user control in the system's agenda setting approach. We found that participants' knowledge improved across all conditions. Although our results showed that any type of agenda setting was perceived as useful, regardless of user control, interviews revealed a preference for more collaboration and user involvement in the agenda setting process. Our study highlights the importance of using patient-centered approaches, such as tailored discussions, when using virtual counselors in healthcare.",967
882,Human-Centered Computing,Timothy W. Bickmore,"July 1st, 2024",Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents,https://doi.org/10.48550/arXiv.2407.01824," Mehdi Arjmand, Farnaz Nouraei, Ian Steenstra, Timothy W. Bickmore. (2024). Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents CoRR, abs/2407.01824. https://doi.org/10.48550/arXiv.2407.01824","We introduce the concept of ""empathic grounding"" in conversational agents as an extension of Clark's conceptualization of grounding in conversation in which the grounding criterion includes listener empathy for the speaker's affective state. Empathic grounding is generally required whenever the speaker's emotions are foregrounded and can make the grounding process more efficient and reliable by communicating both propositional and affective understanding. Both speaker expressions of affect and listener empathic grounding can be multimodal, including facial expressions and other nonverbal displays. Thus, models of empathic grounding for embodied agents should be multimodal to facilitate natural and efficient communication. We describe a multimodal model that takes as input user speech and facial expression to generate multimodal grounding moves for a listening agent using a large language model. We also describe a testbed to evaluate approaches to empathic grounding, in which a humanoid robot interviews a user about a past episode of pain and then has the user rate their perception of the robot's empathy. We compare our proposed model to one that only generates non-affective grounding cues in a between-subjects experiment. Findings demonstrate that empathic grounding increases user perceptions of empathy, understanding, emotional intelligence, and trust. Our work highlights the role of emotion awareness and multimodality in generating appropriate grounding moves for conversational agents.",968
883,Human-Centered Computing,Timothy W. Bickmore,"May 11th, 2024",‚ÄòSomething I Can Lean On‚Äô: A Qualitative Evaluation of a Virtual Palliative Care Counselor for Patients with Life-Limiting Illnesses,https://doi.org/10.1145/3613905.3651106," Teresa K. O'Leary, Michael K. Paasche-Orlow, Timothy W. Bickmore. (2024). 'Something I Can Lean On': A Qualitative Evaluation of a Virtual Palliative Care Counselor for Patients with Life-Limiting Illnesses CHI Extended Abstracts, 380:1-380:7. https://doi.org/10.1145/3613905.3651106","Palliative care is essential for maintaining the highest quality of life for patients with life-limiting illnesses. Although the benefits of palliative care are well supported, palliative care services are often offered late in the trajectory of the patient‚Äôs disease, limiting the beneficial role these services play in mitigating patient suffering. Digital health tools represent a promising approach for expanding access to palliative care. We report findings from interviews with twenty patients who used a virtual palliative care counselor over a six-month study period and provide guidelines for developers based on these results. Through their use of the system, patients characterized how using a digital palliative care counselor that intervenes on multiple dimensions of well-being benefited their experience of illness and quality of life.",969
884,Human-Centered Computing,Timothy W. Bickmore,"May 11th, 2024",Engaging and Entertaining Adolescents in Health Education Using LLM-Generated Fantasy Narrative Games and Virtual Agents,https://doi.org/10.1145/3613905.3650983," Ian Steenstra, Prasanth Murali, Rebecca B. Perkins, Natalie Joseph, Michael K. Paasche-Orlow, Timothy W. Bickmore. (2024). Engaging and Entertaining Adolescents in Health Education Using LLM-Generated Fantasy Narrative Games and Virtual Agents CHI Extended Abstracts, 126:1-126:8. https://doi.org/10.1145/3613905.3650983","Games have been successfully used to provide engaging health interventions for adolescents. However, translating health education goals into a playable game has historically taken many person-months of effort, involving game designers, scriptwriters, and artists. This work presents an exploratory study into rapidly developing physician-validated health education games for adolescents using virtual agents and LLMs. We evaluated this approach in an intervention to promote Human Papillomavirus (HPV) vaccination among adolescents, as lack of knowledge and vaccine hesitancy contribute to suboptimal HPV vaccination rates. We conducted a between-subjects randomized study comparing a fantasy narrative game to a non-gamified pedagogical virtual agent, with both interventions conveying the same HPV information. Among our study‚Äôs 9-12-year-old adolescent participants, our findings demonstrate large pre-to-post improvements in HPV knowledge for both conditions. The gamified intervention showed higher engagement and entertainment than the pedagogical agent based on participant interviews, demonstrating that gamification enriched the educational experience for adolescents.",970
885,Human-Centered Computing,Timothy W. Bickmore,"September 14th, 2021",Diversity Informatics: Reducing Racial and Gender Bias with Virtual Agents,https://dl.acm.org/doi/abs/10.1145/3472306.3478365?sid=SCITRUS," Bickmore, T., Parmar, D., Kimani, E. and Olafsson, S. Diversity Informatics: Reducing Racial and Gender Bias with Virtual Agents. In Proceedings of the ACM International Conference on Intelligent Virtual Agents (IVA) (2021).","Job advertisements in white male-dominated organizations are often biased in ways that discourage female and minority candidates from applying. We explored the use of a female African American virtual agent who provides a first-person reaction to a biased job advertisement, providing an impassioned, vivid description of her feelings about the advertisement, the position, and the organization offering the job, and how the position---as described---would impact her life were she to take the job. We evaluate the impact interactions with this agent have on the effort study participants invest in editing the job advertisement following their interaction with the agent, compared to reading a page of standard educational text on diversity in hiring. Participants who interacted with the agent spent significantly more effort correcting the job ad, as measured both by the number of edit operations and the number of biased phrases removed, compared to participants in the control condition. Implications and a future research agenda for increasing diversity using virtual agents are presented.",971
886,Human-Centered Computing,Timothy W. Bickmore,"May 8th, 2021",‚ÄòMore like a person than reading text in a machine‚Äô: Characterizing User Choice of Embodied Agents vs. Conventional GUIs on Smartphones,https://doi.org/10.1145/3411763.3451664," S. Olafsson, D. Parmar, E. Kimani, T.K. O'Leary, T.W. Bickmore. ""‚ÄòMore like a person than reading text in a machine‚Äô: Characterizing User Choice of Embodied Agents vs. Conventional GUIs on Smartphones."" CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, 2021. DOI: 10.1145/3411763.3451664","Embodied conversational agents (ECAs) provide an interface modality on smartphones that may be particularly effective for tasks with significant social, affective, reflective, and narrative aspects, such as health education and behavior change counseling. However, the conversational medium is significantly slower than conventional graphical user interfaces (GUIs) for brief, time-sensitive tasks. We conducted a randomized experiment to determine user preferences in performing two kinds of health-related tasks‚Äîone affective and narrative in nature and one transactional‚Äîand gave participants a choice of a conventional GUI or a functionally equivalent ECA on a smartphone to complete the task. We found significant main effects of task type and user preference on user choice of modality, with participants choosing the conventional GUI more often for transactional and time-sensitive tasks.",972
887,Human-Centered Computing,Timothy W. Bickmore,"May 6th, 2021","Examining the Intersections of Race, Religion & Community Technologies: A Photovoice Study",https://doi.org/10.1145/3411764.3445418," T.K. O‚ÄôLeary, E. Stowell, J. Hoffman, M.K. Paasche-Orlow, T.W. Bickmore, A.G. Parker. ‚ÄúExamining the Intersections of Race, Religion & Community Technologies: A Photovoice Study.‚Äù ACM Conference on Human Factors in Computing (CHI 2021), 2021. DOI: 10.1145/3411764.3445418","Churches have historically played an important role in Black American communities, catalyzing the pursuit of aims such as social justice, community organization, and health promotion. However, researchers have rarely examined how technology can support an assets-based approach to these efforts, nor the implications of race, traditions, and history when creating such systems. Addressing this gap, we conducted research with two predominantly Black churches to explore health promotion design opportunities. We used photovoice, a research method where participants led their own data collection and analysis. Participants provided nuanced descriptions of the racial and ethnic identities of their communities, and how church history and aspirations for the future impacted these identities. Our findings characterize tensions between tradition and ‚Äòmodernization,‚Äô implications for technology design, and the need for a temporal approach to understanding communities. We conclude with broader implications for studying the intersection of race and religion in community technology design.",973
888,Human-Centered Computing,Timothy W. Bickmore,"October 20th, 2020",Community-Based Cultural Tailoring of Virtual Agents,https://doi.org/10.1145/3383652.3423875," T.K. O‚ÄôLeary, E. Stowell, E. Kimani, D. Parmar, S. Olafsson, J. Hoffman, A.G. Parker, M.K. Paasche-Orlow,  T.W. Bickmore. ‚ÄúCommunity-Based Cultural Tailoring of Virtual Agents.‚Äù IVA ‚Äô20: Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, 2020. DOI: 10.1145/3383652.3423875","Culturally informed design for virtual agents has been shown to positively impact health outcomes when tailored to target audiences. We present a participatory design methodology for culturally tailoring virtual agents. Investigators worked with key informants from our target population, members of predominantly Black church communities, to design culturally-relevant and sensitive virtual agent health promotion interventions. In the first participatory session, key informants designed agents to assist them with different aspects of their lives, providing input on agent appearance and agent functionality. In a second design session, participants re-wrote the content of a health conversation with an agent, to include personally-relevant content related to their community (e.g., religious and scriptural references). We report design principles for religious tailoring derived from these studies. We conducted a validation study to assess the effects of applying these principles to agents that promoted two health behaviors, finding that participants responded very positively to the tailored agents.",974
889,Human-Centered Computing,Timothy W. Bickmore,"September 18th, 2020",Improving the health of young African American women in the preconception period using health information technology: a randomised controlled trial,https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2820%2930189-8/fulltext," Jack, B., Bickmore, T., Yinusa-Nyahkoon, L., Reichert, M., Julce, C., Sidduri, N., Martin-Howard, J., Zhang, Z., Woodhams, E., Fernandez, J., Loafman, M. and Cabral, H. Improving the health of young African American women in the preconception period using health information technology: a randomised controlled trial. The Lancet, Digital Health, 2, 9 (2020)",The aim of this research was to assess the impact of an embodied conversational agent system on preconception risks among African American and Black women. The Gabby system has the potential to improve women's preconception health. Further research is needed to determine if improving preconception. risks impacts outcomes such as preterm delivery.,975
890,Human-Centered Computing,Timothy W. Bickmore,"September 8th, 2020",Effects of Counseling by Peer Human Advisors vs Computers to Increase Walking in Underserved Populations: The COMPASS Randomized Clinical Trial,https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2771193," King, A. C., Campero, M. I., Sheats, J. L., Castro Sweet, C. M., Hauser, M. E., Garcia, D., Chazaro, A., Blanco, G., Banda, J., Ahn, D. K., Fernandez, J. and Bickmore, T. Effects of Counseling by Peer Human Advisors vs Computers to Increase Walking in Underserved Populations: The COMPASS Randomized Clinical Trial. JAMA Intern Med (Sep 28 2020).","Walking represents a popular physical activity that can produce a range of desirable health effects, particularly as people age. To test the hypothesis that counseling by a computer-based virtual advisor is no worse than (ie, noninferior to) counseling by trained human advisors, a cluster-randomized, parallel trial enrolled 245 adults. Improvements emerged in both arms for relevant clinical risk factors, sedentary behavior, and well-being measures.",976
891,Human-Centered Computing,Timothy W. Bickmore,"April 21st, 2020",Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study,https://doi.org/10.1145/3313831.3376833," E. Stowell, T.K. O‚ÄôLeary, E. Kimani, M.K. Paasche-Orlow, T.W. Bickmore, A.G. Parker. ‚ÄúInvestigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study.‚Äù ACM Conference on Human Factors in Computing Systems, 2020. DOI: 10.1145/3313831.3376833","Churches play a major role in providing social support to address health inequities within Black communities, in part by connecting members to key organizations and services. While public health has a history of disseminating interventions in faith communities, little work has explored the use of crowdsourcing to tailor interventions to the unique culture of each church community. Following Community Based Participatory Research principles, we partnered with two predominantly Black churches, and report on a series of three participatory design sessions with nine participants. We developed a novel storyboarding method to explore how crowdsourcing could promote health in these faith-based communities. Our findings characterize existing supports within the church community, and how church social structures impact member access to these supports. We further identify motivations to engage with a church-situated health application, and how these motivations translate to crowdsourcing tasks. Finally, we discuss considerations for public health crowdsourcing tasks.",977
892,Human-Centered Computing,Kathleen (Katie) Creel,"October 16th, 2024",Ecosystem Graphs: Documenting the Foundation Model Supply Chain,https://doi.org/10.1609/aies.v7i1.31629," Rishi Bommasani, Dilara Soylu, Thomas I. Liao, Kathleen A. Creel, Percy Liang. (2024). Ecosystem Graphs: Documenting the Foundation Model Supply Chain AIES (1), 196-209. https://doi.org/10.1609/aies.v7i1.31629","Abstract Foundation models (e.g. GPT-4, Gemini, Llama 3) pervasively influence society, warranting greater understanding. While the models garner much attention, accurately characterizing their impact requires considering the broader sociotechnical ecosystem in which they are created and deployed. We propose Ecosystem Graphs as a documentation framework to centralize knowledge of this ecosystem. Ecosystem Graphs is composed of assets (datasets, models, applications) linked together by dependencies that indicate technical and social relationships. To supplement the graph structure, each asset is further enriched with fine-grained metadata, such as the model‚Äôs estimated training emissions or licensing guidelines. Since its release in March 2023, Ecosystem Graphs represents an ongoing effort to document 568 assets (112 datasets, 359 models, 97 applications) from 117 organizations. Ecosystem Graphs functions as a multifunctional resource: we discuss two major uses by the 2024 AI Index and the UK‚Äôs Competition and Markets Authority that demonstrate the value of Ecosystem Graphs.",978
893,Human-Centered Computing,Kathleen (Katie) Creel,"June 5th, 2024",Algorithmic Pluralism: A Structural Approach To Equal Opportunity,https://doi.org/10.1145/3630106.3658899," Shomik Jain, Vinith Suriyakumar, Kathleen Creel, Ashia Wilson. (2024). Algorithmic Pluralism: A Structural Approach To Equal Opportunity FAccT, 197-206. https://doi.org/10.1145/3630106.3658899","We present a structural approach toward achieving equal opportunity in systems of algorithmic decision-making called algorithmic pluralism. Algorithmic pluralism describes a state of affairs in which no set of algorithms severely limits access to opportunity, allowing individuals the freedom to pursue a diverse range of life paths. To argue for algorithmic pluralism, we adopt Joseph Fishkin‚Äôs theory of bottlenecks, which focuses on the structure of decision-points that determine how opportunities are allocated. The theory contends that each decision-point or ‚Äúbottleneck‚Äô‚Äô limits access to opportunities with some degree of severity and legitimacy. We extend Fishkin‚Äôs structural viewpoint and use it to reframe existing systemic concerns about equal opportunity in algorithmic decision-making, such as patterned inequality and algorithmic monoculture. In proposing algorithmic pluralism, we argue for the urgent priority of alleviating severe bottlenecks in algorithmic-decision-making. We contend that there must be a pluralism of opportunity available to many different individuals in order to promote equal opportunity in a systemic way. We further show how this framework has several implications for system design and regulation through current debates about equal opportunity in algorithmic hiring.",979
894,Human-Centered Computing,Kathleen (Katie) Creel,"April 12th, 2024",Scarce Resource Allocations That Rely On Machine Learning Should Be Randomized,https://doi.org/10.48550/arXiv.2404.08592," Shomik Jain, Kathleen Creel, Ashia Wilson. (2024). Scarce Resource Allocations That Rely On Machine Learning Should Be Randomized CoRR, abs/2404.08592. https://doi.org/10.48550/arXiv.2404.08592","Contrary to traditional deterministic notions of algorithmic fairness, this paper argues that fairly allocating scarce resources using machine learning often requires randomness. We address why, when, and how to randomize by proposing stochastic procedures that more adequately account for all of the claims that individuals have to allocations of social goods or opportunities.",980
895,Human-Centered Computing,Kathleen (Katie) Creel,"July 12th, 2023",Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes,https://doi.org/10.48550/arXiv.2307.05862," Connor Toups, Rishi Bommasani, Kathleen A. Creel, Sarah H. Bana, Dan Jurafsky, Percy Liang. (2023). Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes CoRR, abs/2307.05862. https://doi.org/10.48550/arXiv.2307.05862","Machine learning is traditionally studied at the model level: researchers measure and improve the accuracy, robustness, bias, efficiency, and other dimensions of specific models. In practice, the societal impact of machine learning is determined by the surrounding context of machine learning deployments. To capture this, we introduce ecosystem-level analysis: rather than analyzing a single model, we consider the collection of models that are deployed in a given context. For example, ecosystem-level analysis in hiring recognizes that a job candidate's outcomes are not only determined by a single hiring algorithm or firm but instead by the collective decisions of all the firms they applied to. Across three modalities (text, images, speech) and 11 datasets, we establish a clear trend: deployed machine learning is prone to systemic failure, meaning some users are exclusively misclassified by all models available. Even when individual models improve at the population level over time, we find these improvements rarely reduce the prevalence of systemic failure. Instead, the benefits of these improvements predominantly accrue to individuals who are already correctly classified by other models. In light of these trends, we consider medical imaging for dermatology where the costs of systemic failure are especially high. While traditional analyses reveal racial performance disparities for both models and humans, ecosystem-level analysis reveals new forms of racial disparity in model predictions that do not present in human predictions. These examples demonstrate ecosystem-level analysis has unique strengths for characterizing the societal impact of machine learning.",981
896,Human-Centered Computing,Kathleen (Katie) Creel,"March 28th, 2023",Ecosystem Graphs: The Social Footprint of Foundation Models,https://doi.org/10.48550/arXiv.2303.15772," Rishi Bommasani, Dilara Soylu, Thomas I. Liao, Kathleen A. Creel, Percy Liang. (2023). Ecosystem Graphs: The Social Footprint of Foundation Models CoRR, abs/2303.15772. https://doi.org/10.48550/arXiv.2303.15772","Foundation models (e.g. ChatGPT, StableDiffusion) pervasively influence society, warranting immediate social attention. While the models themselves garner much attention, to accurately characterize their impact, we must consider the broader sociotechnical ecosystem. We propose Ecosystem Graphs as a documentation framework to transparently centralize knowledge of this ecosystem. Ecosystem Graphs is composed of assets (datasets, models, applications) linked together by dependencies that indicate technical (e.g. how Bing relies on GPT-4) and social (e.g. how Microsoft relies on OpenAI) relationships. To supplement the graph structure, each asset is further enriched with fine-grained metadata (e.g. the license or training emissions). We document the ecosystem extensively atthis https URL. As of March 16, 2023, we annotate 262 assets (64 datasets, 128 models, 70 applications) from 63 organizations linked by 356 dependencies. We show Ecosystem Graphs functions as a powerful abstraction and interface for achieving the minimum transparency required to address myriad use cases. Therefore, we envision Ecosystem Graphs will be a community-maintained resource that provides value to stakeholders spanning AI researchers, industry professionals, social scientists, auditors and policymakers.",982
897,Human-Centered Computing,Kathleen (Katie) Creel,"November 25th, 2022",Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome Homogenization?,https://doi.org/10.48550/arXiv.2211.13972," Rishi Bommasani, Kathleen A. Creel, Ananya Kumar, Dan Jurafsky, Percy Liang. (2022). Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome Homogenization? CoRR, abs/2211.13972. https://doi.org/10.48550/arXiv.2211.13972","As the scope of machine learning broadens, we observe a recurring theme of algorithmic monoculture: the same systems, or systems that share components (e.g. training data), are deployed by multiple decision-makers. While sharing offers clear advantages (e.g. amortizing costs), does it bear risks? We introduce and formalize one such risk, outcome homogenization: the extent to which particular individuals or groups experience negative outcomes from all decision-makers. If the same individuals or groups exclusively experience undesirable outcomes, this may institutionalize systemic exclusion and reinscribe social hierarchy. To relate algorithmic monoculture and outcome homogenization, we propose the component-sharing hypothesis: if decision-makers share components like training data or specific models, then they will produce more homogeneous outcomes. We test this hypothesis on algorithmic fairness benchmarks, demonstrating that sharing training data reliably exacerbates homogenization, with individual-level effects generally exceeding group-level effects. Further, given the dominant paradigm in AI of foundation models, i.e. models that can be adapted for myriad downstream tasks, we test whether model sharing homogenizes outcomes across tasks. We observe mixed results: we find that for both vision and language settings, the specific methods for adapting a foundation model significantly influence the degree of outcome homogenization. We conclude with philosophical analyses of and societal challenges for outcome homogenization, with an eye towards implications for deployed machine learning systems.",983
898,Human-Centered Computing,Kathleen (Katie) Creel,"March 3rd, 2022",Nifty Assignments,https://doi.org/10.1145/3478432.3499268," Nick Parlante, Julie Zelenski, Eric S. Roberts, Jed Rembold, Ben Stephenson, Jonathan Hudson, Stephanie Valentine, Juliette Woodrow, Kathleen Creel, Nick Bowman, Larry ""Joshua"" Crotts, Andrew Matzureff, Mike Izbicki. (2022). Nifty Assignments SIGCSE (2), 1067-1068. https://doi.org/10.1145/3478432.3499268","The Nifty Assignments special session is about sharing the ideas and ready-to-use materials of successful assignments. Each presenter will introduce their assignment, give a quick demo, and describe its niche in the curriculum and its strengths and weaknesses. The presentations (and the descriptions below) merely introduce the assignment. A key part of Nifty Assignments is the mundane but vital role of distributing the materials - handouts, data files, starter code, rubrics, autograders - that make each assignment ready to adopt. Each assignment presented has complete materials freely available on the Nifty Assignments home page nifty.stanford.edu. If you have an assignment that works well and would be of interest to the CSE community, please consider applying to present at Nifty Assignments.",984
899,Human-Centered Computing,Kathleen (Katie) Creel,"August 16th, 2021",On the Opportunities and Risks of Foundation Models,https://arxiv.org/abs/2108.07258," Rishi Bommasani, Drew A. Hudson, Ehsan Adeli , Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri S. Chatterji, Annie S. Chen, Kathleen Creel, Jared Quincy Davis, Dorottya Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei , Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah D. Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson , John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark S. Krass, Ranjay Krishna, Rohith Kuditipudi, et al.. (2021). On the Opportunities and Risks of Foundation Models CoRR, abs/2108.07258. https://arxiv.org/abs/2108.07258","AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",985
900,Human-Centered Computing,Kathleen (Katie) Creel,"March 1st, 2021","The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision Making Systems",https://doi.org/10.1145/3442188.3445942," Kathleen Creel, Deborah Hellman. (2021). The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision Making Systems FAccT, 816. https://doi.org/10.1145/3442188.3445942","Automated decision-making systems implemented in public life are typically standardized. One algorithmic decision-making system can replace thousands of human deciders. Each of the humans so replaced had her own decision-making criteria: some good, some bad, and some arbitrary. Is such arbitrariness of moral concern? We argue that an isolated arbitrary decision need not morally wrong the individual whom it misclassifies. However, if the same algorithms are applied across a public sphere, such as hiring or lending, a person could be excluded from a large number of opportunities. This harm persists even when the automated decision-making systems are ""fair"" on standard metrics of fairness. We argue that such arbitrariness at scale is morally problematic and propose technically informed solutions that can lessen the impact of algorithms at scale and so mitigate or avoid the moral harms we identify.",986
901,Human-Centered Computing,Maitraye Das,"October 27th, 2024",‚ÄúI look at it as the king of knowledge‚Äù: How Blind People Use and Understand Generative AI Tools,https://doi.org/10.1145/3663548.3675631," Rudaiba Adnin, Maitraye Das. (2024). ""I look at it as the king of knowledge"": How Blind People Use and Understand Generative AI Tools ASSETS, 64:1-64:14. https://doi.org/10.1145/3663548.3675631","The proliferation of Generative Artificial Intelligence (GenAI) tools has brought a critical shift in how people approach information retrieval and content creation in diverse contexts. Yet, we have limited understanding of how blind people use and make sense of GenAI systems. To bridge this gap, we report findings from interviews with 19 blind individuals who incorporate mainstream GenAI tools like ChatGPT and Be My AI in their everyday practices. Our findings reveal how blind users navigate accessibility issues, inaccuracies, hallucinations, and idiosyncracies associated with GenAI and develop interesting (but often flawed) mental models of how these tools work. We discuss key considerations for rethinking access and information verification in GenAI tools, unpacking erroneous mental models among blind users, and reconciling harms and benefits of GenAI from an accessibility perspective.",987
902,Human-Centered Computing,Maitraye Das,"August 30th, 2024",Incloodle-Classroom: Technology for Inclusive Joint Media Engagement in a Neurodiverse Kindergarten Classroom,https://doi.org/10.1145/3674506," Kiley Sobel, Maitraye Das, Sara M. Behbakht, Julie A. Kientz. (2024). Incloodle-Classroom: Technology for Inclusive Joint Media Engagement in a Neurodiverse Kindergarten Classroom ACM Trans. Comput. Hum. Interact., 31, 41:1-41:45. https://doi.org/10.1145/3674506","Enabling opportunities for young children with disabilities to co-engage in learning activities alongside their non-disabled peers is essential for promoting equity in early childhood education. We investigate how collaborative technology can be designed to support young neurodivergent and neurotypical children in playing together. By integrating theories and methods from design, HCI, and the learning sciences, we iteratively designed, developed, and evaluated a novel tablet application called Incloodle-Classroom (Incloodle in short), that takes into account the needs of neurodiverse groups of children and the adults who support them during play. We deployed Incloodle in a kindergarten classroom of 15 neurodivergent and 16 neurotypical children over a 10-week period. Using interaction analysis, we present rich empirical understandings of how children interacted with each other, with adults, and with Incloodle. In doing so, we contribute new theoretical underpinnings to collaborative and accessible technology design, extending joint media engagement to encompass inclusivity and equity.",988
903,Human-Centered Computing,Maitraye Das,"May 11th, 2024",From Provenance to Aberrations: Image Creator and Screen Reader User Perspectives on Alt Text for AI-Generated Images,https://doi.org/10.1145/3613904.3642325," Maitraye Das, Alexander J. Fiannaca, Meredith Ringel Morris, Shaun K. Kane, Cynthia L. Bennett. (2024). From Provenance to Aberrations: Image Creator and Screen Reader User Perspectives on Alt Text for AI-Generated Images CHI, 900:1-900:21. https://doi.org/10.1145/3613904.3642325","AI-generated images are proliferating as a new visual medium. However, state-of-the-art image generation models do not output alternative (alt) text with their images, rendering them largely inaccessible to screen reader users (SRUs). Moreover, less is known about what information would be most desirable to SRUs in this new medium. To address this, we invited AI image creators and SRUs to evaluate alt text prepared from various sources and write their own alt text for AI images. Our mixed-methods analysis makes three contributions. First, we highlight creators‚Äô perspectives on alt text, as creators are well-positioned to write descriptions of their images. Second, we illustrate SRUs‚Äô alt text needs particular to the emerging medium of AI images. Finally, we discuss the promises and pitfalls of utilizing text prompts written as input for AI models in alt text generation, and areas where broader digital accessibility guidelines could expand to account for AI images.",989
904,Human-Centered Computing,Maitraye Das,"April 26th, 2024",‚ÄúThat comes with a huge career cost:‚Äù Understanding Collaborative Ideation Experiences of Disabled Professionals,https://doi.org/10.1145/3641018," Maitraye Das, Abigale Stangl, Leah Findlater. (2024). ""That comes with a huge career cost:"" Understanding Collaborative Ideation Experiences of Disabled Professionals Proc. ACM Hum. Comput. Interact., 8, 1-28. https://doi.org/10.1145/3641018","Collaborative ideation plays a vital role in driving creativity and innovation across various professional and educational contexts. This study investigates the experiences of disabled individuals within the collaborative ideation process, specifically examining their utilization of digital whiteboarding tools. Through interviews with 19 professionals and academics with disabilities, alongside a thematic analysis of online forum posts for two popular digital whiteboarding platforms (Miro and Figma), we delve into the access barriers encountered by disabled individuals and the strategies they employ to create access in collaborative ideation. Our findings illuminate the multifaceted nature of access barriers, encompassing issues such as inaccessible visual features, technology-induced discomfort, unstructured nature of freeform content, and complex communication setups. Furthermore, we uncover the intricate dynamics involved in negotiating diverse access needs and conflicts within teams involving people with different disabilities. Through this analysis, we highlight tensions around proficiency with inaccessible technologies stemming from ableist standards of professional success and discuss the implications of our findings for the design of accessible collaborative ideation systems.",990
905,Human-Centered Computing,Michael Ann DeVito,"November 8th, 2024",Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge,https://doi.org/10.48550/arXiv.2501.14648," Leah Hope Ajmani, Talia Bhatt, Michael Ann DeVito. (2025). Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge CoRR, abs/2501.14648. https://doi.org/10.48550/arXiv.2501.14648","Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy -- one's ability to govern knowledge about themselves -- as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one's epistemic autonomy, we present six stories from two trans women: (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants.",991
906,Human-Centered Computing,Michael Ann DeVito,"April 26th, 2024",Safety and Community Context: Exploring a Transfeminist Approach to Sapphic Relationship Platforms,https://doi.org/10.1145/3653694," Michael Ann DeVito, Jessica L. Feuston, Erika Melder, Christen Malloy, Cade Ponder, Jed R. Brubaker. (2024). Safety and Community Context: Exploring a Transfeminist Approach to Sapphic Relationship Platforms Proc. ACM Hum. Comput. Interact., 8, 1-34. https://doi.org/10.1145/3653694","Relationship platforms (e.g., dating apps) are crucial tools for sapphics (trans women, cisgender women, and nonbinary people who are attracted to other sapphics). However, current platforms are not designed in a way that accounts for sapphic lived experience, especially the lived experience of sapphics who hold multiple marginalized identity characteristics. Even on platforms that do exist for sapphics, transgender women and nonbinary people are often subject to discrimination, fetishization, and stigmatization. To aid in the design of platforms that better serve the needs of multiply marginalized sapphics, we engaged a diverse group of 25 sapphics in six rounds of community discussion on key topics for relationship platform design. Based on participant discussions, we identify key challenges when designing for multiply marginalized sapphics around relationship structures, gender and sexuality classification, and safety priorities for interaction. We present two design priorities alongside community-sourced design directions which can help future designers address these challenges: identity-centric safety and community-based information formats.",992
907,Human-Centered Computing,Michael Ann DeVito,"March 23rd, 2024",Content Moderation Folk Theories and Perceptions of Platform Spirit among Marginalized Social Media Users,https://doi.org/10.1145/3632741," Samuel Mayworm, Michael Ann DeVito, Daniel Delmonaco, Hibby Thach, Oliver L. Haimson. (2024). Content Moderation Folk Theories and Perceptions of Platform Spirit among Marginalized Social Media Users ACM Trans. Soc. Comput., 7, 1-27. https://doi.org/10.1145/3632741","Social media users create folk theories to help explain how elements of social media operate. Marginalized social media users face disproportionate content moderation and removal on social media platforms. We conducted a qualitative interview study ( n = 24) to understand how marginalized social media users may create folk theories in response to content moderation and their perceptions of platforms‚Äô spirit, and how these theories may relate to their marginalized identities. We found that marginalized social media users develop folk theories informed by their perceptions of platforms‚Äô spirit to explain instances where their content was moderated in ways that violate their perceptions of how content moderation should work in practice. These folk theories typically address content being removed despite not violating community guidelines, along with bias against marginalized users embedded in guidelines. We provide implications for platforms, such as using marginalized users‚Äô folk theories as tools to identify elements of platform moderation systems that function incorrectly and disproportionately impact marginalized users.",993
908,Human-Centered Computing,Michael Ann DeVito,"January 1st, 2024",Whose Knowledge is Valued? Epistemic Injustice in CSCW Applications,https://doi.org/10.1145/3687062," Leah Hope Ajmani, Jasmine C. Foriest, Jordan Taylor, Kyle Pittman, Sarah A. Gilbert, Michael Ann DeVito. (2024). Whose Knowledge is Valued? Epistemic Injustice in CSCW Applications Proc. ACM Hum. Comput. Interact., 8, 1-28. https://doi.org/10.1145/3687062","Social computing scholars have long known that people do not interact with knowledge in straightforward ways, especially in digital environments. While policies around knowledge are essential for targeting misinformation, they are value-laden; in choosing how to present information, we undermine non-traditional, often non-Western, ways of knowing. Epistemic injustice is the systemic exclusion of certain people and methods from the knowledge canon. Epistemic injustice chips away at one's testimony and vocabulary until they are stripped of their due right to know and understand. In this paper, we articulate how epistemic injustice in sociotechnical applications leads to material harm. Inspired by a hybrid collaborative autoethnography of 14 CSCW practitioners, we present three cases of epistemic injustice in sociotechnical applications: online transgender healthcare, identity sensemaking on r/bisexual, and Indigenous ways of knowing on r/AskHistorians. We further explore signature tensions across our autoethnographic materials and relate them to previous CSCW research areas and personal non-technological experiences. We argue that epistemic injustice can serve as a unifying and intersectional lens for CSCW research by surfacing dimensions of epistemic community and power. Finally, we present a call to action of three changes the CSCW community should make to move toward its own goals of research justice. We call for CSCW researchers to center individual experiences, bolster communities, and remediate issues of epistemic power as a means towards epistemic justice. In sum, we recount, synthesize, and propose solutions for the various forms of epistemic injustice that CSCW sites of study---including CSCW itself---propagate.",994
909,Human-Centered Computing,Michael Ann DeVito,"May 8th, 2021",Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research,https://doi.org/10.1145/3411763.3450403," Michael Ann DeVito, Caitlin Lustig, Ellen Simpson, Kimberley R. Allison, Tya S. Chuanromanee, Katta Spiel, Amy J. Ko, Jennifer Ann Rode, Brianna Dym, Michael J. Muller, Morgan Klaus Scheuerman, Ashley Marie Walker, Jed R. Brubaker, Alex A. Ahmed. (2021). Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research CHI Extended Abstracts, 159:1-159:3. https://doi.org/10.1145/3411763.3450403","As Queer Human-Computer Interaction (HCI) becomes an established part of the larger field, both in terms of research on and with queer populations and in terms of employing queering theories and methods, the role of queer researchers has become a timely topic of discussion. However, these discussions have largely centered around member-researcher status and positionality when working with queer populations. Based on insights gathered at multiple ACM events over the past two years, we identified two pressing issues: (1) we need to better support queer people doing HCI research not specific to queer populations, and (2) we need to identify how to best support member-researchers in leading Queer HCI while including collaborators beyond the queer community. This Special Interest Group (SIG) aims to directly address these challenges by convening a broad community of queer researchers and allies, working not only on explicitly-queer topics but across a broad range of HCI topics.",995
910,Human-Centered Computing,Brianna Dym,"October 4th, 2023",Competing Imaginaries and Partisan Divides in the Data Rhetoric of Advocacy Organizations,https://doi.org/10.1145/3610050," Shiva Darian, Brianna Dym, Amy Voida. (2023). Competing Imaginaries and Partisan Divides in the Data Rhetoric of Advocacy Organizations Proc. ACM Hum. Comput. Interact., 7, 1-29. https://doi.org/10.1145/3610050","Data are wielded to shape public opinion, particularly in electoral contexts where the role and veracity of information is questioned. This post-truth era is characterized by world events in which facts too often are obfuscated and evidential standards are abandoned. To study how data are used to influence pressing and divisive contemporary issues, this paper explores the rhetorical work that quantitative data are doing through the blogging practices of advocacy organizations during the highly-polarized month preceding the 2016 United States elections. We present results of a qualitative content analysis of the quantitative data used in 337 blog posts published by five pairs of conservative and liberal advocacy organizations over the course of the month leading up to the 2016 US elections. We identify key data rhetoric practices along partisan lines and contribute an analytic framework-evaluating ethos, pathos, and logos- that can be used to analyze the rhetorical use of data in other contexts. We then characterize two different imaginaries that come into conflict in this research: 1) the political imaginaries being promoted through organizational blogging and 2) the sociotechnical imaginary of the data economy, foregrounding differences in the epistemic value of data in each. We conclude by outlining research challenges and trajectories for future research within each of the two imaginaries of data.",996
911,Human-Centered Computing,Brianna Dym,"March 3rd, 2023","Gaming Together, Coding Together: Collaborative Pathways to Computational Learning",https://doi.org/10.1145/3545945.3569833," Brianna Dym, Cole Rockwood, Casey Fiesler. (2023). Gaming Together, Coding Together: Collaborative Pathways to Computational Learning SIGCSE (1), 1035-1041. https://doi.org/10.1145/3545945.3569833","Collaborative, playful learning represents an important avenue to mastering a range of skills within computer science education. This research presents findings from interviews with 9 members of an online community that started out as a gaming league and transitioned into a game development team. Community members learned programming skills to contribute their ideas to the game and participate in activities based around game development. Drawing on these experiences, we identify key elements from informal learning that can improve computer science education: 1) playful projects can help learners overcome barriers to participating in computer science; 2) community closeness facilitates a collaborative learning environment to support developing expertise in specific computational skills. We consider these findings in the context of learning as an everyday social practice, and discuss means of developing playful learning communities in computer science classrooms.",997
912,Human-Centered Computing,Brianna Dym,"January 14th, 2022",Building a Pillowfort: Political Tensions in Platform Design and Policy,https://doi.org/10.1145/3492835," Brianna Dym, Namita Pasupuleti, Casey Fiesler. (2022). Building a Pillowfort: Political Tensions in Platform Design and Policy Proc. ACM Hum. Comput. Interact., 6, 16:1-16:23. https://doi.org/10.1145/3492835","Social media platforms make trade-offs in their design and policy decisions to attract users and stand out from other platforms. These decisions are influenced by a number of considerations, e.g. what kinds of content moderation to deploy or what kinds of resources a platform has access to. Their choices play into broader political tensions; social media platforms are situated within a social context that frames their impact, and they can have politics through their design that enforce power structures and serve existing authorities. We turn to Pillowfort, a small social media platform, to examine these political tensions as a case study. Using a discourse analysis, we examine public discussion posts between staff and users as they negotiate the site's development over a period of two years. Our findings illustrate the tensions in navigating the politics that users bring with them from previous platforms, the difficulty of building a site's unique identity and encouraging commitment, and examples of how design decisions can both foster and break trust with users. Drawing from these findings, we discuss how the success and failure of new social media platforms are impacted by political influences on design and policy decisions.",998
913,Human-Centered Computing,Brianna Dym,"May 8th, 2021",Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research,https://doi.org/10.1145/3411763.3450403," Michael Ann DeVito, Caitlin Lustig, Ellen Simpson, Kimberley R. Allison, Tya S. Chuanromanee, Katta Spiel, Amy J. Ko, Jennifer Ann Rode, Brianna Dym, Michael J. Muller, Morgan Klaus Scheuerman, Ashley Marie Walker, Jed R. Brubaker, Alex A. Ahmed. (2021). Queer in HCI: Strengthening the Community of LGBTQIA+ Researchers and Research CHI Extended Abstracts, 159:1-159:3. https://doi.org/10.1145/3411763.3450403","As Queer Human-Computer Interaction (HCI) becomes an established part of the larger field, both in terms of research on and with queer populations and in terms of employing queering theories and methods, the role of queer researchers has become a timely topic of discussion. However, these discussions have largely centered around member-researcher status and positionality when working with queer populations. Based on insights gathered at multiple ACM events over the past two years, we identified two pressing issues: (1) we need to better support queer people doing HCI research not specific to queer populations, and (2) we need to identify how to best support member-researchers in leading Queer HCI while including collaborators beyond the queer community. This Special Interest Group (SIG) aims to directly address these challenges by convening a broad community of queer researchers and allies, working not only on explicitly-queer topics but across a broad range of HCI topics.",999
914,Human-Centered Computing,Don Fallis,"July 22nd, 2021",The Epistemic Threat of Deepfakes,https://link.springer.com/article/10.1007/s13347-020-00419-2," Fallis, D. (2020). The Epistemic Threat of Deepfakes. Philosophy & Technology. https://doi.org/10.1007/s13347-020-00419-2","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 28k Accesses",1000
915,Human-Centered Computing,Don Fallis,"July 22nd, 2021",Fake News is Counterfeit News,http://dx.doi.org/10.1080/0020174X.2019.1688179," Fallis, D. & Mathiesen, K. (2019) Fake News is Counterfeit News. Inquiry. doi:10.1080/0020174X.2019.1688179","References ABSTRACT Fake news poses a serious threat to knowledge and democracy. In order to address this threat, it is important to understand exactly what fake news is. After surveying the various definitions that have been proposed in the philosophical literature, we argue that fake news is best understood as counterfeit news . A story is genuine news if and only if it has gone through the standard modern journalistic process involving professionally trained reporters, fact checkers, and editors. And a story is counterfeit news if and only if it is not genuine news, but is presented as genuine news, with the intention and propensity to deceive. This analysis is a contribution to ‚Äòsystems-oriented social epistemology‚Äô (Goldman, Alvin I. 2011. ‚ÄúA Guide to Social Epistemology.‚Äù In Social Epistemology: Essential Readings , edited by Alvin I. Goldman, and Dennis Whitcomb, 11‚Äì37. New York: Oxford University Press). Various social institutions, such as science and journalism, provide important epistemic benefits to society. But unscrupulous agents are often motivated to leverage the epistemic authority of these institutions by counterfeiting them. People can thereby be misled and/or lose faith in these institutions. Thus, society may suffer significant epistemic costs when such counterfeits proliferate. ABSTRACT KEYWORDS: Fake news deception conceptual analysis social epistemology counterfeits",1001
916,Human-Centered Computing,Don Fallis,"July 22nd, 2021","Accuracy, Conditionalization, and Probabilism",https://doi.org/10.1007/s11229-019-02298-3," Lewis, P. J., & Fallis, D. (2021). Accuracy, conditionalization, and probabilism. Synthese, 198(5), 4017-4033. https://doi.org/10.1007/s11229-019-02298-3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 395 Accesses",1002
917,Human-Centered Computing,Matthew Goodwin,"March 25th, 2024",Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic,https://doi.org/10.48550/arXiv.2403.17165," Jessilyn Dunn, Varun Mishra , Md. Mobashir Hasan Shandhi, Hayoung Jeong, Natasha Yamane, Yuna Watanabe, Bill Chen, Matthew S. Goodwin. (2024). Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic CoRR, abs/2403.17165. https://doi.org/10.48550/arXiv.2403.17165","Smartphones and wearable sensors offer an unprecedented ability to collect peripheral psychophysiological signals across diverse timescales, settings, populations, and modalities. However, open-source software development has yet to keep pace with rapid advancements in hardware technology and availability, creating an analytical barrier that limits the scientific usefulness of acquired data. We propose a community-driven, open-source peripheral psychophysiological signal pre-processing and analysis software framework that could advance biobehavioral health by enabling more robust, transparent, and reproducible inferences involving autonomic nervous system data.",1003
918,Human-Centered Computing,Matthew Goodwin,"December 21st, 2023",Wearable biosensing to predict imminent aggressive behaviors in psychiatric inpatient youths with autism,https://doi.org/10.1001%2Fjamanetworkopen.2023.48898," Imbiriba, T, Demirkaya, A, Singh, A, Erdogmus, D, Goodwin, MS (2023). Wearable biosensing to predict imminent aggressive behaviors in psychiatric inpatient youths with autism. JAMA Network Open, 6(12):e2348898.",Data were analyzed from March 2020 through October 2023 from 4 primary care psychiatric inpatient hospitals. Logistic regression was the best-performing overall classifier across all experiments. Further research will explore clinical implications and the potential for personalized interventions in inpatient youths with autistic children and adults. The findings were published in the Journal of Autism and Developmental Disorder.,1004
919,Human-Centered Computing,Matthew Goodwin,"November 29th, 2023",Multiple Toddler Tracking in Indoor Videos,https://doi.org/10.48550/arXiv.2311.17656," Somaieh Amraee, Bishoy Galoaa, Matthew S. Goodwin, Elaheh Hatamimajoumerd, Sarah Ostadabbas. (2023). Multiple Toddler Tracking in Indoor Videos CoRR, abs/2311.17656. https://doi.org/10.48550/arXiv.2311.17656","Multiple toddler tracking (MTT) involves identifying and differentiating toddlers in video footage. While conventional multi-object tracking (MOT) algorithms are adept at tracking diverse objects, toddlers pose unique challenges due to their unpredictable movements, various poses, and similar appearance. Tracking toddlers in indoor environments introduces additional complexities such as occlusions and limited fields of view. In this paper, we address the challenges of MTT and propose MTTSort, a customized method built upon the DeepSort algorithm. MTTSort is designed to track multiple toddlers in indoor videos accurately. Our contributions include discussing the primary challenges in MTT, introducing a genetic algorithm to optimize hyperparameters, proposing an accurate tracking algorithm, and curating the MTTrack dataset using unbiased AI co-labeling techniques. We quantitatively compare MTTSort to state-of-the-art MOT methods on MTTrack, DanceTrack, and MOT15 datasets. In our evaluation, the proposed method outperformed other MOT methods, achieving 0.98, 0.68, and 0.98 in multiple object tracking accuracy (MOTA), higher order tracking accuracy (HOTA), and iterative and discriminative framework 1 (IDF1) metrics, respectively.",1005
920,Human-Centered Computing,Matthew Goodwin,"May 11th, 2023",A user-based information rating scale to evaluate the design of technology-based supports for autism,https://doi.org/10.1007/s10209-023-00995-y," Vanessa Zervogianni, Sue Fletcher-Watson, Gerardo Herrera, Matthew S. Goodwin, Elise Triquell, Patricia P√©rez-Fuster, Mark J. Brosnan, Ouriel Grynszpan. (2024). A user-based information rating scale to evaluate the design of technology-based supports for autism Univers. Access Inf. Soc., 23, 1739-1749. https://doi.org/10.1007/s10209-023-00995-y","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",1006
921,Human-Centered Computing,Matthew Goodwin,"March 29th, 2023",A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants,https://doi.org/10.48550/arXiv.2303.16867," Shaotong Zhu, Michael Wan, Elaheh Hatamimajoumerd, Kashish Jain, Samuel Zlota, Cholpady Vikram Kamath, Cassandra B. Rowan, Emma C. Grace, Matthew S. Goodwin, Marie J. Hayes, Rebecca A. Schwartz-Mette, Emily Zimmerman, Sarah Ostadabbas. (2023). A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants CoRR, abs/2303.16867. https://doi.org/10.48550/arXiv.2303.16867","We present an end-to-end computer vision pipeline to detect non-nutritive sucking (NNS) -- an infant sucking pattern with no nutrition delivered -- as a potential biomarker for developmental delays, using off-the-shelf baby monitor video footage. One barrier to clinical (or algorithmic) assessment of NNS stems from its sparsity, requiring experts to wade through hours of footage to find minutes of relevant activity. Our NNS activity segmentation algorithm solves this problem by identifying periods of NNS with high certainty -- up to 94.0\% average precision and 84.9\% average recall across 30 heterogeneous 60 s clips, drawn from our manually annotated NNS clinical in-crib dataset of 183 hours of overnight baby monitor footage from 19 infants. Our method is based on an underlying NNS action recognition algorithm, which uses spatiotemporal deep learning networks and infant-specific pose estimation, achieving 94.9\% accuracy in binary classification of 960 2.5 s balanced NNS vs. non-NNS clips. Tested on our second, independent, and public NNS in-the-wild dataset, NNS recognition classification reaches 92.3\% accuracy, and NNS segmentation achieves 90.8\% precision and 84.2\% recall.",1007
922,Human-Centered Computing,Matthew Goodwin,"November 7th, 2022",Real-time Public Speaking Anxiety Prediction Model for Oral Presentations,https://doi.org/10.1145/3536220.3563686," Everlyne Kimani, Timothy W. Bickmore, Rosalind W. Picard, Matthew S. Goodwin, Holly Jimison. (2022). Real-time Public Speaking Anxiety Prediction Model for Oral Presentations ICMI Companion, 30-35. https://doi.org/10.1145/3536220.3563686","Oral presentation skills are essential for most people‚Äôs academic and career development. However, due to public speaking anxiety, many people find oral presentations challenging and often avoid them to the detriment of their careers. Public speaking anxiety interventions that help presenters manage their anxiety as it occurs during a presentation can help many presenters. In this paper, we present a model for assessing public speaking anxiety during a presentation‚Äîa first step towards developing real-time anxiety interventions. We present our method for ground truth data collection and the results of neural network models for real-time anxiety detection using audio data. Our results show that using an LSTM model we can predict moments of speaking anxiety during a presentation.",1008
923,Human-Centered Computing,Matthew Goodwin,"July 9th, 2021",Automated Pain Assessment in Children Using Electrodermal Activity and Video Data Fusion via Machine Learning,https://doi.org/10.1109/TBME.2021.3096137," Busra T. Susam, Nathan T. Riek, Murat Ak√ßakaya, Xiaojing Xu, Virginia R. de Sa, Hooman Nezamfar, Damaris Diaz, Kenneth D. Craig, Matthew S. Goodwin, Jeannie S. Huang. (2022). Automated Pain Assessment in Children Using Electrodermal Activity and Video Data Fusion via Machine Learning IEEE Trans. Biomed. Eng., 69, 422-431. https://doi.org/10.1109/TBME.2021.3096137","Pain assessment in children continues to challenge clinicians and researchers, as subjective experiences of pain require inference through observable behaviors. The presented approach supplements the subjective self-report-based method by fusing electrodermal activity (EDA) recordings with video facial expressions to develop an objective pain assessment metric. Findings indicate that EDA and facial expression data independently provide above chance sensitivities and specificities, but their fusion for classifying clinically significant pain vs. clinically nonsignificant pain achieved substantial improvement, yielding 90.91% accuracy, with 100% sensitivity and 81.82% specificity. The multimodal measures capitalize upon different features of the complex pain response.",1009
924,Human-Centered Computing,Matthew Goodwin,"June 30th, 2020",Biosensor prediction of aggression in youth with autism using kernel-based methods,https://doi.org/10.1145/3389189.3389199," Tales Imbiriba, Diana Catalina Cumpanasoiu, James Heathers, Stratis Ioannidis, Deniz Erdogmus, Matthew S. Goodwin. (2020). Biosensor prediction of aggression in youth with autism using kernel-based methods PETRA, 13:1-13:6. https://doi.org/10.1145/3389189.3389199","Aggression to others by youth with autism is a significant problem since their difficulties self-reporting distress can lead to behaviors that appear to occur without warning. To address this issue, we recently demonstrated that biosensor data combined with linear classification algorithms (i.e., ridge-regularized logistic regression) can be used to predict aggression up to 1 minute before it occurs using 3 minutes of data from the past with an average area under the curve (AUC) of 0.71-0.84 depending on whether population versus individual models are used. In the present study, we both extend and enhance these prior results through the use of principal component analysis and a nonlinear kernel-based classifier (Support Vector Machines). Our results illustrate that these newly applied methods yield significant improvements, predicting aggression up to 3 minutes before it occurs with an average AUC of 0.98 in both population and individual models. Furthermore, we extend our prior work by evaluating aggression prediction performance across varying observed aggression intensities and find that moderate and high intensity aggression episodes are detectable with 2 to 5% higher average AUC than low-intensity aggression episodes.",1010
925,Human-Centered Computing,Matthew Goodwin,"September 15th, 2018",Applications of sparse recovery and dictionary learning to enhance analysis of ambulatory electrodermal activity data,https://doi.org/10.1016/j.bspc.2017.08.024," Malia Kelsey, Murat Ak√ßakaya, Ian R. Kleckner, Richard Vincent Palumbo, Lisa Feldman Barrett, Karen S. Quigley, Matthew S. Goodwin. (2018). Applications of sparse recovery and dictionary learning to enhance analysis of ambulatory electrodermal activity data Biomed. Signal Process. Control., 40, 58-70. https://doi.org/10.1016/j.bspc.2017.08.024","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1011
926,Human-Centered Computing,Matthew Goodwin,"July 1st, 2015",Automated Assessment of Children‚Äôs Postoperative Pain Using Computer Vision,http://www.ncbi.nlm.nih.gov/pubmed/26034245," Sikka, K., Ahmed, A. A., Diaz, D., Goodwin, M. S., Craig, K. D., Bartlett, M. S., & Huang, J. S. (2015). Automated Assessment of Children‚Äôs Postoperative Pain Using Computer Vision. Pediatrics, peds-2015.","Abstract Background: Current pain assessment methods in youth are suboptimal and vulnerable to bias and underrecognition of clinical pain. Facial expressions are a sensitive, specific biomarker of the presence and severity of pain, and computer vision (CV) and machine-learning (ML) techniques enable reliable, valid measurement of pain-related facial expressions from video. We developed and evaluated a CVML approach to measure pain-related facial expressions for automated pain assessment in youth. Methods: A CVML-based model for assessment of pediatric postoperative pain was developed from videos of 50 neurotypical youth 5 to 18 years old in both endogenous/ongoing and exogenous/transient pain conditions after laparoscopic appendectomy. Model accuracy was assessed for self-reported pain ratings in children and time since surgery, and compared with by-proxy parent and nurse estimates of observed pain in youth. Results: Model detection of pain versus no-pain demonstrated good-to-excellent accuracy (Area under the receiver operating characteristic curve 0.84-0.94) in both ongoing and transient pain conditions. Model detection of pain severity demonstrated moderate-to-strong correlations (r = 0.65-0.86 within; r = 0.47-0.61 across subjects) for both pain conditions. The model performed equivalently to nurses but not as well as parents in detecting pain versus no-pain conditions, but performed equivalently to parents in estimating pain severity. Nurses were more likely than the model to underestimate youth self-reported pain ratings. Demographic factors did not affect model performance. Conclusions: CVML pain assessment models derived from automatic facial expression measurements demonstrated good-to-excellent accuracy in binary pain classifications, strong correlations with patient self-reported pain ratings, and parent-equivalent estimation of children's pain levels over typical pain trajectories in youth after appendectomy.",1012
927,Human-Centered Computing,Matthew Goodwin,"May 10th, 2014",A non-homogeneous poisson process model of Skin Conductance Responses integrated with observed regulatory behaviors for Autism intervention,http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6853870," Chaspari, T., Goodwin, M., Wilder-Smith, O., Gulsrud, A., Mucchetti, C., Kasari, C., & Narayanan, S. (2014, May). A non-homogeneous Poisson process model of skin conductance responses integrated with observed regulatory behaviors for Autism intervention. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 1611-1615). IEEE.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1013
928,Human-Centered Computing,Matthew Goodwin,"January 2nd, 2010",iCalm: Wearable Sensor and Network Architecture for Wirelessly Communicating and Logging Autonomic Activity,http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5373932," Fletcher R.R., Dobson K., Goodwin M.S., Eydgahi H., Wilder-Smith O., Fernholz D., Kuboyama Y., Hedman E., Poh M.-Z., Picard R.W. iCalm: wearable sensor and network architecture for wirelessly communicating and logging autonomic activity ‚Äî IEEE Transactions on Information Technology in Biomedicine, 2010 14(2): 215‚Äê223.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1014
929,Human-Centered Computing,Megan Hofmann,"October 11th, 2024",KODA: Knit-program Optimization by Dependency Analysis,https://doi.org/10.1145/3654777.3676405," Megan Hofmann. (2024). KODA: Knit-program Optimization by Dependency Analysis UIST, 64:1-64:15. https://doi.org/10.1145/3654777.3676405","Digital knitting machines have the capability to reliably manufacture seamless, textured, and multi-material garments, but these capabilities are obscured by limiting CAD tools. Recent innovations in computational knitting build on emerging programming infrastructure that gives full access to the machine‚Äôs capabilities but requires an extensive understanding of machine operations and execution. In this paper, we contribute a critical missing piece of the knitting-machine programming pipeline‚Äìa program optimizer. Program optimization allows programmers to focus on developing novel algorithms that produce desired fabrics while deferring concerns of efficient machine operations to the optimizer. We present KODA, the Knit-program Optimization by Dependency Analysis method. KODA re-orders and reduces machine instructions to reduce knitting time, increase knitting reliability, and manage boilerplate operations that adjust the machine state. The result is a system that enables programmers to write readable and intuitive knitting algorithms while producing efficient and verified programs.",1015
930,Human-Centered Computing,Megan Hofmann,"April 29th, 2022",Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs,https://doi.org/10.1145/3491102.3517436," Megan Hofmann, Kelly Mack, Jessica Birchfield, Jerry Cao, Autumn G Hughes, Shriya Kurpad, Kathryn J Lum, Emily Warnock, Anat Caspi, Scott E Hudson, and Jennifer Mankoff. (2022). ""Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs"". In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 592, 1‚Äì15. DOI: 10.1145/3491102.3517436","Tactile maps can help people who are blind or have low-vision navigate and familiarize themselves with unfamiliar locations. Ideally, tactile maps can be customized to an individual‚Äôs unique needs and abilities because of their limited space for representation. We present Maptimizer, a tool that generates tactile maps based on users‚Äô preferences and requirements. Maptimizer uses a two stage optimization process to pair representations with geographic information and tune those representations to present that information more clearly. In a small user study, Maptimizer helped participants more successfully and efficiently identify locations of interest in unknown areas. These results demonstrate the utility of optimization techniques and generative design in complex accessibility domains.",1016
931,Human-Centered Computing,Megan Hofmann,"April 7th, 2022",Making a Medical Maker‚Äôs Playbook: An Ethnographic Study of Safety-Critical Collective Design by Makers in Response to COVID-19,https://doi.org/10.1145/3512948," Megan Hofmann, Udaya Lakshmi, Kelly Mack, Rosa I. Arriaga, Scott E. Hudson, and Jennifer Mankoff. (2022). ""Making a Medical Maker's Playbook: An Ethnographic Study of Safety-Critical Collective Design by Makers in Response to COVID-19"". Proc. ACM Hum.-Comput. Interact. 6, CSCW1, Article 101 (April 2022), 26 pages. DOI: 10.1145/3512948","We present an ethnographic study of a maker community that conducted safety-driven medical making to deliver over 80,000 devices for use at medical facilities in response to the COVID-19 pandemic. To achieve this, the community had to balance their clinical value of safety with the maker value of broadened participation in design and production. We analyse their struggles and achievement through the artifacts they produced and the labors of key facilitators between diverse community members. Based on this analysis we provide insights into how medical maker communities, which are necessarily risk-averse and safety-oriented, can still support makers' grassroots efforts to care for their communities. Based on these findings, we recommend that design tools enable adaptation to a wider set of domains, rather than exclusively presenting information relevant to manufacturing. Further, we call for future work on the portability of designs across different types of printers which could enable broader participation in future maker efforts at this scale.",1017
932,Human-Centered Computing,Stephen Intille,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1018
933,Human-Centered Computing,Stephen Intille,"November 21st, 2024","Ask Less, Learn More: Adapting Ecological Momentary Assessment Survey Length by Modeling Question-Answer Information Gain",https://doi.org/10.1145/3699735," Jixin Li, Aditya Ponnada, Wei-Lin Wang, Genevieve F. Dunton, Stephen S. Intille. (2024). Ask Less, Learn More: Adapting Ecological Momentary Assessment Survey Length by Modeling Question-Answer Information Gain Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 166:1-166:32. https://doi.org/10.1145/3699735","Ecological momentary assessment (EMA) is an approach to collect self-reported data repeatedly on mobile devices in natural settings. EMAs allow for temporally dense, ecologically valid data collection, but frequent interruptions with lengthy surveys on mobile devices can burden users, impacting compliance and data quality. We propose a method that reduces the length of each EMA question set measuring interrelated constructs, with only modest information loss. By estimating the potential information gain of each EMA question using question-answer prediction models, this method can prioritize the presentation of the most informative question in a question-by-question sequence and skip uninformative questions. We evaluated the proposed method by simulating question omission using four real-world datasets from three different EMA studies. When compared against the random question omission approach that skips 50% of the questions, our method reduces imputation errors by 15%-52%. In surveys with five answer options for each question, our method can reduce the mean survey length by 34%-56% with a real-time prediction accuracy of 72%-95% for the skipped questions. The proposed method may either allow more constructs to be surveyed without adding user burden or reduce response burden for more sustainable longitudinal EMA data collection.",1019
934,Human-Centered Computing,Stephen Intille,"September 9th, 2024",Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment,https://doi.org/10.1145/3678584," Ha Le, Rithika Lakshminarayanan, Jixin Li, Varun Mishra , Stephen S. Intille. (2024). Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 111:1-111:35. https://doi.org/10.1145/3678584","ŒºEMA is a data collection method that prompts research participants with quick, answer-at-a-glance, single-multiple-choice self-report behavioral questions, thus enabling high-temporal-density self-report of up to four times per hour when implemented on a smartwatch. However, due to the small watch screen, ŒºEMA is better used to select among 2 to 5 multiple-choice answers versus allowing the collection of open-ended responses. We introduce an alternative and novel form of micro-interaction self-report using speech input - audio-ŒºEMA- where a short beep or vibration cues participants to verbally report their behavioral states, allowing for open-ended, temporally dense self-reports. We conducted a one-hour usability study followed by a within-subject, 6-day to 21-day free-living feasibility study in which participants self-reported their physical activities and postures once every 2 to 5 minutes. We qualitatively explored the usability of the system and identified factors impacting the response rates of this data collection method. Despite being interrupted 12 to 20 times per hour, participants in the free-living study were highly engaged with the system, with an average response rate of 67.7% for audio-ŒºEMA for up to 14 days. We discuss the factors that impacted feasibility; some implementation, methodological, and participant challenges we observed; and important considerations relevant to deploying audio-ŒºEMA in real-time activity recognition systems.",1020
935,Human-Centered Computing,Stephen Intille,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1021
936,Human-Centered Computing,Stephen Intille,"November 11th, 2022",Exploring Opportunities to Improve Physical Activity in Individuals with Spinal Cord Injury Using Context-Aware Messaging,https://doi.org/10.1145/3555628," Rithika Lakshminarayanan, Alexandra Canori, Aditya Ponnada, Melissa Nunn, Mary Schmidt Read, Shivayogi V. Hiremath, Stephen S. Intille. (2022). Exploring Opportunities to Improve Physical Activity in Individuals with Spinal Cord Injury Using Context-Aware Messaging Proc. ACM Hum. Comput. Interact., 6, 1-27. https://doi.org/10.1145/3555628","Spinal cord injury (SCI) affects the mobility of 250,000 people per year worldwide. Physical activity (PA) in individuals with SCI is positively associated with improved mental and physical health outcomes. Mobile technologies have been developed to motivate individuals with SCI to increase PA using activity tracking and real-time feedback. We conducted semi-structured interviews and participatory design sessions with 15 manual wheelchair users with SCI and eight of their family members/friends to investigate user impressions of future technologies that might use computer-mediated, sensor-triggered communication to motivate PA. We assessed barriers to PA and how context-aware communication could help overcome them. Participants with SCI expressed that PA tracking and communication technologies must be tailored to their specific needs. Further analysis revealed that context-aware messaging could help participants with SCI connect with others to initiate timely conversations about overcoming PA barriers, and to provide encouragement to meet their PA goals. We discuss opportunities to empower individuals with SCI with regards to PA using tailored, context-aware communication.",1022
937,Human-Centered Computing,Stephen Intille,"September 26th, 2022",Grand Challenges,https://doi.org/10.1109/MPRV.2022.3198813," Sarah Clinch, Stephen S. Intille. (2022). Grand Challenges IEEE Pervasive Comput., 21, 7-8. https://doi.org/10.1109/MPRV.2022.3198813","Abstract: The articles in this special section focus on new applications for pervasive computing. Metadata Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Page(s): 7 - 8 Date of Publication: 26 September 2022 ISSN Information: DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE Abstract: The articles in this special section focus on new applications for pervasive computing. Metadata Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Page(s): 7 - 8 Date of Publication: 26 September 2022 ISSN Information: DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Date of Publication: 26 September 2022 DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE",1023
938,Human-Centered Computing,Stephen Intille,"March 29th, 2022",Contextual Biases in Microinteraction Ecological Momentary Assessment (ŒºEMA) Non-response,https://doi.org/10.1145/3517259," Aditya Ponnada, Jixin Li, Shirlene Wang, Wei-Lin Wang, Bridgette Do, Genevieve F. Dunton, Stephen S. Intille. (2022). Contextual Biases in Microinteraction Ecological Momentary Assessment (ŒºEMA) Non-response Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 6, 26:1-26:24. https://doi.org/10.1145/3517259","Ecological momentary assessment (EMA) is used to gather in-situ self-report on behaviors using mobile devices. Microinteraction EMA (ŒºEMA), is a type of EMA where each survey is only one single question that can be answered with a glanceable microinteraction on a smartwatch. Prior work shows that even when ŒºEMA interrupts far more frequently than smartphone-EMA, ŒºEMA yields higher response rates with lower burden. We examined the contextual biases associated with non-response of ŒºEMA prompts on a smartwatch. Based on prior work on EMA non-response and smartwatch use, we identified 10 potential contextual biases from three categories: temporal (time of the day, parts of waking day, day of the week, and days in study), device use (screen state, charging status, battery mode, and phone usage), and activity (wrist motion and location). We used data from a longitudinal study where 131 participants (Mean age 22.9 years, SD = 3.0) responded to ŒºEMA surveys on a smartwatch for at least six months. Using mixed-effects logistic regression, we found that all temporal, activity/mobility, and device use variables had a statistically significant (p<0.001) association with momentary ŒºEMA non-response. We discuss the implication of these results for future use of context-aware ŒºEMA methodology.",1024
939,Human-Centered Computing,Stephen Intille,"March 20th, 2021",Signaligner Pro: A Tool to Explore and Annotate Multi-day Raw Accelerometer Data,https://ieeexplore.ieee.org/abstract/document/9431110," A. Ponnada et al., ""Signaligner Pro: A Tool to Explore and Annotate Multi-day Raw Accelerometer Data,"" 2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), 2021, pp. 475-480, doi: 10.1109/PerComWorkshops51409.2021.9431110.","Human activity recognition using wearable accelerometers can enable in-situ detection of physical activities to support novel human-computer interfaces. Many of the machine-learning-based activity recognition algorithms require multi-person, multi-day, carefully annotated training data. To date, there is a dearth of usable tools that enable researchers to conveniently visualize and annotate multiple days of high-sampling-rate raw accelerometer data. We developed Signaligner Pro to enable researchers. to conveniently explore and annotated multi- day high-Sampling rate raw accelerometers data.",1025
940,Human-Centered Computing,Stephen Intille,"July 25th, 2019",Classifier personalization for activity recognition using wrist accelerometers,https://ieeexplore.ieee.org/document/8462755," A. Mannini and S. S. Intille, ""Classifier Personalization for Activity Recognition Using Wrist Accelerometers,"" in IEEE Journal of Biomedical and Health Informatics, vol. 23, no. 4, pp. 1585-1594, July 2019.","Intersubject variability in accelerometer-based activity recognition may significantly affect classification accuracy. In this paper, we propose an approach for personalizing classification rules to a single person. The method improves activity detection from wrist-worn accelerometer data on a four-class recognition problem of interest to the exercise science community. The new method improved overall recognition accuracy up to 11% on average, with some large person-specific improvements (ranging from -2% to +36%).",1026
941,Human-Centered Computing,Stephen Intille,"October 18th, 2018",The Association Between Engagement and Weight Loss Through Personal Coaching and Cell Phone Interventions in Young Adults: Randomized Controlled Trial,https://www.ncbi.nlm.nih.gov/pubmed/30341051," P.-H. Lin, S. Grambow, S. Intille, J. Gallis, T. Lazenka, H. Bosworth, C. Voils, G. Bennett, B. Batch, J. Allen, L. Corsino, C. Tyson, and L. Svetkey, ""The association between engagement and weight loss through personal coaching and cell phone interventions in young adults: Randomized controlled trial,"" JMIR mHealth and uHealth, vol. 6, p. e10471, 2018.","The CITY trial tested two 24-month weight loss interventions. One was delivered with a smartphone app (cell phone) containing 24 components. The other was delivered by a coach via monthly calls (personal coaching) The cell phone arm used the apps an average of 5.3 times/day (SD 3.1), whereas the personal coaching participants used them 1.7 times/ day (SD 1.2)",1027
942,Human-Centered Computing,Stephen Intille,"September 1st, 2017",Microinteraction ecological momentary assessment response rates: Effect of microinteractions or the smartwatch?,https://dl.acm.org/citation.cfm?id=3130957," A. Ponnada, C. Haynes, D. Maniar, J. Manjourides, and S. Intille, ""Microinteraction ecological momentary assessment response rates: Effect of microinteractions or the smartwatch?,"" Proc. of the ACM Journal on Interactive, Mobile, Wearable, and Ubiquitous Technology vol. 1, 2017","Mobile-based ecological-momentary-assessment (EMA) is an in-situ measurement methodology where an electronic device prompts a person to answer questions of research interest. EMA has a key limitation: interruption burden. Microinteraction-EMA(¬µEMA) may reduce burden without sacrificing high temporal density of measurement. In ¬µEMA, all EMA prompts can be answered with ‚Äòat a glance' microinteractions. In a prior 4-week pilot study comparing standard EMA delivered on a phone (phone-EMA) vs. ¬µEMA delivered on a smartwatch (watch-¬µEMA), watch-¬µEMA demonstrated higher response rates and lower perceived burden than phone-EMA, even when the watch-¬µEMA interruption rate was 8 times more than phone-EMA. A new 4-week dataset was gathered on smartwatch-based EMA (i.e., watch-EMA with 6 back-to-back, multiple-choice questions on a watch) to compare whether the high response rates of watch-¬µEMA previously observed were a result of using microinteractions, or due to the novelty and accessibility of the smartwatch. No statistically significant differences in compliance, completion, and first-prompt response rates were observed between phone-EMA and watch-EMA. However, watch-¬µEMA response rates were significantly higher than watch-EMA. This pilot suggests that (1) the high compliance and low burden previously observed in watch-¬µEMA is likely due to the microinteraction question technique, not simply the use of the watch versus the phone, and that (2) compliance with traditional EMA (with long surveys) may not improve simply by moving survey delivery from the phone to a smartwatch.",1028
943,Human-Centered Computing,Chenyan Jia,"January 16th, 2024",Training Socially Aligned Language Models on Simulated Social Interactions,https://openreview.net/forum?id=NddKiWtdUm," Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Diyi Yang, Soroush Vosoughi. (2024). Training Socially Aligned Language Models on Simulated Social Interactions ICLR. https://openreview.net/forum?id=NddKiWtdUm","The goal of social alignment for AI systems is to make sure these models can conduct themselves appropriately following social values. Unlike humans who establish a consensus on value judgments through social interaction, current language models are trained to rigidly recite the corpus in social isolation. This paper introduces a framework for aligning language models with social norms and human values through simulated social interactions.",1029
944,Human-Centered Computing,Chenyan Jia,"October 21st, 2023",Non-Parallel Text Style Transfer with Self-Parallel Supervision,https://openreview.net/forum?id=-TSe5o7STVR," Ruibo Liu, Chongyang Gao, Chenyan Jia, Guangxuan Xu, Soroush Vosoughi. (2022). Non-Parallel Text Style Transfer with Self-Parallel Supervision ICLR. https://openreview.net/forum?id=-TSe5o7STVR","LaMer uses scene graphs to align sentences from different styles, requiring neither extra data nor additional systems training. To study the performance of LaMer in extreme data hungry cases, we run new experiments in few-shot scenarios (where only 1% of training data is available) We compare LaMer with several LM-based baselines and the GPT-3 based zero-shot TST method.",1030
945,Human-Centered Computing,Chenyan Jia,"November 28th, 2022",Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits,http://papers.nips.cc/paper_files/paper/2022/hash/01c4593d60a020fed5607944330106b1-Abstract-Conference.html," Ruibo Liu, Chenyan Jia, Ge Zhang, Ziyu Zhuang, Tony X. Liu, Soroush Vosoughi. (2022). Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits NeurIPS. http://papers.nips.cc/paper_files/paper/2022/hash/01c4593d60a020fed5607944330106b1-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 35 (NeurIPS 2022) Main Conference Track Ruibo Liu, Chenyan Jia, Ge Zhang, Ziyu Zhuang, Tony Liu, Soroush Vosoughi We present Second Thoughts, a new learning paradigm that enables language models (LMs) to re-align with human values. By modeling the chain-of-edits between value-unaligned and value-aligned text, with LM fine-tuning and additional refinement through reinforcement learning, Second Thoughts not only achieves superior performance in three value alignment benchmark datasets but also shows strong human-value transfer learning ability in few-shot scenarios. The generated editing steps also offer better interpretability and ease for interactive error correction. Extensive human evaluations further confirm its effectiveness.",1031
946,Human-Centered Computing,Chenyan Jia,"May 18th, 2021",Mitigating Political Bias in Language Models through Reinforced Calibration,https://doi.org/10.1609/aaai.v35i17.17744," Ruibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu, Lili Wang, Soroush Vosoughi. (2021). Mitigating Political Bias in Language Models through Reinforced Calibration AAAI, 14857-14866. https://doi.org/10.1609/aaai.v35i17.17744","Abstract Current large-scale language models can be politically biased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real-world settings. In this paper, we describe metrics for measuring political bias in GPT-2 generation and propose a reinforcement learning (RL) framework for mitigating political biases in generated text. By using rewards from word embeddings or a classifier, our RL framework guides debiased generation without having access to the training data or requiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias (gender, location, and topic), our methods reduced bias according to both our metrics and human evaluation, while maintaining readability and semantic coherence.",1032
947,Human-Centered Computing,R√©becca Kleinberger,"December 2nd, 2024",Empowering Animals Through Technology: Enhancing Animal Agency in the Sound Environment,https://doi.org/10.1145/3702336.3702354," Fiona French, Dominique Potvin, Ilyena Hirskyj-Douglas, Neil Evans, Azadeh Jalali, R√©becca Kleinberger, Ruedi Nager, Oluwaseun Serah Iyasere, Saeed Shafiei Sabet, Michelle Spierings, Pralle Kriengwatana. (2024). Empowering Animals Through Technology: Enhancing Animal Agency in the Sound Environment ACI, 17:1-17:5. https://doi.org/10.1145/3702336.3702354","As we learn more about how cognition, behaviour, health and welfare of animals can be impacted by sound, understanding how sound environments affect different species has become highly important. However, there is very limited evidence about how these sound environments and their acoustic variables might improve or degrade conditions for most animals. This in-person workshop will explore how innovative technologies can be designed to give animals some control over their sound environment for both research and tentatively, for managed scenarios. Participants will discuss advancements in acoustic technologies, its applications in different animal settings, animal-specific interface design, and practical methods for implementing and evaluating these solutions. The workshop will feature several case studies and discussions to deepen understanding and encourage collaborative solutions. The outputs of this workshop will include designs for technological apparatus, evaluations or experiments that allow animals to control their sound environment.",1033
948,Human-Centered Computing,R√©becca Kleinberger,"December 2nd, 2024",Surveying The Extent of Demographic Reporting of Animal Participants in ACI Research,https://doi.org/10.1145/3702336.3702339," Lena Ashooh, Ilyena Hirskyj-Douglas, R√©becca Kleinberger. (2024). Surveying The Extent of Demographic Reporting of Animal Participants in ACI Research ACI, 3:1-3:7. https://doi.org/10.1145/3702336.3702339","We present a review of demographic information collected and reported about animal research participants in Animal-Computer Interaction (ACI) research. Starting from the complete ACI proceedings of 161 publications from the conference beginnings in 2016 until 2023, we established a corpus of 79 publications involving live animal participants. Our aim was to paint a picture of who these animals are, what demographic data was collected about them, and how this data varied across different research contexts. Our analysis revealed 841 live animals represented in ACI research, encompassing 23 different types of animals across 10 research contexts. We observed differences in the demographic information correlating with the animals‚Äô types and contexts. We argue that these differences might reflect biases about animals and could impact the interdisciplinary exchange of research findings. In particular, descriptors such as breed, species, and context-specific details were frequently reported, while aspects like personalities, life experiences, and social relationships were less consistently documented, and only in some specific contexts. We discuss the implications of these findings for research validity, reproducibility, and ethical considerations within ACI, proposing recommendations for more consistent and comprehensive reporting practices. This work aims to enhance our understanding of animal participants in ACI research and advance efforts towards equitable and ethical interspecies relationships through technology.",1034
949,Human-Centered Computing,R√©becca Kleinberger,"May 11th, 2024",Call of the Wild Web: Comparing Parrot Engagement in Live vs. Pre-Recorded Video Calls,https://doi.org/10.1145/3613904.3641938," Ilyena Hirskyj-Douglas, Jennifer M. Cunha, R√©becca Kleinberger. (2024). Call of the Wild Web: Comparing Parrot Engagement in Live vs. Pre-Recorded Video Calls CHI, 625:1-625:14. https://doi.org/10.1145/3613904.3641938","The concept of the animal Internet has flourished, with many conceptualisations proceeding from the premise that connecting animals online may enrich their social life. Yet we remain unaware of how ‚Äì or even whether ‚Äì online interactions (either live or with pre-recorded material) might affect how animals engage with other animals. We implemented a system for parrots to trigger live video calls with other birds or playback from a pre-recorded video call. The goal was to identify differences in engagement and behaviours. Over a six-month study, parrots triggered significantly more live calls and engaged longer in that setting relative to the playback condition, while the animals‚Äô caregivers found greater value in the latter but preferred the live alternative for the birds under their care. The results begin to question what animals make of online remote connections, putting forward considerations as to how the internet can affect animals‚Äô experiences.",1035
950,Human-Centered Computing,R√©becca Kleinberger,"May 11th, 2024",Ellie Talks About the Weather: Toward Evaluating the Expressive and Enrichment Potential of a Tablet-Based Speech Board in a Single Goffin‚Äôs Cockatoo,https://doi.org/10.1145/3613904.3643654," Jennifer M. Cunha, Corinne C. Renguette, Nikhil Singh , Lily Stella, Megan McMahon, Hao Jin, R√©becca Kleinberger. (2024). Ellie Talks About the Weather: Toward Evaluating the Expressive and Enrichment Potential of a Tablet-Based Speech Board in a Single Goffin's Cockatoo CHI, 627:1-627:16. https://doi.org/10.1145/3613904.3643654","Augmentative and alternative communication devices (AACs) are designed to assist humans with complex communication needs. Recently, AAC use has been reported in non-human animals. Such tools may potentially provide enrichment and increase interspecies connection. However, there is no evaluation framework and little data available to assess AAC potential. Here, we examine seven months of a single parrot‚Äôs sustained use of a tablet-based AAC totaling 129 sessions within 190 days. After devising a coding schema, we propose a framework to explore the expressive potential and enrichment value for the parrot. Our results suggest that the choice of destination words cannot be simply explained based on random selection or icon location alone, and 92% of corroborable selections are validated by behaviors. The parrot interactions also appear significantly skewed toward social and cognitive enrichment. This work is a first step toward assessment of AAC use for parrot enrichment.",1036
951,Human-Centered Computing,Wallace Lages,"November 1st, 2024",Audio augmented reality using sonification to enhance visual art experiences: Lessons learned,https://doi.org/10.1016/j.ijhcs.2024.103329," Abhraneil Dam, Yeaji Lee, Arsh Siddiqui, Wallace Santos Lages, Myounghoon Jeon . (2024). Audio augmented reality using sonification to enhance visual art experiences: Lessons learned Int. J. Hum. Comput. Stud., 191, 103329. https://doi.org/10.1016/j.ijhcs.2024.103329","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1037
952,Human-Centered Computing,Wallace Lages,"October 29th, 2024","Breaking Barriers in Immersive Stories: Empathy, Representation, and Access",https://doi.org/10.1145/3698391," Tyechia L. Thompson, Eric Lyon, Wallace Lages. (2024). Breaking Barriers in Immersive Stories: Empathy, Representation, and Access Interactions, 31, 6-7. https://doi.org/10.1145/3698391","The Interactions website (interactions.acm.org) hosts a stable of bloggers who share insights and observations on HCI, often challenging current practices. Each issue we'll publish selected posts from some of the leading and emerging voices in the field.",1038
953,Human-Centered Computing,Wallace Lages,"October 7th, 2024","Examining Pair Dynamics in Shared, Co-located Augmented Reality Narratives",https://doi.org/10.1145/3677386.3682091," Cherelle Connor, Eric Cade Schoenborn, Sathaporn Hu, Thiago Malheiros Porcino, Cameron Moore, Derek Reilly, Wallace Santos Lages. (2024). Examining Pair Dynamics in Shared, Co-located Augmented Reality Narratives SUI, 17:1-17:11. https://doi.org/10.1145/3677386.3682091","Augmented reality (AR) allows users to experience stories together in the same physical space. However, little is known about the experience of sharing AR narratives with others. Much of our current understanding is derived from multi-user VR applications, which can differ significantly in presence, social interaction, and spatial awareness from narratives and other entertainment content designed for AR head-worn displays. To understand the dynamics of multi-user, co-located, AR storytelling, we conducted an exploratory study involving three original AR narratives. Participants experienced each narrative alone or in pairs via the Microsoft Hololens 2. We collected qualitative and quantitative data from 42 participants through questionnaires and post-experience semi-structured interviews. Results indicate participants enjoyed experiencing AR narratives together and revealed five themes relevant to the design of multi-user, co-located AR narratives. We discuss the implications of these themes and provide design recommendations for AR experience designers and storytellers regarding the impact of interaction, physical space, spatial coherence, and narrative timing. Our findings highlight the importance of exploring both user interactions and pair interactions as factors in AR storytelling research.",1039
954,Human-Centered Computing,Wallace Lages,"May 11th, 2020",Where to display? How Interface Position Affects Comfort and Task Switching Time on Glanceable Interfaces,https://doi.org/10.1109/VR46266.2020.1581435674325," Samat Imamov, Daniel Monzel, Wallace Santos Lages. (2020). Where to display? How Interface Position Affects Comfort and Task Switching Time on Glanceable Interfaces VR, 851-858. https://doi.org/10.1109/VR46266.2020.1581435674325","A critical decision when designing glanceable information displays is where to place the content. Since blocking the center of the field of view with virtual information is not desirable, designers often opt for placement in the visual periphery. No study has been made to systematically evaluate world-locked content position, considering both cognitive and physiological constraints. We found participants preferred content at medium distances, although they were also faster with content at far distances. The same happens with discomfort: content placed at eye level, or below, was faster and more comfortable than in other positions.",1040
955,Human-Centered Computing,Chris Le Dantec,"November 8th, 2024",Reimagining Meaningful Data Work through Citizen Science,https://doi.org/10.1145/3687049," Ashley Boone, Annabel Rothschild, Xander Koo, Grace Pfohl, Alyssa Sheehan, Betsy DiSalvo, Christopher A. Le Dantec, Carl DiSalvo. (2024). Reimagining Meaningful Data Work through Citizen Science Proc. ACM Hum. Comput. Interact., 8, 1-26. https://doi.org/10.1145/3687049","Data work is often completed by crowdworkers, who are routinely dehumanized, disempowered, and sidelined. We turn to citizen science to reimagine data work, highlighting collaborative relationships between citizen science project managers and volunteers. Though citizen science and traditional crowd work entail similar forms of data work, such as classifying or transcribing large data sets, citizen science relies on volunteer contributions rather than paid data work. We detail the work citizen science project managers did to shape volunteer experiences: aligning science goals, minimizing barriers to participation, engaging communities, communicating with volunteers, providing training and education, rewarding contributions, and reflecting on volunteer work. These management strategies created opportunities for meaningful work by cultivating intrinsic motivation and fostering collaborative work relationships but ultimately limited participation to specific data-related tasks. We recommend management tactics and task design strategies for creating meaningful work for ""invisible collar"" workers, an understudied class of labor in CSCW.",1041
956,Human-Centered Computing,Chris Le Dantec,"July 1st, 2024",Embodied Traces: Multispecies Entanglement in Urban Spaces,https://doi.org/10.1145/3643834.3660746," Ashley Boone, Christopher A. Le Dantec, Carl DiSalvo. (2024). Embodied Traces: Multispecies Entanglement in Urban Spaces Conference on Designing Interactive Systems. https://doi.org/10.1145/3643834.3660746","Collisions with man-made structures such as buildings, vehicles, and energy infrastructure are a significant threat to bird populations. Throughout the U.S., groups of volunteers monitor bird-building collisions to better understand the environmental impact of collisions and to advocate for the use of bird-safe building materials. The first author participated in monitoring bird-building collisions in Atlanta during the spring and fall migration seasons of 2023. This pictorial is a reflection on the experience of producing this data based on interviews with volunteers and the experiences and photographs of the first author. We contribute a rich account of the experiential elements of data production and a discussion of more-than-human entanglements in urban spaces.",1042
957,Human-Centered Computing,Chris Le Dantec,"July 1st, 2024",Tuning into the World: Designing Community Safety Technologies to Reduce Dysfunctional Fear of Crime,https://doi.org/10.1145/3643834.3661578," Ishita Chordia, Jaewon Kim, Zhuoyan Liu, Hayley Park, Lesley Garrett, Sheena Erete, Christopher A. Le Dantec, Jason C. Yip , Alexis Hiniker. (2024). Tuning into the World: Designing Community Safety Technologies to Reduce Dysfunctional Fear of Crime Conference on Designing Interactive Systems. https://doi.org/10.1145/3643834.3661578","Platforms like Nextdoor and Citizen can increase users‚Äô fear of crime by broadcasting frequent, local, and personalized information about potential safety risks. These platforms can contribute to a dysfunctional fear of crime, which undermines a person‚Äôs quality of life and mental health without actually making them feel safer. In this work, we conducted a mixed-methods study to understand the potential for design to foster a functional fear of crime, which motivates precaution without negatively impacting quality of life. We first interview individuals with a dysfunctional fear of crime and then validate interview results with a survey. Through this process, we identified five strategies for designers to support users in developing a more functional fear of crime. These strategies surface overarching theoretical and design implications for designers and researchers of safety platform with the ultimate goal of supporting safety, quality of life, and mental health for users of these platforms.",1043
958,Human-Centered Computing,Chris Le Dantec,"May 11th, 2024",Bitacora: A Toolkit for Supporting NonProfits to Critically Reflect on Social Media Data Use,https://doi.org/10.1145/3613904.3642673," Adriana Alvarado Garcia, Marisol Wong-Villacres, Benjam√≠n Hern√°ndez, Christopher A. Le Dantec. (2024). Bitacora: A Toolkit for Supporting NonProfits to Critically Reflect on Social Media Data Use CHI, 230:1-230:29. https://doi.org/10.1145/3613904.3642673","In this paper, we describe the design and evaluation of the toolkit Bitacora, addressed to practitioners working in non-profit organizations interested in integrating Twitter data into their work. The toolkit responds to the call to maintain the locality of data by promoting a qualitative and contextualized approach to analyzing Twitter data. We assessed the toolkit‚Äôs effectiveness in guiding practitioners to search, collect, and be critical when analyzing data from Twitter. We evaluated the toolkit with ten practitioners from three non-profit organizations of different aims and sizes in Mexico. The assessment surfaced tensions between the assumptions embedded in the toolkit‚Äôs design and practitioners‚Äô expectations, needs, and backgrounds. We show that practitioners navigated these tensions in some cases by developing strategies and, in others, questioning the appropriateness of using Twitter data to inform their work. We conclude with recommendations for researchers who developed tools for non-profit organizations to inform humanitarian action.",1044
959,Human-Centered Computing,Ada Lerner,"August 1st, 2024",Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit,https://www.usenix.org/conference/usenixsecurity24/presentation/tabassum," Madiha Tabassum, Alana Mackey, Ashley Schuett, Ada Lerner. (2024). Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit USENIX Security Symposium. https://www.usenix.org/conference/usenixsecurity24/presentation/tabassum","Madiha Tabassum, Northeastern University; Alana Mackey, Wellesley College; Ashley Schuett, George Washington University; Ada Lerner, Northeastern University Social media platforms often rely on volunteer moderators to combat hate and harassment and create safe online environments. In the face of challenges combating hate and harassment, moderators engage in mutual support with one another. We conducted a qualitative content analysis of 115 hate and harassment-related threads from r/ModSupport and r/modhelp, two major subreddit forums for this type of mutual support. We analyze the challenges moderators face; complex tradeoffs related to privacy, utility, and harassment; and major challenges in the relationship between moderators and platform admins. We also present the first systematization of how platform features (including especially security, privacy, and safety features) are misused for online abuse, and drawing on this systematization we articulate design themes for platforms that want to resist such misuse. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. ¬© USENIX 2025 EIN 13-3055038",1045
960,Human-Centered Computing,Ada Lerner,"August 1st, 2024",‚ÄòCustodian of Online Communities‚Äô: How Moderator Mutual Support in Communities Help Fight Hate and Harassment Online,https://www.usenix.org/conference/soups2024/presentation/tabassum-madiha," Madiha Tabassum, Alana Mackey, Ada Lerner. (2024). 'Custodian of Online Communities': How Moderator Mutual Support in Communities Help Fight Hate and Harassment Online SOUPS @ USENIX Security Symposium, 297-314. https://www.usenix.org/conference/soups2024/presentation/tabassum-madiha","Madiha Tabassum, Northeastern University; Alana Mackey, Wellesley College; Ada Lerner, Northeastern University Volunteer moderators play a crucial role in safeguarding online communities, actively combating hate, harassment, and inappropriate content while enforcing community standards. Prior studies have examined moderation tools and practices, moderation challenges, and the emotional labor and burnout of volunteer moderators. However, researchers have yet to delve into the ways moderators support one another in combating hate and harassment within the communities they moderate through participation in meta-communities of moderators. To address this gap, we have conducted a qualitative content analysis of 115 hate and harassment-related threads from r/ModSupport and r/modhelp, two major subreddit forums for moderators for this type of mutual support. Our study reveals that moderators seek assistance on topics ranging from fighting attacks to understanding Reddit policies and rules to just venting their frustration. Other moderators respond to these requests by validating their frustration and challenges, showing emotional support, and providing information and tangible resources to help with their situation. Based on these findings, we share the implications of our work in facilitating platform and peer support for online volunteer moderators on Reddit and similar platforms. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. ¬© USENIX 2025 EIN 13-3055038",1046
961,Human-Centered Computing,Ada Lerner,"May 11th, 2024",Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom,https://doi.org/10.1145/3613904.3642664," Kelly Wang, Dan Bially Levy, Kien T. Nguyen, Ada Lerner, Abigail Marsh. (2024). Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom CHI, 575:1-575:13. https://doi.org/10.1145/3613904.3642664","The privacy practices of transformative fandom are of interest to HCI researchers both for the community‚Äôs high proportion of queer members and for the community‚Äôs sophisticated privacy norms and behaviors. We investigated fans‚Äô use of single-serving websites on Carrd.co (‚ÄúCarrds‚Äù) as personal profiles linked from Twitter accounts. We scraped Twitter to gather 5252 Carrds from fans in a variety of fandoms, which we analyzed using a combination of keyword searches and hand-coding. Fans‚Äô Carrds frequently disclose queer identity, and articulate a complex system of community values and boundary management. Inspired by how these findings aren‚Äôt well-explained by individual theories of privacy, we articulate first steps towards a theory of collective privacy based in a communal process of values construction, trust building, and personal disclosure that we believe helps us to understand the sophisticated nature of fans‚Äô observed behaviors.",1047
962,Human-Centered Computing,Ada Lerner,"April 26th, 2024",Privacy Norms of Transformative Fandom: A Case Study of an Activity-Defined Community,https://doi.org/10.1145/3637388," Abby Marsh, Ada Lerner. (2024). Privacy Norms of Transformative Fandom: A Case Study of an Activity-Defined Community Proc. ACM Hum. Comput. Interact., 8, 1-29.","Transformative media fandom is a remarkably coherent, long-lived, and diverse community united primarily by shared engagement in the varied activities of fandom. Its social norms are highly-developed and frequently debated, and have been studied by the CSCW and Media Studies communities in the past, but rarely using the tools and theories of privacy, despite fannish norms often bearing strongly on privacy. We use privacy scholarship and existing theories thereof to examine these norms and bring an additional perspective to understanding fandom communities. In this work, we analyze over 250,000 words of ""meta'' essays and comments on those essays, reflecting the views and debates of hundreds of fans on these privacy norms. Drawing on Solove's theory of privacy as an aggregation of different ideas and on a variety of other academic theories of privacy, we analyze these norms as highly effective at protecting the integrity of fannish activities. We then articulate the value of studying these sorts of diverse ""activity-defined'' communities, arguing that such approaches grant us greater power to understand privacy experiences in ways that are specific, contextual, and intersectional yet still generalizable where possible.",1048
963,Human-Centered Computing,Ada Lerner,"December 24th, 2023",SoK: Technical Implementation and Human Impact of Internet Privacy Regulations,https://doi.org/10.48550/arXiv.2312.15383," Eleanor Birrell, Jay Rodolitz, Angel Ding, Jenna Lee, Emily McReynolds, Jevan Hutson, Ada Lerner. (2023). SoK: Technical Implementation and Human Impact of Internet Privacy Regulations CoRR, abs/2312.15383. https://doi.org/10.48550/arXiv.2312.15383","Growing recognition of the potential for exploitation of personal data and of the shortcomings of prior privacy regimes has led to the passage of a multitude of new online privacy regulations. Some of these laws -- notably the European Union's General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) -- have been the focus of large bodies of research by the computer science community, while others have received less attention. In this work, we analyze a set of Internet privacy and data protection regulations drawn from around the world -- both those that have frequently been studied by computer scientists and those that have not -- and develop a taxonomy of rights granted and obligations imposed by these laws. We then leverage this taxonomy to systematize 270 technical research papers published in computer science venues that investigate the impact of these laws and explore how technical solutions can complement legal protections. Finally, we analyze the results in this space through an interdisciplinary lens and make recommendations for future work at the intersection of computer science and legal privacy.",1049
964,Human-Centered Computing,Ada Lerner,"September 20th, 2023","‚ÄúIt‚Äôs a Fair Game‚Äù, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents",https://doi.org/10.48550/arXiv.2309.11653," Zhiping Zhang, Michelle Jia, Hao-Ping Hank Lee, Bingsheng Yao, Sauvik Das, Ada Lerner, Dakuo Wang, Tianshi Li. (2023). ""It's a Fair Game"", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents CoRR, abs/2309.11653. https://doi.org/10.48550/arXiv.2309.11653","The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigm shifts to protect the privacy of LLM-based CA users.",1050
965,Human-Centered Computing,Ada Lerner,"November 14th, 2022",Buying Privacy: User Perceptions of Privacy Threats from Mobile Apps,https://doi.org/10.48550/arXiv.2211.07235," Jenny Tang, Hannah Shoemaker, Leah Teffera, Eleanor Birrell, Ada Lerner. (2022). Buying Privacy: User Perceptions of Privacy Threats from Mobile Apps CoRR, abs/2211.07235. https://doi.org/10.48550/arXiv.2211.07235","As technology and technology companies have grown in power, ubiquity, and societal influence, some companies -- and notably some mobile apps -- have come to be perceived as privacy threats. Prior work has considered how various factors impact perceptions of threat, including social factors, political speech, and user-interface design. In this work, we investigate how user-visible context clues impact perceptions about whether a mobile application application poses a privacy threat. We conduct a user study with 2109 users in which we find that users depend on context clues -- such as presence of advertising and occurrence (and timing of payment) -- to determine the extent to which a mobile app poses a privacy threat. We also quantify how accurately user assessments match published data collection practices, and we identify a commonly-held misconception about how payments are processed. This work provides new insight into how users assess the privacy threat posed by mobile apps and into social norms around data collection.",1051
966,Human-Centered Computing,Ada Lerner,"August 7th, 2022",How Well Do My Results Generalize Now? The External Validity of Online Privacy and Security Surveys,https://doi.org/10.48550/arXiv.2202.14036," Jenny Tang, Eleanor Birrell, and Ada Lerner. ""How Well Do My Results Generalize Now? The External Validity of Online Privacy and Security Surveys."" In Symposium on Usable Privacy and Security (SOUPS), 2022.","Privacy and security researchers often rely on data collected through online crowdsourcing platforms such as Amazon Mechanical Turk (MTurk) and Prolific. Prior work -- which used data collected in the United States between 2013 and 2017 -- found that MTurk responses regarding security and privacy were generally representative for people under 50 or with some college education. However, the landscape of online crowdsourcing has changed significantly over the last five years, with the rise of Prolific as a major platform and the increasing presence of bots. This work attempts to replicate the prior results about the external validity of online privacy and security surveys. We conduct an online survey on MTurk (n=800), a gender-balanced survey on Prolific (n=800), and a representative survey on Prolific (n=800) and compare the responses to a probabilistic survey conducted by the Pew Research Center (n=4272). We find that MTurk response quality has degraded over the last five years, and our results do not replicate the earlier finding about the generalizability of MTurk responses. By contrast, we find that data collected through Prolific is generally representative for questions about user perceptions and experiences, but not for questions about security and privacy knowledge. We also evaluate the impact of Prolific settings, attention check questions, and statistical methods on the external validity of online surveys, and we develop recommendations about best practices for conducting online privacy and security surveys.",1052
967,Human-Centered Computing,Ada Lerner,"July 11th, 2022",The Buffet Overflow Caf√©,https://doi.org/10.1109/MSEC.2022.3173122," Tadayoshi Kohno, Camille Cobb, Ada Lerner, Michelle Lin, Adam Shostack. (2022). The Buffet Overflow Caf√© IEEE Secur. Priv., 20, 4-7. https://doi.org/10.1109/MSEC.2022.3173122","Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Metadata Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Page(s): 4 - 7 Date of Publication: 11 July 2022 ISSN Information: DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Metadata Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Page(s): 4 - 7 Date of Publication: 11 July 2022 ISSN Information: DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE Abstract: The Buffet Overflow Caf√© is a restaurant for dining cryptographers and cybersecurity professionals. Published in: IEEE Security & Privacy ( Volume: 20 , Issue: 4 , July-Aug. 2022 ) Date of Publication: 11 July 2022 DOI: 10.1109/MSEC.2022.3173122 Publisher: IEEE",1053
968,Human-Centered Computing,Ada Lerner,"March 16th, 2021",Defining Privacy: How Users Interpret Technical Terms in Privacy Policies,https://doi.org/10.2478/popets-2021-0038," Jenny Tang, Hannah Shoemaker, Ada Lerner, and Eleanor Birrell. ""Defining Privacy: How Users Interpret Technical Terms in Privacy Policies."" In Proceedings on Privacy Enhancing Technologies, 2021(3):70-94., 2021. DOI: 10.2478/popets-2021-0038","Authors: Jenny Tang (Wellesley College), Hannah Shoemaker (Pomona College), Ada Lerner (Wellesley College), Eleanor Birrell (Pomona College) Volume: 2021 Issue: 3 Pages: 70‚Äì94 DOI: https://doi.org/10.2478/popets-2021-0038 Download PDF Abstract: Recent privacy regulations such as GDPR and CCPA have emphasized the need for transparent, understandable privacy policies. This work investigates the role technical terms play in policy transparency. We identify potentially misunderstood technical terms that appear in privacy policies through a survey of current privacy policies and a pilot user study. We then run a user study on Amazon Mechanical Turk to evaluate whether users can accurately define these technical terms, to identify commonly held misconceptions, and to investigate how the use of technical terms affects users‚Äô comfort with privacy policies. We find that technical terms are broadly misunderstood and that particular misconceptions are common. We also find that the use of technical terms affects users‚Äô comfort with various privacy policies and their reported likeliness to accept those policies. We conclude that current use of technical terms in privacy policies poses a challenge to policy transparency and user privacy, and that companies should take steps to mitigate this effect. Keywords: privacy policies, policy transparency",1054
969,Human-Centered Computing,Ada Lerner,"April 23rd, 2020",Privacy and Activism in the Transgender Community,https://doi.org/10.1145/3313831.3376339," Ada Lerner, Helen Yuxun He, Anna Kawakami, Silvia Catherine Zeamer, and Roberto Hoyle. 2020. Privacy and Activism in the Transgender Community. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). Association for Computing Machinery, New York, NY, USA, 1‚Äì13. DOI: 10.1145/3313831.3376339","Transgender people are marginalized, facing specific privacy concerns and high risk of online and offline harassment, discrimination, and violence. They also benefit tremendously from technology. We conducted semi-structured interviews with 18 transgender people from 3 U.S. cities about their computer security and privacy experiences broadly construed. Participants frequently returned to themes of activism and prosocial behavior, such as protest organization, political speech, and role-modeling transgender identities, so we focus our analysis on these themes. We identify several prominent risk models related to visibility, luck, and identity that participants used to analyze their own risk profiles, often as distinct or extreme. These risk perceptions may heavily influence transgender people's defensive behaviors and self-efficacy, jeopardizing their ability to defend themselves or gain technology's benefits. We articulate design lessons emerging from these ideas, contrasting and relating them to lessons about other marginalized groups whenever possible.",1055
970,Human-Centered Computing,Stacy C. Marsella,"January 20th, 2025",Integrating Actual Human Behavior into an Agent-Based School Shooting Simulation,https://doi.org/10.1109/WSC63780.2024.10838721," Kevin Kapadia, Nutchanon Yongsatianchot, Stacy Marsella, Richard S. John. (2024). Integrating Actual Human Behavior into an Agent-Based School Shooting Simulation WSC, 2094-2105. https://doi.org/10.1109/WSC63780.2024.10838721","With the ever-growing threat of school shootings, modeling these tragedies is crucial to mitigate or reduce casualties in future events. We present the results of 81,000 simulations of a school shooting where agent behavior is modeled after actual human behavior from a similar virtual scenario. Results show mixed agent behavior and lower dispatch times had the largest influence on casualties. The methodology demonstrates the power of empirically defining agent behavior in ABMs.",1056
971,Human-Centered Computing,Stacy C. Marsella,"December 26th, 2024",Exploring Theory of Mind in Large Language Models through Multimodal Negotiation,https://doi.org/10.1145/3652988.3673960," Nutchanon Yongsatianchot, Tobias Thejll-Madsen, Stacy Marsella. (2024). Exploring Theory of Mind in Large Language Models through Multimodal Negotiation IVA, 9:1-9:9. https://doi.org/10.1145/3652988.3673960","With the advancement of Large Language Models (LLMs), they are increasingly being used as a backend for interactive virtual agents and assistants. Therefore, a critical social skill for these agents is Theory of Mind (ToM): the ability to model and reason about other agents. Research has investigated ToM in LLMs using standard, modified, and extended versions of false-belief tasks. These tests include explicit prompts asking LLMs to answer questions about other agents. However, in real situations, people have to use ToM unprompted to navigate social life. Additionally, oftentimes, people have to rely on nonverbal cues such as facial expressions. This work seeks to address this gap by studying implicit ToM in LLMs in a negotiation task. In negotiation, agents have to implicitly reason about other agents to reach an agreed-upon best possible deal. We conducted the negotiation experiment by prompting different LLMs to roleplay as characters and pitting them against rule-based agents that may respond with different facial expressions. We measure and compare the outcomes of the negotiation across models. Our results show that strong LLMs like GPT-4 turbo and Claude 3 Opus can perform decently and adjust their offers based on access to facial expression information, but weaker models are far behind. Our work contributes to our understanding of LLMs‚Äô capabilities and limitations for serving as intelligent and interactive agents.",1057
972,Human-Centered Computing,Stacy C. Marsella,"December 2nd, 2024","Do You Understand Me, DUM-E? Enabling Seamless Human-Robot Communication Through Augmented Reality",https://doi.org/10.1109/ISMAR-Adjunct64951.2024.00153," Akhil Ajikumar, Stacy Marsella, Mohsen Moghaddam. (2024). Do You Understand Me, DUM-E? Enabling Seamless Human-Robot Communication Through Augmented Reality ISMAR-Adjunct, 529-532. https://doi.org/10.1109/ISMAR-Adjunct64951.2024.00153","This paper introduces an Augmented Reality (AR) system that facilitates seamless intent communication between a human and a collaborative robot during complex assembly tasks. The effects of the AR system on participants‚Äô task performance and user satisfaction were analyzed. The paper will be presented at the 2024 IEEE International Symposium on Mixed and Augmented reality Adjunct (ISMAR-Adjunct) in Bellevue, WA, USA.",1058
973,Human-Centered Computing,Stacy C. Marsella,"November 5th, 2024",A Unified Dynamic Model for the Decomposition of Skin Conductance and the Inference of Sudomotor Nerve Activities,https://doi.org/10.1109/TBME.2024.3492112," Hui S. Wang, Stacy Marsella, Misha Pavel. (2025). A Unified Dynamic Model for the Decomposition of Skin Conductance and the Inference of Sudomotor Nerve Activities IEEE Trans. Biomed. Eng., 72, 1178-1187. https://doi.org/10.1109/TBME.2024.3492112"," Electrodermal activity (EDA), commonly measured as skin conductance (SC), is a widely used physiological signal in psychological research and behavioral health applications. EDA is considered an indicator of arousal, a key aspect of emotion and stress. This work lays the foundation for numerous behavioral health. applications and paves the road for designing physiology-based interventions aimed at regulating arousal. The study was published in: IEEE Transactions on Biomedical Engineering ( Volume: 72 , Issue: 3 , March 2025 )",1059
974,Human-Centered Computing,Stacy C. Marsella,"July 5th, 2024",Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces,https://doi.org/10.1145/3649921.3656986," Abdelrahman Madkour, Ross Mawhorter, Stacy Marsella, Adam M. Smith , Steven Holtzen. (2024). Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces FDG, 54. https://doi.org/10.1145/3649921.3656986","We introduce a new approach to deploying constraint-based content generators that better supports online generation. Constraint-based generators ensure that certain properties hold in each design they output. However, when deployed a general-purpose solver is often required, thus guarantees come with unpredictable search times and little control over sequentially-generated outputs. In this paper, we outline how we can encode design constraints into a compact circuit representation that affords generation without search. These generators yield samples that are distributed uniformly over the space of valid designs. We illustrate our approach with binary decision diagrams (BDDs) in comparison to the traditional approach with answer-set programming (ASP) in two scenarios: a grid-based tile placement scenario inspired by WaveFunctionCollapse, and a playable platformer level design scenario. These compiled design-space models make constraint-based methods easier to deploy by improving on both the running time and diversity of previous constraint-based methods.",1060
975,Human-Centered Computing,Stacy C. Marsella,"October 6th, 2023",Probabilistic Logic Programming Semantics For Procedural Content Generation,https://doi.org/10.1609/aiide.v19i1.27525," Abdelrahman Madkour, Chris Martens , Steven Holtzen, Casper Harteveld, Stacy Marsella. (2023). Probabilistic Logic Programming Semantics For Procedural Content Generation AIIDE, 295-305. https://doi.org/10.1609/aiide.v19i1.27525","Abstract Research in procedural content generation (PCG) has recently heralded two major methodologies: machine learning (PCGML) and declarative programming. The former shows promise by automating the specification of quality criteria through latent patterns in data, while the latter offers significant advantages for authorial control. In this paper we propose the use of probabilistic logic as a unifying framework that combines the benefits of both methodologies. We propose a Bayesian formalization of content generators as probability distributions and show how common PCG tasks map naturally to operations on the distribution. Further, through a series of experiments with maze generation, we demonstrate how probabilistic logic semantics allows us to leverage the authorial control of declarative programming and the flexibility of learning from data.",1061
976,Human-Centered Computing,Stacy C. Marsella,"May 30th, 2023",Agent-Based Modeling of Human Decision-makers Under Uncertain Information During Supply Chain Shortages,https://dl.acm.org/doi/10.5555/3545946.3598855," Nutchanon Yongsatianchot, Noah Chicoine, Jacqueline A. Griffin, √ñzlem Ergun, Stacy Marsella. (2023). Agent-Based Modeling of Human Decision-makers Under Uncertain Information During Supply Chain Shortages AAMAS, 1886-1894. https://dl.acm.org/doi/10.5555/3545946.3598855","In recent years, product shortages caused by supply chain disruptions have generated problems for consumers worldwide. In supply chains, multiple decision-makers act on uncertain information they receive from others, often leading to sub-optimal decisions that propagate the effects of supply chain disruptions to other stakeholders. Therefore, understanding how humans learn to interpret information from others and how it influences their decision-making is key to alleviating supply chain shortages. In this work, we investigated how downstream supply chain echelons, health centers in pharmaceutical supply chains, interpret and use manufacturers' estimated resupply date (ERD) information during drug shortages. We formulated a computational model of a health center based on a partially observable Markov decision process that learns a manufacturer's information sharing tendencies through an observation function. To investigate the model and important factors influencing decisions and perceptions of ERD, we conducted a human experiment to study where subjects played the role of a health center during a drug shortage. They received ERDs from a manufacturer on a weekly basis and decided whether or not to switch to an alternative product (and pay additional costs) to avoid running out of stock. The results show that different manufacturers' sequences of ERDs and the accuracy of ERDs could impact subjects' decisions, beliefs, performance, and perception of the manufacturer. We also found that the subjective belief of ERDs is the best predictor of subjects' switching decisions. Lastly, we fit the observation function's learning rate and show that the model can predict subjects' decisions better than other baseline models in most conditions.",1062
977,Human-Centered Computing,Stacy C. Marsella,"May 30th, 2023",Effectiveness of Teamwork-Level Interventions through Decision-Theoretic Reasoning in a Minecraft Search-and-Rescue Task,https://dl.acm.org/doi/10.5555/3545946.3598925," David V. Pynadath, Nikolos Gurney, Sarah Kenny, Rajay Kumar, Stacy C. Marsella, Haley Matuszak, Hala Mostafa, Pedro Sequeira, Volkan Ustun, Peggy Wu. (2023). Effectiveness of Teamwork-Level Interventions through Decision-Theoretic Reasoning in a Minecraft Search-and-Rescue Task AAMAS, 2334-2336. https://dl.acm.org/doi/10.5555/3545946.3598925","Autonomous agents offer the promise of improved human teamwork through automated assessment and assistance during task performance [15, 16, 18]. Studies of human teamwork have identified various processes that underlie joint task performance, while abstracting away the specifics of the task [7, 11, 13, 17].We present here an agent that focuses exclusively on teamwork-level variables in deciding what interventions to use in assisting a human team. Our agent does not directly observe or model the environment or the people in it, but instead relies on input from analytic components (ACs) (developed by other research teams) that process environmental information and output only teamwork-relevant measures. Our agent models these teamwork variables and updates its beliefs over them using a Bayesian Theory of Mind [1], applying Partially Observable Markov Decision Processes (POMDPs) [9] in a recursive manner to assess the state of the team it is currently observing and to choose interventions to best assist them.",1063
978,Human-Centered Computing,Stacy C. Marsella,"January 30th, 2023",Thought Bubbles: A Proxy into Players‚Äô Mental Model Development,https://doi.org/10.48550/arXiv.2301.13101," Omid Mohaddesi, Noah Chicoine, Min Gong, √ñzlem Ergun, Jacqueline A. Griffin, David R. Kaeli, Stacy Marsella, Casper Harteveld. (2023). Thought Bubbles: A Proxy into Players' Mental Model Development CoRR, abs/2301.13101. https://doi.org/10.48550/arXiv.2301.13101","Studying mental models has recently received more attention, aiming to understand the cognitive aspects of human-computer interaction. However, there is not enough research on the elicitation of mental models in complex dynamic systems. We present Thought Bubbles as an approach for eliciting mental models and an avenue for understanding players' mental model development in interactive virtual environments. We demonstrate the use of Thought Bubbles in two experimental studies involving 250 participants playing a supply chain game. In our analyses, we rely on Situation Awareness (SA) levels, including perception, comprehension, and projection, and show how experimental manipulations such as disruptions and information sharing shape players' mental models and drive their decisions depending on their behavioral profile. Our results provide evidence for the use of thought bubbles in uncovering cognitive aspects of behavior by indicating how disruption location and availability of information affect people's mental model development and influence their decisions.",1064
979,Human-Centered Computing,Stacy C. Marsella,"November 25th, 2022",Modeling Emotion-Focused Coping as a Decision Process,https://doi.org/10.1109/ACII55700.2022.9953834," Nutchanon Yongsatianchot, Stacy Marsella. (2022). Modeling Emotion-Focused Coping as a Decision Process ACII, 1-8. https://doi.org/10.1109/ACII55700.2022.9953834","People experience many stressful, emotion-evoking situations in everyday life. How they cope with these situations is crucial to their well-being. Research shows that people may change their beliefs to perceive the situations in a better, less-stressful light. We model coping, based on Lazarus's appraisal theory of emotion, as a two-step decision problem. We found that when the hurricane worsens, those who stayed believe the hurricane to be less severe than the most likely outcome from the information and those who evacuated. The results also show that the uncertainty of information and the utility of the beliefs about that information is related. These findings illustrate the relevance of applying a decision-making model analysis to coping.",1065
980,Human-Centered Computing,Stacy C. Marsella,"June 6th, 2022",Investigating the Non-verbal Behavior Features of Bullying for the Development of an Automatic Recognition System in Social Virtual Reality,https://doi.org/10.1145/3531073.3534492," Cristina Fiani, Stacy Marsella. (2022). Investigating the Non-verbal Behavior Features of Bullying for the Development of an Automatic Recognition System in Social Virtual Reality AVI, 67:1-67:3. https://doi.org/10.1145/3531073.3534492","We look at the possibilities of automatically detecting social discomfort and social anxiety via non-verbal behaviours in social Virtual Reality (VR). This is important because a well-developed automatic recognition system could facilitate interventions and moderation in social VR without requiring real-time parental supervision. To initially explore this question of recognition, we prototyped a small set of 3D stimuli representing a bullying scenario and explored in a small formative preliminary study what human observers perceived from the stimuli. Future work is required with different problematic situations in social VR and evaluations with more participants before developing an automatic recognition system.",1066
981,Human-Centered Computing,Stacy C. Marsella,"May 18th, 2022",Disaster world,https://doi.org/10.1007/s10588-022-09359-y," David V. Pynadath, Bistra Dilkina, David C. Jeong, Richard S. John, Stacy C. Marsella, Chirag Merchant, Lynn C. Miller, Stephen J. Read. (2023). Disaster world Comput. Math. Organ. Theory, 29, 84-117. https://doi.org/10.1007/s10588-022-09359-y","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Decision-theoretic agents for simulating population responses to hurricanes",1067
982,Human-Centered Computing,Stacy C. Marsella,"April 28th, 2022","Shifting Trust: Examining How Trust and Distrust Emerge, Transform, and Collapse in COVID-19 Information Seeking",https://doi.org/10.1145/3491102.3501889," Yixuan Zhang, Nurul M Suhaimi, Nutchanon Yongsatianchot, Joseph D Gaggiano, Miso Kim, Shivani A Patel, Yifan Sun, Stacy Marsella, Jacqueline Grifn, and Andrea G Parker. 2022. Shifting Trust: Examining How Trust and Distrust Emerge, Transform, and Collapse in COVID-19 Information Seeking. In CHI Conference on Human Factors in Computing Systems (CHI ‚Äô22), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 21 pages. doi:10.1145/3491102.3501889","During crises like COVID-19, individuals are inundated with conflicting and time-sensitive information that drives a need for rapid assessment of the trustworthiness and reliability of information sources and platforms. This parallels evolutions in information infrastructures, ranging from social media to government data platforms. Distinct from current literature, which presumes a static relationship between the presence or absence of trust and people‚Äôs behaviors, our mixed-methods research focuses on situated trust, or trust that is shaped by people‚Äôs information-seeking and assessment practices through emerging information platforms (e.g., social media, crowdsourced systems, COVID data platforms). Our findings characterize the shifts in trustee (what/who people trust) from information on social media to the social media platform(s), how distrust manifests skepticism in issues of data discrepancy, the insufficient presentation of uncertainty, and how this trust and distrust shift over time. We highlight the deep challenges in existing information infrastructures that influence trust and distrust formation.",1068
983,Human-Centered Computing,Stacy C. Marsella,"May 3rd, 2021",A Computational Model of Coping for Simulating Human Behavior in High-Stress Situations,https://dl.acm.org/doi/10.5555/3463952.3464116," Nutchanon Yongsatianchot and Stacy Marsella. 2021. A Computational Model of Coping for Simulating Human Behavior in High-Stress Situations. In Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS '21). International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 1425‚Äì1433. doi:10.5555/3463952.3464116","People often encounter high-stress situations. Modeling and being able to predict people's behavior in such situations, how they cope, is a critical research topic. To that end, we propose a computational model of coping that casts Lazarus' theory of coping into a Partial Observable Markov Decision Process (POMDP) framework. This includes an appraisal process that models the factors that lead to stress by assessing a person's relation to the environment and a coping process that models people's behavior in the face of such stress. This coping process includes problem-focused coping, whereby people seek to alter the external environment, and emotion-focused coping, whereby people alter their internal beliefs, goals, and intentions in the face of stress. We evaluate the model's assumptions and predictions in the context of a high-stress situation that is increasingly common, the extreme conditions of a hurricane. We collected human survey data from the last several years of major U.S. hurricanes to evaluate the features in the models used for appraisal calculation. Additionally, we conducted a controlled human-subject experiment simulating a hurricane experience to investigate the prediction of the model on how people change their beliefs and goals to cope with the situation. The results show that, as predicted by the model, the proposed model features are significantly associated with the evacuation decisions and post-decision people also change their beliefs and goals in the directions that align with their prior decisions. Lastly, we conduct a simulation study showing that the proposed model is qualitatively closer to the experiment data than the baseline models that do not incorporate coping effects.",1069
984,Human-Centered Computing,Stacy C. Marsella,"March 6th, 2021",Training public speaking with virtual social interactions: effectiveness of real-time feedback and delayed feedback,https://doi.org/10.1007/s12193-021-00371-1," Mathieu Chollet, Stacy Marsella, Stefan Scherer. (2022). Training public speaking with virtual social interactions: effectiveness of real-time feedback and delayed feedback J. Multimodal User Interfaces, 16, 17-29. https://doi.org/10.1007/s12193-021-00371-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. 1201 Accesses",1070
985,Human-Centered Computing,Varun Mishra,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1071
986,Human-Centered Computing,Varun Mishra,"September 9th, 2024",Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment,https://doi.org/10.1145/3678584," Ha Le, Rithika Lakshminarayanan, Jixin Li, Varun Mishra , Stephen S. Intille. (2024). Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 111:1-111:35. https://doi.org/10.1145/3678584","ŒºEMA is a data collection method that prompts research participants with quick, answer-at-a-glance, single-multiple-choice self-report behavioral questions, thus enabling high-temporal-density self-report of up to four times per hour when implemented on a smartwatch. However, due to the small watch screen, ŒºEMA is better used to select among 2 to 5 multiple-choice answers versus allowing the collection of open-ended responses. We introduce an alternative and novel form of micro-interaction self-report using speech input - audio-ŒºEMA- where a short beep or vibration cues participants to verbally report their behavioral states, allowing for open-ended, temporally dense self-reports. We conducted a one-hour usability study followed by a within-subject, 6-day to 21-day free-living feasibility study in which participants self-reported their physical activities and postures once every 2 to 5 minutes. We qualitatively explored the usability of the system and identified factors impacting the response rates of this data collection method. Despite being interrupted 12 to 20 times per hour, participants in the free-living study were highly engaged with the system, with an average response rate of 67.7% for audio-ŒºEMA for up to 14 days. We discuss the factors that impacted feasibility; some implementation, methodological, and participant challenges we observed; and important considerations relevant to deploying audio-ŒºEMA in real-time activity recognition systems.",1072
987,Human-Centered Computing,Varun Mishra,"August 14th, 2024",Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices,https://doi.org/10.48550/arXiv.2408.07784," Jiachen Li, Justin Steinberg, Elizabeth D. Mynatt, Varun Mishra . (2024). Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices CoRR, abs/2408.07784. https://doi.org/10.48550/arXiv.2408.07784","Mental health has become a growing concern among university students. While medication is a common treatment, understanding how university students manage their medication for mental health symptoms in real-world practice has not been fully explored. In this study, we conducted semi-structured interviews with university students to understand the unique challenges in the mental health medication management process and their coping strategies, particularly examining the role of various technologies in this process. We discovered that due to struggles with self-acceptance and the interdependent relationship between medication, symptoms, schedules, and life changes, the medication management process for students was a highly dynamic journey involving frequent dosage changes. Thus, students adopted flexible strategies of using minimal technology to manage their medication in different situations while maintaining a high degree of autonomy. Based on our findings, we propose design implications for future technologies to seamlessly integrate into their daily lives and assist students in managing their mental health medications.",1073
988,Human-Centered Computing,Varun Mishra,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1074
989,Human-Centered Computing,Varun Mishra,"March 25th, 2024",Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic,https://doi.org/10.48550/arXiv.2403.17165," Jessilyn Dunn, Varun Mishra , Md. Mobashir Hasan Shandhi, Hayoung Jeong, Natasha Yamane, Yuna Watanabe, Bill Chen, Matthew S. Goodwin. (2024). Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic CoRR, abs/2403.17165. https://doi.org/10.48550/arXiv.2403.17165","Smartphones and wearable sensors offer an unprecedented ability to collect peripheral psychophysiological signals across diverse timescales, settings, populations, and modalities. However, open-source software development has yet to keep pace with rapid advancements in hardware technology and availability, creating an analytical barrier that limits the scientific usefulness of acquired data. We propose a community-driven, open-source peripheral psychophysiological signal pre-processing and analysis software framework that could advance biobehavioral health by enabling more robust, transparent, and reproducible inferences involving autonomic nervous system data.",1075
990,Human-Centered Computing,Varun Mishra,"March 11th, 2024",SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild,https://doi.org/10.1109/JIOT.2024.3375299," Kobiljon Toshnazarov, Uichin Lee, Byung Hyung Kim, Varun Mishra , Lismer Andres Caceres Najarro, Youngtae Noh. (2024). SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild IEEE Internet Things J., 11, 21527-21545. https://doi.org/10.1109/JIOT.2024.3375299","We propose SOSW, a comprehensive methodology for robust sensor data processing by considering both physiological and contextual data. SOSW employs a two-layer machine learning (ML) architecture. The results are comparable to those achieved by the state-of-the-art methods that rely on dedicated wearables. The study was published in IEEE Internet of Things Journal ( Volume: 11 , Issue: 12 , 15 June 2024 ) The results indicate that our methodology can successfully detect stressful events with an F-1 score of up to 0.84 in laboratory conditions.",1076
991,Human-Centered Computing,Varun Mishra,"January 16th, 2024",Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping,https://doi.org/10.1109/ACIIW59127.2023.10388164," Ohida Binte Amin, Varun Mishra , Aarti Sathyanarayana. (2023). Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping ACIIW, 1-4. https://doi.org/10.1109/ACIIW59127.2023.10388164","Depression is a prevalent mental health concern among students. Students with high neuroticism and increased depression exhibit greater variability in the number of social contacts. This may be because these students possess more emotional instability, self-esteem, and negative self-perception. Understanding the dynamic interplay between personality traits, social interactions, and depression can aid in developing targeted interventions to promote mental well-being for students.",1077
992,Human-Centered Computing,Varun Mishra,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1078
993,Human-Centered Computing,Varun Mishra,"August 5th, 2023",Detecting Receptivity for mHealth Interventions,https://doi.org/10.1145/3614214.3614221," Varun Mishra , Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, David Kotz. (2023). Detecting Receptivity for mHealth Interventions GetMobile Mob. Comput. Commun., 27, 23-28. https://doi.org/10.1145/3614214.3614221","Just-In-Time Adaptive Interventions (JITAI) have the potential to provide effective support for health behavior by delivering the right type and amount of intervention at the right time. The timing of interventions is crucial to ensure that users are receptive and able to use the support provided. Previous research has explored the association of context and user-specific traits on receptivity and built machine-learning models to detect receptivity after the study was completed. However, for effective intervention delivery, JITAI systems need to make in-the-moment decisions about a user's receptivity. In this study, we deployed machinelearning models in a chatbot-based digital coach to predict receptivity for physical-activity interventions. We included a static model that was built before the study and an adaptive model that continuously updated itself during the study. Compared to a control model that sent intervention messages randomly, the machine-learning models improved receptivity by up to 36%. Receptivity to messages from the adaptive model increased over time.",1079
994,Human-Centered Computing,Varun Mishra,"November 1st, 2021",FLIRT: A Feature Generation Toolkit for Wearable Data,https://www.sciencedirect.com/science/article/pii/S0169260721005356," F√∂ll, Simon, Martin Maritsch, Federica Spinola, Varun Mishra, Filipe Barata, Tobias Kowatsch, Elgar Fleisch, and Felix Wortmann. ""FLIRT: A Feature Generation Toolkit for Wearable Data."" Computer Methods and Programs in Biomedicine (2021): 106461.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1080
995,Human-Centered Computing,Varun Mishra,"September 24th, 2021",6th International Workshop on Mental Health and Well-being: Sensing and Intervention,https://doi.org/10.1145/3460418.3479264," Varun Mishra , Akane Sano, Sahiti Kunchay, Saeed Abdullah, Jakob E. Bardram, Elizabeth L. Murnane, Tanzeem Choudhury, Mirco Musolesi, Giovanna Nunes Vilaza, Rajalakshmi Nandakumar, Tauhidur Rahman. (2021). 6th International Workshop on Mental Health and Well-being: Sensing and Intervention UbiComp/ISWC Adjunct, 185-187. https://doi.org/10.1145/3460418.3479264","Mental health issues affect a significant portion of the world‚Äôs population and can result in debilitating and life-threatening outcomes. To address this increasingly pressing healthcare challenge, there is a need to research novel approaches for early detection and prevention. Toward this, ubiquitous systems can play a central role in revealing and tracking clinically relevant behaviors, contexts, and symptoms. Further, such systems can passively detect relapse onset and enable the opportune delivery of effective intervention strategies. However, despite their clear potential, the uptake of ubiquitous technologies into clinical mental healthcare is slow, and a number of challenges still face the overall efficacy of such technology-based solutions. The goal of this workshop is to bring together researchers interested in identifying, articulating, and addressing such issues and opportunities. Following the success of this workshop for the last five years, we aim to continue facilitating the UbiComp community in developing a holistic approach for sensing and intervention in the context of mental health.",1081
996,Human-Centered Computing,Varun Mishra,"March 29th, 2021",When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads,https://dl.acm.org/doi/abs/10.1145/3448116," Kevin Koch, Varun Mishra, Shu Liu, Thomas Berger, Elgar Fleisch, David Kotz, and Felix Wortmann. 2021. When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 1, Article 19 (March 2021), 30 pages. DOI:https://doi.org/10.1145/3448116","Recent developments of novel in-vehicle interventions show the potential to transform the otherwise routine and mundane task of commuting into opportunities to improve the drivers' health and well-being. Prior research has explored the effectiveness of various in-vehicle interventions and has identified moments in which drivers could be interruptible to interventions. All the previous studies, however, were conducted in either simulated or constrained real-world driving scenarios on a pre-determined route. In this paper, we take a step forward and evaluate when drivers interact with in-vehicle interventions in unconstrained free-living conditions. To this end, we conducted a two-month longitudinal study with 10 participants, in which each participant was provided with a study car for their daily driving needs. We delivered two in-vehicle interventions - each aimed at improving affective well-being - and simultaneously recorded the participants' driving behavior. In our analysis, we found that several pre-trip characteristics (like trip length, traffic flow, and vehicle occupancy) and the pre-trip affective state of the participants had significant associations with whether the participants started an intervention or canceled a started intervention. Next, we found that several in-the-moment driving characteristics (like current road type, past average speed, and future brake behavior) showed significant associations with drivers' responsiveness to the intervention. Further, we identified several driving behaviors that ""negated"" the effectiveness of interventions and highlight the potential of using such ""negative"" driving characteristics to better inform intervention delivery. Finally, we compared trips with and without intervention and found that both interventions employed in our study did not have a negative effect on driving behavior. Based on our analyses, we provide solid recommendations on how to deliver interventions to maximize responsiveness and effectiveness and minimize the burden on the drivers.",1082
997,Human-Centered Computing,Varun Mishra,"December 17th, 2020",Evaluating the Reproducibility of Physiological Stress Detection Models,https://dl.acm.org/doi/abs/10.1145/3432220," Varun Mishra, Sougata Sen, Grace Chen, Tian Hao, Jeffrey Rogers, Ching-Hua Chen, and David Kotz. 2020. Evaluating the Reproducibility of Physiological Stress Detection Models. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 4, Article 147 (December 2020), 29 pages. DOI:https://doi.org/10.1145/3432220","Recent advances in wearable sensor technologies have led to a variety of approaches for detecting physiological stress. Even with over a decade of research in the domain, there still exist many significant challenges, including a near-total lack of reproducibility across studies. Researchers often use some physiological sensors (custom-made or off-the-shelf), conduct a study to collect data, and build machine-learning models to detect stress. There is little effort to test the applicability of the model with similar physiological data collected from different devices, or the efficacy of the model on data collected from different studies, populations, or demographics. This paper takes the first step towards testing reproducibility and validity of methods and machine-learning models for stress detection. To this end, we analyzed data from 90 participants, from four independent controlled studies, using two different types of sensors, with different study protocols and research goals. We started by evaluating the performance of models built using data from one study and tested on data from other studies. Next, we evaluated new methods to improve the performance of stress-detection models and found that our methods led to a consistent increase in performance across all studies, irrespective of the device type, sensor type, or the type of stressor. Finally, we developed and evaluated a clustering approach to determine the stressed/not-stressed classification when applying models on data from different studies, and found that our approach performed better than selecting a threshold based on training data. This paper's thorough exploration of reproducibility in a controlled environment provides a critical foundation for deeper study of such methods, and is a prerequisite for tackling reproducibility in free-living conditions.",1083
998,Human-Centered Computing,Elizabeth Mynatt,"January 12th, 2025",A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place,https://doi.org/10.1145/3688828.3699640," Niharika Mathur, Tamara Zubatiy, Elizabeth D. Mynatt. (2025). A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place GROUP Companion, 48-53. https://doi.org/10.1145/3688828.3699640","Designing explainable and personalized AI systems to provide support to older adults aging in place requires an understanding of their motivations and expectations for the explanations. This poster presents our ongoing work in exploring explanation preferences within AI systems for older adults aging in place with their carepartners. We do so by leveraging the speculative and iterative benefits of the Research through Design (RtD) approach in HCI, and explore variations in explanation requirements for different users by understanding their needs, goals and motivations for the different sources of information within the home. We illustrate an example for employing a Research through Design inquiry for the design of AI applications, adopting speculative methods to probe into future possibilities of Explainable AI (XAI) using a human-centered design framework. Through a Speed Dating study and a Co-Design activity, we investigate different explanation types and scenarios and argue for a shift in the algorithmic focus of Explainable AI research toward user-centered requirements, positioning explanation as a collaborative process between AI systems and users.",1084
999,Human-Centered Computing,Elizabeth Mynatt,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1085
1000,Human-Centered Computing,Elizabeth Mynatt,"August 14th, 2024",Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices,https://doi.org/10.48550/arXiv.2408.07784," Jiachen Li, Justin Steinberg, Elizabeth D. Mynatt, Varun Mishra . (2024). Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices CoRR, abs/2408.07784. https://doi.org/10.48550/arXiv.2408.07784","Mental health has become a growing concern among university students. While medication is a common treatment, understanding how university students manage their medication for mental health symptoms in real-world practice has not been fully explored. In this study, we conducted semi-structured interviews with university students to understand the unique challenges in the mental health medication management process and their coping strategies, particularly examining the role of various technologies in this process. We discovered that due to struggles with self-acceptance and the interdependent relationship between medication, symptoms, schedules, and life changes, the medication management process for students was a highly dynamic journey involving frequent dosage changes. Thus, students adopted flexible strategies of using minimal technology to manage their medication in different situations while maintaining a high degree of autonomy. Based on our findings, we propose design implications for future technologies to seamlessly integrate into their daily lives and assist students in managing their mental health medications.",1086
1001,Human-Centered Computing,Elizabeth Mynatt,"July 7th, 2024",Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place,https://doi.org/10.48550/arXiv.2406.05111," Niharika Mathur, Tamara Zubatiy, Elizabeth D. Mynatt. (2024). Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place CoRR, abs/2406.05111. https://doi.org/10.48550/arXiv.2406.05111","As the permeability of AI systems in interpersonal domains like the home expands, their technical capabilities of generating explanations are required to be aligned with user expectations for transparency and reasoning. This paper presents insights from our ongoing work in understanding the effectiveness of explanations in Conversational AI systems for older adults aging in place and their family caregivers. We argue that in collaborative and multi-user environments like the home, AI systems will make recommendations based on a host of information sources to generate explanations. These sources may be more or less salient based on user mental models of the system and the specific task. We highlight the need for cross technological collaboration between AI systems and other available sources of information in the home to generate multiple explanations for a single user query. Through example scenarios in a caregiving home setting, this paper provides an initial framework for categorizing these sources and informing a potential design space for AI explanations surrounding everyday tasks in the home.",1087
1002,Human-Centered Computing,Elizabeth Mynatt,"February 23rd, 2024",AI-CARING: National AI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups,https://doi.org/10.1002/aaai.12162," Sonia Chernova, Elizabeth D. Mynatt, Agata Rozga, Reid G. Simmons, Holly A. Yanco. (2024). AI-CARING: National AI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups AI Mag., 45, 124-130. https://doi.org/10.1002/aaai.12162","Abstract Over 13 million Americans aged 65 and older are currently living with a diagnosis of mild cognitive impairment (MCI), a common precursor to dementia. These individuals largely rely on a network of informal caregivers‚Äîfamily, friends, and community members‚Äîwho work together with professional healthcare and social service providers to provide care and support in home settings. The AI-CARING Institute contributes foundational AI research focused on developing personalized collaborative AI systems that improve the quality of life and independence of aging adults living at¬†home. Abstract Over 13 million Americans aged 65 and older are currently living with a diagnosis of mild cognitive impairment (MCI), a common precursor to dementia. These individuals largely rely on a network of informal caregivers‚Äîfamily, friends, and community members‚Äîwho work together with professional healthcare and social service providers to provide care and support in home settings. The AI-CARING Institute contributes foundational AI research focused on developing personalized collaborative AI systems that improve the quality of life and independence of aging adults living at¬†home.",1088
1003,Human-Centered Computing,Elizabeth Mynatt,"November 25th, 2023",A Distributed Cognition Approach to Understanding Compensatory Calendaring Cognitive Systems of Older Adults with Mild Cognitive Impairment and Their Care Partners,https://doi.org/10.1007/978-3-031-48306-6_19," Tamara Zubatiy, Kayci L. Vickers, Jessica L. Saurman, Felicia Goldstein, Amy D. Rodriguez, Niharika Mathur, Elizabeth D. Mynatt. (2023). A Distributed Cognition Approach to Understanding Compensatory Calendaring Cognitive Systems of Older Adults with Mild Cognitive Impairment and Their Care Partners UCAmI (1), 190-201. https://doi.org/10.1007/978-3-031-48306-6_19","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1089
1004,Human-Centered Computing,Elizabeth Mynatt,"November 25th, 2023",‚ÄúWhy Did You Say That?‚Äù: Understanding Explainability in Conversational AI Systems for Older Adults with Mild Cognitive Impairment (MCI),https://doi.org/10.1007/978-3-031-48306-6_21," Niharika Mathur, Tamara Zubatiy, Agata Rozga, Elizabeth D. Mynatt. (2023). ""Why Did You Say That?"": Understanding Explainability in Conversational AI Systems for Older Adults with Mild Cognitive Impairment (MCI) UCAmI (1), 208-214. https://doi.org/10.1007/978-3-031-48306-6_21","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1090
1005,Human-Centered Computing,Elizabeth Mynatt,"October 9th, 2023","‚ÄúMango Mango, How to Let The Lettuce Dry Without A Spinner?‚Äù: Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner",https://doi.org/10.48550/arXiv.2310.05853," Szeyi Chan, Jiachen Li, Bingsheng Yao, Amama Mahmood, Chien-Ming Huang , Holly Jimison, Elizabeth D. Mynatt, Dakuo Wang. (2023). ""Mango Mango, How to Let The Lettuce Dry Without A Spinner?"": Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner CoRR, abs/2310.05853. https://doi.org/10.48550/arXiv.2310.05853","The rapid advancement of the Large Language Model (LLM) has created numerous potentials for integration with conversational assistants (CAs) assisting people in their daily tasks, particularly due to their extensive flexibility. However, users' real-world experiences interacting with these assistants remain unexplored. In this research, we chose cooking, a complex daily task, as a scenario to investigate people's successful and unsatisfactory experiences while receiving assistance from an LLM-based CA, Mango Mango. We discovered that participants value the system's ability to provide extensive information beyond the recipe, offer customized instructions based on context, and assist them in dynamically planning the task. However, they expect the system to be more adaptive to oral conversation and provide more suggestive responses to keep users actively involved. Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development.",1091
1006,Human-Centered Computing,Elizabeth Mynatt,"October 4th, 2023",‚ÄúI don‚Äôt know how to help with that‚Äù ‚Äì Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks,https://doi.org/10.1145/3610170," Tamara Zubatiy, Niharika Mathur, Larry Heck, Kayci L. Vickers, Agata Rozga, Elizabeth D. Mynatt. (2023). ""I don't know how to help with that"" - Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks Proc. ACM Hum. Comput. Interact., 7, 1-28. https://doi.org/10.1145/3610170","While commercial conversational agents (CA) (i.e. Google assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization and overall dialogue management that are amplified in care coordination settings. In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10 week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.",1092
1007,Human-Centered Computing,Elizabeth Mynatt,"October 4th, 2023",Privacy vs. Awareness: Relieving the Tension between Older Adults and Adult Children When Sharing In-home Activity Data,https://doi.org/10.1145/3610202," Jiachen Li, Bingrui Zong, Tingyu Cheng, Yunzhi Li, Elizabeth D. Mynatt, Ashutosh Dhekne. (2023). Privacy vs. Awareness: Relieving the Tension between Older Adults and Adult Children When Sharing In-home Activity Data Proc. ACM Hum. Comput. Interact., 7, 1-30. https://doi.org/10.1145/3610202","While aging adults frequently prefer to ""age in place"", their children can worry about their well-being, especially when they live at a distance. Many in-home systems are designed to monitor the real-time status of seniors at home and provide information to their adult children. However, we observed that the needs and concerns of both sides in the information sharing process are often not aligned. In this research, we examined the design of a system that mitigates the privacy needs of aging adults in light of the information desires of adult children. We apply an iterative process to design and evaluate a visualization of indoor location data and compare its benefits to displaying raw video from cameras. We elaborate on the tradeoffs surrounding privacy and awareness made by older adults and their children, and synthesize design criteria for designing a visualization system to manage these tensions and tradeoffs.",1093
1008,Human-Centered Computing,Elizabeth Mynatt,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1094
1009,Human-Centered Computing,Elizabeth Mynatt,"October 22nd, 2022",A Collaborative Approach to Support Medication Management in Older Adults with Mild Cognitive Impairment Using Conversational Assistants (CAs),https://doi.org/10.1145/3517428.3544830," Niharika Mathur, Kunal Dhodapkar, Tamara Zubatiy, Jiachen Li, Brian Jones, Elizabeth D. Mynatt. (2022). A Collaborative Approach to Support Medication Management in Older Adults with Mild Cognitive Impairment Using Conversational Assistants (CAs) ASSETS, 42:1-42:14. https://doi.org/10.1145/3517428.3544830","Improving medication management for older adults with Mild Cognitive Impairment (MCI) requires designing systems that support functional independence and provide compensatory strategies as their abilities change. Traditional medication management interventions emphasize forming new habits alongside the traditional path of learning to use new technologies. In this study, we navigate designing for older adults with gradual cognitive decline by creating a conversational ‚Äúcheck-in‚Äù system for routine medication management. We present the design of MATCHA - Medication Action To Check-In for Health Application, informed by exploratory focus groups and design sessions conducted with older adults with MCI and their caregivers, alongside our evaluation based on a two-phased deployment period of 20 weeks. Our results indicate that a conversational ‚Äúcheck-in‚Äù medication management assistant increased system acceptance while also potentially decreasing the likelihood of accidental over-medication, a common concern for older adults dealing with MCI.",1095
1010,Human-Centered Computing,Elizabeth Mynatt,"April 29th, 2022",Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education,https://doi.org/10.1145/3491102.3501824," Georgianna E. Lin, Elizabeth D. Mynatt, Neha Kumar. (2022). Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education CHI, 437:1-437:15. https://doi.org/10.1145/3491102.3501824","Human-Computer Interaction (HCI) research on menstrual tracking has emphasized the need for more inclusive design of mechanisms for tracking and sharing information on menstruation. We investigate menstrual tracking and data-sharing attitudes and practices in educated, young (20-30 years old) menstruating individuals based in the United States, with self-identified minimal menstrual education backgrounds. Using interviews (N=18), a survey (N=62), and participatory design (N=7), we find that existing mechanisms for tracking and sharing data on menstruation are not adequately responsive to the needs of those who seek relevant menstrual education, are not in the sexual majority, and/or wish to customize what menstrual data they share and with whom. Our analysis highlights a design gap for participants with minimal sexual education backgrounds who wish to better understand their cycles. We also contribute a deepened understanding of structural health inequities that impact menstrual tracking and sharing practices, making recommendations for technology-mediated menstrual care.",1096
1011,Human-Centered Computing,Elizabeth Mynatt,"January 14th, 2022",Pivoting an MCI Empowerment Program to Online Engagement,https://doi.org/10.1145/3492851," Elizabeth D. Mynatt, Kayci L. Vickers, Salimah LaForce, Sarah Farmer, Jeremy M. Johnson, Matthew Doiron, Aparna Ramesh, W. Bradley Fain, Tamara Zubatiy, Amy D. Rodriguez. (2022). Pivoting an MCI Empowerment Program to Online Engagement Proc. ACM Hum. Comput. Interact., 6, 32:1-32:26. https://doi.org/10.1145/3492851","In the Spring of 2020, closures and safe distancing orders swept much of the United States due to the COVID-19 pandemic. This paper presents a case study of pivoting an in-person empowerment program focused on lifestyle interventions for people newly diagnosed with Mild Cognitive Impairment (MCI) to an online program. Working as rapidly as possible to sustain participant engagement, our design decisions and subsequent iterations point to initial constraints in telehealth capabilities, as well as learning on the fly as new capabilities and requirements emerged. We present the discovery of emergent practices by family members and healthcare providers to meet the new requirements for successful online engagement. For some participants, the online program led to greater opportunities for empowerment while others were hampered by the lack of in-person program support. Providers experienced a sharp learning curve and likewise missed the benefits of in-person interaction, but also discovered new benefits of online collaboration. This work lends insights and potential new avenues for understanding how lifestyle interventions can empower people with MCI and the role of technology in that process.",1097
1012,Human-Centered Computing,Elizabeth Mynatt,"January 14th, 2022",Cultivating the Community: Inferring Influence within Eating Disorder Networks on Twitter,https://doi.org/10.1145/3492826," Fayika Farhat Nova, Amanda Coupe, Elizabeth D. Mynatt, Shion Guha, Jessica Pater. (2022). Cultivating the Community: Inferring Influence within Eating Disorder Networks on Twitter Proc. ACM Hum. Comput. Interact., 6, 7:1-7:33. https://doi.org/10.1145/3492826","A growing body of HCI research has sought to understand how online networks are utilized in the adoption and maintenance of disordered activities and behaviors associated with mental illness, including eating habits. However, individual-level influences over discrete online eating disorder (ED) communities are not yet well understood. This study reports results from a comprehensive network and content analysis (combining computational topic modeling and qualitative thematic analysis) of over 32,000 public tweets collected using popular ED-related hashtags during May 2020. Our findings indicate that this ED network in Twitter consists of multiple smaller ED communities where a majority of the nodes are exposed to unhealthy ED contents through retweeting certain influential central nodes. The emergence of novel linguistic indicators and trends (e.g., ""#meanspo"") also demonstrates the evolving nature of the ED network. This paper contextualizes ED influence in online communities through node-level participation and engagement, as well as relates emerging ED contents with established online behaviors, such as self-harassment.",1098
1013,Human-Centered Computing,Mahsan Nourani,"December 8th, 2023",Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models,https://doi.org/10.1145/3626961," Chiradeep Roy, Mahsan Nourani, Shivvrat Arya, Mahesh Shanbhag, Tahrima Rahman, Eric D. Ragan, Nicholas Ruozzi, Vibhav Gogate. (2023). Explainable Activity Recognition in Videos using Deep Learning and Tractable Probabilistic Models ACM Trans. Interact. Intell. Syst., 13, 29:1-29:32. https://doi.org/10.1145/3626961","We consider the following video activity recognition (VAR) task: given a video, infer the set of activities being performed in the video and assign each frame to an activity. Although VAR can be solved accurately using existing deep learning techniques, deep networks are neither interpretable nor explainable and as a result their use is problematic in high stakes decision-making applications (in healthcare, experimental Biology, aviation, law, etc.). In such applications, failure may lead to disastrous consequences and therefore it is necessary that the user is able to either understand the inner workings of the model or probe it to understand its reasoning patterns for a given decision. We address these limitations of deep networks by proposing a new approach that feeds the output of a deep model into a tractable, interpretable probabilistic model called a dynamic conditional cutset network that is defined over the explanatory and output variables and then performing joint inference over the combined model. The two key benefits of using cutset networks are: (a) they explicitly model the relationship between the output and explanatory variables and as a result, the combined model is likely to be more accurate than the vanilla deep model and (b) they can answer reasoning queries in polynomial time and as a result, they can derive meaningful explanations by efficiently answering explanation queries. We demonstrate the efficacy of our approach on two datasets, Textually Annotated Cooking Scenes (TACoS), and wet lab, using conventional evaluation measures such as the Jaccard Index and Hamming Loss, as well as a human-subjects study.",1099
1014,Human-Centered Computing,Mahsan Nourani,"March 17th, 2023",An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality,https://doi.org/10.1109/TVCG.2023.3258693," Brett Benda, Shyam Prathish Sargunam, Mahsan Nourani, Eric D. Ragan. (2024). An Evaluation of View Rotation Techniques for Seated Navigation in Virtual Reality IEEE Trans. Vis. Comput. Graph., 30, 4257-4270. https://doi.org/10.1109/TVCG.2023.3258693","Head tracking is commonly used in VR applications to allow users to naturally view 3D content using physical head movement. Controller and joystick controls are convenient for practical settings where full 360-degree physical rotation is not possible, such as when the user is sitting at a desk. Previous research has demonstrated that virtual or joystick-controlled view rotation to have drawbacks of sickness and disorientation compared to physical turning. Our findings indicate a preference by users towards directly-manipulated joystick-based rotations compared to user-initiated resetting and minimal effects of technique on spatial awareness.",1100
1015,Human-Centered Computing,Mahsan Nourani,"December 12th, 2022",On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications,https://doi.org/10.1145/3531066," Mahsan Nourani, Chiradeep Roy, Jeremy E. Block, Donald R. Honeycutt, Tahrima Rahman, Eric D. Ragan, Vibhav Gogate. (2022). On the Importance of User Backgrounds and Impressions: Lessons Learned from Interactive AI Applications ACM Trans. Interact. Intell. Syst., 12, 28:1-28:29. https://doi.org/10.1145/3531066","While EXplainable Artificial Intelligence (XAI) approaches aim to improve human-AI collaborative decision-making by improving model transparency and mental model formations, experiential factors associated with human users can cause challenges in ways system designers do not anticipate. In this article, we first showcase a user study on how anchoring bias can potentially affect mental model formations when users initially interact with an intelligent system and the role of explanations in addressing this bias. Using a video activity recognition tool in cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. However, those who encountered weaknesses earlier made significantly fewer errors, since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Motivated by these findings and similar existing work, we formalize and present a conceptual model of user‚Äôs past experiences that examine the relations between user‚Äôs backgrounds, experiences, and human factors in XAI systems based on usage time. Our work presents strong findings and implications, aiming to raise the awareness of AI designers toward biases associated with user impressions and backgrounds.",1101
1016,Human-Centered Computing,Mahsan Nourani,"August 24th, 2022",DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification,https://doi.org/10.1109/MCG.2022.3201465," Mahsan Nourani, Chiradeep Roy, Donald R. Honeycutt, Eric D. Ragan, Vibhav Gogate. (2022). DETOXER: A Visual Debugging Tool With Multiscope Explanations for Temporal Multilabel Classification IEEE Computer Graphics and Applications, 42, 37-46. https://doi.org/10.1109/MCG.2022.3201465"," Debugging some models, such as temporal multilabel classification (TMLC), can be especially more challenging due to the complexity of the analysis. We propose DETOXER, an interactive visual debugging system to support finding different error types and scopes through providing multiscope explanations.",1102
1017,Human-Centered Computing,Lace Padilla,"September 10th, 2024",Impact of Vertical Scaling on Normal Probability Density Function Plots,https://doi.org/10.1109/TVCG.2024.3456396," Racquel Fygenson, Lace M. K. Padilla. (2025). Impact of Vertical Scaling on Normal Probability Density Function Plots IEEE Trans. Vis. Comput. Graph., 31, 984-994. https://doi.org/10.1109/TVCG.2024.3456396","Keeping vertical scaling consistent, and therefore maintaining equal pixel areas under PDF curves, results in the highest likelihood of accurate comparisons. Findings provide insights into the impact of vertical scaled on PDFs, and reveal the complicated nature of proportional area comparisons. In some contexts, we find including a y-axis can help reduce this effect. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the paper, you can download your copy of the IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 1 , January 2025 ) for free. The paper is available to download now for free by clicking here.",1103
1018,Human-Centered Computing,Lace Padilla,"September 9th, 2024","Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations",https://doi.org/10.1109/TVCG.2024.3456344," Anjana Arunkumar, Lace M. K. Padilla, Chris Bryan. (2025). Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations IEEE Trans. Vis. Comput. Graph., 31, 1169-1179. https://doi.org/10.1109/TVCG.2024.3456344","Mind wandering is a phenomenon where attention spontaneously shifts from a primary task to internal, task-related thoughts or unrelated distractions. Results show that mind wandering negatively affects short-term visualization recall, particularly for visualizations with little text annotation. Mind wandering also functions as an intermediate process linking visualization design elements to post-viewing measures, influencing how viewers engage with and interpret visual information over time. Overall, this research underscores the importance of incorporating mind wandering as aynamic measure in visualization design and evaluation, offering novel avenues for enhancing user engagement and comprehension.",1104
1019,Human-Centered Computing,Lace Padilla,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1105
1020,Human-Centered Computing,Lace Padilla,"March 4th, 2024",Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs,https://doi.org/10.1109/TVCG.2024.3372620," Helia Hosseinpour, Laura E. Matzen, Kristin M. Divis, Spencer C. Castro, Lace M. K. Padilla. (2025). Examining Limits of Small Multiples: Frame Quantity Impacts Judgments With Line Graphs IEEE Trans. Vis. Comput. Graph., 31, 1875-1887. https://doi.org/10.1109/TVCG.2024.3372620","Small multiples are a popular visualization method, displaying different views of a dataset using multiple frames, often with the same scale and axes. We found a linear decline in accuracy with increasing frames across seven tasks, which was not fully explained by differences in frame size. highlighting specific frames can mitigate some visual search difficulties but, surprisingly, not eliminate them. This research offers insights into optimizing the utility of small multiples by aligning them with human limitations. It was published in: IEEE Transactions on Visualization and Computer Graphics ( Volume: 31 , Issue: 3 , March 2025 ) and will be published in the next issue of the journal.",1106
1021,Human-Centered Computing,Lace Padilla,"October 23rd, 2023",Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,https://doi.org/10.1109/TVCG.2023.3326589," Dominik Moritz, Lace M. K. Padilla, Francis Nguyen, Steven L. Franconeri. (2024). Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability IEEE Trans. Vis. Comput. Graph., 30, 306-315. https://doi.org/10.1109/TVCG.2023.3326589","Bias might arise because higher variability leads to stronger weighting in the average calculation. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders. The study was published in IEEE Transactions on Visualization and Computer Graphics ( Volume: 30, Issue: 1, January 2024) We found this effect across two preregistered experiments with 140 and 420 participants. We can model the bias with the average of the data series and theAverage of the points drawn along the line.",1107
1022,Human-Centered Computing,Lace Padilla,"January 1st, 2023",Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations,https://doi.org/10.1109/TVCG.2022.3209457," Lace M. K. Padilla, Racquel Fygenson, Spencer C. Castro, Enrico Bertini. (2023). Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations IEEE Trans. Vis. Comput. Graph., 29, 12-22. https://doi.org/10.1109/TVCG.2022.3209457","The prevalence of inadequate SARS-COV-2 (COVID-19) responses may indicate a lack of trust in forecasts and risk communication. No work has empirically tested how multiple forecast visualization choices impact trust and task-based performance. The studies reveal that trust in. CO VID-19 forecast visualizations initially increases with the number of forecasts and then plateaus after. 6‚Äì9 forecasts. Participants were most trusting of visualizations that showed less visual information, including a 95% confidence. interval, single forecast, and grayscale encoded forecasts. was the most likely to evoke predictions that did not correspond with the actual CO VID -19 trend.",1108
1023,Human-Centered Computing,Rupal Patel,"October 13th, 2018",The Prosodic Marionette: A method to visualize speech prosody and assess perceptual and expressive prosodic abilities,https://doi.org/10.1016/j.specom.2018.09.009," Jonathan S. Brumberg, Jill C. Thorson, Rupal Patel. (2018). The Prosodic Marionette: A method to visualize speech prosody and assess perceptual and expressive prosodic abilities Speech Commun., 104, 95-105. https://doi.org/10.1016/j.specom.2018.09.009","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1109
1024,Human-Centered Computing,Rupal Patel,"September 6th, 2018","Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data",https://doi.org/10.21437/Interspeech.2018-1316," Markus Toman, Geoffrey S. Meltzner, Rupal Patel. (2018). Data Requirements, Selection and Augmentation for DNN-based Speech Synthesis from Crowdsourced Data INTERSPEECH, 2878-2882. https://doi.org/10.21437/Interspeech.2018-1316","Crowdsourcing speech recordings provides unique opportunities and challenges for personalized speech synthesis as it allows gathering of large quantities of data but with a huge variety in quality. Manual methods for data selection and cleaning quickly become infeasible, especially when producing larger quantities of voices. We present and analyze approaches for data selection and augmentation to cope with this. For differently-sized training sets, we assess speaker adaptation by transfer learning, including layer freezing and sentence selection using maximum likelihood of forced alignment. The methodological framework utilizes statistical parametric speech synthesis based on Deep Neural Networks (DNNs). We compare objective scores for 576 voice models, representing all condition combinations. For a constrained set of conditions we also present results from a subjective listening test. We show that speaker adaptation improves overall quality in nearly all cases, sentence selection helps detecting recording errors and layer freezing proves to be ineffective in our system. We also found that while Mel-Cepstral Distortion (MCD) does not correlate with listener preference across the range of values, the most preferred voices also exhibited the lowest values for MCD. These findings have implications on scalable methods of customized voice building and clinical applications with sparse data.",1110
1025,Human-Centered Computing,Herman Saksono,"August 30th, 2024",Socio-Cognitive Framework for Personal Informatics: A Preliminary Framework for Socially-Enabled Health Technologies,https://doi.org/10.1145/3674504," Herman Saksono, Andrea G. Parker. (2024). Socio-Cognitive Framework for Personal Informatics: A Preliminary Framework for Socially-Enabled Health Technologies ACM Trans. Comput. Hum. Interact., 31, 42:1-42:41. https://doi.org/10.1145/3674504","Personal health informatics systems have been centered around individual efforts, overlooking the role of social factors in health. Over seven years of research ( n = 153), we examined how socially-enabled personal informatics systems can support physical activity‚Äîa behavior critical in promoting physical and mental health. We prioritized exploring this topic with families in low-socioeconomic status (SES) neighborhoods because they face increased barriers to being active due to inequities. Through our systems development, qualitative studies, and theoretical foundation, we developed the Socio-Cognitive Framework for Personal Health Informatics systems that shows how five socio-cognitive concepts (aspirations, data exposure, stories, belongingness, and impediments) influence self-efficacy and outcome expectations that are linked to health behavior. We then provide recommendations on how to design and evaluate such systems. We further argue that socially-enabled health informatics tools can support marginalized communities in reducing health disparities through the collective efforts of families, neighbors, and peers.",1111
1026,Human-Centered Computing,Herman Saksono,"May 1st, 2021",StoryMap: Using Social Modeling and Self-Modeling to Support Physical Activity Among Families of Low-SES Backgrounds,https://dl.acm.org/doi/10.1145/3411764.3445087," Herman Saksono, Carmen Castaneda-Sceppa, Jessica A. Hoffman, Magy Seif El-Nasr, and Andrea Parker. 2021. StoryMap: Using Social Modeling and Self-Modeling to Support Physical Activity Among Families of Low-SES Backgrounds. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 203, 1‚Äì14. https://doi.org/10.1145/3411764.3445087","Physical activity (PA) is crucial for reducing the risk of obesity, an epidemic that disproportionately burdens families of low-socioeconomic status (SES). While fitness tracking tools can increase PA awareness, more work is needed to examine (1) how such tools can help people benefit from their social environment, and (2) how reflections can help enhance PA attitudes. We investigated how fitness tracking tools for families can support social modeling and self-modeling (through reflection), two critical processes in Social Cognitive Theory. We developed StoryMap, a novel fitness tracking app for families aimed at supporting both modes of modeling. Then, we conducted a five-week qualitative study evaluating StoryMap with 16 low-SES families. Our findings contribute an understanding of how social and self-modeling can be implemented in fitness tracking tools and how both modes of modeling can enhance key PA attitudes: self-efficacy and outcome expectations. Finally, we propose design recommendations for social personal informatics tools.",1112
1027,Human-Centered Computing,Herman Saksono,"October 15th, 2020",Go&Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia,https://doi.org/10.1145/3415222," Xin Yao Lin, Herman Saksono, Elizabeth Stowell, Margie E. Lachman, Carmen Castaneda-Sceppa, Andrea G. Parker. (2020). Go&Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia Proc. ACM Hum. Comput. Interact., 4, 151:1-151:28. https://doi.org/10.1145/3415222","Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.",1113
1028,Human-Centered Computing,Herman Saksono,"April 1st, 2020",Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection,https://dl.acm.org/doi/abs/10.1145/3313831.3376686," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Vivien Morris, Magy Seif El-Nasr, and Andrea G. Parker. 2020. Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). Association for Computing Machinery, New York, NY, USA, 1‚Äì13. https://doi.org/10.1145/3313831.3376686","Physical activity (PA) is critical for reducing the risk of obesity, a prevalent health concern that burdens low-socioeconomic status (SES) households. While self-tracking apps can increase PA, encouraging app engagement remains a challenge, thus limiting the app's efficacy. To understand how to better support caregiver's motivation to use family health apps, we designed and evaluated Storywell?a mobile app for promoting family PA. Guided by Self-Determination Theory, Storywell provides social rewards (e.g., storybooks with interactive reflective questions) aimed at supporting relatedness and motivation. Our 3-month qualitative study with 18 families revealed satisfying moments that can affect caregiver's motivation. We contribute new knowledge on designing satisfying moments that heighten the motivation to use health apps, especially for low-SES families who face many barriers to using such systems.",1114
1029,Human-Centered Computing,Herman Saksono,"August 5th, 2019",Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,https://doi.org/10.1145/3290605.3300543," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Magy Seif El-Nasr, Vivien Morris, and Andrea G. Parker. 2019. Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19). ACM, New York, NY, USA, Paper 313, 14 pages. DOI","Wearable activity trackers can encourage physical activity (PA)-a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active-wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data.",1115
1030,Human-Centered Computing,Herman Saksono,"July 24th, 2018",Family Health Promotion in Low-SES Neighborhoods: A Two-Month Study of Wearable Activity Tracking,https://dl.acm.org/citation.cfm?id=3173883," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Magy Seif El-Nasr, Vivien Morris, Andrea G. Parker. 2018. Family Health Promotion in Low-SES Neighborhoods: A Two-Month Study of Wearable Activity Tracking. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Low-socioeconomic status (SES) families face increased barriers to physical activity (PA)-a behavior critical for reducing and preventing chronic disease. Research has explored how wearable PA trackers can encourage increased activity, and how the adoption of such trackers is driven by people's emotions and social needs. However, more work is needed to understand how PA trackers are perceived and adopted by low-SES families, where PA may be deprioritized due to economic stresses, limited resources, and perceived crime. Accordingly, we conducted a two-month, in-depth qualitative study, exploring low-SES caregivers' perspectives on PA tracking and promotion. Our findings show how PA tracking was impacted by caregivers' attitudes toward safety, which were influenced by how they perceived social connections within their neighborhoods; and cognitive-emotional processes. We conclude that PA tracking tools for low-SES families should help caregivers and children to experience and celebrate progress.",1116
1031,Human-Centered Computing,Herman Saksono,"July 24th, 2018",Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review,https://dl.acm.org/citation.cfm?id=3173589," Elizabeth Stowell, Mercedes C. Lyson, Herman Saksono, Rene√© C. Wurth, Holly Jimison, Misha Pavel, Andrea G. Parker. 2018. Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Diverse disciplines, including Human-Computer Interaction have explored how mobile health (mHealth) applications can transform healthcare and health promotion. Increasingly, research has explored how mHealth tools can promote healthy behaviors within vulnerable populations-groups that disproportionately experience barriers to wellness. We conducted a systematic review of 83 papers from diverse disciplines to characterize the design and impact of mHealth tools in low-socioeconomic (low-SES) and racial/ethnic minority individuals. Our findings highlight that the diversity within low-SES and racial/ethnic minority groups was not reflected in the populations studied. Most studies focused on improving the health of individuals, often neglecting factors at the community and society levels that influence health disparities. Moreover, few improvements in health outcomes were demonstrated. We further discuss factors that acted as barriers and facilitators of mHealth intervention adoption. Our findings highlight trends that can drive critically needed digital health innovations for vulnerable populations.",1117
1032,Human-Centered Computing,Herman Saksono,"May 6th, 2017",Reflective Informatics Through Family Storytelling: Self-discovering Physical Activity Predictors,http://doi.org/10.1145/3025453.3025651," Herman Saksono and Andrea Grimes Parker. 2017. Reflective Informatics Through Family Storytelling: Self-discovering Physical Activity Predictors. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ‚Äô17, ACM.","HCI research has increasingly examined how sensing technologies can help people capture and visualize data about their health-related behaviors. Yet, few systems help people reflect more fundamentally on the factors that influence behaviors such as physical activity (PA). To address this research gap, we take a novel approach, examining how such reflections can be stimulated through a medium that generations of families have used for reflection and teaching: storytelling. Through observations and interviews, we studied how 13 families interacted with a low-fidelity prototype, and their attitudes towards this tool. Our prototype used storytelling and interactive prompts to scaffold reflection on factors that impact children's PA. We contribute to HCI research by characterizing how families interacted with a story-driven reflection tool, and how such a tool can encourage critical processes for behavior change. Informed by the Transtheoretical Model, we present design implications for reflective informatics systems.",1118
1033,Human-Centered Computing,Herman Saksono,"May 7th, 2016",Youth Advocacy in SNAs: Challenges for Addressing Health Disparities,https://dl.acm.org/citation.cfm?id=2858492," Farnaz Irannejad Bisafar, Herman Saksono, Priscilla Baquerizo, Dana Moore, and Andrea G Parker. 2016. Youth Advocacy in SNAs: Challenges for Addressing Health Disparities. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ‚Äô16: 3620‚Äì3624.","Social networking applications (SNAs) have been touted as promising platforms for activism: they provide a platform by which voices can be heard and collective action mobilized. Yet, little work has studied the suitability of existing SNAs for enabling youth advocacy efforts. We conducted an intensive 5-week qualitative study with 10th graders to understand how existing SNAs support and inhibit youth advocacy. We contribute to the field of Human-Computer Interaction (HCI) by explicating several themes regarding the barriers youth face when using SNAs for advocacy, features in existing SNAs that are not suitable for youth advocacy, and the peer pressure youth perceive when advocating for serious issues in these environments. We conclude with recommendations for how existing SNA features could be reformed to better support youth advocacy.",1119
1034,Human-Centered Computing,Herman Saksono,"February 28th, 2015",Spaceship Launch: Designing a Collaborative Exergame for Families,http://dl.acm.org/citation.cfm?id=2675159&dl=ACM&coll=DL," Saksono, H., Ranade, A., Kamarthi, G., Castaneda-Sceppa, C., Hoffman, J.A., Wirth, C. and Parker, A.G., ""Spaceship Launch: Designing a Collaborative Exergame for Families,"" Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing (2015), 1776-1787.","Parents play a critical role in facilitating children's physical activity, as they are an important source of modeling and support. While Human-Computer Interaction (HCI) researchers have explored exergame design for children or adults separately, an important open area of work is identifying design guidelines for family exergames. One question that researchers have increasingly posed is, how can exergames be designed to avoid potential negative consequences of competition? To address these questions we designed Spaceship Launch, an exergame for parents and kids in lower income neighborhoods, where obesity is most prevalent. We describe our iterative design process: the formative study to identify design opportunities, our resulting system, and our field evaluation of the tool. Our findings highlight the impact of SL on physical activity intentions, and how parental preferences for in-game competition were aligned with the psychological needs of relatedness and competence. We conclude with design recommendations for future family-focused exergames.",1120
1035,Human-Centered Computing,Saiph Savage,"January 13th, 2025",Data Enrichment Work and AI Labor in Latin America and the Caribbean,https://doi.org/10.48550/arXiv.2501.06981," Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage. (2025). Data Enrichment Work and AI Labor in Latin America and the Caribbean CoRR, abs/2501.06981. https://doi.org/10.48550/arXiv.2501.06981","The global AI surge demands crowdworkers from diverse languages and cultures. They are pivotal in labeling data for enabling global AI systems. Despite global significance, research has primarily focused on understanding the perspectives and experiences of US and India crowdworkers, leaving a notable gap. To bridge this, we conducted a survey with 100 crowdworkers across 16 Latin American and Caribbean countries. We discovered that these workers exhibited pride and respect for their digital labor, with strong support and admiration from their families. Notably, crowd work was also seen as a stepping stone to financial and professional independence. Surprisingly, despite wanting more connection, these workers also felt isolated from peers and doubtful of others' labor quality. They resisted collaboration and gender-based tools, valuing gender-neutrality. Our work advances HCI understanding of Latin American and Caribbean crowdwork, offering insights for digital resistance tools for the region.",1121
1036,Human-Centered Computing,Saiph Savage,"November 8th, 2024",A Culturally-Aware AI Tool for Crowdworkers: Leveraging Chronemics to Support Diverse Work Styles,https://doi.org/10.1145/3686899," Carlos Toxtli, Christopher Curtis, Saiph Savage. (2024). A Culturally-Aware AI Tool for Crowdworkers: Leveraging Chronemics to Support Diverse Work Styles Proc. ACM Hum. Comput. Interact., 8, 1-34. https://doi.org/10.1145/3686899","Crowdsourcing markets are expanding worldwide, but often feature standardized interfaces that ignore the cultural diversity of their workers, negatively impacting their well-being and productivity. To transform these workplace dynamics, this paper proposes creating culturally-aware workplace tools, specifically designed to adapt to the cultural dimensions of monochronic and polychronic work styles. We illustrate this approach with ""CultureFit,"" a tool that we engineered based on extensive research in Chronemics and culture theories. To study and evaluate our tool in the real world, we conducted a field experiment with 55 workers from 24 different countries. Our field experiment revealed that CultureFit significantly improved the earnings of workers from cultural backgrounds often overlooked in design. Our study is among the pioneering efforts to examine culturally aware digital labor interventions. It also provides access to a dataset with over two million data points on culture and digital work, which can be leveraged for future research in this emerging field. The paper concludes by discussing the importance and future possibilities of incorporating cultural insights into the design of tools for digital labor.",1122
1037,Human-Centered Computing,Saiph Savage,"May 11th, 2024",Designing Gig Worker Sousveillance Tools,https://doi.org/10.1145/3613904.3642614," Kimberly Do, Maya De Los Santos, Michael Muller, Saiph Savage. (2024). Designing Gig Worker Sousveillance Tools CHI, 384:1-384:19. https://doi.org/10.1145/3613904.3642614","As independently-contracted employees, gig workers disproportionately suffer the consequences of workplace surveillance, which include increased pressures to work, breaches of privacy, and decreased digital autonomy. Despite the negative impacts of workplace surveillance, gig workers lack the tools, strategies, and workplace social support to protect themselves against these harms. Meanwhile, some critical theorists have proposed sousveillance as a potential means of countering such abuses of power, whereby those under surveillance monitor those in positions of authority (e.g., gig workers collect data about requesters/platforms). To understand the benefits of sousveillance systems in the gig economy, we conducted semi-structured interviews and led co-design activities with gig workers. We use ‚Äúcare ethics‚Äù as a guiding concept to understand our interview and co-design data, while also focusing on empathic sousveillance technology design recommendations. Through our study we identify gig workers‚Äô attitudes towards and past experiences with sousveillance. We also uncover the type of sousveillance technologies imagined by workers, provide design recommendations, and finish by discussing how to create empowering, empathic spaces on gig platforms.",1123
1038,Human-Centered Computing,Saiph Savage,"March 4th, 2024",Unveiling AI-Driven Collective Action for a Worker-Centric Future,https://doi.org/10.1145/3616855.3637633," Saiph Savage. (2024). Unveiling AI-Driven Collective Action for a Worker-Centric Future WSDM, 6-7. https://doi.org/10.1145/3616855.3637633","Gig knowledge workers are a potent method for enhancing labor conditions on platforms like Upwork, Amazon Mechanical Turk, and Toloka. Existing systems for supporting collective action are inadequate for workers to identify and understand their different workplace problems, plan effective solutions, and put the solutions into action. Building solid AI enhanced technologies to enable gig worker collective action will pave the way for a fair and ethical gig economy.",1124
1039,Human-Centered Computing,Saiph Savage,"February 20th, 2024","Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning",https://doi.org/10.48550/arXiv.2402.12667," Derek Jacoby, Saiph Savage, Yvonne Coady. (2024). Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning CoRR, abs/2402.12667. https://doi.org/10.48550/arXiv.2402.12667","Increasing diversity in educational settings is challenging in part due to the lack of access to resources for non-traditional learners in remote communities. Post-pandemic platforms designed specifically for remote and hybrid learning -- supporting team-based collaboration online -- are positioned to bridge this gap. Our work combines the use of these new platforms with co-creation and collaboration tools for AI assisted remote Work-Integrated-Learning (WIL) opportunities, including efforts in community and with the public library system. This paper outlines some of our experiences to date, and proposes methods to further integrate AI education into community-driven applications for remote WIL.",1125
1040,Human-Centered Computing,Saiph Savage,"April 12th, 2023",Why Do We Need to Learn about Citational Practices? Recognizing Knowledge Production from the Global Souths and Beyond,https://doi.org/10.1145/3589256," Amy Ogan, Frederick M. C. van Amstel, Gabriela Molina Le√≥n, Juan Fernando Maestre, Kristin Williams, Nicola J. Bidwell, Pedro Reynolds-Cu√©llar, Saiph Savage, Sushil K. Oswal, Vishal Sharma. (2023). Why Do We Need to Learn about Citational Practices? Recognizing Knowledge Production from the Global Souths and Beyond XRDS, 29, 12-17. https://doi.org/10.1145/3589256","How do you decide which papers to cite, how many, and from which particular sources? We reflect and discuss the implications of these critical questions based on our experiences in the panel and workshops on the topic of citational justice that took place at CSCW, CLIHC, and India HCI in 2021.",1126
1041,Human-Centered Computing,Saiph Savage,"February 27th, 2023",4th Crowd Science Workshop ‚Äì CANDLE: Collaboration of Humans and Learning Algorithms for Data Labeling,https://doi.org/10.1145/3539597.3572703," Dmitry Ustalov, Saiph Savage, Niels van Berkel, Yang Liu. (2023). 4th Crowd Science Workshop - CANDLE: Collaboration of Humans and Learning Algorithms for Data Labeling WSDM, 1268. https://doi.org/10.1145/3539597.3572703","Crowdsourcing has been used to produce impactful and large-scale datasets for Machine Learning and Artificial Intelligence (AI), such as ImageNET, SuperGLUE, etc. Since the rise of crowdsourcing in early 2000s, the AI community has been studying its computational, system design, and data-centric aspects at various angles. We welcome the studies on developing and enhancing of crowdworker-centric tools, that offer task matching, requester assessment, instruction validation, among other topics. We are also interested in exploring methods that leverage the integration of crowdworkers to improve the recognition and performance of the machine learning models. Thus, we invite studies that focus on shipping active learning techniques, methods for joint learning from noisy data and from crowds, novel approaches for crowd-computer interaction, repetitive task automation, and role separation between humans and machines. Moreover, we invite works on designing and applying such techniques in various domains, including e-commerce and medicine.",1127
1042,Human-Centered Computing,Saiph Savage,"November 11th, 2022",Datavoidant: An AI System for Addressing Political Data Voids on Social Media,https://doi.org/10.1145/3555616," Claudia Flores-Saviaga, Shangbin Feng, Saiph Savage. (2022). Datavoidant: An AI System for Addressing Political Data Voids on Social Media Proc. ACM Hum. Comput. Interact., 6, 1-29. https://doi.org/10.1145/3555616","The limited information (data voids) on political topics relevant to underrepresented communities has facilitated the spread of disinformation. Independent journalists who combat disinformation in underrepresented communities have reported feeling overwhelmed because they lack the tools necessary to make sense of the information they monitor and address the data voids. In this paper, we present a system to identify and address political data voids within underrepresented communities. Armed with an interview study, indicating that the independent news media has the potential to address them, we designed an intelligent collaborative system, called Datavoidant. Datavoidant uses state-of-the-art machine learning models and introduces a novel design space to provide independent journalists with a collective understanding of data voids to facilitate generating content to cover the voids. We performed a user interface evaluation with independent news media journalists (N=22). These journalists reported that Datavoidant's features allowed them to more rapidly while easily having a sense of what was taking place in the information ecosystem to address the data voids. They also reported feeling more confident about the content they created and the unique perspectives they had proposed to cover the voids. We conclude by discussing how Datavoidant enables a new design space wherein individuals can collaborate to make sense of their information ecosystem and actively devise strategies to prevent disinformation.",1128
1043,Human-Centered Computing,Saiph Savage,"October 22nd, 2022",The Global Care Ecosystems of 3D Printed Assistive Devices,https://doi.org/10.1145/3537676," Saiph Savage, Claudia Flores-Saviaga, Rachel Rodney, Liliana Savage, Jon Schull, Jennifer Mankoff. (2022). The Global Care Ecosystems of 3D Printed Assistive Devices ACM Trans. Access. Comput., 15, 31:1-31:29. https://doi.org/10.1145/3537676","The popularity of 3D printed assistive technology has led to the emergence of new ecosystems of care, where multiple stakeholders (makers, clinicians, and recipients with disabilities) work toward creating new upper limb prosthetic devices. However, despite the increasing growth, we currently know little about the differences between these care ecosystems. Medical regulations and the prevailing culture have greatly impacted how ecosystems are structured and stakeholders work together, including whether clinicians and makers collaborate. To better understand these care ecosystems, we interviewed a range of stakeholders from multiple countries, including Brazil, Chile, Costa Rica, France, India, Mexico, and the U.S. Our broad analysis allowed us to uncover different working examples of how multiple stakeholders collaborate within these care ecosystems and the main challenges they face. Through our study, we were able to uncover that ecosystems with multi-stakeholder collaborations exist (something prior work had not seen), and these ecosystems showed increased success and impact. We also identified some of the key follow-up practices to reduce device abandonment. Of particular importance are to have ecosystems put in place follow-up practices that integrate formal agreements and compensations for participation (which do not need to be just monetary). We identified that these features helped to ensure multi-stakeholder involvement and ecosystem sustainability. We finished the article with socio-technical recommendations to create vibrant care ecosystems that include multiple stakeholders in the production of 3D printed assistive devices.",1129
1044,Human-Centered Computing,Saiph Savage,"April 28th, 2022",REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration,https://doi.org/10.1145/3491101.3503725," Andy Alorwu, Saiph Savage, Niels van Berkel, Dmitry Ustalov, Alexey Drutsa, Jonas Oppenlaender, Oliver Bates, Danula Hettiachchi, Ujwal Gadiraju, Jorge Gon√ßalves , Simo Hosio. (2022). REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration CHI Extended Abstracts, 88:1-88:7. https://doi.org/10.1145/3491101.3503725","Crowdworkers silently enable much of today‚Äôs AI-based products, with several online platforms offering a myriad of data labelling and content moderation tasks through convenient labour marketplaces. The HCI community has been increasingly interested in investigating the worker-centric issues inherent in the current model and seeking for potential improvements that could be implemented in the future. This workshop explores how a reimagined perspective on crowdsourcing platforms could provide a more equitable, fair, and rewarding experience. This includes not only the workers but also the platforms, who could benefit e.g. from better processes for worker onboarding, skills-development, and growth. We invite visionary takes in various formats on this topic to spread awareness of worker-centric research and developments to the CHI community. As a result of interactive ideation work in the workshop, we articulate a future direction roadmap for research centred around crowdsourcing platforms. Finally, as a specific interest area, the workshop seeks to study crowdwork from the context of the Global South, which has been arising as an important but critically understudied crowdsourcing market in recent years.",1130
1045,Human-Centered Computing,Saiph Savage,"October 1st, 2021",Quantifying the Invisible Labor in Crowd Work,https://arxiv.org/abs/2110.00169," Carlos Toxtli, Siddharth Suri, and Saiph Savage. 2021. Quantifying the Invisible Labor in Crowd Work. Proc. ACM Hum.-Comput. Interact. 5, CSCW2, Article 319 (October 2021), 26 pages. DOI:https://doi.org/10.1145/3476060","Crowdsourcing markets provide workers with a centralized place to find paid work. What may not be obvious at first glance is that, in addition to the work they do for pay, crowd workers also have to shoulder a variety of unpaid invisible labor in these markets, which ultimately reduces workers' hourly wages. Invisible labor includes finding good tasks, messaging requesters, or managing payments. However, we currently know little about how much time crowd workers actually spend on invisible labor or how much it costs them economically. To ensure a fair and equitable future for crowd work, we need to be certain that workers are being paid fairly for all of the work they do. In this paper, we conduct a field study to quantify the invisible labor in crowd work. We build a plugin to record the amount of time that 100 workers on Amazon Mechanical Turk dedicate to invisible labor while completing 40,903 tasks. If we ignore the time workers spent on invisible labor, workers' median hourly wage was3.76.But,weestimatedthatcrowdworkersinourstudyspent332.83. We found that the invisible labor differentially impacts workers depending on their skill level and workers' demographics. The invisible labor category that took the most time and that was also the most common revolved around workers having to manage their payments. The second most time-consuming invisible labor category involved hyper-vigilance, where workers vigilantly watched over requesters' profiles for newly posted work or vigilantly searched for labor. We hope that through our paper, the invisible labor in crowdsourcing becomes more visible, and our results help to reveal the larger implications of the continuing invisibility of labor in crowdsourcing.",1131
1046,Human-Centered Computing,Saiph Savage,"November 30th, 2020",Meta-Gig: Empowering Anyone to Create Crowd Marketplaces,http://dx.doi.org/10.47756/aihc.y5i1.62," TOXTLI, Carlos; SAVAGE, Saiph. Meta-Gig: Empowering anyone to create crowd marketplaces. Avances en Interacci√≥n Humano-Computadora, [S.l.], n. 1, p. 11-19, nov. 2020. ISSN 2594-2352. Available at: . Date accessed: 09 nov. 2021. doi: http://dx.doi.org/10.47756/aihc.y5i1.62.","Abstract Few have the power to create crowd markets. Existing marketplaces may thus not embody workers‚Äô or requesters‚Äô needs. In this paper, we imagine a future where anyone could create the crowd markets they desire. We study the characteristics of the markets that 40 workers and 40 requesters from Amazon Mechanical Turk propose. We uncover that workers pushed for marketplaces that either empowered workers to set their own salaries without requiring a minimum wage or had intelligent algorithms that could automatically decide the salaries while also ensuring everyone received a minimum wage. Requesters were consistent in their preference of paying by commission and preferred markets that automatically set the salary. Both workers and requesters advocated for mechanisms to ensure quality and flexible time schedules in the market. We conclude by discussing design implications from our findings.",1132
1047,Human-Centered Computing,Saiph Savage,"May 13th, 2019",TurkScanner: Predicting the Hourly Wage of Microtasks,https://doi.org/10.1145/3308558.3313716," Susumu Saito, Chun-Wei Chiang, Saiph Savage, Teppei Nakano, Tetsunori Kobayashi, Jeffrey P. Bigham. (2019). TurkScanner: Predicting the Hourly Wage of Microtasks WWW, 3187-3193. https://doi.org/10.1145/3308558.3313716","Workers in crowd markets struggle to earn a living. One reason for this is that it is difficult for workers to accurately gauge the hourly wages of microtasks, and they consequently end up performing labor with little pay. In general, workers are provided with little information about tasks, and are left to rely on noisy signals, such as textual description of the task or rating of the requester. This study explores various computational methods for predicting the working times (and thus hourly wages) required for tasks based on data collected from other workers completing crowd work. We provide the following contributions. (i) A data collection method for gathering real-world training data on crowd-work tasks and the times required for workers to complete them; (ii) TurkScanner: a machine learning approach that predicts the necessary working time to complete a task (and can thus implicitly provide the expected hourly wage). We collected 9,155 data records using a web browser extension installed by 84 Amazon Mechanical Turk workers, and explored the challenge of accurately recording working times both automatically and by asking workers. TurkScanner was created using ~ 150 derived features, and was able to predict the hourly wages of 69.6% of all the tested microtasks within a 75% error. Directions for future research include observing the effects of tools on people's working practices, adapting this approach to a requester tool for better price setting, and predicting other elements of work (e.g., the acceptance likelihood and worker task preferences.)",1133
1048,Human-Centered Computing,Jessica Staddon,"November 21st, 2024",Assessment of LLM Responses to End-user Security Questions,https://doi.org/10.48550/arXiv.2411.14571," Vijay Prakash, Kevin Lee, Arkaprabha Bhattacharya, Danny Yuxing Huang, Jessica Staddon. (2024). Assessment of LLM Responses to End-user Security Questions CoRR, abs/2411.14571. https://doi.org/10.48550/arXiv.2411.14571","Answering end user security questions is challenging. While large language models (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have shown promise in answering a variety of questions outside of security. We studied LLM performance in the area of end user security by qualitatively evaluating 3 popular LLMs on 900 systematically collected end user security questions.While LLMs demonstrate broad generalist ``knowledge'' of end user security information, there are patterns of errors and limitations across LLMs consisting of stale and inaccurate answers, and indirect or unresponsive communication styles, all of which impacts the quality of information received. Based on these patterns, we suggest directions for model improvement and recommend user strategies for interacting with LLMs when seeking assistance with security.",1134
1049,Human-Centered Computing,Jessica Staddon,"October 14th, 2024",Can LLMs be Scammed? A Baseline Measurement Study,https://doi.org/10.48550/arXiv.2410.13893," Udari Madhushani Sehwag, Kelly Patel, Francesca Mosca, Vineeth Ravi, Jessica Staddon. (2024). Can LLMs be Scammed? A Baseline Measurement Study CoRR, abs/2410.13893. https://doi.org/10.48550/arXiv.2410.13893","Despite the importance of developing generative AI models that can effectively resist scams, current literature lacks a structured framework for evaluating their vulnerability to such threats. In this work, we address this gap by constructing a benchmark based on the FINRA taxonomy and systematically assessing Large Language Models' (LLMs') vulnerability to a variety of scam tactics. First, we incorporate 37 well-defined base scam scenarios reflecting the diverse scam categories identified by FINRA taxonomy, providing a focused evaluation of LLMs' scam detection capabilities. Second, we utilize representative proprietary (GPT-3.5, GPT-4) and open-source (Llama) models to analyze their performance in scam detection. Third, our research provides critical insights into which scam tactics are most effective against LLMs and how varying persona traits and persuasive techniques influence these vulnerabilities. We reveal distinct susceptibility patterns across different models and scenarios, underscoring the need for targeted enhancements in LLM design and deployment.",1135
1050,Human-Centered Computing,Jessica Staddon,"May 11th, 2024",Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints,https://doi.org/10.1145/3613904.3642033," Arkaprabha Bhattacharya, Kevin Lee, Vineeth Ravi, Jessica Staddon, Rosanna Bellini. (2024). Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints CHI, 354:1-354:20. https://doi.org/10.1145/3613904.3642033","Digital financial services can introduce new digital-safety risks for users, particularly survivors of intimate partner financial abuse (IPFA). To offer improved support for such users, a comprehensive understanding of their support needs and the barriers they face to redress by financial institutions is essential. Drawing from a dataset of 2.7 million customer complaints, we implement a bespoke workflow that utilizes language-modeling techniques and expert human review to identify complaints describing IPFA. Our mixed-method analysis provides insight into the most common digital financial products involved in these attacks, and the barriers consumers report encountering when doing so. Our contributions are twofold; we offer the first human-labeled dataset for this overlooked harm and provide practical implications for technical practice, research, and design for better supporting and protecting survivors of IPFA.",1136
1051,Human-Centered Computing,Alexandra To,"January 13th, 2025",Data Enrichment Work and AI Labor in Latin America and the Caribbean,https://doi.org/10.48550/arXiv.2501.06981," Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage. (2025). Data Enrichment Work and AI Labor in Latin America and the Caribbean CoRR, abs/2501.06981. https://doi.org/10.48550/arXiv.2501.06981","The global AI surge demands crowdworkers from diverse languages and cultures. They are pivotal in labeling data for enabling global AI systems. Despite global significance, research has primarily focused on understanding the perspectives and experiences of US and India crowdworkers, leaving a notable gap. To bridge this, we conducted a survey with 100 crowdworkers across 16 Latin American and Caribbean countries. We discovered that these workers exhibited pride and respect for their digital labor, with strong support and admiration from their families. Notably, crowd work was also seen as a stepping stone to financial and professional independence. Surprisingly, despite wanting more connection, these workers also felt isolated from peers and doubtful of others' labor quality. They resisted collaboration and gender-based tools, valuing gender-neutrality. Our work advances HCI understanding of Latin American and Caribbean crowdwork, offering insights for digital resistance tools for the region.",1137
1052,Human-Centered Computing,Alexandra To,"July 24th, 2024","Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing",https://doi.org/10.48550/arXiv.2407.17579," JaeWon Kim, Lindsay Popowski, Anna Fang, Cassidy Pyle, Guo Freeman, Ryan M. Kelly, Angela Y. Lee, Fannie Liu, Angela D. R. Smith, Alexandra To, Amy X. Zhang. (2024). Envisioning New Futures of Positive Social Technology: Beyond Paradigms of Fixing, Protecting, and Preventing CoRR, abs/2407.17579. https://doi.org/10.48550/arXiv.2407.17579","Social technology research today largely focuses on mitigating the negative impacts of technology and, therefore, often misses the potential of technology to enhance human connections and well-being. However, we see a potential to shift towards a holistic view of social technology's impact on human flourishing. We introduce Positive Social Technology (Positech), a framework that shifts emphasis toward leveraging social technologies to support and augment human flourishing. This workshop is organized around three themes relevant to Positech: 1) ""Exploring Relevant and Adjacent Research"" to define and widen the Positech scope with insights from related fields, 2) ""Projecting the Landscape of Positech"" for participants to outline the domain's key aspects and 3) ""Envisioning the Future of Positech,"" anchored around strategic planning towards a sustainable research community. Ultimately, this workshop will serve as a platform to shift the narrative of social technology research towards a more positive, human-centric approach. It will foster research that goes beyond fixing technologies to protect humans from harm, to also pursue enriching human experiences and connections through technology.",1138
1053,Human-Centered Computing,Alexandra To,"July 5th, 2024","Queer TTRPGs‚Äô Visibility, Safety, and Allegory as Resistance",https://doi.org/10.1145/3649921.3650022," Jailyn Zabala, Josie Zvelebilova, Alexandra To. (2024). Queer TTRPGs' Visibility, Safety, and Allegory as Resistance FDG, 30. https://doi.org/10.1145/3649921.3650022","Responding to Ruberg‚Äôs notion of the ‚Äúqueer games avant-garde‚Äù where games are made by, for, and about queer gamers [23], we sought out ‚Äúqueer TTRPGs‚Äù where queerness is centered in the design of a given tabletop roleplaying game (TTRPG) system and/or setting. In this study, we curated a ludography of seven queer TTRPGs that support the exploration of queer identity: Thirsty Sword Lesbians [36], Monsterhearts 2 [2], Dream Askew [1], Alice is Missing [29], Sleepaway [8], Lichcraft [19], and Wanderhome [9]. In our content analysis of the game guidebooks, we found that the games guide players through queer play experiences through tenets of queer theory, while using visibility and direct disclosure of the game‚Äôs themes to resist the status-quo of erasing queerness in traditional media. We close with reflections on how other game designers can leverage these strategies to support and uplift queer gamers.",1139
1054,Human-Centered Computing,Alexandra To,"May 11th, 2024",An Exploration of Learned Values Through Lived Experiences to Design for BIPOC Students‚Äô Flourishing,https://doi.org/10.1145/3613905.3650899," Laveda Chan, Dilruba Showkat, Alexandra To. (2024). An Exploration of Learned Values Through Lived Experiences to Design for BIPOC Students' Flourishing CHI Extended Abstracts, 43:1-43:7. https://doi.org/10.1145/3613905.3650899","Prior research has primarily focused on the negative experiences faced by BIPOC students and sought to identify ways to counter harms. In contrast, our work seeks to characterize and support the positive, valuable, and meaningful experiences of BIPOC to support their holistic thriving at predominantly white institutions (PWIs). Experiences where students can share their stories and engage with racial identity development, are paramount to their flourishing. However, these stories and connections are not widely accessible. In this work, we gathered stories of meaningful experiences by conducting a qualitative semi-structured interview with 17 BIPOC students from diverse races and ethnic backgrounds, all studying across various PWIs. Our preliminary findings revealed that students derive meaningful experiences by engaging in activities that lead to the cultivation of learned values and personal growth. We discuss and situate our findings within a positive design framework to support BIPOC students‚Äô sustained well-being and flourishing.",1140
1055,Human-Centered Computing,Alexandra To,"October 31st, 2022",Alienated Serendipity and Reflective Failure: Exploring Queer Game Mechanics and Queerness in Games via Queer Temporality,https://doi.org/10.1145/3549484," Matthew Hantsbarger, Giovanni Maria Troiano, Alexandra To, Casper Harteveld. (2022). Alienated Serendipity and Reflective Failure: Exploring Queer Game Mechanics and Queerness in Games via Queer Temporality Proc. ACM Hum. Comput. Interact., 6, 1-27. https://doi.org/10.1145/3549484","Queerness can help redefine interactive technologies and re-conceptualize their design beyond cisheteronormativity. Recently, games have emerged as promising avenues for exploring queerness. In this research-through-design (RtD) effort, we advance queer explorations in games by leveraging queer temporality to evoke and explore feelings of alienation and isolation in a horror game called You're Going To Be Late. We further engage with queer individuals who playtest our game and participate in focus groups to discuss how queer they felt our game was and what they regard as queer game mechanics. Participants had varying experiences while playing our game, ranging from serendipity and wonder to alienation and confusion. The focus groups described queer game mechanics as queer modes of play and often tapped into gender representation. Finally, we show how including and amplifying queer voices in discursive efforts around interactive technology design has implications for transformative and critical reflections that can broadly benefit game design and HCI research.",1141
1056,Human-Centered Computing,Alexandra To,"April 29th, 2022",Interactive Fiction Provotypes for Coping with Interpersonal Racism,https://doi.org/10.1145/3491102.3502044," Alexandra To, Hillary Carey, Riya Shrivastava, Jessica Hammer, Geoff Kaufman. (2022). Interactive Fiction Provotypes for Coping with Interpersonal Racism CHI, 453:1-453:14. https://doi.org/10.1145/3491102.3502044","Reducing uncertainty around the nature of racist interactions is one of the key motivations driving individual behaviors for coping with those incidents. However, there are few appropriate technologies to support BIPOC (Black, Indigenous, People of Color) in engaging in social uncertainty reduction around this vulnerable, sensitive topic. This paper reports on an exploratory design study investigating how social technology might facilitate uncertainty reduction through three ‚Äúprovotypes‚Äù - provocative prototypes of user-generated speculative design concepts. U.S.-based participants engaged with the provotypes through an interactive fiction to explore their usefulness in the context of a racist microaggression. Results showed that engaging the provotypes through interactive fiction facilitated complex and productive interactions and critiques. This work contributes a novel method for conducting exploratory design, remote user studies using interactive fiction as well as priorities, tensions, and further information what role, if any, technology might play in managing racist interactions.",1142
1057,Human-Centered Computing,Alexandra To,"April 28th, 2022",Collecting and Reporting Race and Ethnicity Data in HCI,https://doi.org/10.1145/3491101.3519685," Yiqun T. Chen, Angela D. R. Smith, Katharina Reinecke, Alexandra To. (2022). Collecting and Reporting Race and Ethnicity Data in HCI CHI Extended Abstracts, 327:1-327:8. https://doi.org/10.1145/3491101.3519685","Engaging racially and ethnically diverse participants in Human-Computer Interaction (HCI) research is critical for creating safe, inclusive, and equitable technology. However, it remains unclear why and how HCI researchers collect study participants‚Äô race and ethnicity. Through a systematic literature analysis of 2016‚Äì2021 CHI proceedings and a survey with 15 authors who published in these proceedings, we found that reporting race and ethnicity of participants is uncommon and that HCI researchers are far from consensus on the collection and analysis of this data. Because a majority (>90%) of the articles that report participants‚Äô race and ethnicity are conducted in the United States, we focused our discussion on race and ethnicity accordingly. In future work, we plan to investigate considerations and best practices for collecting and analyzing race and ethnicity data in a global context.",1143
1058,Human-Centered Computing,Alexandra To,"June 30th, 2021",Discovering intersectionality: part 2: reclaiming our time,https://doi.org/10.1145/3468783," Jakita Owensby Thomas, Neha Kumar, Alexandra To, Quincy Brown, Yolanda A. Rankin. (2021). Discovering intersectionality: part 2: reclaiming our time Interactions, 28, 72-75. https://doi.org/10.1145/3468783","In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors",1144
1059,Human-Centered Computing,Alexandra To,"April 27th, 2021",Discovering intersectionality part I: researcher interrupted,https://doi.org/10.1145/3457869," Quincy Brown, Neha Kumar, Jakita Owensby Thomas, Alexandra To, Yolanda A. Rankin. (2021). Discovering intersectionality part I: researcher interrupted Interactions, 28, 73-77. https://doi.org/10.1145/3457869","In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors",1145
1060,Human-Centered Computing,Alexandra To,"May 1st, 2020",‚ÄúThey Just Don‚Äôt Get It‚Äù: Towards Social Technologies for Coping with Interpersonal Racism,https://dl.acm.org/doi/abs/10.1145/3392828," To, A., Sweeney, W., Hammer, J., & Kaufman, G. (2020). "" They Just Don't Get It"": Towards Social Technologies for Coping with Interpersonal Racism. Proceedings of the ACM on Human-Computer Interaction, 4(CSCW1), 1-29.","Over 35% of Americans belong to racial minority groups. Racism targeting these individuals results in a range of harmful physical, psychological, and practical consequences. The present work aims to shed light on the current sense-making and support-seeking practices exhibited by targets of racism, as well as to identify the core needs and barriers that future socio-technical interventions could potentially address. The long-term goal of this work is to understand how CSCW researchers and designers could best support members of marginalized groups to make sense of and to seek support for experiences with racism. Narrative episode interviews with targets of racism revealed a number of key entry points for intervention. For example, participants' personal stories confirmed that uncertainty, both about the nature and consequences of the experience of racism, is a key motivator for support-seeking. In addition, despite the need for support, participants largely do not trust public forms of social media for support-seeking. We discuss how participants' accounts of the complex labor involved in determining who ""gets it"" in identifying potential supporters, and in navigating the complexities of trust and agency in sharing their experiences, present clear implications for the design of new socio-technical platforms for members of racial minority groups.",1146
1061,Human-Centered Computing,Alexandra To,"April 1st, 2020",Critical Race Theory for HCI,https://dl.acm.org/doi/abs/10.1145/3313831.3376392?casa_token=bFFinok3wQUAAAAA:pIhe3UMXrdodkEObdgnJcVrJ91iHRaDQj3hzi9YtI7dYpIxsSbLgPNrIFz6HrG-Zqbxif1e-CzE," Ogbonnaya-Ogburu, I. F., Smith, A. D., To, A., & Toyama, K. (2020, April). Critical race theory for HCI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1-16).","The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to ""interest convergence"", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: all HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.",1147
1062,Human-Centered Computing,Melanie Tory,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1148
1063,Human-Centered Computing,Melanie Tory,"April 15th, 2024",Struggles and Strategies in Understanding Information Visualizations,https://doi.org/10.1109/TVCG.2024.3388560," Maryam Rezaie, Melanie Tory, Sheelagh Carpendale. (2024). Struggles and Strategies in Understanding Information Visualizations IEEE Trans. Vis. Comput. Graph., 30, 3035-3048. https://doi.org/10.1109/TVCG.2024.3388560","Empirical studies are needed to tease apart the details of what makes the process of understanding difficult for visualization viewers. We conducted a qualitative study with 14 participants, observing them as they described how they were trying to make sense of 20 information visualizations. We identified the challenges participants faced throughout their sensemaking process and the strategies they employed to help themselves in overcoming the challenges. Our findings show how details and nuances within visualizations can impact comprehensibility and offer research suggestions to help us move toward more understandable visualizations, the authors say.",1149
1064,Human-Centered Computing,Melanie Tory,"October 26th, 2023",Heuristics for Supporting Cooperative Dashboard Design,https://doi.org/10.1109/TVCG.2023.3327158," Vidya Setlur, Michael Correll, Arvind Satyanarayan, Melanie Tory. (2024). Heuristics for Supporting Cooperative Dashboard Design IEEE Trans. Vis. Comput. Graph., 30, 370-380. https://doi.org/10.1109/TVCG.2023.3327158","Dashboards are no longer mere static displays of metrics. Through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines are often unable to account for this expanded scope as they largely focus on best practices for visual design. Our approach suggests several compelling directions for future work. including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement. and extending cooperative principles to other analytical workflows. The study was published in the IEEE Transactions on Visualization and Computer Graphics ( Volume: 30 , Issue: 1 , January 2024 ) and is available online at: 10.1109/TVCG.2023.",1150
1065,Human-Centered Computing,Melanie Tory,"July 5th, 2023",Investigating the Visual Utility of Differentially Private Scatterplots,https://doi.org/10.1109/TVCG.2023.3292391," Liudas Panavas, Tarik Crnovrsanin, Jane Lydia Adams, Jonathan R. Ullman, Ali Sarvghad, Melanie Tory, Cody Dunne. (2024). Investigating the Visual Utility of Differentially Private Scatterplots IEEE Trans. Vis. Comput. Graph., 30, 5370-5385. https://doi.org/10.1109/TVCG.2023.3292391","Increasingly, visualization practitioners are working with, using, and studying private data. Differential privacy algorithms do this by aggregating data statistics with noise. This now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.",1151
1066,Human-Centered Computing,Melanie Tory,"June 28th, 2021",Untidy Data: The Unreasonable Effectiveness of Tables,https://arxiv.org/abs/2106.15005," Bartram, Lyn, Michael Correll, and Melanie Tory. ""Untidy data: The unreasonable effectiveness of tables."" IEEE Computer Graphics and Applications, (2021).","Working with data in table form is usually considered a preparatory and tedious step in the sensemaking pipeline; a way of getting the data ready for more sophisticated visualization and analytical tools. But for many people, spreadsheets -- the quintessential table tool -- remain a critical part of their information ecosystem, allowing them to interact with their data in ways that are hidden or abstracted in more complex tools. This is particularly true for data workers: people who work with data as part of their job but do not identify as professional analysts or data scientists. We report on a qualitative study of how these workers interact with and reason about their data. Our findings show that data tables serve a broader purpose beyond data cleanup at the initial stage of a linear analytic flow: users want to see and ""get their hands on"" the underlying data throughout the analytics process, reshaping and augmenting it to support sensemaking. They reorganize, mark up, layer on levels of detail, and spawn alternatives within the context of the base data. These direct interactions and human-readable table representations form a rich and cognitively important part of building understanding of what the data mean and what they can do with it. We argue that interactive tables are an important visualization idiom in their own right; that the direct data interaction they afford offers a fertile design space for visual analytics; and that sense making can be enriched by more flexible human-data interaction than is currently supported in visual analytics tools.",1152
1067,Human-Centered Computing,Melanie Tory,"April 15th, 2021",The Unmet Data Visualization Needs of Decision Makers within Organizations,https://research.tableau.com/paper/unmet-data-visualization-needs-decision-makers-within-organizations," Evanthia Dimara, Harry Zhang, Melanie Tory, and Steven Franconeri, The Unmet Data Visualization Needs of Decision Makers within Organizations, IEEE Transactions on Visualization and Computer Graphics, 2021.","Tableau Research is an industrial research team focused on Tableau‚Äôs mission of helping people see and understand data. We actively work to be a source of new and inspiring product and technology directions, generating ideas that influence, drive, or significantly change what Tableau delivers to customers. We are also active members of the academic community, where we regularly publish and participate in top-tier conferences and journals. Tableau Research‚Äôs charter is to explore ways in which a computer can support humans when they are exploring, interacting, or presenting data. Be it new ML models that can provide reasonable defaults, support data augmentation, better search algorithms for helping people discover content and answer their questions, tools for better supporting data presentations, or figuring out how new channels can support new experiences for seeing and understanding data. Dennis Bromley Principal Research Scientist",1153
1068,Human-Centered Computing,Christo Wilson,"May 13th, 2024",Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results,https://doi.org/10.1145/3589334.3645666," Jeffrey L. Gleason, Avijit Ghosh, Ronald E. Robertson, Christo Wilson. (2024). Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results WWW, 1249-1259. https://doi.org/10.1145/3589334.3645666","The results returned by image search engines have the power to shape peoples' perceptions about social groups. Existing work on image search engines leverages hand-selected queries for occupations like ""doctor"" and ""engineer"" to quantify racial and gender bias in search results. We complement this work by analyzing peoples' real-world image search queries and measuring the distributions of perceived gender, skin tone, and age in their results. We collect 54,070 unique image search queries and analyze 1,481 open-ended people queries (i.e. not queries for named entities) from a representative sample of 643 US residents. For each query, we analyze the top 15 results returned on both Google and Bing Images. Analysis of real-world image search queries produces multiple insights. First, less than 5% of unique queries are open-ended people queries. Second, fashion queries are, by far, the most common category of open-ended people queries, accounting for over 30% of the total. Third, the modal skin tone on the Monk Skin Tone scale is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US.",1154
1069,Human-Centered Computing,Christo Wilson,"November 7th, 2022","Hammurabi: A Framework for Pluggable, Logic-based X.509 Certificate Validation Policies",https://doi.org/10.1145/3548606.3560594," James Larisch, Waqar Aqeel, Michael Lum, Yaelle Goldschlag, Kasra Torshizi, Leah Kannan, Yujie Wang, Taejoong Chung, Dave Levin, Bruce M. Maggs, Alan Mislove, Bryan Parno, and Christo Wilson. (2022). ""Hammurabi: A Framework for Pluggable, Logic-Based X.509 Certificate Validation Policies"". In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS ‚Äô22), November 7‚Äì11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA, 15 pages. DOI: 10.1145/3548606.3560594","This paper proposes using a logic programming language to disentangle X.509 certificate validation policy from mechanism. Expressing validation policies in a logic programming language provides multiple benefits. First, policy and mechanism can be more independently written, augmented, and analyzed compared to the current practice of interweaving them within a C or C++ implementation. Once written, these policies can be easily shared and modified for use in different TLS clients. Further, logic programming allows us to determine when clients differ in their policies and use the power of imputation to automatically generate interesting certificates, e.g., a certificate that will be accepted by one browser but not by another. We present a new framework called Hammurabi for expressing validation policies, and we demonstrate that we can express the complex policies of the Google Chrome and Mozilla Firefox web browsers in this framework. We confirm the fidelity of the Hammurabi policies by comparing the validation decisions they make with those made by the browsers themselves on over ten million certificate chains derived from Certificate Transparency logs, as well as 100K synthetic chains. We also use imputation to discover nine validation differences between the two browsers' policies. Finally, we demonstrate the feasibility of integrating Hammurabi into Firefox and the Go language in less than 100 lines of code each.",1155
1070,Human-Centered Computing,Christo Wilson,"January 1st, 2022",Setting the Bar Low: Are Websites Complying With the Minimum Requirements of the CCPA?,https://doi.org/10.2478/popets-2022-0030," Maggie Van Nortwick and Christo Wilson. ""Setting the Bar Low: Are Websites Complying With the Minimum Requirements of the CCPA?"". Proceedings on Privacy Enhancing Technologies (PoPETS), 2022(1), January, 2022.","Authors: Maggie Van Nortwick (Northeastern University), Christo Wilson (Northeastern University) Volume: 2022 Issue: 1 Pages: 608‚Äì628 DOI: https://doi.org/10.2478/popets-2022-0030 Download PDF Abstract: On June 28, 2018, the California State Legislature passed the California Consumer Privacy Act (CCPA), arguably the most comprehensive piece of online privacy legislation in the United States. Online services covered by the CCPA are required to provide a hyperlink on their homepage with the text ‚ÄúDo Not Sell My Personal Information‚Äù (DNSMPI). The CCPA went into effect on January 1, 2020, a date that was chosen to give data collectors time to study the new law and bring themselves into compliance. In this study, we begin the process of investigating whether websites are complying with the CCPA by focusing on DNSMPI links. Using longitudinal data crawled from the top 1M websites in the Tranco ranking, we examine which websites are including DNSMPI links, whether the websites without DNSMPI links are out of compliance with the law, whether websites are using geofences to dynamically hide DNSMPI links from nonCalifornians, how DNSMPI adoption has changed over time, and how websites are choosing to present DNSMPI links (e.g., in terms of font size, color, and placement). We argue that the answers to these questions are critical for spurring enforcement actions under the law, and helping to shape future privacy laws and regulations, e.g., rule making that will soon commence around the successor to the CCPA, known as the CPRA.",1156
1071,Human-Centered Computing,Christo Wilson,"October 1st, 2021",A Comparative Study of Dark Patterns Across Mobile and Web Modalities,https://doi.org/10.1145/3479521," Johanna Gunawan, Amogh Pradeep, David Choffnes, Woodrow Hartzog, and Christo Wilson. ""A Comparative Study of Dark Patterns Across Mobile and Web Modalities"". Proceedings of the ACM: Human-Computer Interaction, 5(CSCW2), October, 2021. DOI: 10.1145/3479521","Dark patterns are user interface elements that can influence a person's behavior against their intentions or best interests. Prior work identified these patterns in websites and mobile apps, but little is known about how the design of platforms might impact dark pattern manifestations and related human vulnerabilities. In this paper, we conduct a comparative study of mobile application, mobile browser, and web browser versions of 105 popular services to investigate variations in dark patterns across modalities. We perform manual tests, identify dark patterns in each service, and examine how they persist or differ by modality. Our findings show that while services can employ some dark patterns equally across modalities, many dark patterns vary between platforms, and that these differences saddle people with inconsistent experiences of autonomy, privacy, and control. We conclude by discussing broader implications for policymakers and practitioners, and provide suggestions for furthering dark patterns research.",1157
1072,Human-Centered Computing,Christo Wilson,"July 1st, 2021",When Fair Ranking Meets Uncertain Inference,https://doi.org/10.1145/3506803," Avijit Ghosh, Ritam Dutt, and Christo Wilson. ""When Fair Ranking Meets Uncertain Inference"". In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021). Virtual Event, Canada, July, 2021. DOI: 10.1145/3506803","We occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you‚Äôve provided to them or that they‚Äôve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device. Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. These cookies do not gather information about you that could be used for marketing purposes and do not remember where you have been on the internet. Preference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in. Statistic cookies help website owners understand how visitors interact with websites by collecting and reporting information anonymously. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.",1158
1073,Human-Centered Computing,Christo Wilson,"March 1st, 2021",Building and Auditing Fair Algorithms: A Case Study in Candidate Screening,https://doi.org/10.1145/3442188.3445928," Christo Wilson, Avijit Ghosh, Shan Jiang, Alan Mislove, Lewis Baker, Janelle Szary, Kelly Trindel, and Frida Polli. ""Building and Auditing Fair Algorithms: A Case Study in Candidate Screening."" In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2021). Virtual Event, Canada, March, 2021. DOI: 10.1145/3442188.3445928","Academics, activists, and regulators are increasingly urging companies to develop and deploy sociotechnical systems that are fair and unbiased. Achieving this goal, however, is complex: the developer must (1) deeply engage with social and legal facets of ""fairness"" in a given context, (2) develop software that concretizes these values, and (3) undergo an independent algorithm audit to ensure technical correctness and social accountability of their algorithms. To date, there are few examples of companies that have transparently undertaken all three steps. In this paper we outline a framework for algorithmic auditing by way of a case-study of pymetrics, a startup that uses machine learning to recommend job candidates to their clients. We discuss how pymetrics approaches the question of fairness given the constraints of ethical, regulatory, and client demands, and how pymetrics' software implements adverse impact testing. We also present the results of an independent audit of pymetrics' candidate screening tool. We conclude with recommendations on how to structure audits to be practical, independent, and constructive, so that companies have better incentive to participate in third party audits, and that watchdog groups can be better prepared to investigate companies.",1159
1074,Human-Centered Computing,Christo Wilson,"January 1st, 2021",Structurizing Misinformation Stories via Rationalizing Fact-Checks,https://doi.org/10.18653/v1/2021.acl-long.51," Shan Jiang , Christo Wilson. (2021). Structurizing Misinformation Stories via Rationalizing Fact-Checks ACL/IJCNLP (1), 617-631. https://doi.org/10.18653/v1/2021.acl-long.51","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Misinformation has recently become a well-documented matter of public concern. Existing studies on this topic have hitherto adopted a coarse concept of misinformation, which incorporates a broad spectrum of story types ranging from political conspiracies to misinterpreted pranks. This paper aims to structurize these misinformation stories by leveraging fact-check articles. Our intuition is that key phrases in a fact-check article that identify the misinformation type(s) (e.g., doctored images, urban legends) also act as rationales that determine the verdict of the fact-check (e.g., false). We experiment on rationalized models with domain knowledge as weak supervision to extract these phrases as rationales, and then cluster semantically similar rationales to summarize prevalent misinformation types. Using archived fact-checks from Snopes.com, we identify ten types of misinformation stories. We discuss how these types have evolved over the last ten years and compare their prevalence between the 2016/2020 US presidential elections and the H1N1/COVID-19 pandemics.",1160
1075,Human-Centered Computing,Christo Wilson,"June 1st, 2020",Modeling and Measuring Expressed (Dis)belief in (Mis)information,https://doi.org/10.1609/icwsm.v14i1.7302," Shan Jiang, Miriam Metzger, Andrew Flanagin, and Christo Wilson. ""Modeling and Measuring Expressed (Dis)belief in (Mis)information"". In Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM 2020). Atlanta, Georgia, June, 2020.","Abstract The proliferation of online misinformation has been raising increasing societal concerns about its potential consequences, e.g., polarizing the public and eroding trust in institutions. These consequences are framed under the public's susceptibility to such misinformation ‚Äî a narrative that needs further investigation and quantification. To this end, our paper proposes an observational approach to model and measure expressed (dis)beliefs in (mis)information by leveraging social media comments as a proxy. We collect a sample of tweets in response to (mis)information and annotate them with (dis)belief labels, explore the dataset using lexicon-based methods, and finally build classifiers based on the state-of-the-art neural transfer-learning models (BERT, XLNet, and RoBERTa). Under a domain-specific thresholding strategy for unbiasedness, the best-performing classifier archives macro-F 1 scores around 0.86 for disbelief and 0.80 for belief. Applying the classifier, we conduct a large-scale measurement study and show that, for true/mixed/false claims on social media, 12%/14%/15% of comments express disbelief and 26%/21%/20% of comments express belief. In addition, our results suggest an extremely slight time effect of falsehood awareness, a positive effect of fact-checks to false claims, and differences in (dis)belief across social media platforms.",1161
1076,Human-Centered Computing,Christo Wilson,"October 21st, 2019",A Longitudinal Analysis of the ads.txt Standard,https://doi.org/10.1145/3355369.3355603," Muhammad Ahmad Bashir, Sajjad Arshad, Engin Kirda, William K. Robertson, Christo Wilson. (2019). A Longitudinal Analysis of the ads.txt Standard Internet Measurement Conference, 294-307. https://doi.org/10.1145/3355369.3355603","Programmatic advertising provides digital ad buyers with the convenience of purchasing ad impressions through Real Time Bidding (RTB) auctions. However, programmatic advertising has also given rise to a novel form of ad fraud known as domain spoofing, in which attackers sell counterfeit impressions that claim to be from high-value publishers. To mitigate domain spoofing, the Interactive Advertising Bureau (IAB) Tech Lab introduced the ads.txt standard in May 2017 to help ad buyers verify authorized digital ad sellers, as well as to promote overall transparency in programmatic advertising. In this work, we present a 15-month longitudinal, observational study of the ads.txt standard. We do this to understand (1) if it is helping ad buyers to combat domain spoofing and (2) whether the transparency offered by the standard can provide useful data to researchers and privacy advocates. With respect to halting domain spoofing, we observe that over 60% of Alexa Top-100K publishers that run RTB ads have adopted ads.txt, and that ad exchanges and advertisers appear to be honoring the standard. With respect to transparency, the widespread adoption of ads.txt allows us to explicitly identify over 1,000 domains belonging to ad exchanges, without having to rely on crowdsourcing or heuristic methods. However, we also find that ads.txt is still a long way from reaching its full potential. Many publishers have yet to adopt the standard, and we observe major ad exchanges purchasing unauthorized impressions that violate the standard. This opens the door to domain spoofing attacks. Further, ads.txt data often include errors that must be cleaned and mitigated before the data is practically useful.",1162
1077,Human-Centered Computing,Christo Wilson,"April 23rd, 2018",Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages,https://doi.org/10.1145/3178876.3186143," Ronald E. Robertson, David Lazer, and Christo Wilson. 2018. Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages. In Proceedings of the 2018 World Wide Web Conference (WWW '18). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 955‚Äì965. DOI: 10.1145/3178876.3186143","Search engines are a primary means through which people obtain information in today¬ªs connected world. Yet, apart from the search engine companies themselves, little is known about how their algorithms filter, rank, and present the web to users. This question is especially pertinent with respect to political queries, given growing concerns about filter bubbles, and the recent finding that bias or favoritism in search rankings can influence voting behavior. In this study, we conduct a targeted algorithm audit of Google Search using a dynamic set of political queries. We designed a Chrome extension to survey participants and collect the Search Engine Results Pages (SERPs) and autocomplete suggestions that they would have been exposed to while searching our set of political queries during the month after Donald Trump¬ªs Presidential inauguration. Using this data, we found significant differences in the composition and personalization of politically-related SERPs by query type, subjects¬ª characteristics, and date.",1163
1078,Human-Centered Computing,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1164
1079,Human-Centered Computing,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",1165
1080,Human-Centered Computing,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1166
1081,Human-Centered Computing,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",1167
1082,Human-Centered Computing,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1168
1083,Human-Centered Computing,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1169
1084,Human-Centered Computing,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",1170
1085,Human-Centered Computing,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1171
1086,Human-Centered Computing,Caglar Yildirim,"November 4th, 2024",Poke Typing: Effects of Hand-Tracking Input and Key Representation on Mid-Air Text Entry Performance in Virtual Reality,https://doi.org/10.1145/3678957.3685734," Mehmet Akhoroz, Caglar Yildirim. (2024). Poke Typing: Effects of Hand-Tracking Input and Key Representation on Mid-Air Text Entry Performance in Virtual Reality ICMI, 293-301. https://doi.org/10.1145/3678957.3685734","In this paper, we investigated the effects of hand-tracking input on mid-air text entry performance in virtual reality as a function of the key representations used in the virtual keyboard, i.e., flat 2D keys vs. protruded 3D keys. This led to a comparison among four conditions: controller input using 2D keys, controller input using 3D keys, hand-tracking input using 2D keys, hand-tracking input using 3D keys. Results from our user study (n = 28) revealed that controller input (15.3 WPM) outperformed hand-tracking input (13.8 WPM) in terms of text entry rates and that protruded 3D keys (15.6 WPM) led to faster text entry performance than did flat 2D keys (13.4 WPM). While the four conditions did not differ in error rates, flat 2D keys led to a greater number of character corrections. In addition, results showed that compared to flat 2D keys, protruded 3D keys lowered the perceived mental workload of the text entry task. These results indicate that despite the technological advances in hand-tracking technology, controller input is still more performant than hand-tracking input for VR text entry tasks and that protruded 3D keys afford faster text entry and better user experience than do flat 2D keys. That said, hand-tracking input can still be used for mid-air text entry without extreme performance losses.",1172
1087,Human-Centered Computing,Caglar Yildirim,"October 27th, 2024",Design considerations for photosensitivity warnings in visual media,https://doi.org/10.1145/3663548.3675643," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Design considerations for photosensitivity warnings in visual media ASSETS, 68:1-68:12. https://doi.org/10.1145/3663548.3675643","When digital content is tested for photosensitive safety and is found to contain seizure-inducing strobes or flashing lights, warnings about photosensitive risk are usually shown to the user prior to viewing the content. These photosensitivity warnings are an important accessibility feature for people with photosensitive epilepsy, allowing them to avoid interacting with content that may trigger seizures. However, little is known about how these warnings should be structured to maximize effectiveness in helping with people PSE navigate visual media safely. The design space for photosensitivity warnings is vast and includes questions such as what details to include about strobing light sequences or the content itself, where to place warnings within an interface, and what methods to use to extract information about the strobing light sequences (e.g., crowdsourced or automated methods). In this work, we contribute a thematic analysis of crowdsourced warnings drawn from the DoesTheDogDie online forum and an interview study with five people who have been diagnosed with photosensitive epilepsy about design considerations for photosensitivity warnings on digital platforms. To guide our interviews, we assembled examples of both crowdsourced and automated warnings about seizure-inducing content in films. Automated warnings were presented in the form of a high fidelity sketch demonstrating what an automated system for photosensitivity warnings might look like when deployed by a film streaming platform. We contribute design suggestions for the structure, content, and data sourcing of photosensitivity warnings for visual media based on the findings of our interviews. The results of this work will enable more effective and informative photosensitivity warnings across all forms of digital visual media.",1173
1088,Human-Centered Computing,Caglar Yildirim,"May 11th, 2024",Barriers to Photosensitive Accessibility in Virtual Reality,https://doi.org/10.1145/3613904.3642635," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2024). Barriers to Photosensitive Accessibility in Virtual Reality CHI, 58:1-58:13. https://doi.org/10.1145/3613904.3642635","Virtual reality (VR) systems have grown in popularity as an immersive modality for daily activities such as gaming, socializing, and working. However, this technology is not always accessible for people with photosensitive epilepsy (PSE) who may experience seizures or other adverse symptoms when exposed to certain light stimuli (e.g., flashes or strobes). How can VR be made more inclusive and safer for people with PSE? In this paper, we report on a series of semi-structured interviews about current perceptions of accessibility in VR among people with PSE. We identify 12 barriers to accessibility that fall into four categories: physical VR equipment, VR interfaces and content, specific VR applications, and individual differences in sensitivity. Our findings allow researchers and practitioners to better understand the meaning of photosensitive accessibility in the context of VR, and provide a step towards enabling people with PSE to enjoy the benefits offered by immersive technology.",1174
1089,Human-Centered Computing,Caglar Yildirim,"January 30th, 2024",On the Plane: A Roleplaying Game for Simulating Ingroup-Outgroup Biases in Virtual Reality,https://doi.org/10.1109/AIVR56993.2022.00041," Caglar Yildirim, D. Fox Harrell. (2022). On the Plane: A Roleplaying Game for Simulating Ingroup-Outgroup Biases in Virtual Reality AIVR, 207-209. https://doi.org/10.1109/AIVR56993.2022.00041","On the Plane is a roleplaying game aimed at simulating ingroup-outgroup biases with the goal of supporting positive perspective taking in virtual reality. The game presents players with a simulation of air travel experience, from airport security screening to in-flight events. On the Plane affords the ability to experience the simulation as different characters, supporting both ingroup and outgroup perspectives. We describe how the game is structured to simulate and challenge ingroup outgroup biases within the context of xenophobia.",1175
1090,Human-Centered Computing,Caglar Yildirim,"October 29th, 2023",E4UnityIntegration-MIT: An Open-Source Unity Plug-in for Collecting Physiological Data using Empatica E4 during Gameplay,https://doi.org/10.1145/3586182.3616627," Eduard De Vidal Flores, Caglar Yildirim, D. Fox Harrell. (2023). E4UnityIntegration-MIT: An Open-Source Unity Plug-in for Collecting Physiological Data using Empatica E4 during Gameplay UIST (Adjunct Volume), 49:1-49:3. https://doi.org/10.1145/3586182.3616627","Physiological measurement of player experience (PX) during gameplay has been of increasing interest within game research circles. A commonly-used non-invasive wearable device for physiological measurement is the Empatica E4 wristband, which offers multiple physiological metrics, ranging from electrodermal activity to heart rate. That said, the E4‚Äôs integration with popular game engines such as Unity 3D presents certain challenges due to non-obvious critical bugs in the library and limited documentation applicability within the Unity context. In this paper, we present an open-source Unity plug-in designed to mitigate the challenges associated with integrating the E4 into Unity projects: E4UnityIntegration-MIT. The plug-in exposes the E4‚Äôs API for interfacing with Unity C# scripts, thereby enabling realtime data collection and monitoring. E4UnityIntegration-MIT also provides the affordance of saving the E4 data into an external file for data analysis purposes.",1176
1091,Human-Centered Computing,Caglar Yildirim,"July 9th, 2023",Toward Computationally-Supported Roleplaying for Perspective-Taking,https://doi.org/10.1007/978-3-031-35930-9_11," Caglar Yildirim, Sercan Seng√ºn, Pakinam Amer, JJ Hawke, D. Fox Harrell. (2023). Toward Computationally-Supported Roleplaying for Perspective-Taking HCI (36), 154-171. https://doi.org/10.1007/978-3-031-35930-9_11","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1177
1092,Human-Centered Computing,Caglar Yildirim,"April 19th, 2023",Is ‚ÄúCategorical Imperative‚Äù Metaversal?: A Kantian Ethical Framework for Social Virtual Reality,https://doi.org/10.1145/3544549.3585911," Eyup Engin Kucuk, Caglar Yildirim. (2023). Is ""Categorical Imperative"" Metaversal?: A Kantian Ethical Framework for Social Virtual Reality CHI Extended Abstracts, 193:1-193:7. https://doi.org/10.1145/3544549.3585911","The increasing adoption of social virtual reality (VR) environments for socializing and collaborating with others has led to a growing concern about ethical issues in these immersive environments. Beyond the introduction of some practical guidelines, theoretical work on this topic has been scant. In this paper, we propose an ethical framework for social VR based on Kant‚Äôs Theory of Morality. In so doing, we argue that the Kantian concept of categorical imperative does apply to social VR, that the reality of VR is not different from the reality of real life, and that what is morally unacceptable in real life is and should be unacceptable in social VR. In our framework, we provide three principles that can aid users and developers of social VR environments in reasoning about ethical issues in social VR, while advocating for more theoretical approaches to addressing the issue of VR ethics in human-computer interaction circles.",1178
1093,Human-Centered Computing,Caglar Yildirim,"April 19th, 2023",Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings,https://doi.org/10.1145/3544549.3585649," Laura South, Caglar Yildirim, Amy Pavel, Michelle A. Borkin. (2023). Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings CHI Extended Abstracts, 111:1-111:7. https://doi.org/10.1145/3544549.3585649","Films often include sequences of flashing lights for visual effect that may inadvertently trigger seizures when viewed by individuals with photosensitive epilepsy (PSE). Warnings about photosensitive risk in films can help people with PSE make informed decisions about their personal safety, but little is known about how to design such warnings and what information to include. To better understand the design space for photosensitive risk warnings, we conducted a qualitative analysis of 265 crowdsourced warnings about flashing lights in films. We find that the crowdsourced warnings were tightly coupled to the scenic and temporal contexts of the films being described, unlike current practices for labeling media with potentially seizure-inducing sequences using general warnings that are not specific to the media at hand. As technological capabilities for detecting seizure-inducing sequences continue to improve, understanding how to effectively communicate this information to individuals with photosensitive epilepsy is critical for ensuring accessibility.",1179
1094,Human-Centered Computing,Caglar Yildirim,"September 20th, 2022",Co-located Immersive Gaming: A Comparison between Augmented and Virtual Reality,https://doi.org/10.1109/CoG51982.2022.9893708," Moinak Ghoshal, Juan Ong, Hearan Won, Dimitrios Koutsonikolas, Caglar Yildirim. (2022). Co-located Immersive Gaming: A Comparison between Augmented and Virtual Reality CoG, 594-597. https://doi.org/10.1109/CoG51982.2022.9893708","Escape from Kyle-Earth is a co-located, multiplayer XR game that can be played in both AR and VR using a head-mounted display. Results indicate that VR evoked a stronger sense of presence while its AR counterpart increased co-presence between players. There was no significant difference in game enjoyment between the two platforms.",1180
1095,Human-Centered Computing,Caglar Yildirim,"November 15th, 2021",Detecting Mental Workload in Virtual Reality Using EEG Spectral Data: A Deep Learning Approach,https://doi.org/10.1109/AIVR52153.2021.00039," H. Ved and C. Yildirim, ""Detecting Mental Workload in Virtual Reality Using EEG Spectral Data: A Deep Learning Approach,"" 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR), 2021, pp. 173-178, doi: 10.1109/AIVR52153.2021.00039.","Mental workload is the amount of mental effort a task requires users to exert. It is a critical consideration in various human-computer interaction scenarios, including virtual reality (VR) interactions. Automatic detection of mental workload as users are completing their tasks in interactive systems is crucial in terms of avoiding the possibility of overwhelming users and negatively affecting their task performance. This study investigated the possibility. of classifying mental workload levels in VR from electroencephalogram (EEG) signals through. the application of deep learning models.",1181
1096,Human-Centered Computing,Caglar Yildirim,"July 3rd, 2021",The Effect of Body-Based Haptic Feedback on Player Experience During VR Gaming,https://doi.org/10.1007/978-3-030-77599-5_13," Michael Carroll, Caglar Yildirim. (2021). The Effect of Body-Based Haptic Feedback on Player Experience During VR Gaming HCI (9), 163-171. https://doi.org/10.1007/978-3-030-77599-5_13","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1182
1097,Human-Centered Computing,Caglar Yildirim,"May 7th, 2021",Remote and Collaborative Virtual Reality Experiments via Social VR Platforms,https://doi.org/10.1145/3411764.3445426," David Saffo, Sara Di Bartolomeo, Caglar Yildirim, and Cody Dunne. 2021. Remote and Collaborative Virtual Reality Experiments via Social VR Platforms. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 523, 1‚Äì15. DOI:https://doi.org/10.1145/3411764.3445426","Virtual reality (VR) researchers struggle to conduct remote studies. Previous work has focused on working around limitations imposed by traditional crowdsourcing methods. However, the potential for leveraging social VR platforms for HCI evaluations is largely unexplored. These platforms have large VR-ready user populations, distributed synchronous virtual environments, and support for user-generated content. We demonstrate how social VR platforms can be used to practically and ethically produce valid research results by replicating two studies using one such platform (VRChat): a quantitative study on Fitts‚Äô Law and a qualitative study on tabletop collaboration. Our replication studies exhibited analogous results to the originals, indicating the research validity of this approach. Moreover, we easily recruited experienced VR users with their own hardware for synchronous, remote, and collaborative participation. We further provide lessons learned for future researchers experimenting using social VR platforms. This paper and all supplemental materials are available at osf.io/c2amz.",1183
1098,Human-Centered Computing,Caglar Yildirim,"July 24th, 2019",Cybersickness during VR gaming undermines game enjoyment: A mediation model,https://doi.org/10.1016/j.displa.2019.07.002," Yildirim, Caglar. ""Cybersickness during VR gaming undermines game enjoyment: a mediation model."" Displays 59 (2019): 35-43.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1184
1099,Human-Centered Computing,Ilmi Yoon,"March 7th, 2024",Socially Responsible Computing in an Introductory Course,https://doi.org/10.1145/3626252.3630926," Aakash Gautam, Anagha Kulkarni , Sarah Hug, Jane Lehr, Ilmi Yoon. (2024). Socially Responsible Computing in an Introductory Course SIGCSE (1), 373-379. https://doi.org/10.1145/3626252.3630926","Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum. Our students need to be able to examine the social complexities in which technology development and use are situated. Also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging. Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing. Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules. Rather than adding social on top of the technical content, our curricular approach seeks to weave them together. The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change. We share our approach to designing this new introductory socially responsible computing course and the students' reflections. We also highlight seven considerations for educators seeking to incorporate socially responsible computing.",1185
1100,Human-Centered Computing,Ilmi Yoon,"December 10th, 2023",Validated Image Caption Rating Dataset,http://papers.nips.cc/paper_files/paper/2023/hash/c0b91f9a3587bf35287f41dba5d20233-Abstract-Datasets_and_Benchmarks.html," Lothar D. Narins, Andrew T. Scott, Aakash Gautam, Anagha Kulkarni , Mar Castanon, Benjamin Kao, Shasta Ihorn, Yue-Ting Siu, James M. Mason, Alexander Blum, Ilmi Yoon. (2023). Validated Image Caption Rating Dataset NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/c0b91f9a3587bf35287f41dba5d20233-Abstract-Datasets_and_Benchmarks.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Datasets and Benchmarks Track Lothar D Narins, Andrew Scott, Aakash Gautam, Anagha Kulkarni, Mar Castanon, Benjamin Kao, Shasta Ihorn, Yue-Ting Siu, James M. Mason, Alexander Blum, Ilmi Yoon We present a new high-quality validated image caption rating (VICR) dataset. How well a caption fits an image can be difficult to assess due to the subjective nature of caption quality. How do we evaluate whether a caption is good? We generated a new dataset to help answer this question by using our new image caption rating system, which consists of a novel robust rating scale and gamified approach to gathering human ratings. We show that our approach is consistent and teachable. 113 participants were involved in generating the dataset, which is composed of 68,217 ratings among 15,646 image-caption pairs. Our new dataset has greater inter-rater agreement than the state of the art, and custom machine learning rating predictors that were trained on our dataset outperform previous metrics. We improve over Flickr8k-Expert in Kendall's W W by 12\% and in Fleiss' Œ∫ Œ∫ by 19\%, and thus provide a new benchmark dataset for image caption rating. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",1186
1101,Human-Centered Computing,Ilmi Yoon,"October 22nd, 2023",The Potential of a Visual Dialogue Agent In a Tandem Automated Audio Description System for Videos,https://doi.org/10.1145/3597638.3608402," Abigale Stangl, Shasta Ihorn, Yue-Ting Siu, Aditya Bodi, Mar Castanon, Lothar D. Narins, Ilmi Yoon. (2023). The Potential of a Visual Dialogue Agent In a Tandem Automated Audio Description System for Videos ASSETS, 32:1-32:17. https://doi.org/10.1145/3597638.3608402","The relentless pace of video production exacerbates the digital accessibility gap that individuals who are blind or low vision (BLV) face on a daily basis, resulting in disproportionate exclusion from community opportunities and risk management. Whereas previous automated audio description (AD) systems provide single-tool approaches for delivering minimum viable description (MVD) or delivering on-demand visual question answering (VQA), we present a tandem AI-based AD tool that combines MVD and on-demand VQA. A user study with 26 BLV individuals explored how the tandem system may be used under the conditions of delivering MVD and/or on-demand VQA with AI-only or human-in-the-loop support. When each tool was used in isolation, AI-only conditions scored significantly lower in both user enjoyment and comprehension. When used in tandem, AI-only conditions matched outcomes delivered with human-in-the-loop, which suggests that AI-only AD tools may be most effective when both types of tools are used in tandem. A multimodal analysis of interactions with the tandem system revealed areas for system improvement in terms of the timing of AD delivery and accurate content delivery. We discuss how the use of both types of tools in a tandem system can mitigate some of the digital frictions that have plagued efforts in machine learning and automated tools for accessibility.",1187
1102,Machine Learning,Christopher Amato,"December 10th, 2024",SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html," Ethan Rathbun, Christopher Amato, Alina Oprea. (2024). SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Ethan Rathbun, Christopher Amato, Alina Oprea Reinforcement learning (RL) is an actively growing field that is seeing increased usage in real-world, safety-critical applications -- making it paramount to ensure the robustness of RL algorithms against adversarial attacks. In this work we explore a particularly stealthy form of training-time attacks against RL -- backdoor poisoning. Here the adversary intercepts the training of an RL agent with the goal of reliably inducing a particular action when the agent observes a pre-determined trigger at inference time. We uncover theoretical limitations of prior work by proving their inability to generalize across domains and MDPs. Motivated by this, we formulate a novel poisoning attack framework which interlinks the adversary's objectives with those of finding an optimal policy -- guaranteeing attack success in the limit. Using insights from our theoretical analysis we develop ""SleeperNets"" as a universal backdoor attack which exploits a newly proposed threat model and leverages dynamic reward poisoning techniques. We evaluate our attack in 6 environments spanning multiple domains and demonstrate significant improvements in attack success over existing methods, while preserving benign episodic return.",1188
1103,Machine Learning,Christopher Amato,"August 8th, 2024",Robot Navigation in Unseen Environments using Coarse Maps,https://doi.org/10.1109/ICRA57147.2024.10611256," Chengguang Xu, Christopher Amato, Lawson L. S. Wong. (2024). Robot Navigation in Unseen Environments using Coarse Maps ICRA, 2932-2938. https://doi.org/10.1109/ICRA57147.2024.10611256","Can an autonomous robot directly navigate in previously unseen environments using coarse maps? We propose the Coarse Map Navigator (CMN), a navigation framework that can perform robot navigation in unseen environments. Empirical results demonstrate that CMN achieves high navigation success rates in unseen. environments. The study was presented at the 2024 IEEE International Conference on Robotics and Automation (ICRA) in Yokohama, Japan. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",1189
1104,Machine Learning,Christopher Amato,"December 13th, 2023",On-Robot Bayesian Reinforcement Learning for POMDPs,https://doi.org/10.1109/IROS55552.2023.10342114," Hai Nguyen, Sammie Katt, Yuchen Xiao, Christopher Amato. (2023). On-Robot Bayesian Reinforcement Learning for POMDPs IROS, 9480-9487. https://doi.org/10.1109/IROS55552.2023.10342114","Bayesian reinforcement learning (BRL) is uniquely positioned as such a solution method. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach can, for example, utilize typical low-level robot simulators and handle uncertainty over unknown dynamics of the environment. We empirically demonstrate its efficiency by performing on-robot learning in two human-ro Bot interaction tasks with uncertainty about human behavior, achieving near-optimal performance after only a handful of real-world episodes.",1190
1105,Machine Learning,Christopher Amato,"May 31st, 2023",Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning,https://proceedings.mlr.press/v202/daley23a.html," Brett Daley, Martha White, Christopher Amato, Marlos C. Machado. (2023). Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning ICML, 6818-6835. https://proceedings.mlr.press/v202/daley23a.html","Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across Œª Œª -values in an off-policy control task.",1191
1106,Machine Learning,Christopher Amato,"June 28th, 2022",A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning,https://ojs.aaai.org/index.php/AAAI/article/view/21171," Xueguang Lyu, Andrea Baisero, Yuchen Xiao, Christopher Amato. (2022). A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning AAAI, 9396-9404. https://ojs.aaai.org/index.php/AAAI/article/view/21171","Abstract Centralized Training for Decentralized Execution, where training is done in a centralized offline fashion, has become a popular solution paradigm in Multi-Agent Reinforcement Learning. Many such methods take the form of actor-critic with state-based critics, since centralized training allows access to the true system state, which can be useful during training despite not being available at execution time. State-based critics have become a common empirical choice, albeit one which has had limited theoretical justification or analysis. In this paper, we show that state-based critics can introduce bias in the policy gradient estimates, potentially undermining the asymptotic guarantees of the algorithm. We also show that, even if the state-based critics do not introduce any bias, they can still result in a larger gradient variance, contrary to the common intuition. Finally, we show the effects of the theories in practice by comparing different forms of centralized critics on a wide range of common benchmarks, and detail how various environmental properties are related to the effectiveness of different types of critics.",1192
1107,Machine Learning,Christopher Amato,"August 11th, 2021",Reconciling Rewards with Predictive State Representations,https://doi.org/10.24963/ijcai.2021/299," Andrea Baisero, Christopher Amato. (2021). Reconciling Rewards with Predictive State Representations IJCAI, 2170-2176. https://doi.org/10.24963/ijcai.2021/299","Copyright ¬© 2025,",1193
1108,Machine Learning,Christopher Amato,"January 1st, 2020",To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots,https://doi.org/10.1109/IROS45743.2020.9341607," Balint Gucsi, Danesh S. Tarapore, William Yeoh , Christopher Amato, Long Tran-Thanh. (2020). To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots IROS, 7935-7940. https://doi.org/10.1109/IROS45743.2020.9341607","Social robots can efficiently gather user preferences without exceeding the allowed user annoyance threshold. To do so, we use a Gazebo based simulated office environment with a TIAGo Steel robot. We then test our approach on the aforementioned simulated environment and demonstrate that it can accurately estimate user preferences.",1194
1109,Machine Learning,Christopher Amato,"September 19th, 2019",Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net,https://arxiv.org/abs/1909.08776," Xiao, Yuchen & Hoffman, Joshua & Xia, Tian & Amato, Christopher. (2020). Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net.","In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec-MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near-centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.",1195
1110,Machine Learning,David Bau,"November 1st, 2024",Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs,https://aclanthology.org/2024.emnlp-main.543," Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs EMNLP, 9727-9739. https://aclanthology.org/2024.emnlp-main.543","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b‚Äôs tokenizer splits the word ‚Äúpatrolling‚Äù into two tokens, ‚Äúpat‚Äù and ‚Äúrolling‚Äù, neither of which correspond to semantically meaningful units like ‚Äúpatrol‚Äù or ""-ing.‚Äù Similarly, the overall meanings of named entities like ‚ÄúNeil Young‚Äù and multi-word expressions like ‚Äúbreak a leg‚Äù cannot be directly inferred from their constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups of tokens into useful higher-level representations? In this work, we find that last token representations of named entities and multi-token words exhibit a pronounced ‚Äúerasure‚Äù effect, where information about previous and current tokens is rapidly forgotten in early layers. Using this observation, we propose a method to ‚Äúread out‚Äù the implicit vocabulary of an autoregressive LLM by examining differences in token representations across layers, and present results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is the first attempt to probe the implicit vocabulary of an LLM.",1196
1111,Machine Learning,David Bau,"January 16th, 2024",Linearity of Relation Decoding in Transformer Language Models,https://openreview.net/forum?id=w7LU2s14kE," Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, David Bau. (2024). Linearity of Relation Decoding in Transformer Language Models ICLR. https://openreview.net/forum?id=w7LU2s14kE","Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations. For a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. The authors conduct experiments on 47 different relations, showing that linear approximations hold for some but not all relations.",1197
1112,Machine Learning,David Bau,"January 16th, 2024",Function Vectors in Large Language Models,https://openreview.net/forum?id=AwyxtyMwaG," Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. (2024). Function Vectors in Large Language Models ICLR. https://openreview.net/forum?id=AwyxtyMwaG",This paper delves into the concept of function vectors (FVs) within autoregressive transformer language models (LLMs) FVs encapsulate task-specific information and exhibit robustness across various contexts. The study uncovers that FVs don't directly execute tasks but trigger the model to perform them through complex computations.,1198
1113,Machine Learning,David Bau,"January 16th, 2024",Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking,https://openreview.net/forum?id=8sKcAWOf2D," Nikhil Prakash, Tamar Rott Shaham, Tal Haklay, Yonatan Belinkov, David Bau. (2024). Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking ICLR. https://openreview.net/forum?id=8sKcAWOf2D",The paper focuses on entity tracking (model inferring properties with an entity previously defined in the input context) to understand how LMs change during fine-tuning. They use a path-patching technique on synthetic dataset to isolate circuits responsible for entity tracking. They find all three models reach high faithfulness scores with the circuit identified in Llama-7B.,1199
1114,Machine Learning,David Bau,"January 15th, 2024",Erasing Concepts from Diffusion Models,https://doi.org/10.1109/ICCV51070.2023.00230," Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau. (2023). Erasing Concepts from Diffusion Models ICCV, 2426-2436. https://doi.org/10.1109/ICCV51070.2023.00230","Motivated by concerns that large-scale diffusion models can produce undesirable output such as sexually explicit content or copyrighted artistic styles. We propose a fine-tuning method that can erase a visual concept from a pre-trained diffusion model, given only the name of the style. Unlike previous methods, our approach can remove concepts from a diffusion model permanently rather than modifying the output at the inference time, so it cannot be circumvented. Our code, data, and results are available at erasing.baulab.info.",1200
1115,Machine Learning,David Bau,"November 8th, 2023",Future Lens: Anticipating Subsequent Tokens from a Single Hidden State,https://arxiv.org/abs/2311.04897," Pal, K., Sun, J., Yuan, A., Wallace, B.C., & Bau, D. (2023). Future Lens: Anticipating Subsequent Tokens from a Single Hidden State. ArXiv, abs/2311.04897.","We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at positiontin an input, can we reliably anticipate the tokens that will appear at positions‚â•t+2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a ""Future Lens"" visualization that uses these methods to create a new view of transformer states.",1201
1116,Machine Learning,David Bau,"September 7th, 2023",FIND: A Function Description Benchmark for Evaluating Interpretability Methods,http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html," Sarah Schwettmann, Tamar Rott Shaham, Joanna Materzynska, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, Antonio Torralba . (2023). FIND: A Function Description Benchmark for Evaluating Interpretability Methods NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html",FIND (Function INterpretation and Description) is a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks. The results suggest that FIND will be useful for characterizing the performance of more sophisticated interpretable methods before they are applied to real- world models.,1202
1117,Machine Learning,David Bau,"February 28th, 2022",Toward a Visual Concept Vocabulary for GAN Latent Space,https://doi.org/10.1109/ICCV48922.2021.00673," Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas, Antonio Torralba . (2021). Toward a Visual Concept Vocabulary for GAN Latent Space ICCV, 6784-6792. https://doi.org/10.1109/ICCV48922.2021.00673","New method for building open-ended vocabularies of primitive visual concepts. Concepts learned with our approach are reliable and composable, and enabling fine-grained manipulation of image style and content. Based on automatic identification of perceptually salient directions based on their layer selectivity. Human annotation of these directions with free-form, natural language descriptions. decomposition of these annotations into a visual concept vocabulary.",1203
1118,Machine Learning,David Bau,"February 10th, 2022",Locating and Editing Factual Associations in GPT,https://arxiv.org/abs/2202.05262," Meng, K., Bau, D., Andonian, A., & Belinkov, Y. (2022). Locating and Editing Factual Associations in GPT. Neural Information Processing Systems.","We analyze the storage and recall of factual associations in autoregressive transformer language models, finding evidence that these associations correspond to localized, directly-editable computations. We first develop a causal intervention for identifying neuron activations that are decisive in a model's factual predictions. This reveals a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions while processing subject tokens. To test our hypothesis that these computations correspond to factual association recall, we modify feed-forward weights to update specific factual associations using Rank-One Model Editing (ROME). We find that ROME is effective on a standard zero-shot relation extraction (zsRE) model-editing task, comparable to existing methods. To perform a more sensitive evaluation, we also evaluate ROME on a new dataset of counterfactual assertions, on which it simultaneously maintains both specificity and generalization, whereas other methods sacrifice one or another. Our results confirm an important role for mid-layer feed-forward modules in storing factual associations and suggest that direct manipulation of computational mechanisms may be a feasible approach for model editing. The code, dataset, visualizations, and an interactive demo notebook are available atthis https URL",1204
1119,Machine Learning,David Bau,"January 28th, 2022",Disentangling visual and written concepts in CLIP,https://doi.org/10.1109/CVPR52688.2022.01592," Joanna Materzynska, Antonio Torralba , David Bau. (2022). Disentangling visual and written concepts in CLIP CVPR, 16389-16398. https://doi.org/10.1109/CVPR52688.2022.01592","The CLIP network measures the similarity between natural text and images. In this work, we investigate the entanglement of the representation of word images and natural images in its image encoder. This is consistent with previous research that suggests that the meaning and the spelling of a word might be entangled deep within the network. We find that our methods are able to cleanly separate spelling capabilities of CLIP from the visual processing of natural images. On the other hand, we also find that CLIP has a strong ability to match nonsense words, suggesting that processing of letters is separated from processing of their meaning.",1205
1120,Machine Learning,David Bau,"August 5th, 2021",Sketch Your Own GAN,https://peterwang512.github.io/GANSketching/," Sheng-Yu Wang, David Bau, and Jun-Yan Zhu. Sketch Your Own GAN. Proceedings of the IEEE/CVF International Conference on Computer Vision. (ICCV 2021)","Our method can customize a pre-trained GAN to match input sketches. Interpolation using our customized models. Latent space interpolation is smooth with our customized models. Image editing using our customized models. (a) Given a real image, (b) we project it to the original model's noise z using Huh et al. (c) We feed the projected z to the standing cat model trained on sketches. (d) we edit the image with `add fur` operation using GANSpace . We can interpolate between the customized model by interpolating the W-latent space.",1206
1121,Machine Learning,David Bau,"January 1st, 2020",Diverse Image Generation via Self-Conditioned GANs,https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html," Steven Liu, Tongzhou Wang , David Bau, Jun-Yan Zhu, Antonio Torralba . (2020). Diverse Image Generation via Self-Conditioned GANs CVPR, 14274-14283. https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html","We introduce a simple but effective unsupervised method for generating diverse images. We train a class-conditional GAN model without using manually annotated class labels. Instead, our model is conditional on labels automatically derived from clustering in the discriminator's feature space. Our clustering step automatically discovers diverse modes, and explicitly requires the generator to cover them. Experiments on standard mode collapse benchmarks show that our method outperforms several competing methods when addressing mode collapse. Our method also performs well on large-scale datasets such as ImageNet and Places365, improving both diversity and standard metrics (e.g., Frechet Inception Distance), compared to previous methods.",1207
1122,Machine Learning,Divya Chaudhary,"February 6th, 2025",Leveraging Geolocation in Clinical Records to Improve Alzheimer‚Äôs Disease Diagnosis Using DMV Framework,https://doi.org/10.48550/arXiv.2502.04288," Peng Zhang, Divya Chaudhary. (2025). Leveraging Geolocation in Clinical Records to Improve Alzheimer's Disease Diagnosis Using DMV Framework CoRR, abs/2502.04288. https://doi.org/10.48550/arXiv.2502.04288","Alzheimer's Disease (AD) early detection is critical for enabling timely intervention and improving patient outcomes. This paper presents a DMV framework using Llama3-70B and GPT-4o as embedding models to analyze clinical notes and predict a continuous risk score associated with early AD onset. Framing the task as a regression problem, we model the relationship between linguistic features in clinical notes (inputs) and a target variable (data value) that answers specific questions related to AD risk within certain topic categories. By leveraging a multi-faceted feature set that includes geolocation data, we capture additional environmental context potentially linked to AD. Our results demonstrate that the integration of the geolocation information significantly decreases the error of predicting early AD risk scores over prior models by 28.57% (Llama3-70B) and 33.47% (GPT4-o). Our findings suggest that this combined approach can enhance the predictive accuracy of AD risk assessment, supporting early diagnosis and intervention in clinical settings. Additionally, the framework's ability to incorporate geolocation data provides a more comprehensive risk assessment model that could help healthcare providers better understand and address environmental factors contributing to AD development.",1208
1123,Machine Learning,Divya Chaudhary,"December 19th, 2024",Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization,https://doi.org/10.48550/arXiv.2412.15453," Sahil Wadhwa, Chengtian Xu, Haoming Chen, Aakash Mahalingam, Akankshya Kar, Divya Chaudhary. (2024). Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization CoRR, abs/2412.15453. https://doi.org/10.48550/arXiv.2412.15453","The automatic generation of counter-speech (CS) is a critical strategy for addressing hate speech by providing constructive and informed responses. However, existing methods often fail to generate high-quality, impactful, and scalable CS, particularly across diverse linguistic contexts. In this paper, we propose a novel methodology to enhance CS generation by aligning Large Language Models (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Our approach leverages DPO to align LLM outputs with human preferences, ensuring contextually appropriate and linguistically adaptable responses. Additionally, we incorporate knowledge grounding to enhance the factual accuracy and relevance of generated CS. Experimental results demonstrate that DPO-aligned models significantly outperform SFT baselines on CS benchmarks while scaling effectively to multiple languages. These findings highlight the potential of preference-based alignment techniques to advance CS generation across varied linguistic settings. The model supervision and alignment is done in English and the same model is used for reporting metrics across other languages like Basque, Italian, and Spanish.",1209
1124,Machine Learning,Divya Chaudhary,"December 19th, 2024",SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval,https://doi.org/10.48550/arXiv.2412.15443," Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary. (2024). SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval CoRR, abs/2412.15443. https://doi.org/10.48550/arXiv.2412.15443","Retrieval-Augmented Generation (RAG) systems have become pivotal in leveraging vast corpora to generate informed and contextually relevant responses, notably reducing hallucinations in Large Language Models. Despite significant advancements, these systems struggle to efficiently process and retrieve information from large datasets while maintaining a comprehensive understanding of the context. This paper introduces SKETCH, a novel methodology that enhances the RAG retrieval process by integrating semantic text retrieval with knowledge graphs, thereby merging structured and unstructured data for a more holistic comprehension. SKETCH, demonstrates substantial improvements in retrieval performance and maintains superior context integrity compared to traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER, NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline approaches on key RAGAS metrics such as answer_relevancy, faithfulness, context_precision and context_recall. Notably, on the Italian Cuisine dataset, SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99, representing the highest performance across all evaluated metrics. These results highlight SKETCH's capability in delivering more accurate and contextually relevant responses, setting new benchmarks for future retrieval systems.",1210
1125,Machine Learning,Divya Chaudhary,"June 16th, 2024",Hybrid Deep Learning Framework for Enhanced Melanoma Detection,https://doi.org/10.48550/arXiv.2408.00772," Peng Zhang, Divya Chaudhary. (2024). Hybrid Deep Learning Framework for Enhanced Melanoma Detection CoRR, abs/2408.00772. https://doi.org/10.48550/arXiv.2408.00772","Cancer is a leading cause of death worldwide, necessitating advancements in early detection and treatment technologies. In this paper, we present a novel and highly efficient melanoma detection framework that synergistically combines the strengths of U-Net for segmentation and EfficientNet for the classification of skin images. The primary objective of our study is to enhance the accuracy and efficiency of melanoma detection through an innovative hybrid approach. We utilized the HAM10000 dataset to meticulously train the U-Net model, enabling it to precisely segment cancerous regions. Concurrently, we employed the ISIC 2020 dataset to train the EfficientNet model, optimizing it for the binary classification of skin cancer. Our hybrid model demonstrates a significant improvement in performance, achieving a remarkable accuracy of 99.01% on the ISIC 2020 dataset. This exceptional result underscores the superiority of our approach compared to existing model structures. By integrating the precise segmentation capabilities of U-Net with the advanced classification prowess of EfficientNet, our framework offers a comprehensive solution for melanoma detection. The results of our extensive experiments highlight the high accuracy and reliability of our method in both segmentation and classification tasks. This indicates the potential of our hybrid approach to significantly enhance cancer detection, providing a robust tool for medical professionals in the early diagnosis and treatment of melanoma. We believe that our framework can set a new benchmark in the field of automated skin cancer detection, encouraging further research and development in this crucial area of medical imaging.",1211
1126,Machine Learning,Divya Chaudhary,"March 5th, 2023",WADER at SemEval-2023 Task 9: A Weak-labelling framework for Data augmentation in tExt Regression Tasks,https://doi.org/10.48550/arXiv.2303.02758," Manan Suri, Aaryak Garg, Divya Chaudhary, Ian Gorton, Bijendra Kumar. (2023). WADER at SemEval-2023 Task 9: A Weak-labelling framework for Data augmentation in tExt Regression Tasks CoRR, abs/2303.02758. https://doi.org/10.48550/arXiv.2303.02758","Intimacy is an essential element of human relationships and language is a crucial means of conveying it. Textual intimacy analysis can reveal social norms in different contexts and serve as a benchmark for testing computational models' ability to understand social information. In this paper, we propose a novel weak-labeling strategy for data augmentation in text regression tasks called WADER. WADER uses data augmentation to address the problems of data imbalance and data scarcity and provides a method for data augmentation in cross-lingual, zero-shot tasks. We benchmark the performance of State-of-the-Art pre-trained multilingual language models using WADER and analyze the use of sampling techniques to mitigate bias in data and optimally select augmentation candidates. Our results show that WADER outperforms the baseline model and provides a direction for mitigating data imbalance and scarcity in text regression tasks.",1212
1127,Machine Learning,Divya Chaudhary,"March 6th, 2022",I don‚Äôt feel so good! Detecting Depressive Tendencies using Transformer-based Multimodal Frameworks,https://doi.org/10.1145/3578741.3578817," Manan Suri, Nalin Semwal, Divya Chaudhary, Ian Gorton, Bijendra Kumar. (2022). I don't feel so good! Detecting Depressive Tendencies using Transformer-based Multimodal Frameworks MLNLP, 360-365. https://doi.org/10.1145/3578741.3578817",One of the most common mental illnesses that affects 5% of adults globally is depression. The advancement of social media has meant that more and more people have gained a platform to voice their thoughts and beliefs. People‚Äôs social media interactions and posted content can be used to infer critical characteristics such as depressive tendencies which will allow for timely intervention and help. This paper describes a novel supervised approach to detect depressive tendencies in Twitter users using multimodal frameworks which account for user interaction and online behaviour in addition to the tweet content processed using transformers like BERT. The performance of three multimodal frameworks is described with different methods for combining modalities. The best result is obtained a cross-modality based model which improves the baseline by 12% points.,1213
1128,Machine Learning,Divya Chaudhary,"July 15th, 2019",Cost optimized Hybrid Genetic-Gravitational Search Algorithm for load scheduling in Cloud Computing,https://doi.org/10.1016/j.asoc.2019.105627," Divya Chaudhary, Bijendra Kumar, Cost optimized Hybrid Genetic-Gravitational Search Algorithm for load scheduling in Cloud Computing, Applied Soft Computing, Volume 83, 2019, 105627, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2019.105627.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1214
1129,Machine Learning,Divya Chaudhary,"January 24th, 2019",Diversity and Progress Controlled Gravitational Search Algorithm for Balancing Load in Cloud,https://doi.org/10.1007/978-981-13-5826-5_24," Chaudhary D., Kumar B., Garg S. (2019) Diversity and Progress Controlled Gravitational Search Algorithm for Balancing Load in Cloud. In: Thampi S., Madria S., Wang G., Rawat D., Alcaraz Calero J. (eds) Security in Computing and Communications. SSCC 2018. Communications in Computer and Information Science, vol 969. Springer, Singapore. https://doi.org/10.1007/978-981-13-5826-5_24","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1215
1130,Machine Learning,Divya Chaudhary,"July 24th, 2018",Cloudy GSA for load scheduling in cloud computing,https://www.sciencedirect.com/science/article/abs/pii/S1568494618304344," Divya Chaudhary, Bijendra Kumar, Cloudy GSA for load scheduling in cloud computing, Applied Soft Computing, Volume 71, 2018, Pages 861-871, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2018.07.046.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1216
1131,Machine Learning,Divya Chaudhary,"March 8th, 2018",Improved Bee Swarm Optimization Algorithm for Load Scheduling in Cloud Computing Environment,https://doi.org/10.1007/978-981-10-8527-7_33," Chaudhary D., Kumar B., Sakshi S., Khanna R. (2018) Improved Bee Swarm Optimization Algorithm for Load Scheduling in Cloud Computing Environment. In: Panda B., Sharma S., Roy N. (eds) Data Science and Analytics. REDSET 2017. Communications in Computer and Information Science, vol 799. Springer, Singapore. https://doi.org/10.1007/978-981-10-8527-7_33","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1217
1132,Machine Learning,Jennifer Dy,"March 28th, 2022",Deep Layer-wise Networks Have Closed-Form Weights,https://proceedings.mlr.press/v151/tzu-wu22a.html," Chieh Tzu Wu, Aria Masoomi, Arthur Gretton, Jennifer G. Dy. (2022). Deep Layer-wise Networks Have Closed-Form Weights AISTATS, 188-225. https://proceedings.mlr.press/v151/tzu-wu22a.html","There is currently a debate within the neuroscience community over the likelihood of the brain performing backpropagation (BP). To better mimic the brain, training a network one layer at a time with only a ""single forward pass"" has been proposed as an alternative to bypass BP; we refer to these networks as ""layer-wise"" networks. We continue the work on layer-wise networks by answering two outstanding questions. First, do they have a closed-form solution? Second, how do we know when to stop adding more layers? This work proves that the ""Kernel Mean Embedding"" is the closed-form solution that achieves the network global optimum while driving these networks to converge towards a highly desirable kernel for classification; we call it the Neural Indicator Kernel.",1218
1133,Machine Learning,Jennifer Dy,"February 23rd, 2021",Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth,https://doi.org/10.1109/ICMLA51294.2020.00124," Shi Dong , Zlatan Feric, Guangyu Li, Chieh Wu, April Z. Gu, Jennifer G. Dy, John Meeker, Ingrid Y. Padilla, Jos√© Cordero, Carmen Velez Vega, Zaira Rosario, Akram Alshawabkeh, David R. Kaeli. (2020). Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth ICMLA, 759-764. https://doi.org/10.1109/ICMLA51294.2020.00124","We propose Ensemble Learning models to identify factors contributing to preterm birth. Our work leverages a rich dataset collected by a NIEHS P42 Center in Puerto Rico. We propose two novel methods: 1) Missing Data Rate and Accuracy Based Aggregation (MAA) and 2) Entropy and Accuracy based Aggregation. Both proposed models balance the degree of data variance introduced by the missing data handling during the feature selection process, while maintaining model performance. Our results show a 42% improvement in sensitivity versus fallout over previous state-of-the-art methods. We leverage and compare multiple Ensemble Feature selection methods, including Complete Linear Aggregation, Weighted Mean Aggregation and Feature Occurrence Frequency (OFA)",1219
1134,Machine Learning,Jennifer Dy,"December 1st, 2020",Instance-wise Feature Grouping,https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html," Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang , Peter J. Castaldi, Jennifer G. Dy. (2020). Instance-wise Feature Grouping NeurIPS. https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html","Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang, Peter Castaldi, Jennifer Dy In many learning problems, the domain scientist is often interested in discovering the groups of features that are redundant and are important for classification. Moreover, the features that belong to each group, and the important feature groups may vary per sample. But what do we mean by feature redundancy? In this paper, we formally define two types of redundancies using information theory: \textit{Representation} and \textit{Relevant redundancies}. We leverage these redundancies to design a formulation for instance-wise feature group discovery and reveal a theoretical guideline to help discover the appropriate number of groups. We approximate mutual information via a variational lower bound and learn the feature group and selector indicators with Gumbel-Softmax in optimizing our formulation. Experiments on synthetic data validate our theoretical claims. Experiments on MNIST, Fashion MNIST, and gene expression datasets show that our method discovers feature groups with high classification accuracies.",1220
1135,Machine Learning,Ehsan Elhamifar,"September 16th, 2024",Error Detection in Egocentric Procedural Task Videos,https://doi.org/10.1109/CVPR52733.2024.01765," Shih-Po Lee, Zijia Lu, Zekun Zhang, Minh Hoai, Ehsan Elhamifar. (2024). Error Detection in Egocentric Procedural Task Videos CVPR, 18655-18666. https://doi.org/10.1109/CVPR52733.2024.01765","We present a new egocentric procedural error dataset containing videos with various types of errors as well as normal videos. We propose to combine holistic frame features with relations features, which we learn by building a graph using active object detection followed by a Graph Convolutional Network. To handle errors, unseen during training, we use our contrastive step prototype learning to learn multiple prototypes for each step, capturing variations of error-free step executions. By experiments on three datasets, we show that our proposed framework outperforms state-of-the-art video anomaly detection methods.",1221
1136,Machine Learning,Ehsan Elhamifar,"September 16th, 2024",FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation,https://doi.org/10.1109/CVPR52733.2024.01721," Zijia Lu, Ehsan Elhamifar. (2024). FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation CVPR, 18175-18185. https://doi.org/10.1109/CVPR52733.2024.01721","We study supervised action segmentation, whose goal is to predict framewise action labels of a video. We propose an efficient Frame-Action Cross-attention Temporal modeling (FACT) framework that performs temporal modeling withframe and action features in parallel. FACT network contains aframe branch to learn frame-level information with convolutions and frame features, action branch to learning action-level depen-dencies with transformers and action tokens. We also propose a new matching loss to ensure each action to-ken uniquely encodes an action segment, thus better captures its semantics.",1222
1137,Machine Learning,Ehsan Elhamifar,"September 16th, 2024",Learning to Segment Referred Objects from Narrated Egocentric Videos,https://doi.org/10.1109/CVPR52733.2024.01375," Yuhan Shen, Huiyu Wang, Xitong Yang, Matt Feiszli, Ehsan Elhamifar, Lorenzo Torresani, Effrosyni Mavroudi. (2024). Learning to Segment Referred Objects from Narrated Egocentric Videos CVPR, 14510-14520. https://doi.org/10.1109/CVPR52733.2024.01375","Egocentric videos provide a first-person perspective of the wearer's activities, involving simultaneous interactions with multiple objects. Given an egocentric video clip and a narration, our aim is to segment object instances mentioned in the narration, with-out using any spatial annotations during training. Our model harnesses vision-language models pre-trained on image-text pairs to embed region masks and object phrases. Our approach achieves state-of-the-art zero-shot pixel-level grounding performance compared to strong baselines under similar supervision.",1223
1138,Machine Learning,Ehsan Elhamifar,"September 16th, 2024",Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos,https://doi.org/10.1109/CVPR52733.2024.01722," Yuhan Shen, Ehsan Elhamifar. (2024). Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos CVPR, 18186-18197. https://doi.org/10.1109/CVPR52733.2024.01722","We address the problem of online (streaming) action seg-mentation for egocentric procedural task videos. We propose an online action segmentation framework by first modifying existing architectures to make them causal. Third, we propose to learn task graphs from training videos and leverage them to obtain smooth and procedure-consistent segmentations. With the combination of progress and task graph with casualaction segmentation, our frame-work effectively addresses prediction uncertainty and over-segmentation. We also develop a novel action progress prediction module to dynamically estimate the progress of ongoing actions.",1224
1139,Machine Learning,Ehsan Elhamifar,"November 3rd, 2022",Zero-Shot Attribute Attacks on Fine-Grained Recognition Models,https://doi.org/10.1007/978-3-031-20065-6_16," Nasim Shafiee, Ehsan Elhamifar. (2022). Zero-Shot Attribute Attacks on Fine-Grained Recognition Models ECCV (5), 262-282. https://doi.org/10.1007/978-3-031-20065-6_16","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1225
1140,Machine Learning,Ehsan Elhamifar,"September 27th, 2022",Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency,https://doi.org/10.1109/CVPR52688.2022.01928," Zijia Lu, Ehsan Elhamifar. (2022). Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency CVPR, 19871-19881. https://doi.org/10.1109/CVPR52688.2022.01928","We address the problem of set-supervised action learning, whose goal is to learn an action segmentation model using weak supervision. We propose an attention-based method with a new Pairwise Ordering Consistency (POC) loss that encourages that for each common action pair in two videos of the same task, the attentions of actions follow a similar ordering. Unlike existing sequence alignment methods, which misalign actions in videos with different orderings, our POC loss efficiently aligns videos with same action orders and is differentiable, which enables end-to-end training. Our method efficiently learns the actions and their temporal locations, therefore, extends the existing attention- based action localization methods.",1226
1141,Machine Learning,Ehsan Elhamifar,"September 27th, 2022",Semi-Weakly-Supervised Learning of Complex Actions from Instructional Task Videos,https://doi.org/10.1109/CVPR52688.2022.00334," Yuhan Shen, Ehsan Elhamifar. (2022). Semi-Weakly-Supervised Learning of Complex Actions from Instructional Task Videos CVPR, 3334-3344. https://doi.org/10.1109/CVPR52688.2022.00334","We address the problem of action segmentation in instructional task videos with a small number of weakly-labeled training videos and a large number of unlabeled videos. We propose a general SWSL framework that can efficiently learn from both types of videos and can leverage any of the existingweakly-supervisedaction segmentation methods. We develop a Soft Restricted Edit (SRE) loss to encourage small variations between the predicted transcripts of unlLabeled videos and ground-truth transcripts of the weaklylabeled videos of the same task. By experiments on two benchmark datasets, we demonstrate that our approach can significantly improve the performance by using unlabeling videos.",1227
1142,Machine Learning,Ehsan Elhamifar,"September 27th, 2022",Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling,https://doi.org/10.1109/CVPR52688.2022.00689," Dat Huynh, Jason Kuen, Zhe Lin, Jiuxiang Gu, Ehsan Elhamifar. (2022). Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling CVPR, 7010-7021. https://doi.org/10.1109/CVPR52688.2022.00689","Open-vocabulary instance segmentation aims at segmenting novel classes without mask annotations. We propose a cross-modal pseudo-labeling framework, which generates training pseudo masks by aligning word semantics in captions with visual features of object masks in images. We significantly improve mAP score by 4.5% on MS-COCO and 5.1% on the large-scale Open Images & Conceptual Captions datasets compared to the state-of-the-art.",1228
1143,Machine Learning,Ehsan Elhamifar,"June 27th, 2012",Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation,http://link.springer.com/chapter/10.1007%2F978-3-642-30618-1_17," Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation, L. Tao, E. Elhamifar, S. Khudanpur, G. Hager, and R. Vidal, Information Processing in Computer Assisted Interventions (IPCAI), 2012.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1229
1144,Machine Learning,Tina Eliassi-Rad,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1230
1145,Machine Learning,Tina Eliassi-Rad,"August 5th, 2024",Using overlapping methods to counter adversaries in community detection,https://doi.org/10.1093/comnet/cnae030," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Using overlapping methods to counter adversaries in community detection J. Complex Networks, 12. https://doi.org/10.1093/comnet/cnae030","Community detection is a useful data triage tool that can identify subsets of the network that a data analyst should investigate. In an adversarial scenario, the graph may be manipulated to avoid scrutiny of certain nodes by the analyst. Robustness to such behaviour is an important consideration for data analysts in high-stakes scenarios such as cyber defense and counterterrorism. We find that, when the attacker has a sufficient budget, overlapping community detection methods outperform non-overlapping methods, often overwhelmingly so. Our extensible analytic framework enables network data analysts to take these attacks into account and use them to make better decisions about which nodes to focus on.",1231
1146,Machine Learning,Tina Eliassi-Rad,"May 30th, 2024",Distributed constrained combinatorial optimization leveraging hypergraph neural networks,https://doi.org/10.1038/s42256-024-00833-7," Nasimeh Heydaribeni, Xinrui Zhan, Ruisi Zhang, Tina Eliassi-Rad, Farinaz Koushanfar. (2024). Distributed constrained combinatorial optimization leveraging hypergraph neural networks Nat. Mac. Intell., 6, 664-672. https://doi.org/10.1038/s42256-024-00833-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1232
1147,Machine Learning,Tina Eliassi-Rad,"February 21st, 2024",Complex network effects on the robustness of graph convolutional networks,https://doi.org/10.1007/s41109-024-00611-9," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Complex network effects on the robustness of graph convolutional networks Appl. Netw. Sci., 9, 5. https://doi.org/10.1007/s41109-024-00611-9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1233
1148,Machine Learning,Tina Eliassi-Rad,"January 16th, 2024","A Survey on Hypergraph Mining: Patterns, Tools, and Generators",https://doi.org/10.48550/arXiv.2401.08878," Geon Lee, Fanchen Bu, Tina Eliassi-Rad, Kijung Shin. (2024). A Survey on Hypergraph Mining: Patterns, Tools, and Generators CoRR, abs/2401.08878. https://doi.org/10.48550/arXiv.2401.08878","Hypergraphs, which belong to the family of higher-order networks, are a natural and powerful choice for modeling group interactions in the real world. For example, when modeling collaboration networks, which may involve not just two but three or more people, the use of hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for hypergraph mining. The goal of hypergraph mining is to find structural properties recurring in real-world hypergraphs across different domains, which we call patterns. To find patterns, we need tools. We divide hypergraph mining tools into three categories: (1) null models (which help test the significance of observed patterns), (2) structural elements (i.e., substructures in a hypergraph such as open and closed triangles), and (3) structural quantities (i.e., numerical tools for computing hypergraph patterns such as transitivity). There are also hypergraph generators, whose objective is to produce synthetic hypergraphs that are a faithful representation of real-world hypergraphs. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for each and offer in-depth discussions for future research on hypergraph mining.",1234
1149,Machine Learning,Tina Eliassi-Rad,"December 18th, 2023",Using sequences of life-events to predict human lives,https://doi.org/10.1038/s43588-023-00573-5," Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Hvas Mortensen, Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann. (2024). Using sequences of life-events to predict human lives Nat. Comput. Sci., 4, 43-56. https://doi.org/10.1038/s43588-023-00573-5","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1235
1150,Machine Learning,Tina Eliassi-Rad,"November 14th, 2023",Attacking Shortest Paths by Cutting Edges,https://doi.org/10.1145/3622941," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2024). Attacking Shortest Paths by Cutting Edges ACM Trans. Knowl. Discov. Data, 18, 35:1-35:42. https://doi.org/10.1145/3622941","Identifying shortest paths between nodes in a network is a common graph analysis problem that is important for many applications involving routing of resources. An adversary that can manipulate the graph structure could alter traffic patterns to gain some benefit (e.g., make more money by directing traffic to a toll road). This article presents the Force Path Cut problem, in which an adversary removes edges from a graph to make a particular path the shortest between its terminal nodes. We prove that the optimization version of this problem is APX-hard but introduce PATHATTACK , a polynomial-time approximation algorithm that guarantees a solution within a logarithmic factor of the optimal value. In addition, we introduce the Force Edge Cut and Force Node Cut problems, in which the adversary targets a particular edge or node, respectively, rather than an entire path. We derive a nonconvex optimization formulation for these problems and derive a heuristic algorithm that uses PATHATTACK as a subroutine. We demonstrate all of these algorithms on a diverse set of real and synthetic networks, illustrating where the proposed algorithms provide the greatest improvement over baseline methods.",1236
1151,Machine Learning,Tina Eliassi-Rad,"August 21st, 2023",TenGAN: adversarially generating multiplex tensor graphs,https://doi.org/10.1007/s10618-023-00947-3," William Shiao, Benjamin A. Miller, Kevin Chan , Paul L. Yu, Tina Eliassi-Rad, Evangelos E. Papalexakis. (2024). TenGAN: adversarially generating multiplex tensor graphs Data Min. Knowl. Discov., 38, 1-21. https://doi.org/10.1007/s10618-023-00947-3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",1237
1152,Machine Learning,Tina Eliassi-Rad,"August 18th, 2023",Modeling self-propagating malware with epidemiological models,https://doi.org/10.1007/s41109-023-00578-z," Alesia Chernikova, Nicol√≤ Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. (2023). Modeling self-propagating malware with epidemiological models Appl. Netw. Sci., 8, 52. https://doi.org/10.1007/s41109-023-00578-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1238
1153,Machine Learning,Tina Eliassi-Rad,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",1239
1154,Machine Learning,Tina Eliassi-Rad,"May 30th, 2023",Defense Against Shortest Path Attacks,https://doi.org/10.48550/arXiv.2305.19083," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2023). Defense Against Shortest Path Attacks CoRR, abs/2305.19083. https://doi.org/10.48550/arXiv.2305.19083","Identifying shortest paths between nodes in a network is an important task in applications involving routing of resources. Recent work has shown that a malicious actor can manipulate a graph to make traffic between two nodes of interest follow their target path. In this paper, we develop a defense against such attacks by modifying the weights of the graph that users observe. The defender must balance inhibiting the attacker against any negative effects of the defense on benign users. Specifically, the defender's goals are: (a) to recommend the shortest paths possible to users, (b) for the lengths of the shortest paths in the published graph to be close to those of the same paths in the true graph, and (c) to minimize the probability of an attack. We formulate the defense as a Stackelberg game in which the defender is the leader and the attacker is the follower. In this context, we also consider a zero-sum version of the game, in which the defender's goal is to minimize cost while achieving the minimum possible attack probability. We show that this problem is NP-hard and propose heuristic solutions based on increasing edge weights along target paths in both the zero-sum and non-zero-sum settings. Relaxing some constraints of the original problem, we formulate a linear program for local optimization around a feasible point. We present defense results with both synthetic and real network datasets and show that these methods often reach the lower bound of the defender's cost.",1240
1155,Machine Learning,Tina Eliassi-Rad,"April 12th, 2023",STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core,https://doi.org/10.1137/1.9781611977653.ch46," David Liu, Tina Eliassi-Rad. (2023). STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core SDM, 406-414. https://doi.org/10.1137/1.9781611977653.ch46","Are the embeddings of a graph's degenerate core stable? What happens to the embeddings of nodes in the degenerate core as we systematically remove periphery nodes (by repeatedly peeling off Œ∫ -cores)? We discover three patterns w.r.t. instability in degenerate-core embeddings across a variety of popular graph embedding algorithms and datasets. We correlate instability with an increase in edge density, and then theoretically show that in the case of Erd√∂s-R√©nyi graphs embedded with Laplacian Eigenmaps, the best and worst possible embeddings become less distinguishable as density increases. Furthermore, we present the STABLE algorithm, which takes an existing graph embedding algorithm and makes it stable. We show the effectiveness of STABLE in terms of making the degenerate-core embedding stable and still producing state-of-the-art link prediction performance.",1241
1156,Machine Learning,Tina Eliassi-Rad,"September 10th, 2021",PATHATTACK: Attacking Shortest Paths in Complex Networks,https://doi.org/10.1007/978-3-030-86520-7_33," B.A. Miller, Z. Shafi, W. Ruml, Y. Vorobeychik, T. Eliassi-Rad, S. Alfeld. ""PATHATTACK: Attacking Shortest Paths in Complex Networks"". In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD), September 2021.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1242
1157,Machine Learning,Miguel Fuentes-Cabrera,"May 3rd, 2023",Predicting partner fitness based on spatial structuring in a light-driven microbial community,https://doi.org/10.1371/journal.pcbi.1011045," Jonathan K. Sakkos, Mar√≠a Santos-Merino, Emmanuel J. Kokarakis, Bowen Li , Miguel Fuentes-Cabrera, Paolo Zuliani, Daniel C. Ducat. (2023). Predicting partner fitness based on spatial structuring in a light-driven microbial community PLoS Comput. Biol., 19. https://doi.org/10.1371/journal.pcbi.1011045","Microbial communities have vital roles in systems essential to human health and agriculture, such as gut and soil microbiomes. To better understand how these microbes interact with each other, we want to monitor the exchange of metabolites and the locations of the microbes. We developed a computerized model of a synthetic microbial community of two bacteria, one which performs photosynthesis and supplies sugar and another which consumes the sugar for growth. We showed that the relative level of sugar secretion regulates not only the steady-state support for the consumer partner‚Äôs growth, but also how the community changes with time. We anticipate that the synergy between experimental and computational approaches will improve our ability to design microbial communities with new functions.",1243
1158,Machine Learning,Miguel Fuentes-Cabrera,"April 5th, 2023",Inferring assembly-curving trends of bacterial micro-compartment shell hexamers from crystal structure arrangements,https://doi.org/10.1371/journal.pcbi.1011038," Luis F. Garcia-Alles, Miguel Fuentes-Cabrera, Gilles Truan, David Reguera. (2023). Inferring assembly-curving trends of bacterial micro-compartment shell hexamers from crystal structure arrangements PLoS Comput. Biol., 19. https://doi.org/10.1371/journal.pcbi.1011038","BMC-encapsulated enzymatic activities are segregated from other cell contents by means of semipermeable shells. Understanding how such complex objects form is essential, say the authors. They claim that only one of the two possible pathways is ready to curve. They also pinpointed a residue that seems to be pivotal in triggering bending. The study was published in the journal Cell, which was published by the University of California, San Diego, and the journal of the American Chemical Society, which published the study.",1244
1159,Machine Learning,Miguel Fuentes-Cabrera,"May 12th, 2022",Performing Video Frame Prediction of Microbial Growth with a Recurrent Neural Network,https://doi.org/10.48550/arXiv.2205.05810," Connor Robertson, Jared L. Wilmoth, Scott Retterer, Miguel Fuentes-Cabrera. (2022). Performing Video Frame Prediction of Microbial Growth with a Recurrent Neural Network CoRR, abs/2205.05810. https://doi.org/10.48550/arXiv.2205.05810","A Recurrent Neural Network (RNN) was used to perform video frame prediction of microbial growth for a population of two mutants of Pseudomonas aeruginosa. The RNN was trained on videos of 20 frames that were acquired using fluorescence microscopy and microfluidics. The network predicted the last 10 frames of each video, and the accuracy's of the predictions was assessed by comparing raw images, population curves, and the number and size of individual colonies. Overall, we found the predictions to be accurate using this approach. The implications this result has on designing autonomous experiments in microbiology, and the steps that can be taken to make the predictions even more accurate, are discussed.",1245
1160,Machine Learning,Miguel Fuentes-Cabrera,"February 22nd, 2020",Self-Propulsion Enhances Polymerization,https://doi.org/10.3390/e22020251," Maximino Aldana, Miguel Fuentes-Cabrera, Mart√≠n Zumaya. (2020). Self-Propulsion Enhances Polymerization Entropy, 22, 251. https://doi.org/10.3390/e22020251","Self-Propulsion Enhances Polymerization. The assembly of active molecules might have promoted the formation of large pre-biotic polymers that could be the precursors of the informational polymers we observe nowadays. Numerical simulations clearly show that self-propulsion considerably speeds up the assembly of polymers, somewhat in agreement with previous related studies. We conclude by discussing the differences between self-Assembly and self-Organization and discuss the role of self-propelled particles in the development of the self-organized system. For confidential support call the Samaritans on 08457 90 90 90 or visit a local Samaritans branch, see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. We show how a model that borrows some of these ideas can be used to study polymer formation from a collection of self-propelled monomers. We will not attempt to provide a theoretical description of the active self-assembly process presented here. Instead, we will present only numerical results obtained through molecular dynamics simulations. The motivation for studying the channel system is based on the hypothesis that the formation of organic macro-molecules relevant to the origin of life may have occurred in micro-channels formed either in meteorites [ 38 , 39 , 40 , 41 ] or in confined micro-spaces of marine vent chimneys in which molecules are driven by thermal gradients. The results show that the external input of energy, via self-propulsion or other sources (such as ATP), can considerably enhance the assembly of structures. Propulsion considerably improves theassembly of molecules as compared to spontaneous self-assembly. At high temperatures, mostly monomers and dimers coexist, whereas longer polymer appear in negligible amounts. At low temperatures, the average polymer length does not reach a maximum at any value of the self-propulsion force. This is due to the aggregation of molecules and polymers next to the repulsive channel walls, which decreases the rate at which the chains grow. In the high-temperature regime, the system reaches a stationary state within the simulation time. In every case reported in Figure 4 , it can be seen that increasing ùêπ sp F sp increases the growth rate of the polymer chains. The tail of the distribution reveals that much longer polymers are created. The narrower the channel, the less self- Propulsion force is needed to create long polymers. This effect clearly becomes stronger for narrow channels. The aggregation and jammingof active particles next to the confining Walls has been observed in both numerical simulations and experiments. Self-propulsion could have been an important mechanism for the formation of pre-biotic structures or the synthesis of nanometric structures. The model we have introduced takes into account the full geometry of the molecules by discretizing them into subunits. All authors have read and agree to the published version of the manuscript. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; or in the decision to publish the results. This article includes a review of attraction and repulsion models of aggregation. The study of active matter has the potential to provide new insights into the nature of the universe. The author‚Äôs conclusion is that active matter is a form of ‚Äòactive matter‚Äô and should be considered as a type of ‚Äúactive‚Äù matter, rather than as a ‚Äònon-active‚Äô matter. In silico synthesis of microgel particles. The role of clay minerals in chemical evolution and the origins of life. In Clay Minerals in Nature; Valaskova, M., Martynkov√°, G.S., Eds.; IntechOpen: London, UK, 2012; Chapter 10; pp. 191‚Äì208. Figure 6 shows the average chain length in a channel with semi-periodic boundary conditions. Almost all the points fall above the identity line, which means that the polymers formed in the channel are considerably longer than the ones observed in the bulk. All the results presented in this figure were computed at constant temperature ùëá = 0.1 T =0.1 . The histograms also show the probability of the distribution P ( L ) in order to better appreciate the existence of long polymers. The ensemble averages were computed over 20 different realizations for each condition. Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here . Article Metrics Yes Citations Yes Web of Science 3 ads 2 Scopus 3 PubMed 1 PMC 1 Google Scholar",1246
1161,Machine Learning,Yifan Hu,"November 1st, 2021",BERT-Beta: A Proactive Probabilistic Approach to Text Moderation,https://doi.org/10.18653/v1/2021.emnlp-main.682," Fei Tan, Yifan Hu , Kevin Yen, Changwei Hu. (2021). BERT-Beta: A Proactive Probabilistic Approach to Text Moderation EMNLP (1), 8667-8675. https://doi.org/10.18653/v1/2021.emnlp-main.682","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text moderation for user generated content, which helps to promote healthy interaction among users, has been widely studied and many machine learning models have been proposed. In this work, we explore an alternative perspective by augmenting reactive reviews with proactive forecasting. Specifically, we propose a new concept text toxicity propensity to characterize the extent to which a text tends to attract toxic comments. Beta regression is then introduced to do the probabilistic modeling, which is demonstrated to function well in comprehensive experiments. We also propose an explanation method to communicate the model decision clearly. Both propensity scoring and interpretation benefit text moderation in a novel manner. Finally, the proposed scaling mechanism for the linear model offers useful insights beyond this work.",1247
1162,Machine Learning,Yifan Hu,"November 1st, 2020",HABERTOR: An Efficient and Effective Deep Hatespeech Detector,https://doi.org/10.18653/v1/2020.emnlp-main.606," Thanh Tran , Yifan Hu , Changwei Hu, Kevin Yen, Fei Tan, Kyumin Lee, Se Rim Park. (2020). HABERTOR: An Efficient and Effective Deep Hatespeech Detector EMNLP (1), 7486-7502. https://doi.org/10.18653/v1/2020.emnlp-main.606","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present our HABERTOR model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. HABERTOR inherits BERT‚Äôs architecture, but is different in four aspects: (i) it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset; (ii) it consists of Quaternion-based factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage; (iii) it uses our proposed multi-source ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and (iv) it uses a regularized adversarial training with our proposed fine-grained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that HABERTOR works better than 15 state-of-the-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our HABERTOR is 4 5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pre-train it by using less than 1% of the number of words. Our generalizability analysis shows that HABERTOR transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.",1248
1163,Machine Learning,Yifan Hu,"November 1st, 2020",Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference,https://doi.org/10.18653/v1/2020.emnlp-main.17," Bang An, Jie Lyu , Zhenyi Wang , Chunyuan Li, Changwei Hu, Fei Tan, Ruiyi Zhang, Yifan Hu , Changyou Chen. (2020). Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference EMNLP (1), 236-255. https://doi.org/10.18653/v1/2020.emnlp-main.17","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The neural attention mechanism plays an important role in many natural language processing applications. In particular, multi-head attention extends single-head attention by allowing a model to jointly attend information from different perspectives. However, without explicit constraining, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the model‚Äôs representation power. In this paper, for the first time, we provide a novel understanding of multi-head attention from a Bayesian perspective. Based on the recently developed particle-optimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens model‚Äôs expressiveness. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions: why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on multiple tasks.",1249
1164,Machine Learning,Yifan Hu,"November 1st, 2020",TNT: Text Normalization based Pre-training of Transformers for Content Moderation,https://doi.org/10.18653/v1/2020.emnlp-main.383," Fei Tan, Yifan Hu , Changwei Hu, Keqian Li, Kevin Yen. (2020). TNT: Text Normalization based Pre-training of Transformers for Content Moderation EMNLP (1), 4735-4741. https://doi.org/10.18653/v1/2020.emnlp-main.383","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract In this work, we present a new language pre-training model TNT (Text Normalization based pre-training of Transformers) for content moderation. Inspired by the masking strategy and text normalization, TNT is developed to learn language representation by training transformers to reconstruct text from four operation types typically seen in text manipulation: substitution, transposition, deletion, and insertion. Furthermore, the normalization involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery. As a result, the experiments demonstrate that TNT outperforms strong baselines on the hate speech classification task. Additional text normalization experiments and case studies show that TNT is a new potential approach to misspelling correction.",1250
1165,Machine Learning,Huaizu Jiang,"December 25th, 2024","NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices",https://doi.org/10.1109/IROS58592.2024.10802353," Zhiyong Zhang, Huaizu Jiang, Hanumant Singh. (2024). NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices IROS, 5048-5055. https://doi.org/10.1109/IROS58592.2024.10802353","Real-time high-accuracy optical flow estimation is a crucial component in various applications, including localization and mapping in robotics. While recent learning-based optical flow methods have achieved high accuracy, they often come with heavy computation costs. We propose a highly efficient optical flow architecture, called NeuFlow, that addresses both high accuracy and computational cost concerns. We achieve a notable 10-80 speedup compared to several state-of-the-art methods, while maintaining comparable accuracy. Our approach achieves around 30 FPS on edge computing platforms, which represents a significant breakthrough in deploying complex computer vision tasks.",1251
1166,Machine Learning,Huaizu Jiang,"September 30th, 2024",SMooDi: Stylized Motion Diffusion Model,https://doi.org/10.1007/978-3-031-73232-4_23," Lei Zhong, Yiming Xie, Varun Jampani, Deqing Sun, Huaizu Jiang. (2024). SMooDi: Stylized Motion Diffusion Model ECCV (1), 405-421. https://doi.org/10.1007/978-3-031-73232-4_23","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1252
1167,Machine Learning,Huaizu Jiang,"September 16th, 2024",Zero-Shot Referring Expression Comprehension via Structural Similarity Between Images and Captions,https://doi.org/10.1109/CVPR52733.2024.01362," Zeyu Han, Fangrui Zhu, Qianru Lao, Huaizu Jiang. (2024). Zero-Shot Referring Expression Comprehension via Structural Similarity Between Images and Captions CVPR, 14364-14375. https://doi.org/10.1109/CVPR52733.2024.01362","Zero-shot referring expression comprehension aims at localizing bounding boxes in an image corresponding to provided textual prompts. We leverage large foundation models to disentangle both images and texts into triplets in the for-mat of (subject, predicate, object) After that, grounding is accomplished by calculating the structural similarity matrix between visual and textual triplets with a VLA model. Experiments demonstrate that our visual grounding performance increase of up to 19.5% over the SOTA zero-shot model on RefCOCO/g.",1253
1168,Machine Learning,Huaizu Jiang,"January 16th, 2024",OmniControl: Control Any Joint at Any Time for Human Motion Generation,https://openreview.net/forum?id=gd0lAEtWso," Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, Huaizu Jiang. (2024). OmniControl: Control Any Joint at Any Time for Human Motion Generation ICLR. https://openreview.net/forum?id=gd0lAEtWso","OmniControl is a novel approach for incorporating flexible spatial control signals into a text-conditioned human motion generation model. The method employs spatial and realism guidance in an effort to achieve a balance between motion that is both accurate and natural. One limitation of the method is the relatively high cost of inference, which several reviewers point out.",1254
1169,Machine Learning,Huaizu Jiang,"January 15th, 2024",Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection,https://doi.org/10.1109/ICCV51070.2023.01684," Yiming Xie, Huaizu Jiang, Georgia Gkioxari, Julian Straub. (2023). Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection ICCV, 18324-18334. https://doi.org/10.1109/ICCV51070.2023.01684",Parq is a multi-view 3D object detector with transformer and pixel-aligned recurrent queries. PARQ outperforms prior best methods on the ScanNet and ARKitScenes datasets. Code is available on GitHub at http://www.ymingxi.com/parq.,1255
1170,Machine Learning,Huaizu Jiang,"July 4th, 2023",StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks,https://doi.org/10.1109/ICRA48891.2023.10160924," Hongyu Li, Zhengang Li, Neset √únver Akmandor, Huaizu Jiang, Yanzhi Wang, Taskin Padir. (2023). StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks ICRA, 4826-4833. https://doi.org/10.1109/ICRA48891.2023.10160924"," Obstacle detection is a safety-critical problem in robot navigation, where stereo matching is a popular vision-based approach. This paper proposes a computationally efficient method that employs a deep neural network to detect occupancy from stereo images directly. Instead of learning the point cloud correspondence from the stereo data, our approach extracts the compact obstacle distribution based on volumetric representations. Our approach detects obstacles accurately in the range of 32 meters and achieves better IoU (Intersection over Union) and CD (Chamfer Distance) scores with only 2% of the computation cost of the state-of-the-art stereo model.",1256
1171,Machine Learning,Huaizu Jiang,"September 27th, 2022",PlanarRecon: Realtime 3D Plane Detection and Reconstruction from Posed Monocular Videos,https://doi.org/10.1109/CVPR52688.2022.00612," Yiming Xie, Matheus Gadelha, Fengting Yang, Xiaowei Zhou, Huaizu Jiang. (2022). PlanarRecon: Realtime 3D Plane Detection and Reconstruction from Posed Monocular Videos CVPR, 6209-6218. https://doi.org/10.1109/CVPR52688.2022.00612","PlanarRecon is a novel framework for globally coherent detection and reconstruction of 3D planes from a posed monocular video. It incrementally detects planes in 3D for each video fragment, which consists of a set of key frames, from a volumetric representation of the scene using neural networks. Experiments show that the proposed approach achieves state-of-the-art performances on the ScanNet dataset while being real-time.",1257
1172,Machine Learning,Huaizu Jiang,"September 27th, 2022",Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions,https://doi.org/10.1109/CVPR52688.2022.01847," Huaizu Jiang, Xiaojian Ma, Weili Nie, Zhiding Yu, Yuke Zhu, Anima Anandkumar. (2022). Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions CVPR, 19034-19043. https://doi.org/10.1109/CVPR52688.2022.01847","A significant gap remains between today's visual pattern recognition models and humanlevel visual cognition. We introduce Bongard-HOI, a new visual reasoning benchmark that focuses on compositional learning of humanobject interactions (HOIs) from natural images. The state-of-the-art HOI detection model achieves only 62% accuracy on fewshot binary prediction while even amateur human testers on MTurk have 91% accuracy. We hope to further advance research efforts in visual reasoning, especially in holistic perception-reasoning systems and better representation learning.",1258
1173,Machine Learning,Huaizu Jiang,"January 1st, 2020",In Defense of Grid Features for Visual Question Answering,https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_In_Defense_of_Grid_Features_for_Visual_Question_Answering_CVPR_2020_paper.html," Huaizu Jiang, Ishan Misra, Marcus Rohrbach, Erik G. Learned-Miller, Xinlei Chen. (2020). In Defense of Grid Features for Visual Question Answering CVPR, 10264-10273. https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_In_Defense_of_Grid_Features_for_Visual_Question_Answering_CVPR_2020_paper.html","Popularized as `bottom-up' attention, bounding box (or region) based visual features have recently surpassed vanilla grid-based convolutional features as the de facto standard for vision and language tasks like visual question answering (VQA). However, it is not clear whether the advantages of regions (e.g. better localization) are the key reasons for the success of bottom-up attention. In this paper, we revisit grid features for VQA, and find they can work surprisingly well -- running more than an order of magnitude faster with the same accuracy (e.g. if pre-trained in a similar fashion). Through extensive experiments, we verify that this observation holds true across different VQA models (reporting a state-of-the-art accuracy on VQA 2.0 test-std, 72.71), datasets, and generalizes well to other tasks like image captioning. As grid features make the model design and training process much simpler, this enables us to train them end-to-end and also use a more flexible network design. We learn VQA models end-to-end, from pixels directly to answers, and show that strong performance is achievable without using any region annotations in pre-training. We hope our findings help further improve the scientific understanding and the practical application of VQA. Code and features will be made available.",1259
1174,Machine Learning,Huaizu Jiang,"January 1st, 2019",Automatic Adaptation of Object Detectors to New Domains Using Self-Training,http://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html," Aruni RoyChowdhury, Prithvijit Chakrabarty, Ashish Singh, SouYoung Jin, Huaizu Jiang, Liangliang Cao, Erik G. Learned-Miller. (2019). Automatic Adaptation of Object Detectors to New Domains Using Self-Training CVPR, 780-790. http://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html","This work addresses the unsupervised adaptation of an existing object detector to a new target domain. We assume that a large number of unlabeled videos from this domain are readily available. We automatically obtain labels on the target data by using high-confidence detections from the existing detector, augmented with hard (misclassified) examples acquired by exploiting temporal cues using a tracker. These automatically-obtained labels are then used for re-training the original model. A modified knowledge distillation loss is proposed, and we investigate several ways of assigning soft-labels to the training examples from the target domain. Our approach is empirically evaluated on challenging face and pedestrian detection tasks: a face detector trained on WIDER-Face, which consists of high-quality images crawled from the web, is adapted to a large-scale surveillance data set; a pedestrian detector trained on clear, daytime images from the BDD-100K driving data set is adapted to all other scenarios such as rainy, foggy, night-time. Our results demonstrate the usefulness of incorporating hard examples obtained from tracking, the advantage of using soft-labels via distillation loss versus hard-labels, and show promising performance as a simple method for unsupervised domain adaptation of object detectors, with minimal dependence on hyper-parameters.",1260
1175,Machine Learning,Huy L√™ Nguyen,"May 1st, 2024",Private Vector Mean Estimation in the Shuffle Model: Optimal Rates Require Many Messages,https://openreview.net/forum?id=PTGJOUlQ68," Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar, Samson Zhou. (2024). Private Vector Mean Estimation in the Shuffle Model: Optimal Rates Require Many Messages ICML. https://openreview.net/forum?id=PTGJOUlQ68","We study the problem of private vector mean estimation in the shuffle model of privacy where n users each have a unit vector v ( i ) ‚àà R d . We propose a new multi-message protocol that achieves the optimal error using O ( min ( n Œµ 2 , d ) ) messages per user. Moreover, we show that any (unbiased) protocol that achieves optimal error must require each user to send Œ© ( min ( n Œµ 2 , d ) / log ‚Å° ( n ) ) messages, demonstrating the optimality of our message complexity up to logarithmic factors. Additionally, we study the single-message setting and design a protocol that achieves mean squared error O ( d n d / ( d + 2 ) Œµ ‚àí 4 / ( d + 2 ) ) . Moreover, we show that any single-message protocol must incur mean squared error Œ© ( d n d / ( d + 2 ) ) , showing that our protocol is optimal in the standard setting where Œµ = Œò ( 1 ) . Finally, we study robustness to malicious users and show that malicious users can incur large additive error with a single shuffler. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",1261
1176,Machine Learning,Huy L√™ Nguyen,"June 26th, 2023",An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret,https://ojs.aaai.org/index.php/AAAI/article/view/25985," Matthew Jones, Huy L. Nguyen, Thy Dinh Nguyen. (2023). An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret AAAI, 8159-8167. https://ojs.aaai.org/index.php/AAAI/article/view/25985","Abstract Recently a multi-agent variant of the classical multi-armed bandit was proposed to tackle fairness issues in online learning. Inspired by a long line of work in social choice and economics, the goal is to optimize the Nash social welfare instead of the total utility. Unfortunately previous algorithms either are not efficient or achieve sub-optimal regret in terms of the number of rounds. We propose a new efficient algorithm with lower regret than even previous inefficient ones. We also complement our efficient algorithm with an inefficient approach with regret that matches the lower bound for one agent. The experimental findings confirm the effectiveness of our efficient algorithm compared to the previous approaches.",1262
1177,Machine Learning,Huy L√™ Nguyen,"June 7th, 2023",Fast Optimal Locally Private Mean Estimation via Random Projections,http://papers.nips.cc/paper_files/paper/2023/hash/34822dab66c13f0100017b8ea373038a-Abstract-Conference.html," Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar. (2023). Fast Optimal Locally Private Mean Estimation via Random Projections NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/34822dab66c13f0100017b8ea373038a-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Main Conference Track Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy Nguyen, Kunal Talwar We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, namely ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a 1 + o ( 1 ) 1 + o ( 1 ) -factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace and then runs an optimal algorithm such a PrivUnitG in the lower dimensional space. We analyze the error of the algorithm in terms of properties of the random projection ensemble, and study two instantiations. We conduct several experiments for private mean estimation and private federated learning which demonstrate that our algorithms obtain nearly the same utility as optimal algorithms while having significantly lower communication and computational cost. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",1263
1178,Machine Learning,Huy L√™ Nguyen,"October 25th, 2022",Streaming Submodular Maximization with Differential Privacy,https://proceedings.mlr.press/v202/chaturvedi23a.html," Anamay Chaturvedi, Huy L. Nguyen, Thy Dinh Nguyen. (2023). Streaming Submodular Maximization with Differential Privacy ICML, 4116-4143. https://proceedings.mlr.press/v202/chaturvedi23a.html","In this work, we study the problem of privately maximizing a submodular function in the streaming setting. Extensive work has been done on privately maximizing submodular functions in the general case when the function depends upon the private data of individuals. However, when the size of the data stream drawn from the domain of the objective function is large or arrives very fast, one must privately optimize the objective within the constraints of the streaming setting. We establish fundamental differentially private baselines for this problem and then derive better trade-offs between privacy and utility for the special case of decomposable submodular functions. A submodular function is decomposable when it can be written as a sum of submodular functions; this structure arises naturally when each summand function models the utility of an individual and the goal is to study the total utility of the whole population as in the well-known Combinatorial Public Projects Problem. Finally, we complement our theoretical analysis with experimental corroboration.",1264
1179,Machine Learning,Huy L√™ Nguyen,"June 28th, 2022",Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence,https://ojs.aaai.org/index.php/AAAI/article/view/20609," Alina Ene, Huy Le Nguyen. (2022). Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence AAAI, 6559-6567. https://ojs.aaai.org/index.php/AAAI/article/view/20609","Abstract We develop new adaptive algorithms for variational inequalities with monotone operators, which capture many problems of interest, notably convex optimization and convex-concave saddle point problems. Our algorithms automatically adapt to unknown problem parameters such as the smoothness and the norm of the operator, and the variance of the stochastic evaluation oracle. We show that our algorithms are universal and simultaneously achieve the optimal convergence rates in the non-smooth, smooth, and stochastic settings. The convergence guarantees of our algorithms improve over existing adaptive methods and match the optimal non-adaptive algorithms. Additionally, prior works require that the optimization domain is bounded. In this work, we remove this restriction and give algorithms for unbounded domains that are adaptive and universal. Our general proof techniques can be used for many variants of the algorithm using one or two operator evaluations per iteration. The classical methods based on the ExtraGradient/MirrorProx algorithm require two operator evaluations per iteration, which is the dominant factor in the running time in many settings.",1265
1180,Machine Learning,Huy L√™ Nguyen,"January 1st, 2022",Streaming Algorithm for Monotone k-Submodular Maximization with Cardinality Constraints,https://proceedings.mlr.press/v162/ene22a.html," Alina Ene, Huy L. Nguyen. (2022). Streaming Algorithm for Monotone k-Submodular Maximization with Cardinality Constraints ICML, 5944-5967. https://proceedings.mlr.press/v162/ene22a.html","Maximizing a monotone k-submodular function subject to cardinality constraints is a general model for several applications ranging from influence maximization with multiple products to sensor placement with multiple sensor types and online ad allocation. Due to the large problem scale in many applications and the online nature of ad allocation, a need arises for algorithms that process elements in a streaming fashion and possibly make online decisions. In this work, we develop a new streaming algorithm for maximizing a monotone k-submodular function subject to a per-coordinate cardinality constraint attaining an approximation guarantee close to the state of the art guarantee in the offline setting. Though not typical for streaming algorithms, our streaming algorithm also readily applies to the online setting with free disposal. Our algorithm is combinatorial and enjoys fast running time and small number of function evaluations. Furthermore, its guarantee improves as the cardinality constraints get larger, which is especially suited for the large scale applications. For the special case of maximizing a submodular function with large budgets, our combinatorial algorithm matches the guarantee of the state-of-the-art continuous algorithm, which requires significantly more time and function evaluations.",1266
1181,Machine Learning,Huy L√™ Nguyen,"January 1st, 2022",Private frequency estimation via projective geometry,https://proceedings.mlr.press/v162/feldman22a.html," Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar. (2022). Private frequency estimation via projective geometry ICML, 6418-6433. https://proceedings.mlr.press/v162/feldman22a.html","In this work, we propose a new algorithm ProjectiveGeometryResponse (PGR) for locally differentially private (LDP) frequency estimation. For universe size of k and with n users, our eps-LDP algorithm has communication cost ceil(log_2 k) and computation cost O(n + k\exp(eps) log k) for the server to approximately reconstruct the frequency histogram, while achieve optimal privacy-utility tradeoff. In many practical settings this is a significant improvement over the O¬†(n+k^2) computation cost that is achieved by the recent PI-RAPPOR algorithm (Feldman and Talwar; 2021). Our empirical evaluation shows a speedup of over 50x over PI-RAPPOR while using approximately 75x less memory. In addition, the running time of our algorithm is comparable to that of HadamardResponse (Acharya, Sun, and Zhang; 2019) and RecursiveHadamardResponse (Chen, Kairouz, and Ozgur; 2020) which have significantly worse reconstruction error. The error of our algorithm essentially matches that of the communication- and time-inefficient but utility-optimal SubsetSelection (SS) algorithm (Ye and Barg; 2017). Our new algorithm is based on using Projective Planes over a finite field to define a small collection of sets that are close to being pairwise independent and a dynamic programming algorithm for approximate histogram reconstruction for the server.",1267
1182,Machine Learning,Huy L√™ Nguyen,"May 31st, 2021",Locally Private k-Means Clustering with Constant Multiplicative Approximation and Near-Optimal Additive Error,https://arxiv.org/abs/2105.15007," Locally Private k-Means Clustering with Constant Multiplicative Approximation and Near-Optimal Additive Error. CoRR abs/2105.15007 (2021), Anamay Chaturvedi, Matthew Jones, Huy L. Nguyen.","Given a data set of sizenind‚Ä≤-dimensional Euclidean space, thek-means problem asks for a set ofkpoints (called centers) so that the sum of the‚Ñì22-distances between points of a given data set of sizenand the set ofkcenters is minimized. Recent work on this problem in the locally private setting achieves constant multiplicative approximation with additive errorO~(n1/2+a‚ãÖk‚ãÖmax{d‚àí‚àí‚àö,k‚àí‚àí‚àö})and proves a lower bound ofŒ©(n‚àí‚àí‚àö)on the additive error for any solution with a constant number of rounds. In this work we bridge the gap between the exponents ofnin the upper and lower bounds on the additive error with two new algorithms. Given anyŒ±>0, our first algorithm achieves a multiplicative approximation guarantee which is at most a(1+Œ±)factor greater than that of any non-privatek-means clustering algorithm withkO~(1/Œ±2)d‚Ä≤n‚àí‚àí‚àí‚àöpolylognadditive error. Given anyc>2‚Äì‚àö, our second algorithm achievesO(k1+O~(1/(2c2‚àí1))d‚Ä≤n‚àí‚àí‚àí‚àöpolylogn)additive error with constant multiplicative approximation. Both algorithms go beyond theŒ©(n1/2+a)factor that occurs in the additive error for arbitrarily small parametersain previous work, and the second algorithm in particular shows for the first time that it is possible to solve the locally privatek-means problem in a constant number of rounds with constant factor multiplicative approximation and polynomial dependence onkin the additive error arbitrarily close to linear.",1268
1183,Machine Learning,Huy L√™ Nguyen,"December 8th, 2018",Improved Algorithms for Collaborative PAC Learning,https://papers.nips.cc/paper/7990-improved-algorithms-for-collaborative-pac-learning," Huy L√™ Nguy·ªÖn and Lydia Zakynthinou. ""Improved Algorithms for Collaborative PAC Learning.""  Advances in Neural Information Processing Systems 31 (NeurIPS‚Äô18), 2018.","Part of Advances in Neural Information Processing Systems 31 (NeurIPS 2018) Huy Nguyen, Lydia Zakynthinou We study a recent model of collaborative PAC learning where k k players with k k different tasks collaborate to learn a single classifier that works for all tasks. Previous work showed that when there is a classifier that has very small error on all tasks, there is a collaborative algorithm that finds a single classifier for all tasks and has O ( ( ln ( k ) ) 2 ) O ( ( ln ‚Å° ( k ) ) 2 ) times the worst-case sample complexity for learning a single task. In this work, we design new algorithms for both the realizable and the non-realizable setting, having sample complexity only O ( ln ( k ) ) O ( ln ‚Å° ( k ) ) times the worst-case sample complexity for learning a single task. The sample complexity upper bounds of our algorithms match previous lower bounds and in some range of parameters are even better than previous algorithms that are allowed to output different classifiers for different tasks. Requests for name changes in the electronic proceedings will be accepted with no questions asked. However name changes may cause bibliographic tracking issues. Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings. Use the ""Report an Issue"" link to request a name change.",1269
1184,Machine Learning,Huy L√™ Nguyen,"June 14th, 2015",Time Lower Bounds for Nonadaptive Turnstile Streaming Algorithms,https://dl.acm.org/citation.cfm?id=2746542," Kasper Green Larsen, Jelani Nelson, Huy L. Nguyen. Time Lower Bounds for Nonadaptive Turnstile Streaming Algorithms. STOC 2015: 803-812","We say a turnstile streaming algorithm is {\em non-adaptive} if, during updates, the memory cells written and read depend only on the index being updated and random coins tossed at the beginning of the stream (and not on the memory contents of the algorithm). Memory cells read during queries may be decided upon adaptively. All known turnstile streaming algorithms in the literature, except a single recent example for a particular promise problem [7], are non-adaptive. In fact, even more specifically, they are all linear sketches. We prove the first non-trivial update time lower bounds for both randomized and deterministic turnstile streaming algorithms, which hold when the algorithms are non-adaptive. While there has been abundant success in proving space lower bounds, there have been no non-trivial turnstile update time lower bounds. Our lower bounds hold against classically studied problems such as heavy hitters, point query, entropy estimation, and moment estimation. In some cases of deterministic algorithms, our lower bounds nearly match known upper bounds.",1270
1185,Machine Learning,Jonathan Mwaura,"September 28th, 2023",A Conceptual Framework for Automatic Generation of Examinations Using Machine Learning Algorithms in Learning Management Systems,https://doi.org/10.1007/978-3-031-43393-1_41," Emma Cheserem, Elizaphan M. Maina, John Kihoro, Jonathan Mwaura. (2022). A Conceptual Framework for Automatic Generation of Examinations Using Machine Learning Algorithms in Learning Management Systems WCCE, 441-450. https://doi.org/10.1007/978-3-031-43393-1_41","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1271
1186,Machine Learning,Jonathan Mwaura,"January 26th, 2021",Diversity Measures for Niching Algorithms,https://doi.org/10.3390/a14020036," Jonathan Mwaura, Andries P Engelbrecht, Filipe V Nepomuceno (2021). Diversity Measures for Niching Algorithms. Journal of Algorithms, Vol 14, Issue 2.","Swarm diversity measures can be used to quantify spread in niching algorithms. Niches are formed by a cluster of candidate solutions. A candidate niche can still be refined to find an actual solution, or optimum. An averaged candidate Niches‚Äô diversity (SD diversity per niche) corresponds to the intra-niche distances. This article belongs to the Special Issue Benchmarking, Selecting and Configuring Learning and Optimization Algorithms. It is available as an Open Access PDF and can be read in the following formats: PDF with Cover, Epub, or PDF with Keyboard and Arrow, as well as the usual print and e-book formats. The adapted SDNN is shown in Appendix A , Appendix B and Appendix C. The results of the experiments are presented in Section 5.1. The average distance around the swarm centre (ADSC) computes the swarm diversity by calculating the average distance of particles to a central point in each dimension. A high SDNN value means that particles in a niche are far from each other. Low SDNN values may not indicate niche convergence because the calculated distance is only with respect to NNs and not entire members of a candidate niche. In the work presented here, the entropy measure value was normalised between 0 and 1. In this case, 1 represents high diversity while 0 represents no diversity. The work reported here, was calculated per niche, then averaged. 2.1.6 Solow‚ÄìPolasky Diversity measure (SPD) The SPD measure relies on the use of the inverse of the matrix, M . The swarm center and the swarm coherence is similar to ADSC with the only exception that a further normalisation is carried out. Each candidate niche contains a neighbourhood best (i.e., the best candidate in a niche) Niche diversity refers to diversity with respect to the neighbourhood bests in each of the identified candidate niches. A good niching algorithm is expected to have a considerable high diversity both at the exploration and exploitation phases of the search process. However, niche diversity is still affected by such drawbacks as ‚Äòoutliers‚Äô and niche identification strategies. The results for all the considered multimodal problems show that the diversity quantified using the standard SD is high. In conclusion, the standardSD is not suitable for niched algorithms. Diversity is not measured on how far apart the solutions are from each other but from the ‚Äòswarm best‚Äô which are multiple. As the particles converge towards optima, the diversity will decrease and then stagnate at a relatively high diversity value. The results of the study were published in the open-access issue of Theoretical Physics, published by the University of California, San Diego, on November 14, 2013. The embargo on this article has been lifted at the request of the author. The work presented here postulates that entropy is a suitable measure for quantifying dispersion for solutions and candidate solutions of niching algorithms. In summary, the nADAA is a useful measure to quantify the spread. of the solutions. of nICHing algorithms, while the mAD AA is a Useful measure to. quantify diversity within the candidate niches. Diversity measures are discussed with respect to the search space, i.e. swarm diversity, and with respect. to solution space,i.e., niche diversity. An empirical study involving the reviewed measures was carried out using a set of multimodal functions optimised using the enhanced species-based particle swarm optimisation (ESPSO) niching algorithm. The obtained diversity results showed that some measures are more suited to the task than others. High niche diversity during the exploration phase indicates that a niched algorithm is capable of identifying potential niches. It is, however, expected that niche diversity will decrease as the swarm moves from the exploration to the exploitation phase. The presented study can thus only be seen as a first step towards this investigation. The analysis of the population diversity of a swarm using a multi-objective search algorithm. The construction of a model of the swarm to measure its structural diversity. The selection of the best particles to search for and analyse. Figure 1. Illustration of swarm diversity for niching algorithms. The crosses show the positions of optima. ( a ) particles during search process; ( b ) particles at convergence. a swarm. A swarm is a collection of particles that can be searched for and analysed by different algorithms. For more information, see theADAA.org website or see the NADAA website for more information about ADAA, including variants, and how to get the measure for your home town or city. For the full version of this article, please visit the N ADAA website. The SPD measure is the most widely used measure of entropy in the U.S. and other countries. It is based on the E-meter, which has been shown to be more sensitive to changes in the environment than other measures such as the Pearson correlation coefficient (PE) or the Kruskal constant (K) The original version of this article stated that the results of the study werebased on the data for the SR measure. We are happy to clarify that the data was based on a different measure for theSR measure, and that the differences between the two measurements were due to the different weights. MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. From the first issue of 2016, this journal uses article numbers instead of page numbers.",1272
1187,Machine Learning,Jonathan Mwaura,"September 24th, 2020",Optimized K-Means clustering algorithm using an intelligent stable-plastic variational autoencoder with self-intrinsic cluster validation mechanism,https://doi.org/10.1145/3415088.3415125," Rufus Gikera, Shadrack Mambo, Jonathan Mwaura (2020). Optimized K-Means clustering algorithm using an intelligent stable-plastic variational autoencoder with self-intrinsic cluster validation mechanism. ICONIC '20: Proceedings of the 2nd International Conference on Intelligent and Innovative Computing Applications.","Clustering is one of the most important tasks in exploratory data analysis [1, 55, 59]. K-means are the most popular clustering algorithms [51, 61]. This is because of their ability to adapt to new examples and to scale up to large datasets. They are also easily understandable and computationally faster [57, 60, 3, 62]. However, the number of clusters, K , has to be specified by the user [50]. Random process is the norm of searching for appropriate number of clusters, until convergence [53, 5]. Several variants of the k-means algorithm have been proposed, geared towards optimal selection of the K [8, 48]. The objective of this paper is to analyze the scaling up problems associated with these variants for optimizing K in the k-means clustering algorithms. Finally, a more enhanced ""hybrid autoencoder-based"" k-means will be developed and evaluated against the existing variants.",1273
1188,Machine Learning,Ryan M. Rad,"April 8th, 2024",GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery,https://doi.org/10.48550/arXiv.2404.05180," Zhiyuan Yang, Ryan Rad. (2024). GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery CoRR, abs/2404.05180. https://doi.org/10.48550/arXiv.2404.05180","Solar Photovoltaic (PV) technology is increasingly recognized as a pivotal solution in the global pursuit of clean and renewable energy. This technology addresses the urgent need for sustainable energy alternatives by converting solar power into electricity without greenhouse gas emissions. It not only curtails global carbon emissions but also reduces reliance on finite, non-renewable energy sources. In this context, monitoring solar panel farms becomes essential for understanding and facilitating the worldwide shift toward clean energy. This study contributes to this effort by developing the first comprehensive global dataset of multispectral satellite imagery of solar panel farms. This dataset is intended to form the basis for training robust machine learning models, which can accurately map and analyze the expansion and distribution of solar panel farms globally. The insights gained from this endeavor will be instrumental in guiding informed decision-making for a sustainable energy future.this https URL",1274
1189,Machine Learning,Ryan M. Rad,"November 1st, 2023",Remote Wildfire Detection using Multispectral Satellite Imagery and Vision Transformers,https://proceedings.mlr.press/v222/rad24a.html," Ryan Rad. (2023). Remote Wildfire Detection using Multispectral Satellite Imagery and Vision Transformers ACML, 1135-1150. https://proceedings.mlr.press/v222/rad24a.html","Wildfires pose a significant and recurring challenge in North America, impacting both human and natural environments. The size and severity of wildfires in the region have been increasing in recent years, making it a pressing concern for communities, ecosystems, and the economy. The accurate and timely detection of active wildfires in remote areas is crucial for effective wildfire management and mitigation efforts. In this research paper, we propose a robust approach for detecting active wildfires using multispectral satellite imagery by leveraging vision transformers and a vast repository of landsat- 8 8 satellite data with a 30 30 m spatial resolution in North America. Our methodology involves experimenting with vision transformers and deep convolutional neural networks for wildfire detection in multispectral satellite images. We compare the capabilities of these two architecture families in detecting wildfires within the multispectral satellite imagery. Furthermore, we propose a novel u-shape vision transformer that effectively captures spatial dependencies and learns meaningful representations from multispectral images, enabling precise discrimination between wildfire and non-wildfire regions. To evaluate the performance of our approach, we conducted experiments on a comprehensive dataset of wildfire incidents. The results demonstrate the effectiveness of the proposed method in accurately detecting active wildfires with an \textit{Dice Score or F 1 1 } of and \textit{Recall} of . Overall, our research presents a promising approach for leveraging vision transformers for multispectral satellite imagery to detect remote wildfires.",1275
1190,Machine Learning,David Smith,"February 21st, 2025",Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training,https://doi.org/10.48550/arXiv.2502.15680," Jaydeep Borkar, Matthew Jagielski, Katherine Lee, Niloofar Mireshghallah, David A. Smith, Christopher A. Choquette-Choo. (2025). Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training CoRR, abs/2502.15680. https://doi.org/10.48550/arXiv.2502.15680","Due to the sensitive nature of personally identifiable information (PII), its owners may have the authority to control its inclusion or request its removal from large-language model (LLM) training. Beyond this, PII may be added or removed from training datasets due to evolving dataset curation techniques, because they were newly scraped for retraining, or because they were included in a new downstream fine-tuning stage. We find that the amount and ease of PII memorization is a dynamic property of a model that evolves throughout training pipelines and depends on commonly altered design choices. We characterize three such novel phenomena: (1) similar-appearing PII seen later in training can elicit memorization of earlier-seen sequences in what we call assisted memorization, and this is a significant factor (in our settings, up to 1/3); (2) adding PII can increase memorization of other PII significantly (in our settings, as much as‚âà7.5√ó); and (3) removing PII can lead to other PII being memorized. Model creators should consider these first- and second-order privacy risks when training models to avoid the risk of new PII regurgitation.",1276
1191,Machine Learning,David Smith,"September 11th, 2024","MONSTERMASH: Multidirectional, Overlapping, Nested, Spiral Text Extraction for Recognition Models of Arabic-Script Handwriting",https://doi.org/10.1007/978-3-031-70642-4_6," Danlu Chen, Jacob Murel, Taimoor Shahid, Xiang Zhang, Jonathan Parkes Allen, Taylor Berg-Kirkpatrick, David A. Smith. (2024). MONSTERMASH: Multidirectional, Overlapping, Nested, Spiral Text Extraction for Recognition Models of Arabic-Script Handwriting ICDAR (Workshops 2), 87-101. https://doi.org/10.1007/978-3-031-70642-4_6","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1277
1192,Machine Learning,David Smith,"September 11th, 2024",Retrieving and Analyzing Translations of American Newspaper Comics with Visual Evidence,https://doi.org/10.1007/978-3-031-70645-5_9," Jacob Murel, David A. Smith. (2024). Retrieving and Analyzing Translations of American Newspaper Comics with Visual Evidence ICDAR (Workshops 1), 125-137. https://doi.org/10.1007/978-3-031-70645-5_9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1278
1193,Machine Learning,David Smith,"September 9th, 2024",Self-training and Active Learning with Pseudo-relevance Feedback for Handwriting Detection in Historical Print,https://doi.org/10.1007/978-3-031-70543-4_18," Jacob Murel, David A. Smith. (2024). Self-training and Active Learning with Pseudo-relevance Feedback for Handwriting Detection in Historical Print ICDAR (3), 305-324. https://doi.org/10.1007/978-3-031-70543-4_18","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1279
1194,Machine Learning,David Smith,"June 28th, 2024",Mind the Gap: Analyzing Lacunae with Transformer-Based Transcription,https://doi.org/10.48550/arXiv.2407.00250," Jaydeep Borkar, David A. Smith. (2024). Mind the Gap: Analyzing Lacunae with Transformer-Based Transcription CoRR, abs/2407.00250. https://doi.org/10.48550/arXiv.2407.00250","Historical documents frequently suffer from damage and inconsistencies, including missing or illegible text resulting from issues such as holes, ink problems, and storage damage. These missing portions or gaps are referred to as lacunae. In this study, we employ transformer-based optical character recognition (OCR) models trained on synthetic data containing lacunae in a supervised manner. We demonstrate their effectiveness in detecting and restoring lacunae, achieving a success rate of 65%, compared to a base model lacking knowledge of lacunae, which achieves only 5% restoration. Additionally, we investigate the mechanistic properties of the model, such as the log probability of transcription, which can identify lacunae and other errors (e.g., mistranscriptions due to complex writing or ink issues) in line images without directly inspecting the image. This capability could be valuable for scholars seeking to distinguish images containing lacunae or errors from clean ones. Although we explore the potential of attention mechanisms in flagging lacunae and transcription errors, our findings suggest it is not a significant factor. Our work highlights a promising direction in utilizing transformer-based OCR models for restoring or analyzing damaged historical documents.",1280
1195,Machine Learning,David Smith,"February 24th, 2024",Detecting Manuscript Annotations in Historical Print: Negative Evidence and Evaluation Metrics,https://doi.org/10.5220/0012365600003654," Jacob Murel, David A. Smith. (2024). Detecting Manuscript Annotations in Historical Print: Negative Evidence and Evaluation Metrics ICPRAM, 745-752. https://doi.org/10.5220/0012365600003654","Early readers‚Äô manuscript annotations in books have been analyzed by bibliographers for evidence about book history and reading practice. Since handwritten annotations are not uniformly distributed across or within books, even the compilers of censuses of all copies of a single edition have very seldom produced systematic information. This paper analyzes the use of object detection models (ODMs) for detecting handwritten annotations on the pages of printed books.",1281
1196,Machine Learning,David Smith,"June 5th, 2023",Composition and Deformance: Measuring Imageability with a Text-to-Image Model,https://doi.org/10.48550/arXiv.2306.03168," Si Wu, David A. Smith. (2023). Composition and Deformance: Measuring Imageability with a Text-to-Image Model CoRR, abs/2306.03168. https://doi.org/10.48550/arXiv.2306.03168","Although psycholinguists and psychologists have long studied the tendency of linguistic strings to evoke mental images in hearers or readers, most computational studies have applied this concept of imageability only to isolated words. Using recent developments in text-to-image generation models, such as DALLE mini, we propose computational methods that use generated images to measure the imageability of both single English words and connected text. We sample text prompts for image generation from three corpora: human-generated image captions, news article sentences, and poem lines. We subject these prompts to different deformances to examine the model's ability to detect changes in imageability caused by compositional change. We find high correlation between the proposed computational measures of imageability and human judgments of individual words. We also find the proposed measures more consistently respond to changes in compositionality than baseline approaches. We discuss possible effects of model training and implications for the study of compositionality in text-to-image models.",1282
1197,Machine Learning,David Smith,"May 5th, 2023",Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces,https://doi.org/10.48550/arXiv.2305.03819," Shijia Liu, David A. Smith. (2023). Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces CoRR, abs/2305.03819. https://doi.org/10.48550/arXiv.2305.03819","Brain-computer interfaces (BCI) are an important mode of alternative and augmentative communication for many people. Unlike keyboards, many BCI systems do not display even the 26 letters of English at one time, let alone all the symbols in more complex systems. Using language models to make character-level predictions, therefore, can greatly speed up BCI typing (Ghosh and Kristensson, 2017). While most existing BCI systems employ character n-gram models or no LM at all, this paper adapts several wordpiece-level Transformer LMs to make character predictions and evaluates them on typing tasks. GPT-2 fares best on clean text, but different LMs react differently to noisy histories. We further analyze the effect of character positions in a word and context lengths.",1283
1198,Machine Learning,David Smith,"December 8th, 2022",An Experiment in Live Collaborative Programming on the Croquet Shared Experience Platform,https://doi.org/10.1145/3532512.3535224," Yoshiki Ohshima, Aran Lunzer, Jenn Evans, Vanessa Freudenberg, Brian Upton, David A. Smith. (2022). An Experiment in Live Collaborative Programming on the Croquet Shared Experience Platform Programming, 46-53. https://doi.org/10.1145/3532512.3535224","This paper describes our experiences in building a live collaborative programming environment on top of the JavaScript version of the Croquet shared experience platform. Croquet provides a clean substrate for building real-time collaborative applications. We created an application framework that supports live programming, and used that framework to build the Greenlight collaborative application, then in turn, modified it to do live programming experiments. The environment allows multiple users to modify the running application from within, with changes taking effect immediately. The experiment was inspired by earlier work including Douglas Engelbart‚Äôs oN-Line System (NLS) and the Kansas system in Self. Analogically, the system is like the Smalltalk environment made collaborative. In this paper we explain the Croquet architecture, its library and framework, and the Greenlight application used to make the live programming environment. The standard version of Greenlight is available at https://croquet.io/greenlight, and the modified demo system is available at https://croquet.io/scripting.",1284
1199,Machine Learning,David Smith,"February 27th, 2021",Text mining Mill: Computationally detecting influence in the writings of John Stuart Mill from library records,https://doi.org/10.1093/llc/fqab010," Helen O'Neill, Anne Welsh, David A. Smith, Glenn Roe, Melissa Terras. (2021). Text mining Mill: Computationally detecting influence in the writings of John Stuart Mill from library records Digit. Scholarsh. Humanit., 36, 1013-1029. https://doi.org/10.1093/llc/fqab010","How can computational methods illuminate the relationship between a leading intellectual, and their lifetime library membership? We report here on an international collaboration that explored the interrelation between the reading record and the publications of the British philosopher and economist John Stuart Mill, focusing on his relationship with the London Library, an independent lending library of which Mill was a member for 32 years. Building on detailed archival research of the London Library‚Äôs lending and book donation records, a digital library of texts borrowed, and publications produced was assembled, which enabled natural language processing approaches to detect textual reuse and similarity, establishing the relationship between Mill and the Library. Text mining the books Mill borrowed and donated against his published outputs demonstrates that the collections of the London Library influenced his thought, transferred into his published oeuvre, and featured in his role as political commentator and public moralist. We reconceive archival library issue registers as data for triangulating against the growing body of digitized historical texts and the output of leading intellectual figures. We acknowledge, however, that this approach is dependent on the resources and permissions to transcribe extant library registers, and on access to previously digitized sources. Related copyright and privacy restrictions mean our approach is most likely to succeed for other leading eighteenth- and nineteenth-century figures. Open in new tab Download slide Open in new tab Download slide",1285
1200,Machine Learning,David Smith,"January 1st, 2021",Content-based Models of Quotation,https://doi.org/10.18653/v1/2021.eacl-main.195," Ansel MacLaughlin, David A. Smith. (2021). Content-based Models of Quotation EACL, 2296-2314. https://doi.org/10.18653/v1/2021.eacl-main.195","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We explore the task of quotability identification, in which, given a document, we aim to identify which of its passages are the most quotable, i.e. the most likely to be directly quoted by later derived documents. We approach quotability identification as a passage ranking problem and evaluate how well both feature-based and BERT-based (Devlin et al., 2019) models rank the passages in a given document by their predicted quotability. We explore this problem through evaluations on five datasets that span multiple languages (English, Latin) and genres of literature (e.g. poetry, plays, novels) and whose corresponding derived documents are of multiple types (news, journal articles). Our experiments confirm the relatively strong performance of BERT-based models on this task, with the best model, a RoBERTA sequential sentence tagger, achieving an average rho of 0.35 and NDCG@1, 5, 50 of 0.26, 0.31 and 0.40, respectively, across all five datasets.",1286
1201,Machine Learning,David Smith,"February 8th, 2018",Contrastive Training for Models of Information Cascades,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17086," Shaobin Xu, David A. Smith. (2018). Contrastive Training for Models of Information Cascades AAAI, 483-490. https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17086","AAAI Association for the Advancement of Artificial Intelligence AAAI Association for the Advancement of Artificial Intelligence March 15, 2023",1287
1202,Machine Learning,Robin Walters,"June 16th, 2024",Improving Convergence and Generalization Using Parameter Symmetries,https://openreview.net/forum?id=L0r0GphlIL," Bo Zhao, Robert M. Gower, Robin Walters , Rose Yu. (2024). Improving Convergence and Generalization Using Parameter Symmetries ICLR. https://openreview.net/forum?id=L0r0GphlIL","In many neural networks, different values of the parameters may result in the same loss value. We show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization. The reviewers are unanimous that this is a good submission and that it should be accepted.",1288
1203,Machine Learning,Robin Walters,"May 1st, 2024",Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution,https://openreview.net/forum?id=59oXyDTLJv," Rui Wang , Elyssa F. Hofgard, Hang Gao , Robin Walters , Tess E. Smidt. (2024). Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution ICML. https://openreview.net/forum?id=59oXyDTLJv","Modeling symmetry breaking is essential for understanding the fundamental changes in the behaviors and properties of physical systems, from microscopic particle interactions to macroscopic phenomena like fluid dynamics and cosmic structures. Thus, identifying sources of asymmetry is an important tool for understanding physical systems. In this paper, we focus on learning asymmetries of data using relaxed group convolutions. We provide both theoretical and empirical evidence that this flexible convolution technique allows the model to maintain the highest level of equivariance that is consistent with data and discover the subtle symmetry-breaking factors in various physical systems. We employ various relaxed group convolution architectures to uncover various symmetry-breaking factors that are interpretable and physically meaningful in different physical systems, including the phase transition of crystal structure, the isotropy and homogeneity breaking in turbulent flow, and the time-reversal symmetry breaking in pendulum systems. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",1289
1204,Machine Learning,Robin Walters,"May 1st, 2024",Latent Space Symmetry Discovery,https://openreview.net/forum?id=qstt2OguvM," Jianke Yang, Nima Dehmamy, Robin Walters , Rose Yu. (2024). Latent Space Symmetry Discovery ICML. https://openreview.net/forum?id=qstt2OguvM","Equivariant neural networks require explicit knowledge of the symmetry group. Automatic symmetry discovery methods aim to relax this constraint and learn invariance and equivariance from data. However, existing symmetry discovery methods are limited to simple linear symmetries and cannot handle the complexity of real-world data. We propose a novel generative model, Latent LieGAN (LaLiGAN), which can discover symmetries of nonlinear group actions. It learns a mapping from the data space to a latent space where the symmetries become linear and simultaneously discovers symmetries in the latent space. Theoretically, we show that our model can express nonlinear symmetries under some conditions about the group action. Experimentally, we demonstrate that our method can accurately discover the intrinsic symmetry in high-dimensional dynamical systems. LaLiGAN also results in a well-structured latent space that is useful for downstream tasks including equation discovery and long-term forecasting. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",1290
1205,Machine Learning,Robin Walters,"January 16th, 2024",Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D,https://openreview.net/forum?id=UulwvAU1W0," Haojie Huang, Owen Howell, Dian Wang , Xupeng Zhu, Robert Platt , Robin Walters . (2024). Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D ICLR. https://openreview.net/forum?id=UulwvAU1W0",FourTran is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks. The paper presents a novel approach in robotic manipulation using Wigner D-matrices for fast cross-correlations in 3D pick and place tasks.,1291
1206,Machine Learning,Robin Walters,"July 4th, 2023",SEIL: Simulation-augmented Equivariant Imitation Learning,https://doi.org/10.1109/ICRA48891.2023.10161252," Mingxi Jia, Dian Wang , Guanang Su, David Klee, Xupeng Zhu, Robin Walters, Robert Platt. (2023). SEIL: Simulation-augmented Equivariant Imitation Learning ICRA, 1845-1851. https://doi.org/10.1109/ICRA48891.2023.10161252","Simulation-augmented Equivariant Imitation Learning (SEIL) combines a novel augmentation strategy of supplementing expert trajectories with simulated transitions. SEIL can learn non-trivial manipulation tasks within ten demonstrations and outperform the baselines by a significant margin. IEEE Conference will be held in London, UK, on July 4, 2023.",1292
1207,Machine Learning,Robin Walters,"July 4th, 2023",Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection,https://doi.org/10.1109/ICRA48891.2023.10160728," Haojie Huang, Dian Wang , Xupeng Zhu, Robin Walters, Robert Platt. (2023). Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection ICRA, 3882-3888. https://doi.org/10.1109/ICRA48891.2023.10160728",The problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. Here we propose a novel method and neural network model that enables better grasp success rates. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions.,1293
1208,Machine Learning,Robin Walters,"February 1st, 2023",Generative Adversarial Symmetry Discovery,https://doi.org/10.48550/arXiv.2302.00236," Jianke Yang, Robin Walters, Nima Dehmamy, Rose Yu. (2023). Generative Adversarial Symmetry Discovery CoRR, abs/2302.00236. https://doi.org/10.48550/arXiv.2302.00236","Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation groupSO(n), restricted Lorentz groupSO(1,3)+in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.",1294
1209,Machine Learning,Robin Walters,"July 17th, 2022",Toward Compositional Generalization in Object-Oriented World Modeling,https://proceedings.mlr.press/v162/zhao22b.html," Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2022). Toward Compositional Generalization in Object-Oriented World Modeling ICML, 26841-26864. https://proceedings.mlr.press/v162/zhao22b.html","Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves soft but more efficient compositional generalization.",1295
1210,Machine Learning,Robin Walters,"May 4th, 2022",Probabilistic Symmetry for Multi-Agent Dynamics,https://proceedings.mlr.press/v211/sun23a.html," Sophia Huiwen Sun, Robin Walters, Jinxi Li, Rose Yu. (2023). Probabilistic Symmetry for Multi-Agent Dynamics L4DC, 1231-1244. https://proceedings.mlr.press/v211/sun23a.html","Learning multi-agent dynamics is a core AI problem with broad applications in robotics and autonomous driving. While most existing works focus on deterministic prediction, producing probabilistic forecasts to quantify uncertainty and assess risks is critical for downstream decision-making tasks such as motion planning and collision avoidance. Multi-agent dynamics often contains internal symmetry. By leveraging symmetry, specifically rotation equivariance, we can improve not only the prediction accuracy but also uncertainty calibration. We introduce Energy Score, a proper scoring rule, to evaluate probabilistic predictions. We propose a novel deep dynamics model, Probabilistic Equivariant Continuous COnvolution (PECCO) for probabilistic prediction of multi-agent trajectories. PECCO extends equivariant continuous convolution to model the joint velocity distribution of multiple agents. It uses dynamics integration to propagate the uncertainty from velocity to position. On both synthetic and real-world datasets, PECCO shows significant improvements in accuracy and calibration compared to non-equivariant baselines.",1296
1211,Machine Learning,Robin Walters,"January 1st, 2022",Learning Symmetric Embeddings for Equivariant World Models,https://proceedings.mlr.press/v162/park22a.html," Jung Yeon Park, Ondrej Biza, Linfeng Zhao, Jan-Willem van de Meent, Robin Walters. (2022). Learning Symmetric Embeddings for Equivariant World Models ICML, 17372-17389. https://proceedings.mlr.press/v162/park22a.html","Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.",1297
1212,Machine Learning,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1298
1213,Machine Learning,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",1299
1214,Machine Learning,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1300
1215,Machine Learning,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",1301
1216,Machine Learning,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1302
1217,Machine Learning,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1303
1218,Machine Learning,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",1304
1219,Machine Learning,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1305
1220,Machine Learning,Chieh Wu,"March 28th, 2022",Deep Layer-wise Networks Have Closed-Form Weights,https://proceedings.mlr.press/v151/tzu-wu22a.html," Chieh Tzu Wu, Aria Masoomi, Arthur Gretton, Jennifer G. Dy. (2022). Deep Layer-wise Networks Have Closed-Form Weights AISTATS, 188-225. https://proceedings.mlr.press/v151/tzu-wu22a.html","There is currently a debate within the neuroscience community over the likelihood of the brain performing backpropagation (BP). To better mimic the brain, training a network one layer at a time with only a ""single forward pass"" has been proposed as an alternative to bypass BP; we refer to these networks as ""layer-wise"" networks. We continue the work on layer-wise networks by answering two outstanding questions. First, do they have a closed-form solution? Second, how do we know when to stop adding more layers? This work proves that the ""Kernel Mean Embedding"" is the closed-form solution that achieves the network global optimum while driving these networks to converge towards a highly desirable kernel for classification; we call it the Neural Indicator Kernel.",1306
1221,Machine Learning,Chieh Wu,"May 7th, 2021","A Chinese-Language Validation of the Video Game Demand Scale (VGDS-C): Measuring the Cognitive, Emotional, Physical, and Social Demands of Video Games",https://doi.org/10.1145/3411764.3445348," Nicholas David Bowman, JihHsuan Tammy Lin, Chieh Wu. (2021). A Chinese-Language Validation of the Video Game Demand Scale (VGDS-C): Measuring the Cognitive, Emotional, Physical, and Social Demands of Video Games CHI, 117:1-117:10. https://doi.org/10.1145/3411764.3445348","Video games are engaging multimedia experiences that require players‚Äô cognitive, emotional, physical (in terms of controllers and exertion), and social faculties. Recent theorizing has suggested that these dimensions of demand can explain processes by which players engage with and respond to gameplay. A relatively new measure‚Äîthe five-factor, 26-item Video Game Demand Scale (VGDS)‚Äîhas been tested for dimensionality and measurement validity with English- and German-speaking players, but not for other play populations. Given the popularity of video games among Chinese-speaking players, this brief report demonstrates a successful translation of VGDS into Traditional Chinese (VGDS-C). A sample of N = 863 Chinese speakers in Taiwan were asked to recall and describe a recent gaming experience before completing the VGDS-C along with other gaming-related measures (tests of construct validity). VGDS-C was shown to be a reliable and valid way of assessing players‚Äô perceptions of the myriad demands of video gaming.",1307
1222,Machine Learning,Chieh Wu,"February 23rd, 2021",Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth,https://doi.org/10.1109/ICMLA51294.2020.00124," Shi Dong , Zlatan Feric, Guangyu Li, Chieh Wu, April Z. Gu, Jennifer G. Dy, John Meeker, Ingrid Y. Padilla, Jos√© Cordero, Carmen Velez Vega, Zaira Rosario, Akram Alshawabkeh, David R. Kaeli. (2020). Using Undersampling with Ensemble Learning to Identify Factors Contributing to Preterm Birth ICMLA, 759-764. https://doi.org/10.1109/ICMLA51294.2020.00124","We propose Ensemble Learning models to identify factors contributing to preterm birth. Our work leverages a rich dataset collected by a NIEHS P42 Center in Puerto Rico. We propose two novel methods: 1) Missing Data Rate and Accuracy Based Aggregation (MAA) and 2) Entropy and Accuracy based Aggregation. Both proposed models balance the degree of data variance introduced by the missing data handling during the feature selection process, while maintaining model performance. Our results show a 42% improvement in sensitivity versus fallout over previous state-of-the-art methods. We leverage and compare multiple Ensemble Feature selection methods, including Complete Linear Aggregation, Weighted Mean Aggregation and Feature Occurrence Frequency (OFA)",1308
1223,Machine Learning,Chieh Wu,"December 1st, 2020",Instance-wise Feature Grouping,https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html," Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang , Peter J. Castaldi, Jennifer G. Dy. (2020). Instance-wise Feature Grouping NeurIPS. https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html","Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang, Peter Castaldi, Jennifer Dy In many learning problems, the domain scientist is often interested in discovering the groups of features that are redundant and are important for classification. Moreover, the features that belong to each group, and the important feature groups may vary per sample. But what do we mean by feature redundancy? In this paper, we formally define two types of redundancies using information theory: \textit{Representation} and \textit{Relevant redundancies}. We leverage these redundancies to design a formulation for instance-wise feature group discovery and reveal a theoretical guideline to help discover the appropriate number of groups. We approximate mutual information via a variational lower bound and learn the feature group and selector indicators with Gumbel-Softmax in optimizing our formulation. Experiments on synthetic data validate our theoretical claims. Experiments on MNIST, Fashion MNIST, and gene expression datasets show that our method discovers feature groups with high classification accuracies.",1309
1224,Machine Learning,Hongyang Zhang,"August 24th, 2024",Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity,https://doi.org/10.1145/3637528.3671835," Dongyue Li, Aneesh Sharma, Hongyang R. Zhang. (2024). Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity KDD, 1542-1553. https://doi.org/10.1145/3637528.3671835","A key notion for modeling relationships is task affinity. Naively computing either of them requires repeatedly training on data pooled from various task combinations. We present a new algorithm Grad-TAG that can estimate task affinities without this repeated training. On our largest graph with 21M edges and 500 labeling tasks, our algorithm delivers an estimate accurate to within 5% of thetrue affinity.",1310
1225,Machine Learning,Hongyang Zhang,"June 23rd, 2024",Learning Tree-Structured Composition of Data Augmentation,https://openreview.net/forum?id=lmgf03HeqV," Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang. (2024). Learning Tree-Structured Composition of Data Augmentation Trans. Mach. Learn. Res., 2024. https://openreview.net/forum?id=lmgf03HeqV","The problem of data augmentation is of significant importance across the spectrum of machine learning. The authors propose what I believe to be an intuitively clear and interesting approach for selecting sample transformations for creating a new training point instance. Although the approach of a top-down tree-based search is fairly simple, the added mixture of tree transforms idea for different data splits makes it rather interesting. The whole approach reduces the augmentation process complexity significantly. There are extensive experimental results that show the utility of the method, but there are no theoretical results that can provably establish the improvement of the method over other approaches. I find the lack of analyses reasonable due to the difficulty of the problem. I believe that a broad audience will be interested in this line of work since it has many practical applications (e.g., computational biology). The problem of data augmentation is of significant importance across the spectrum of machine learning. The authors propose what I believe to be an intuitively clear and interesting approach for selecting sample transformations for creating a new training point instance. Although the approach of a top-down tree-based search is fairly simple, the added mixture of tree transforms idea for different data splits makes it rather interesting. The whole approach reduces the augmentation process complexity significantly. There are extensive experimental results that show the utility of the method, but there are no theoretical results that can provably establish the improvement of the method over other approaches. I find the lack of analyses reasonable due to the difficulty of the problem.",1311
1226,Machine Learning,Hongyang Zhang,"August 4th, 2023",Boosting Multitask Learning on Graphs through Higher-Order Task Affinities,https://doi.org/10.1145/3580305.3599265," Dongyue Li, Haotian Ju, Aneesh Sharma, Hongyang R. Zhang. (2023). Boosting Multitask Learning on Graphs through Higher-Order Task Affinities KDD, 1213-1222. https://doi.org/10.1145/3580305.3599265","Predicting node labels on a given graph is a widely studied problem with many applications, including community detection and molecular graph prediction. This paper considers predicting multiple node labeling functions on graphs simultaneously and revisits this problem from a multitask learning perspective. For a concrete example, consider overlapping community detection: each community membership is a binary node classification task. Due to complex overlapping patterns, we find that negative transfer is prevalent when we apply naive multitask learning to multiple community detection, as task relationships are highly nonlinear across different node labeling. To address the challenge, we develop an algorithm to cluster tasks into groups based on a higher-order task affinity measure. We then fit a multitask model on each task group, resulting in a boosting procedure on top of the baseline model. We estimate the higher-order task affinity measure between two tasks as the prediction loss of one task in the presence of another task and a random subset of other tasks. Then, we use spectral clustering on the affinity score matrix to identify task grouping. We design several speedup techniques to compute the higher-order affinity scores efficiently and show that they can predict negative transfers more accurately than pairwise task affinities. We validate our procedure using various community detection and molecular graph prediction data sets, showing favorable results compared with existing methods. Lastly, we provide a theoretical analysis to show that under a planted block model of tasks on graphs, our affinity scores can provably separate tasks into groups.",1312
1227,Machine Learning,Hongyang Zhang,"January 1st, 2022",Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees,https://proceedings.mlr.press/v162/ju22a.html," Haotian Ju, Dongyue Li, Hongyang R. Zhang. (2022). Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees ICML, 10431-10461. https://proceedings.mlr.press/v162/ju22a.html","We consider transfer learning approaches that fine-tune a pretrained deep neural network on a target task. We investigate generalization properties of fine-tuning to understand the problem of overfitting, which often happens in practice. Previous works have shown that constraining the distance from the initialization of fine-tuning improves generalization. Using a PAC-Bayesian analysis, we observe that besides distance from initialization, Hessians affect generalization through the noise stability of deep neural networks against noise injections. Motivated by the observation, we develop Hessian distance-based generalization bounds for a wide range of fine-tuning methods. Next, we investigate the robustness of fine-tuning with noisy labels. We design an algorithm that incorporates consistent losses and distance-based regularization for fine-tuning. Additionally, we prove a generalization error bound of our algorithm under class conditional independent noise in the training dataset labels. We perform a detailed empirical study of our algorithm on various noisy environments and architectures. For example, on six image classification tasks whose training labels are generated with programmatic labeling, we show a 3.26% accuracy improvement over prior methods. Meanwhile, the Hessian distance measure of the fine-tuned network using our algorithm decreases by six times more than existing approaches.",1313
1228,Machine Learning,Hongyang Zhang,"January 1st, 2022",Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations,https://proceedings.mlr.press/v162/zhang22z.html," Michael Zhang, Nimit Sharad Sohoni, Hongyang R. Zhang, Chelsea Finn, Christopher R√©. (2022). Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations ICML, 26484-26516. https://proceedings.mlr.press/v162/zhang22z.html","Spurious correlations pose a major challenge for robust machine learning. Models trained with empirical risk minimization (ERM) may learn to rely on correlations between class labels and spurious attributes, leading to poor performance on data groups without these correlations. This is challenging to address when the spurious attribute labels are unavailable. To improve worst-group performance on spuriously correlated data without training attribute labels, we propose Correct-N-Contrast (CNC), a contrastive approach to directly learn representations robust to spurious correlations. As ERM models can be good spurious attribute predictors, CNC works by (1) using a trained ERM model‚Äôs outputs to identify samples with the same class but dissimilar spurious features, and (2) training a robust model with contrastive learning to learn similar representations for these samples. To support CNC, we introduce new connections between worst-group error and a representation alignment loss that CNC aims to minimize. We empirically observe that worst-group error closely tracks with alignment loss, and prove that the alignment loss over a class helps upper-bound the class‚Äôs worst-group vs. average error gap. On popular benchmarks, CNC reduces alignment loss drastically, and achieves state-of-the-art worst-group accuracy by 3.6% average absolute lift. CNC is also competitive with oracle methods that require group labels.",1314
1229,Machine Learning,Hongyang Zhang,"January 1st, 2021",Improved Regularization and Robustness for Fine-tuning in Neural Networks,https://proceedings.neurips.cc/paper/2021/hash/e4a93f0332b2519177ed55741ea4e5e7-Abstract.html," Dongyue Li, Hongyang R. Zhang. (2021). Improved Regularization and Robustness for Fine-tuning in Neural Networks NeurIPS, 27249-27262. https://proceedings.neurips.cc/paper/2021/hash/e4a93f0332b2519177ed55741ea4e5e7-Abstract.html","Part of Advances in Neural Information Processing Systems 34 (NeurIPS 2021) Dongyue Li, Hongyang Zhang A widely used algorithm for transfer learning is fine-tuning, where a pre-trained model is fine-tuned on a target task with a small amount of labeled data. When the capacity of the pre-trained model is much larger than the size of the target data set, fine-tuning is prone to overfitting and ""memorizing"" the training labels. Hence, an important question is to regularize fine-tuning and ensure its robustness to noise. To address this question, we begin by analyzing the generalization properties of fine-tuning. We present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the fine-tuned model. We empirically measure these quantities. Based on the analysis, we propose regularized self-labeling---the interpolation between regularization and self-labeling methods, including (i) layer-wise regularization to constrain the distance traveled in each layer; (ii) self label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. We validate our approach on an extensive collection of image and text data sets using multiple pre-trained model architectures. Our approach improves baseline methods by 1.76% (on average) for seven image classification tasks and 0.75% for a few-shot classification task. When the target data set includes noisy labels, our approach outperforms baseline methods by 3.56% on average in two noisy settings.",1315
1230,Machine Learning,Hongyang Zhang,"October 22nd, 2020",Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in High-dimensional Linear Regression,https://arxiv.org/abs/2010.11750," Zhang, H.R., Yang, F., Wu, S., Su, W.J. and R√©, C., 2020. Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in High-dimensional Linear Regression. arXiv preprint arXiv:2010.11750.","The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes and covariate/model shifts, which can be used to study transfer effects: In a random-effects model, we give conditions to determine positive and negative transfers between learning two tasks versus single-task learning; the conditions reveal intricate relations between dataset shifts and transfer effects. Simulations justify the validity of the asymptotics in finite dimensions. Our analysis examines several functions of two different sample covariance matrices, revealing some estimates that generalize classical results in the random matrix theory literature, which may be of independent interest.",1316
1231,Machine Learning,Hongyang Zhang,"July 23rd, 2020",Learning Over-Parametrized Two-Layer ReLU Neural Networks beyond NTK,https://arxiv.org/abs/2007.04596," Li, Y., Ma, T. and Zhang, H.R., 2020, July. Learning Over-parametrized Two-layer Neural Networks beyond NTK. In Conference on Learning Theory.","We consider the dynamic of gradient descent for learning a two-layer neural network. We assume the inputx‚ààRdis drawn from a Gaussian distribution and the label ofxsatisfiesf‚ãÜ(x)=a‚ä§|W‚ãÜx|, wherea‚ààRdis a nonnegative vector andW‚ãÜ‚ààRd√ódis an orthonormal matrix. We show that an over-parametrized two-layer neural network with ReLU activation, trained by gradient descent from random initialization, can provably learn the ground truth network with population loss at mosto(1/d)in polynomial time with polynomial samples. On the other hand, we prove that any kernel method, including Neural Tangent Kernel, with a polynomial number of samples ind, has population loss at leastŒ©(1/d).",1317
1232,Machine Learning,Hongyang Zhang,"July 7th, 2020",On the Generalization Effects of Linear Transformations in Data Augmentation,https://arxiv.org/abs/2005.00695," Wu, S., Zhang, H.R., Valiant, G. and R√©, C., 2020. On the Generalization Effects of Linear Transformations in Data Augmentation. ICML.","Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations that preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations that mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST. Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms random sampling methods by 1.24% on CIFAR-100 using Wide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA Adversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",1318
1233,Machine Learning,Hongyang Zhang,"May 2nd, 2020",Understanding and Improving Information Transfer in Multi-Task Learning,https://arxiv.org/abs/2005.00944," Wu, S., Zhang, H.R. and R√©, C., 2020. Understanding and Improving Information Transfer in Multi-Task Learning. ICLR.","We investigate multi-task learning approaches that use a shared feature representation for all tasks. To better understand the transfer of task information, we study an architecture with a shared module for all tasks and a separate output module for each task. We study the theory of this setting on linear and ReLU-activated models. Our key observation is that whether or not tasks' data are well-aligned can significantly affect the performance of multi-task learning. We show that misalignment between task data can cause negative transfer (or hurt performance) and provide sufficient conditions for positive transfer. Inspired by the theoretical insights, we show that aligning tasks' embedding layers leads to performance gains for multi-task training and transfer learning on the GLUE benchmark and sentiment analysis tasks; for example, we obtain a 2.35% GLUE score average improvement on 5 GLUE tasks over BERT-LARGE using our alignment method. We also design an SVD-based task reweighting scheme and show that it improves the robustness of multi-task training on a multi-label image dataset.",1319
1234,Machine Learning,Hongyang Zhang,"May 1st, 2019",Pruning based Distance Sketches with Provable Guarantees on Random Graphs,https://arxiv.org/abs/1712.08709," Zhang, H., Yu, H. and Goel, A., 2019, May. Pruning based Distance Sketches with Provable Guarantees on Random Graphs. In The World Wide Web Conference.","Measuring the distances between vertices on graphs is one of the most fundamental components in network analysis. Since finding shortest paths requires traversing the graph, it is challenging to obtain distance information on large graphs very quickly. In this work, we present a preprocessing algorithm that is able to create landmark based distance sketches efficiently, with strong theoretical guarantees. When evaluated on a diverse set of social and information networks, our algorithm significantly improves over existing approaches by reducing the number of landmarks stored, preprocessing time, or stretch of the estimated distances.On Erd√∂s-R√©nyi graphs and random power law graphs with degree distribution exponent2<Œ≤<3, our algorithm outputs an exact distance data structure with space betweenŒò(n5/4)andŒò(n3/2)depending on the value ofŒ≤, wherenis the number of vertices. We complement the algorithm with tight lower bounds for Erdos-Renyi graphs and the case whenŒ≤is close to two.",1320
1235,Machine Learning,Hongyang Zhang,"July 1st, 2018",Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations,https://arxiv.org/abs/1712.09203," Li, Y., Ma, T. and Zhang, H.R., 2018, July. Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations. In Conference On Learning Theory.","We show that the gradient descent algorithm provides an implicit regularization effect in the learning of over-parameterized matrix factorization models and one-hidden-layer neural networks with quadratic activations. Concretely, we show that givenO~(dr2)random linear measurements of a rankrpositive semidefinite matrixX‚ãÜ, we can recoverX‚ãÜby parameterizing it byUU‚ä§withU‚ààRd√ódand minimizing the squared loss, even ifr‚â™d. We prove that starting from a small initialization, gradient descent recoversX‚ãÜinO~(r‚àö)iterations approximately. The results solve the conjecture of Gunasekar et al.'17 under the restricted isometry property. The technique can be applied to analyzing neural networks with one-hidden-layer quadratic activations with some technical modifications.",1321
1236,Natural Language Processing,Malihe Alikhani,"November 1st, 2024",Studying and Mitigating Biases in Sign Language Understanding Models,https://aclanthology.org/2024.emnlp-main.17," Katherine Atwell, Danielle Bragg, Malihe Alikhani. (2024). Studying and Mitigating Biases in Sign Language Understanding Models EMNLP, 268-283. https://aclanthology.org/2024.emnlp-main.17","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Ensuring that the benefits of sign language technologies are distributed equitably among all community members is crucial. Thus, it is important to address potential biases and inequities that may arise from the design or use of these resources. Crowd-sourced sign language datasets, such as the ASL Citizen dataset, are great resources for improving accessibility and preserving linguistic diversity, but they must be used thoughtfully to avoid reinforcing existing biases.In this work, we utilize the rich information about participant demographics and lexical features present in the ASL Citizen dataset to study and document the biases that may result from models trained on crowd-sourced sign datasets. Further, we apply several bias mitigation techniques during model training, and find that these techniques reduce performance disparities without decreasing accuracy. With the publication of this work, we release the demographic information about the participants in the ASL Citizen dataset to encourage future bias mitigation work in this space.",1322
1237,Natural Language Processing,Malihe Alikhani,"December 1st, 2023",SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization,https://doi.org/10.18653/v1/2023.emnlp-main.799," Hyunwoo Kim , Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras , Malihe Alikhani, Gunhee Kim, Maarten Sap, Yejin Choi . (2023). SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization EMNLP, 12930-12949. https://doi.org/10.18653/v1/2023.emnlp-main.799","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Data scarcity has been a long standing issue in the field of open-domain social dialogue. To quench this thirst, we present SODA: the first publicly available, million-scale high-quality social dialogue dataset. By contextualizing social commonsense knowledge from a knowledge graph, we are able to distill an exceptionally broad spectrum of social interactions from a large language model. Human evaluation shows that conversations in SODA are more consistent, specific, and (surprisingly) natural than those in prior human-authored datasets. Using SODA, we train COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna). Experiments reveal COSMO is sometimes even preferred to the original human-written gold responses. Additionally, our results shed light on the distinction between knowledge-enriched conversations and natural social chitchats. We plan to make our data, model, and code public.",1323
1238,Natural Language Processing,Malihe Alikhani,"July 1st, 2023",Learning to Generate Equitable Text in Dialogue from Biased Training Data,https://doi.org/10.18653/v1/2023.acl-long.163," Anthony Sicilia, Malihe Alikhani. (2023). Learning to Generate Equitable Text in Dialogue from Biased Training Data ACL (1), 2898-2917. https://doi.org/10.18653/v1/2023.acl-long.163","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The ingrained principles of fairness in a dialogue system‚Äôs decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn. To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative-performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.",1324
1239,Natural Language Processing,Malihe Alikhani,"June 28th, 2022",Cross-Modal Coherence for Text-to-Image Retrieval,https://doi.org/10.1609/aaai.v36i10.21285," Malihe Alikhani, Fangda Han, Hareesh Ravi, Mubbasir Kapadia, Vladimir Pavlovic , Matthew Stone. (2022). Cross-Modal Coherence for Text-to-Image Retrieval AAAI, 10427-10435. https://doi.org/10.1609/aaai.v36i10.21285","Abstract Common image-text joint understanding techniques presume that images and the associated text can universally be characterized by a single implicit model. However, co-occurring images and text can be related in qualitatively different ways, and explicitly modeling it could improve the performance of current joint understanding models. In this paper, we train a Cross-Modal Coherence Model for text-to-image retrieval task. Our analysis shows that models trained with image‚Äìtext coherence relations can retrieve images originally paired with target text more often than coherence-agnostic models. We also show via human evaluation that images retrieved by the proposed coherence-aware model are preferred over a coherence-agnostic baseline by a huge margin. Our findings provide insights into the ways that different modalities communicate and the role of coherence relations in capturing commonsense inferences in text and imagery.",1325
1240,Natural Language Processing,Silvio Amir,"August 1st, 2024",Open (Clinical) LLMs are Sensitive to Instruction Phrasings,https://aclanthology.org/2024.bionlp-1.5," Alberto Mario Ceballos-Arroyo, Monica Munnangi, Jiuding Sun, Karen Y. C. Zhang, Denis Jered McInerney, Byron C. Wallace, Silvio Amir. (2024). Open (Clinical) LLMs are Sensitive to Instruction Phrasings BioNLP@ACL, 50-71. https://aclanthology.org/2024.bionlp-1.5","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain. This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs‚Äîsome general, others specialized‚Äîto natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that‚Äîperhaps surprisingly‚Äîdomain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",1326
1241,Natural Language Processing,Silvio Amir,"June 20th, 2024",Investigating Mysteries of CoT-Augmented Distillation,https://doi.org/10.48550/arXiv.2406.14511," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2024). Investigating Mysteries of CoT-Augmented Distillation CoRR, abs/2406.14511. https://doi.org/10.48550/arXiv.2406.14511","Eliciting ""chain of thought"" (CoT) rationales -- sequences of token that convey a ""reasoning"" process -- has been shown to consistently improve LLM performance on tasks like question answering. More recent efforts have shown that such rationales can also be used for model distillation: Including CoT sequences (elicited from a large ""teacher"" model) in addition to target labels when fine-tuning a small student model yields (often substantial) improvements. In this work we ask: Why and how does this additional training signal help in model distillation? We perform ablations to interrogate this, and report some potentially surprising results. Specifically: (1) Placing CoT sequences after labels (rather than before) realizes consistently better downstream performance -- this means that no student ""reasoning"" is necessary at test time to realize gains. (2) When rationales are appended in this way, they need not be coherent reasoning sequences to yield improvements; performance increases are robust to permutations of CoT tokens, for example. In fact, (3) a small number of key tokens are sufficient to achieve improvements equivalent to those observed when full rationales are used in model distillation.",1327
1242,Natural Language Processing,Silvio Amir,"March 29th, 2024",On-the-fly Definition Augmentation of LLMs for Biomedical NER,https://doi.org/10.48550/arXiv.2404.00152," Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik. (2024). On-the-fly Definition Augmentation of LLMs for Biomedical NER CoRR, abs/2404.00152. https://doi.org/10.48550/arXiv.2404.00152","Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code atthis https URL.",1328
1243,Natural Language Processing,Silvio Amir,"July 1st, 2023",SemEval-2023 Task 8: Causal Medical Claim Identification and Related PIO Frame Extraction from Social Media Posts,https://aclanthology.org/2023.semeval-1.311," Vivek Khetan, Somin Wadhwa, Byron C. Wallace, Silvio Amir. (2023). SemEval-2023 Task 8: Causal Medical Claim Identification and Related PIO Frame Extraction from Social Media Posts SemEval@ACL, 2266-2274. https://aclanthology.org/2023.semeval-1.311","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Identification of medical claims from user-generated text data is an onerous but essential step for various tasks including content moderation, and hypothesis generation. SemEval-2023 Task 8 is an effort towards building those capabilities and motivating further research in this direction. This paper summarizes the details and results of shared task 8 at SemEval-2023 which involved identifying causal medical claims and extracting related Populations, Interventions, and Outcomes (‚ÄúPIO‚Äù) frames from social media (Reddit) text. This shared task comprised two subtasks: (1) Causal claim identification; and (2) PIO frame extraction. In total, seven teams participated in the task. Of the seven, six provided system descriptions which we summarize here. For the first subtask, the best approach yielded a macro-averaged F-1 score of 78.40, and for the second subtask, the best approach achieved token-level F-1 scores of 40.55 for Populations, 49.71 for Interventions, and 30.08 for Outcome frames.",1329
1244,Natural Language Processing,Silvio Amir,"June 2nd, 2023",An Example of (Too Much) Hyper-Parameter Tuning In Suicide Ideation Detection,https://doi.org/10.1609/icwsm.v17i1.22227," Annika Marie Schoene, John E. Ortega, Silvio Amir, Kenneth Church . (2023). An Example of (Too Much) Hyper-Parameter Tuning In Suicide Ideation Detection ICWSM, 1158-1162. https://doi.org/10.1609/icwsm.v17i1.22227","Abstract This work starts with the TWISCO baseline, a benchmark of suicide-related content from Twitter. We find that hyper-parameter tuning can improve this baseline by 9%. We examined 576 combinations of hyper-parameters: learning rate, batch size, epochs and date range of training data. Reasonable settings of learning rate and batch size produce better results than poor settings. Date range is less conclusive. Balancing the date range of the training data to match the benchmark ought to improve performance, but the differences are relatively small. Optimal settings of learning rate and batch size are much better than poor settings, but optimal settings of date range are not that different from poor settings of date range. Finally, we end with concerns about reproducibility. Of the 576 experiments, 10% produced F1 performance above baseline. It is common practice in the literature to run many experiments and report the best, but doing so may be risky, especially given the sensitive nature of Suicide Ideation Detection.",1330
1245,Natural Language Processing,Silvio Amir,"May 8th, 2023",Revisiting Relation Extraction in the era of Large Language Models,https://doi.org/10.48550/arXiv.2305.05003," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2023). Revisiting Relation Extraction in the era of Large Language Models CoRR, abs/2305.05003. https://doi.org/10.48550/arXiv.2305.05003","Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a \emph{sequence-to-sequence} task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA results. We release this model as a new baseline for RE tasks.",1331
1246,Natural Language Processing,Silvio Amir,"May 5th, 2023","Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs",https://doi.org/10.48550/arXiv.2305.03642," Somin Wadhwa, Jay DeYoung, Benjamin E. Nye, Silvio Amir, Byron C. Wallace. (2023). Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs CoRR, abs/2305.03642. https://doi.org/10.48550/arXiv.2305.03642","Results from Randomized Controlled Trials (RCTs) establish the comparative effectiveness of interventions, and are in turn critical inputs for evidence-based care. However, results from RCTs are presented in (often unstructured) natural language articles describing the design, execution, and outcomes of trials; clinicians must manually extract findings pertaining to interventions and outcomes of interest from such articles. This onerous manual process has motivated work on (semi-)automating extraction of structured evidence from trial reports. In this work we propose and evaluate a text-to-text model built on instruction-tuned Large Language Models (LLMs) to jointly extract Interventions, Outcomes, and Comparators (ICO elements) from clinical abstracts, and infer the associated results reported. Manual (expert) and automated evaluations indicate that framing evidence extraction as a conditional generation task and fine-tuning LLMs for this purpose realizes considerable (‚àº20 point absolute F1 score) gains over the previous SOTA. We perform ablations and error analyses to assess aspects that contribute to model performance, and to highlight potential directions for further improvements. We apply our model to a collection of published RCTs through mid-2022, and release a searchable database of structured findings:this http URL",1332
1247,Natural Language Processing,Silvio Amir,"October 12th, 2022","RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media",https://doi.org/10.48550/arXiv.2210.06331," Somin Wadhwa, Vivek Khetan, Silvio Amir, Byron C. Wallace. (2022). RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media CoRR, abs/2210.06331. https://doi.org/10.48550/arXiv.2210.06331","We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly annotated social media posts from Reddit spanning 24 health conditions. Annotations include demarcations of spans corresponding to medical claims, personal experiences, and questions. We collect additional granular annotations on identified claims. Specifically, we mark snippets that describe patient Populations, Interventions, and Outcomes (PIO elements) within these. Using this corpus, we introduce the task of retrieving trustworthy evidence relevant to a given claim made on social media. We propose a new method to automatically derive (noisy) supervision for this task which we use to train a dense retrieval model; this outperforms baseline models. Manual evaluation of retrieval results performed by medical doctors indicate that while our system performance is promising, there is considerable room for improvement. Collected annotations (and scripts to assemble the dataset), are available atthis https URL.",1333
1248,Natural Language Processing,Silvio Amir,"August 16th, 2022",UserNLP‚Äô22: 2022 International Workshop on User-centered Natural Language Processing,https://doi.org/10.1145/3487553.3524879," Xiaolei Huang , Lucie Flek, Franck Dernoncourt, Charles Welch, Silvio Amir, Ramit Sawhney, Diyi Yang. (2022). UserNLP'22: 2022 International Workshop on User-centered Natural Language Processing WWW (Companion Volume), 1176-1177. https://doi.org/10.1145/3487553.3524879","We report goals, paper submissions, keynotes, and organizations of this UserNLP workshop. User-centered NLP can fill these gaps by explicitly considering stylistic variations across individuals or groups of individuals and focusing on user-level modeling tasks. While traditional NLP tasks tend to focus on single documents (e.g., sentiment analysis), user-centered NLP aims to make inferences for individual users, on the basis of one or more documents associated with that user. This workshop aims to create a platform where researchers can present rising challenges in building user-centered NLP models and discuss shared issues across multidisciplinary fields. We have received 11 submissions and accepted 6 of the submissions, which were reviewed by our 19 program committee members. The program invited four keynote talks from both academia and industry. We appreciate the valuable contributions from the organizing committee, program committee, keynote speakers, and the manuscript authors.",1334
1249,Natural Language Processing,Silvio Amir,"June 6th, 2021",On the Impact of Random Seeds on the Fairness of Clinical Classifiers,https://doi.org/10.18653/v1/2021.naacl-main.299," Silvio Amir, Jan-Willem van de Meent, Byron C. Wallace. (2021). On the Impact of Random Seeds on the Fairness of Clinical Classifiers NAACL-HLT, 3808-3823. https://doi.org/10.18653/v1/2021.naacl-main.299","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III ‚Äî‚Äî the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of minority groups and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from stochasticity and small sample sizes.",1335
1250,Natural Language Processing,Silvio Amir,"April 22nd, 2021",Demographic Representation and Collective Storytelling in the Me Too Twitter Hashtag Activism Movement,https://doi.org/10.1145/3449181," Aaron Mueller, Zach Wood-Doughty, Silvio Amir, Mark Dredze, Alicia Lynn Nobles. (2021). Demographic Representation and Collective Storytelling in the Me Too Twitter Hashtag Activism Movement Proc. ACM Hum. Comput. Interact., 5, 107:1-107:28. https://doi.org/10.1145/3449181","The #MeToo movement on Twitter has drawn attention to the pervasive nature of sexual harassment and violence. While #MeToo has been praised for providing support for self-disclosures of harassment or violence and shifting societal response, it has also been criticized for exemplifying how women of color have been discounted for their historical contributions to and excluded from feminist movements. Through an analysis of over 600,000 tweets from over 256,000 unique users, we examine online #MeToo conversations across gender and racial/ethnic identities and the topics that each demographic emphasized. We found that tweets authored by white women were overrepresented in the movement compared to other demographics, aligning with criticism of unequal representation. We found that intersected identities contributed differing narratives to frame the movement, co-opted the movement to raise visibility in parallel ongoing movements, employed the same hashtags both critically and supportively, and revived and created new hashtags in response to pivotal moments. Notably, tweets authored by black women often expressed emotional support and were critical about differential treatment in the justice system and by police. In comparison, tweets authored by white women and men often highlighted sexual harassment and violence by public figures and weaved in more general political discussions. We discuss the implications of this work for digital activism research and design, including suggestions to raise visibility by those who were under-represented in this hashtag activism movement. Content warning: this article discusses issues of sexual harassment and violence.",1336
1251,Natural Language Processing,Javed Aslam,"October 30th, 2024","Don‚Äôt Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification",https://doi.org/10.48550/arXiv.2410.23066," Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu. (2024). Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification CoRR, abs/2410.23066. https://doi.org/10.48550/arXiv.2410.23066","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely heavily on multi-label attention layers to focus on key tokens in input text, but obtaining optimal attention weights is challenging and resource-intensive. To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses existing state-of-the-art methods across all metrics on mimicfull, mimicfifty, mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot scenarios, outperforming previous models specifically designed for few-shot scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36 percentage points on mimicfew, demonstrating its superior capability in handling rare codes. PLANT also shows remarkable data efficiency in few-shot scenarios, achieving precision comparable to traditional models with significantly less data. These results are achieved through key technical innovations: leveraging a pretrained Learning-to-Rank model as the planted attention layer, integrating mutual-information gain to enhance attention, introducing an inattention mechanism, and implementing a stateful-decoder to maintain context. Comprehensive ablation studies validate the importance of these contributions in realizing the performance gains.",1337
1252,Natural Language Processing,Javed Aslam,"August 2nd, 2024",Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy,https://doi.org/10.1145/3626324," Maryam Aziz, Jesse Anderton, Kevin G. Jamieson, Alice Wang, Hugues Bouchard, Javed A. Aslam. (2025). Unbiased Identification of Broadly Appealing Content Using a Pure Exploration Infinitely Armed Bandit Strategy Trans. Recomm. Syst., 3, 4:1-4:22. https://doi.org/10.1145/3626324","Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely armed pure-exploration setting. We demonstrate that our algorithm is well suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches. Finally, we study a setting in which users are more likely to stream more-streamed podcasts independent of their general appeal and find that our proposed algorithm is robust to this type of popularity bias.",1338
1253,Natural Language Processing,Javed Aslam,"January 1st, 2021",Improving Query Graph Generation for Complex Question Answering over Knowledge Base,https://doi.org/10.18653/v1/2021.emnlp-main.346," Kechen Qin, Cheng Li, Virgil Pavlu, Javed A. Aslam. (2021). Improving Query Graph Generation for Complex Question Answering over Knowledge Base EMNLP (1), 4201-4207. https://doi.org/10.18653/v1/2021.emnlp-main.346","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Most of the existing Knowledge-based Question Answering (KBQA) methods first learn to map the given question to a query graph, and then convert the graph to an executable query to find the answer. The query graph is typically expanded progressively from the topic entity based on a sequence prediction model. In this paper, we propose a new solution to query graph generation that works in the opposite manner: we start with the entire knowledge base and gradually shrink it to the desired query graph. This approach improves both the efficiency and the accuracy of query graph generation, especially for complex multi-hop questions. Experimental results show that our method achieves state-of-the-art performance on ComplexWebQuestion (CWQ) dataset.",1339
1254,Natural Language Processing,Javed Aslam,"June 23rd, 2019",Adapting RNN Sequence Prediction Model to Multi-label Set Prediction,https://www.aclweb.org/anthology/N19-1321/," Conference Proceedings Adapting RNN Sequence Prediction Model to Multi-label Set Prediction. Qin, Kechen; Li, Cheng; Pavlu, Virgil; Aslam, Javed. Proceedings of the 2019 NAACL-HLT, Volume 1 (Long and Short Papers), 2019 8 jun I Association for Computational Linguistics, Minneapolis, Minnesota","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present an adaptation of RNN sequence models to the problem of multi-label classification for text, where the target is a set of labels, not a sequence. Previous such RNN models define probabilities for sequences but not for sets; attempts to obtain a set probability are after-thoughts of the network design, including pre-specifying the label order, or relating the sequence probability to the set probability in ad hoc ways. Our formulation is derived from a principled notion of set probability, as the sum of probabilities of corresponding permutation sequences for the set. We provide a new training objective that maximizes this set probability, and a new prediction objective that finds the most probable set on a test document. These new objectives are theoretically appealing because they give the RNN model freedom to discover the best label order, which often is the natural one (but different among documents). We develop efficient procedures to tackle the computation difficulties involved in training and prediction. Experiments on benchmark datasets demonstrate that we outperform state-of-the-art methods for this task.",1340
1255,Natural Language Processing,Javed Aslam,"June 15th, 2019",Scaling Up Ordinal Embedding: A Landmark Approach,http://proceedings.mlr.press/v97/anderton19a.html," Anderton, J. & Aslam, J.. (2019). Scaling Up Ordinal Embedding: A Landmark Approach. Proceedings of the 36th International Conference on Machine Learning, in PMLR 97:282-290","Ordinal Embedding is the problem of placing n objects into R^d to satisfy constraints like ""object a is closer to b than to c."" It can accommodate data that embeddings from features or distances cannot, but is a more difficult problem. We propose a novel landmark-based method as a partial solution. At small to medium scales, we present a novel combination of existing methods with some new theoretical justification. For very large values of n optimizing over an entire embedding breaks down, so we propose a novel method which first embeds a subset of m << n objects and then embeds the remaining objects independently and in parallel. We prove a distance error bound for our method in terms of m and that it has O(dn log m) time complexity, and show empirically that it is able to produce high quality embeddings in a fraction of the time needed for any published method.",1341
1256,Natural Language Processing,Javed Aslam,"March 24th, 2018",Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence,https://doi.org/10.48550/arXiv.1803.04665," Aziz, M., Anderton, J., Kaufmann, E. and Aslam, J.. (2018). ""Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence."" Proceedings of Algorithmic Learning Theory, in PMLR 83:3-24. DOI: 0.48550/arXiv.1803.04665","We consider the problem of near-optimal arm identification in the fixed confidence setting of the infinitely armed bandit problem when nothing is known about the arm reservoir distribution. We (1) introduce a PAC-like framework within which to derive and cast results; (2) derive a sample complexity lower bound for near-optimal arm identification; (3) propose an algorithm that identifies a nearly-optimal arm with high probability and derive an upper bound on its sample complexity which is within a log factor of our lower bound; and (4) discuss whether our log^2(1/delta) dependence is inescapable for ""two-phase"" (select arms first, identify the best later) algorithms in the infinite setting. This work permits the application of bandit models to a broader class of problems where fewer assumptions hold.",1342
1257,Natural Language Processing,Javed Aslam,"January 17th, 2018",A Pipeline for Optimizing F1-Measure in Multi-label Text Classification,https://ieeexplore.ieee.org/abstract/document/8614173," B. Wang, C. Li, V. Pavlu, J. Aslam, ""A Pipeline for Optimizing F1-Measure in Multi-label Text Classification ,"" ICMLA, 2018.",Multi-label text classification is the machine learning task wherein each document is tagged with multiple labels. This task is uniquely challenging due to high dimensional features and correlated labels. Such text classifiers need to be regularized to prevent severe over-fitting in the high dimensional space. We propose a new pipeline which takes such algorithms and improves their F1-performance with careful training regularization and a new prediction strategy. We further demonstrate that support inference acts as a strong regularizer on the label prediction structure.,1343
1258,Natural Language Processing,Javed Aslam,"October 23rd, 2015",Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model,https://doi.org/10.1145/2806416.2806492," P. Metrikov, V. Pavlu, J. A. Aslam. ""Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model"". Proceedings of the 24th ACM Conference on Information and Knowledge Management, Melbourne, Australia (2015). DOI: 10.1145/2806416.2806492","Existing approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors. A document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.",1344
1259,Natural Language Processing,Javed Aslam,"September 29th, 2013",A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments,http://dx.doi.org/10.1145/2499178.2499198," Pavel Metrikov, Jie Wu, Jesse Anderton, Virgil Pavlu, and Javed A. Aslam. 2013. A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments. In Proceedings of the 2013 Conference on the Theory of Information Retrieval (ICTIR '13). Association for Computing Machinery, New York, NY, USA, 133‚Äì134. https://doi.org/10.1145/2499178.2499198","We consider noisy crowdsourced assessments and their impact on learning-to-rank algorithms. Starting with EM-weighted assessments, we modify LambdaMART in order to use smoothed probabilistic preferences over pairs of documents, directly as input to the ranking algorithm.",1345
1260,Natural Language Processing,Javed Aslam,"March 24th, 2013",Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency,http://link.springer.com/chapter/10.1007/978-3-642-36973-5_78," P. Metrikov, V. Pavlu, J. A. Aslam, ""Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency"", Advances in Information Retrieval: 35th European Conference on IR Research (ECIR), Moscow, Russia (2013).  Best Poster Paper Award","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1346
1261,Natural Language Processing,Ricardo Baeza-Yates,"February 17th, 2025",A Comparison of Human and Machine Learning Errors in Face Recognition,https://doi.org/10.48550/arXiv.2502.11337," Marina Est√©vez-Almenzar, Ricardo Baeza-Yates, Carlos Castillo . (2025). A Comparison of Human and Machine Learning Errors in Face Recognition CoRR, abs/2502.11337. https://doi.org/10.48550/arXiv.2502.11337","Machine learning applications in high-stakes scenarios should always operate under human oversight. Developing an optimal combination of human and machine intelligence requires an understanding of their complementarities, particularly regarding the similarities and differences in the way they make mistakes. We perform extensive experiments in the area of face recognition and compare two automated face recognition systems against human annotators through a demographically balanced user study. Our research uncovers important ways in which machine learning errors and human errors differ from each other, and suggests potential strategies in which human-machine collaboration can improve accuracy in face recognition.",1347
1262,Natural Language Processing,Ricardo Baeza-Yates,"February 7th, 2025",Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning,https://doi.org/10.1109/ACCESS.2025.3539719," Maria Rauschenberger, Ricardo Baeza-Yates, Luz Rello. (2025). Screening Dyslexia Using Visual Auditory Computer Games and Machine Learning IEEE Access, 13, 29541-29553. https://doi.org/10.1109/ACCESS.2025.3539719",Dyslexia is a type of neuro-developmental disorder that affects the ability to learn how to read and write. We present an approach for screening dyslexic using language-independent games in combination with machine learning models. Our results open the possibility of inexpensive online early screening of dyslexy for young children using non-linguistic elements. The study was published in IEEE Access ( Volume: 13 ) Page(s): 29541 - 29553 Date of Publication: 07 February 2025 Electronic ISSN: 2169-3536. DOI: 10.1109/ACCESS.2025.3539719 Publisher: IEEE Funding Agency.,1348
1263,Natural Language Processing,Ricardo Baeza-Yates,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1349
1264,Natural Language Processing,Ricardo Baeza-Yates,"September 21st, 2024",AI content detection in the emerging information ecosystem: new obligations for media and tech companies,https://doi.org/10.1007/s10676-024-09795-1," Alistair Knott, Dino Pedreschi, Toshiya Jitsuzumi, Susan Leavy, David M. Eyers, Tapabrata Chakraborti, Andrew Trotman, Sundar Sundareswaran, Ricardo Baeza-Yates, Przemyslaw Biecek, Adrian Weller, Paul D. Teal, Subhadip Basu, Mehmet Haklidir, Virginia Morini, Stuart Russell , Yoshua Bengio. (2024). AI content detection in the emerging information ecosystem: new obligations for media and tech companies Ethics Inf. Technol., 26, 63. https://doi.org/10.1007/s10676-024-09795-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",1350
1265,Natural Language Processing,Ricardo Baeza-Yates,"August 4th, 2023",Fair Multilingual Vandalism Detection System for Wikipedia,https://doi.org/10.1145/3580305.3599823," Mykola Trokhymovych, Muniza Aslam, Ai-Jou Chou, Ricardo Baeza-Yates, Diego S√°ez-Trumper. (2023). Fair Multilingual Vandalism Detection System for Wikipedia KDD, 4981-4990. https://doi.org/10.1145/3580305.3599823","This paper presents a novel design of the system aimed at supporting the Wikipedia community in addressing vandalism on the platform. To achieve this, we collected a massive dataset of 47 languages, and applied advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data. The performance of the system was evaluated through comparison with the one used in production in Wikipedia, known as ORES. Our research results in a significant increase in the number of languages covered, making Wikipedia patrolling more efficient to a wider range of communities. Furthermore, our model outperforms ORES, ensuring that the results provided are not only more accurate but also less biased against certain groups of contributors.",1351
1266,Natural Language Processing,Ricardo Baeza-Yates,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",1352
1267,Natural Language Processing,Ricardo Baeza-Yates,"May 14th, 2018",Bias on the Web,https://dl.acm.org/citation.cfm?id=2908135," Ricardo Baeza-Yates. Bias on the Web. Communications of ACM, June 2018.","The Web is the largest public big data repository that humankind has created. In this overwhelming data ocean we need to be aware of the quality of data extracted from it. One important quality issue is data bias, which appears in different forms. These biases affect the (machine learning) algorithms that we design to improve the user experience. This problem is further exacerbated by biases that are added by these algorithms, especially in the context of recommendation and personalization systems. We give several examples, stressing the importance of the user context to avoid these biases.",1353
1268,Natural Language Processing,Ricardo Baeza-Yates,"December 14th, 2017",Quality-efficiency trade-offs in machine learning for text processing,https://arxiv.org/abs/1711.02295," Ricardo A. Baeza-Yates, Zeinab Liaghat:Quality-efficiency trade-offs in machine learning for text processing. IEEE BigData 2017: 897-904.",Are quality gains worth it when the rate of data processing diminishes? Can we trade quality for time efficiency and recover the quality loss by just being able to process more data? We propose a performance trade-off framework and apply it to three important text processing problems. We find that the results do not change significantly and that most of the time the best algorithms is the fastest.,1354
1269,Natural Language Processing,David Bau,"November 1st, 2024",Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs,https://aclanthology.org/2024.emnlp-main.543," Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs EMNLP, 9727-9739. https://aclanthology.org/2024.emnlp-main.543","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b‚Äôs tokenizer splits the word ‚Äúpatrolling‚Äù into two tokens, ‚Äúpat‚Äù and ‚Äúrolling‚Äù, neither of which correspond to semantically meaningful units like ‚Äúpatrol‚Äù or ""-ing.‚Äù Similarly, the overall meanings of named entities like ‚ÄúNeil Young‚Äù and multi-word expressions like ‚Äúbreak a leg‚Äù cannot be directly inferred from their constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups of tokens into useful higher-level representations? In this work, we find that last token representations of named entities and multi-token words exhibit a pronounced ‚Äúerasure‚Äù effect, where information about previous and current tokens is rapidly forgotten in early layers. Using this observation, we propose a method to ‚Äúread out‚Äù the implicit vocabulary of an autoregressive LLM by examining differences in token representations across layers, and present results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is the first attempt to probe the implicit vocabulary of an LLM.",1355
1270,Natural Language Processing,David Bau,"January 16th, 2024",Linearity of Relation Decoding in Transformer Language Models,https://openreview.net/forum?id=w7LU2s14kE," Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, David Bau. (2024). Linearity of Relation Decoding in Transformer Language Models ICLR. https://openreview.net/forum?id=w7LU2s14kE","Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations. For a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. The authors conduct experiments on 47 different relations, showing that linear approximations hold for some but not all relations.",1356
1271,Natural Language Processing,David Bau,"January 16th, 2024",Function Vectors in Large Language Models,https://openreview.net/forum?id=AwyxtyMwaG," Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. (2024). Function Vectors in Large Language Models ICLR. https://openreview.net/forum?id=AwyxtyMwaG",This paper delves into the concept of function vectors (FVs) within autoregressive transformer language models (LLMs) FVs encapsulate task-specific information and exhibit robustness across various contexts. The study uncovers that FVs don't directly execute tasks but trigger the model to perform them through complex computations.,1357
1272,Natural Language Processing,David Bau,"January 16th, 2024",Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking,https://openreview.net/forum?id=8sKcAWOf2D," Nikhil Prakash, Tamar Rott Shaham, Tal Haklay, Yonatan Belinkov, David Bau. (2024). Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking ICLR. https://openreview.net/forum?id=8sKcAWOf2D",The paper focuses on entity tracking (model inferring properties with an entity previously defined in the input context) to understand how LMs change during fine-tuning. They use a path-patching technique on synthetic dataset to isolate circuits responsible for entity tracking. They find all three models reach high faithfulness scores with the circuit identified in Llama-7B.,1358
1273,Natural Language Processing,David Bau,"January 15th, 2024",Erasing Concepts from Diffusion Models,https://doi.org/10.1109/ICCV51070.2023.00230," Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau. (2023). Erasing Concepts from Diffusion Models ICCV, 2426-2436. https://doi.org/10.1109/ICCV51070.2023.00230","Motivated by concerns that large-scale diffusion models can produce undesirable output such as sexually explicit content or copyrighted artistic styles. We propose a fine-tuning method that can erase a visual concept from a pre-trained diffusion model, given only the name of the style. Unlike previous methods, our approach can remove concepts from a diffusion model permanently rather than modifying the output at the inference time, so it cannot be circumvented. Our code, data, and results are available at erasing.baulab.info.",1359
1274,Natural Language Processing,David Bau,"November 8th, 2023",Future Lens: Anticipating Subsequent Tokens from a Single Hidden State,https://arxiv.org/abs/2311.04897," Pal, K., Sun, J., Yuan, A., Wallace, B.C., & Bau, D. (2023). Future Lens: Anticipating Subsequent Tokens from a Single Hidden State. ArXiv, abs/2311.04897.","We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at positiontin an input, can we reliably anticipate the tokens that will appear at positions‚â•t+2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a ""Future Lens"" visualization that uses these methods to create a new view of transformer states.",1360
1275,Natural Language Processing,David Bau,"September 7th, 2023",FIND: A Function Description Benchmark for Evaluating Interpretability Methods,http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html," Sarah Schwettmann, Tamar Rott Shaham, Joanna Materzynska, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, Antonio Torralba . (2023). FIND: A Function Description Benchmark for Evaluating Interpretability Methods NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/ef0164c1112f56246224af540857348f-Abstract-Datasets_and_Benchmarks.html",FIND (Function INterpretation and Description) is a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks. The results suggest that FIND will be useful for characterizing the performance of more sophisticated interpretable methods before they are applied to real- world models.,1361
1276,Natural Language Processing,David Bau,"February 28th, 2022",Toward a Visual Concept Vocabulary for GAN Latent Space,https://doi.org/10.1109/ICCV48922.2021.00673," Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas, Antonio Torralba . (2021). Toward a Visual Concept Vocabulary for GAN Latent Space ICCV, 6784-6792. https://doi.org/10.1109/ICCV48922.2021.00673","New method for building open-ended vocabularies of primitive visual concepts. Concepts learned with our approach are reliable and composable, and enabling fine-grained manipulation of image style and content. Based on automatic identification of perceptually salient directions based on their layer selectivity. Human annotation of these directions with free-form, natural language descriptions. decomposition of these annotations into a visual concept vocabulary.",1362
1277,Natural Language Processing,David Bau,"February 10th, 2022",Locating and Editing Factual Associations in GPT,https://arxiv.org/abs/2202.05262," Meng, K., Bau, D., Andonian, A., & Belinkov, Y. (2022). Locating and Editing Factual Associations in GPT. Neural Information Processing Systems.","We analyze the storage and recall of factual associations in autoregressive transformer language models, finding evidence that these associations correspond to localized, directly-editable computations. We first develop a causal intervention for identifying neuron activations that are decisive in a model's factual predictions. This reveals a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions while processing subject tokens. To test our hypothesis that these computations correspond to factual association recall, we modify feed-forward weights to update specific factual associations using Rank-One Model Editing (ROME). We find that ROME is effective on a standard zero-shot relation extraction (zsRE) model-editing task, comparable to existing methods. To perform a more sensitive evaluation, we also evaluate ROME on a new dataset of counterfactual assertions, on which it simultaneously maintains both specificity and generalization, whereas other methods sacrifice one or another. Our results confirm an important role for mid-layer feed-forward modules in storing factual associations and suggest that direct manipulation of computational mechanisms may be a feasible approach for model editing. The code, dataset, visualizations, and an interactive demo notebook are available atthis https URL",1363
1278,Natural Language Processing,David Bau,"January 28th, 2022",Disentangling visual and written concepts in CLIP,https://doi.org/10.1109/CVPR52688.2022.01592," Joanna Materzynska, Antonio Torralba , David Bau. (2022). Disentangling visual and written concepts in CLIP CVPR, 16389-16398. https://doi.org/10.1109/CVPR52688.2022.01592","The CLIP network measures the similarity between natural text and images. In this work, we investigate the entanglement of the representation of word images and natural images in its image encoder. This is consistent with previous research that suggests that the meaning and the spelling of a word might be entangled deep within the network. We find that our methods are able to cleanly separate spelling capabilities of CLIP from the visual processing of natural images. On the other hand, we also find that CLIP has a strong ability to match nonsense words, suggesting that processing of letters is separated from processing of their meaning.",1364
1279,Natural Language Processing,David Bau,"August 5th, 2021",Sketch Your Own GAN,https://peterwang512.github.io/GANSketching/," Sheng-Yu Wang, David Bau, and Jun-Yan Zhu. Sketch Your Own GAN. Proceedings of the IEEE/CVF International Conference on Computer Vision. (ICCV 2021)","Our method can customize a pre-trained GAN to match input sketches. Interpolation using our customized models. Latent space interpolation is smooth with our customized models. Image editing using our customized models. (a) Given a real image, (b) we project it to the original model's noise z using Huh et al. (c) We feed the projected z to the standing cat model trained on sketches. (d) we edit the image with `add fur` operation using GANSpace . We can interpolate between the customized model by interpolating the W-latent space.",1365
1280,Natural Language Processing,David Bau,"January 1st, 2020",Diverse Image Generation via Self-Conditioned GANs,https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html," Steven Liu, Tongzhou Wang , David Bau, Jun-Yan Zhu, Antonio Torralba . (2020). Diverse Image Generation via Self-Conditioned GANs CVPR, 14274-14283. https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Diverse_Image_Generation_via_Self-Conditioned_GANs_CVPR_2020_paper.html","We introduce a simple but effective unsupervised method for generating diverse images. We train a class-conditional GAN model without using manually annotated class labels. Instead, our model is conditional on labels automatically derived from clustering in the discriminator's feature space. Our clustering step automatically discovers diverse modes, and explicitly requires the generator to cover them. Experiments on standard mode collapse benchmarks show that our method outperforms several competing methods when addressing mode collapse. Our method also performs well on large-scale datasets such as ImageNet and Places365, improving both diversity and standard metrics (e.g., Frechet Inception Distance), compared to previous methods.",1366
1281,Natural Language Processing,Kenneth Church,"May 23rd, 2022",Emerging trends: General fine-tuning (gft),https://doi.org/10.1017/S1351324922000237," K. Church, X. Cai, Y. Ying, Z. Chen, G. Xun, Y. Bian. (2022). Emerging trends: General fine-tuning (gft). Natural Language Engineering, 28(4), 519-535. DOI: 10.1017/S1351324922000237","This paper describes gft (general fine-tuning), a little language for deep nets. gft makes deep nets accessible to a broad audience including non-programmers. It is standard practice in many fields to use statistics packages such as R. The paper is published in the online version with a free download.",1367
1282,Natural Language Processing,Kenneth Church,"February 8th, 2022",Emerging trends: SOTA-Chasing,https://doi.org/10.1017/S1351324922000043," K. Church & V. Kordoni. (2022). Emerging Trends: SOTA-Chasing. Natural Language Engineering, 28(2), 249-269. DOI: 10.1017/S1351324922000043","Many papers are chasing state-of-the-art (SOTA) numbers. SOTA-chasing may be similar to the replication crisis in the scientific literature. Too much SOTA.-chasing could lead to claims of superhuman. performance, unrealistic expectations, and the next AI winter.",1368
1283,Natural Language Processing,Kenneth Church,"May 31st, 2021","Emerging trends: Ethics, intimidation, and the Cold War",https://doi.org/10.1017/S135132492100005X," K. Church & V. Kordoni. (2021). Emerging trends: Ethics, intimidation, and the Cold War. Natural Language Engineering, 27(3), 379-390. DOI: 10.1017/S135132492100005X"," ACL has recently introduced a new process where there are special reviews of some papers for ethics. We would be more comfortable with the new ethics process if there were more checks and balances, due process and transparency. Otherwise, there is a risk that the process could intimidate authors in ways that are not that dissimilar to the ways that academics were intimidated during the Cold War.",1369
1284,Natural Language Processing,Virgil Pavlu,"October 30th, 2024","Don‚Äôt Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification",https://doi.org/10.48550/arXiv.2410.23066," Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu. (2024). Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification CoRR, abs/2410.23066. https://doi.org/10.48550/arXiv.2410.23066","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely heavily on multi-label attention layers to focus on key tokens in input text, but obtaining optimal attention weights is challenging and resource-intensive. To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses existing state-of-the-art methods across all metrics on mimicfull, mimicfifty, mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot scenarios, outperforming previous models specifically designed for few-shot scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36 percentage points on mimicfew, demonstrating its superior capability in handling rare codes. PLANT also shows remarkable data efficiency in few-shot scenarios, achieving precision comparable to traditional models with significantly less data. These results are achieved through key technical innovations: leveraging a pretrained Learning-to-Rank model as the planted attention layer, integrating mutual-information gain to enhance attention, introducing an inattention mechanism, and implementing a stateful-decoder to maintain context. Comprehensive ablation studies validate the importance of these contributions in realizing the performance gains.",1370
1285,Natural Language Processing,Virgil Pavlu,"May 22nd, 2020",A Complex KBQA System using Multiple Reasoning Paths,https://arxiv.org/abs/2005.10970," Kechen Qin, Yu Wang , Cheng Li, Kalpa Gunaratna, Hongxia Jin, Virgil Pavlu, Javed A. Aslam. (2020). A Complex KBQA System using Multiple Reasoning Paths CoRR, abs/2005.10970. https://arxiv.org/abs/2005.10970","Multi-hop knowledge based question answering (KBQA) is a complex task for natural language understanding. Many KBQA approaches have been proposed in recent years, and most of them are trained based on labeled reasoning path. This hinders the system's performance as many correct reasoning paths are not labeled as ground truth, and thus they cannot be learned. In this paper, we introduce an end-to-end KBQA system which can leverage multiple reasoning paths' information and only requires labeled answer as supervision. We conduct experiments on several benchmark datasets containing both single-hop simple questions as well as muti-hop complex questions, including WebQuestionSP (WQSP), ComplexWebQuestion-1.1 (CWQ), and PathQuestion-Large (PQL), and demonstrate strong performance.",1371
1286,Natural Language Processing,Virgil Pavlu,"April 30th, 2020",Learning to Calibrate and Rerank Multi-label Predictions,https://doi.org/10.1007/978-3-030-46133-1_14," Cheng Li, Virgil Pavlu, Javed A. Aslam, Bingyu Wang, Kechen Qin. (2019). Learning to Calibrate and Rerank Multi-label Predictions ECML/PKDD (3), 220-236. https://doi.org/10.1007/978-3-030-46133-1_14","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1372
1287,Natural Language Processing,Virgil Pavlu,"June 23rd, 2019",Adapting RNN Sequence Prediction Model to Multi-label Set Prediction,https://www.aclweb.org/anthology/N19-1321/," Conference Proceedings Adapting RNN Sequence Prediction Model to Multi-label Set Prediction. Qin, Kechen; Li, Cheng; Pavlu, Virgil; Aslam, Javed. Proceedings of the 2019 NAACL-HLT, Volume 1 (Long and Short Papers), 2019 8 jun I Association for Computational Linguistics, Minneapolis, Minnesota","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We present an adaptation of RNN sequence models to the problem of multi-label classification for text, where the target is a set of labels, not a sequence. Previous such RNN models define probabilities for sequences but not for sets; attempts to obtain a set probability are after-thoughts of the network design, including pre-specifying the label order, or relating the sequence probability to the set probability in ad hoc ways. Our formulation is derived from a principled notion of set probability, as the sum of probabilities of corresponding permutation sequences for the set. We provide a new training objective that maximizes this set probability, and a new prediction objective that finds the most probable set on a test document. These new objectives are theoretically appealing because they give the RNN model freedom to discover the best label order, which often is the natural one (but different among documents). We develop efficient procedures to tackle the computation difficulties involved in training and prediction. Experiments on benchmark datasets demonstrate that we outperform state-of-the-art methods for this task.",1373
1288,Natural Language Processing,Virgil Pavlu,"October 24th, 2016",A Study of Realtime Summarization Metrics,https://doi.org/10.1145/2983323.2983653," Matthew Ekstrand-Abueg, Richard McCreadie, Virgil Pavlu, and Fernando Diaz. 2016. A Study of Realtime Summarization Metrics. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM '16). Association for Computing Machinery, New York, NY, USA, 2125‚Äì2130. DOI: 10.1145/2983323.2983653","Unexpected news events, such as natural disasters or other human tragedies, create a large volume of dynamic text data from official news media as well as less formal social media. Automatic real-time text summarization has become an important tool for quickly transforming this overabundance of text into clear, useful information for end-users including affected individuals, crisis responders, and interested third parties. Despite the importance of real-time summarization systems, their evaluation is not well understood as classic methods for text summarization are inappropriate for real-time and streaming conditions. The TREC 2013-2015 Temporal Summarization (TREC-TS) track was one of the first evaluation campaigns to tackle the challenges of real-time summarization evaluation, introducing new metrics, ground-truth generation methodology and dataset. In this paper, we present a study of TREC-TS track evaluation methodology, with the aim of documenting its design, analyzing its effectiveness, as well as identifying improvements and best practices for the evaluation of temporal summarization systems.",1374
1289,Natural Language Processing,Virgil Pavlu,"October 23rd, 2015",Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model,https://doi.org/10.1145/2806416.2806492," P. Metrikov, V. Pavlu, J. A. Aslam. ""Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model"". Proceedings of the 24th ACM Conference on Information and Knowledge Management, Melbourne, Australia (2015). DOI: 10.1145/2806416.2806492","Existing approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors. A document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.",1375
1290,Natural Language Processing,Virgil Pavlu,"September 29th, 2013",A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments,http://dx.doi.org/10.1145/2499178.2499198," Pavel Metrikov, Jie Wu, Jesse Anderton, Virgil Pavlu, and Javed A. Aslam. 2013. A Modification of LambdaMART to Handle Noisy Crowdsourced Assessments. In Proceedings of the 2013 Conference on the Theory of Information Retrieval (ICTIR '13). Association for Computing Machinery, New York, NY, USA, 133‚Äì134. https://doi.org/10.1145/2499178.2499198","We consider noisy crowdsourced assessments and their impact on learning-to-rank algorithms. Starting with EM-weighted assessments, we modify LambdaMART in order to use smoothed probabilistic preferences over pairs of documents, directly as input to the ranking algorithm.",1376
1291,Natural Language Processing,Virgil Pavlu,"March 24th, 2013",Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency,http://link.springer.com/chapter/10.1007/978-3-642-36973-5_78," P. Metrikov, V. Pavlu, J. A. Aslam, ""Optimizing nDCG Gains by Minimizing Effect of Label Inconsistency"", Advances in Information Retrieval: 35th European Conference on IR Research (ECIR), Moscow, Russia (2013).  Best Poster Paper Award","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1377
1292,Natural Language Processing,Virgil Pavlu,"August 12th, 2012",Impact of Assessor Disagreement on Ranking Performance,http://dx.doi.org/10.1145/2348283.2348484," P. Metrikov, V. Pavlu, J. A. Aslam, ""Effect of Assessor Disagreement on Ranking Performance"", Proceedings of the 35th international ACM SIGIR conference on Research and Development in Information Retrieval, Portland, USA (2012)","We consider the impact of inter-assessor disagreement on the maximum performance that a ranker can hope to achieve. We demonstrate that even if a ranker were to achieve perfect performance with respect to a given assessor, when evaluated with respect to a different assessor, the measured performance of the ranker decreases significantly. This decrease in performance may largely account for observed limits on the performance of learning-to-rank algorithms.",1378
1293,Natural Language Processing,Virgil Pavlu,"July 24th, 2011",A Large-scale Study of the Effect of Training Set Characteristics over Learning-to-Rank Algorithms,http://dx.doi.org/10.1145/2009916.2010140," E. Kanoulas, S. Savev, P. Metrikov, V. Pavlu, J. A. Aslam, ""A Large-scale Study of the Effect of Training Set Characteristics over Learning-to-Rank Algorithms"", Proceedings of the 34th international ACM SIGIR conference on Research and Development in Information Retrieval, Beijing, China (2011)",In this work we describe the results of a large-scale study on the effect of the distribution of labels across the different grades of relevance in the training set on the performance of trained ranking functions. In a controlled experiment we generate a large number of training datasets wih different label distributions and employ three learning to rank algo- rithms over these datasets. We investigate the effect of these distributions on the accuracy of obtained ranking functions to give an insight into the manner training sets should be constructed.,1379
1294,Natural Language Processing,David Smith,"February 21st, 2025",Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training,https://doi.org/10.48550/arXiv.2502.15680," Jaydeep Borkar, Matthew Jagielski, Katherine Lee, Niloofar Mireshghallah, David A. Smith, Christopher A. Choquette-Choo. (2025). Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training CoRR, abs/2502.15680. https://doi.org/10.48550/arXiv.2502.15680","Due to the sensitive nature of personally identifiable information (PII), its owners may have the authority to control its inclusion or request its removal from large-language model (LLM) training. Beyond this, PII may be added or removed from training datasets due to evolving dataset curation techniques, because they were newly scraped for retraining, or because they were included in a new downstream fine-tuning stage. We find that the amount and ease of PII memorization is a dynamic property of a model that evolves throughout training pipelines and depends on commonly altered design choices. We characterize three such novel phenomena: (1) similar-appearing PII seen later in training can elicit memorization of earlier-seen sequences in what we call assisted memorization, and this is a significant factor (in our settings, up to 1/3); (2) adding PII can increase memorization of other PII significantly (in our settings, as much as‚âà7.5√ó); and (3) removing PII can lead to other PII being memorized. Model creators should consider these first- and second-order privacy risks when training models to avoid the risk of new PII regurgitation.",1380
1295,Natural Language Processing,David Smith,"September 11th, 2024","MONSTERMASH: Multidirectional, Overlapping, Nested, Spiral Text Extraction for Recognition Models of Arabic-Script Handwriting",https://doi.org/10.1007/978-3-031-70642-4_6," Danlu Chen, Jacob Murel, Taimoor Shahid, Xiang Zhang, Jonathan Parkes Allen, Taylor Berg-Kirkpatrick, David A. Smith. (2024). MONSTERMASH: Multidirectional, Overlapping, Nested, Spiral Text Extraction for Recognition Models of Arabic-Script Handwriting ICDAR (Workshops 2), 87-101. https://doi.org/10.1007/978-3-031-70642-4_6","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1381
1296,Natural Language Processing,David Smith,"September 11th, 2024",Retrieving and Analyzing Translations of American Newspaper Comics with Visual Evidence,https://doi.org/10.1007/978-3-031-70645-5_9," Jacob Murel, David A. Smith. (2024). Retrieving and Analyzing Translations of American Newspaper Comics with Visual Evidence ICDAR (Workshops 1), 125-137. https://doi.org/10.1007/978-3-031-70645-5_9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1382
1297,Natural Language Processing,David Smith,"September 9th, 2024",Self-training and Active Learning with Pseudo-relevance Feedback for Handwriting Detection in Historical Print,https://doi.org/10.1007/978-3-031-70543-4_18," Jacob Murel, David A. Smith. (2024). Self-training and Active Learning with Pseudo-relevance Feedback for Handwriting Detection in Historical Print ICDAR (3), 305-324. https://doi.org/10.1007/978-3-031-70543-4_18","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1383
1298,Natural Language Processing,David Smith,"June 28th, 2024",Mind the Gap: Analyzing Lacunae with Transformer-Based Transcription,https://doi.org/10.48550/arXiv.2407.00250," Jaydeep Borkar, David A. Smith. (2024). Mind the Gap: Analyzing Lacunae with Transformer-Based Transcription CoRR, abs/2407.00250. https://doi.org/10.48550/arXiv.2407.00250","Historical documents frequently suffer from damage and inconsistencies, including missing or illegible text resulting from issues such as holes, ink problems, and storage damage. These missing portions or gaps are referred to as lacunae. In this study, we employ transformer-based optical character recognition (OCR) models trained on synthetic data containing lacunae in a supervised manner. We demonstrate their effectiveness in detecting and restoring lacunae, achieving a success rate of 65%, compared to a base model lacking knowledge of lacunae, which achieves only 5% restoration. Additionally, we investigate the mechanistic properties of the model, such as the log probability of transcription, which can identify lacunae and other errors (e.g., mistranscriptions due to complex writing or ink issues) in line images without directly inspecting the image. This capability could be valuable for scholars seeking to distinguish images containing lacunae or errors from clean ones. Although we explore the potential of attention mechanisms in flagging lacunae and transcription errors, our findings suggest it is not a significant factor. Our work highlights a promising direction in utilizing transformer-based OCR models for restoring or analyzing damaged historical documents.",1384
1299,Natural Language Processing,David Smith,"February 24th, 2024",Detecting Manuscript Annotations in Historical Print: Negative Evidence and Evaluation Metrics,https://doi.org/10.5220/0012365600003654," Jacob Murel, David A. Smith. (2024). Detecting Manuscript Annotations in Historical Print: Negative Evidence and Evaluation Metrics ICPRAM, 745-752. https://doi.org/10.5220/0012365600003654","Early readers‚Äô manuscript annotations in books have been analyzed by bibliographers for evidence about book history and reading practice. Since handwritten annotations are not uniformly distributed across or within books, even the compilers of censuses of all copies of a single edition have very seldom produced systematic information. This paper analyzes the use of object detection models (ODMs) for detecting handwritten annotations on the pages of printed books.",1385
1300,Natural Language Processing,David Smith,"June 5th, 2023",Composition and Deformance: Measuring Imageability with a Text-to-Image Model,https://doi.org/10.48550/arXiv.2306.03168," Si Wu, David A. Smith. (2023). Composition and Deformance: Measuring Imageability with a Text-to-Image Model CoRR, abs/2306.03168. https://doi.org/10.48550/arXiv.2306.03168","Although psycholinguists and psychologists have long studied the tendency of linguistic strings to evoke mental images in hearers or readers, most computational studies have applied this concept of imageability only to isolated words. Using recent developments in text-to-image generation models, such as DALLE mini, we propose computational methods that use generated images to measure the imageability of both single English words and connected text. We sample text prompts for image generation from three corpora: human-generated image captions, news article sentences, and poem lines. We subject these prompts to different deformances to examine the model's ability to detect changes in imageability caused by compositional change. We find high correlation between the proposed computational measures of imageability and human judgments of individual words. We also find the proposed measures more consistently respond to changes in compositionality than baseline approaches. We discuss possible effects of model training and implications for the study of compositionality in text-to-image models.",1386
1301,Natural Language Processing,David Smith,"May 5th, 2023",Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces,https://doi.org/10.48550/arXiv.2305.03819," Shijia Liu, David A. Smith. (2023). Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces CoRR, abs/2305.03819. https://doi.org/10.48550/arXiv.2305.03819","Brain-computer interfaces (BCI) are an important mode of alternative and augmentative communication for many people. Unlike keyboards, many BCI systems do not display even the 26 letters of English at one time, let alone all the symbols in more complex systems. Using language models to make character-level predictions, therefore, can greatly speed up BCI typing (Ghosh and Kristensson, 2017). While most existing BCI systems employ character n-gram models or no LM at all, this paper adapts several wordpiece-level Transformer LMs to make character predictions and evaluates them on typing tasks. GPT-2 fares best on clean text, but different LMs react differently to noisy histories. We further analyze the effect of character positions in a word and context lengths.",1387
1302,Natural Language Processing,David Smith,"December 8th, 2022",An Experiment in Live Collaborative Programming on the Croquet Shared Experience Platform,https://doi.org/10.1145/3532512.3535224," Yoshiki Ohshima, Aran Lunzer, Jenn Evans, Vanessa Freudenberg, Brian Upton, David A. Smith. (2022). An Experiment in Live Collaborative Programming on the Croquet Shared Experience Platform Programming, 46-53. https://doi.org/10.1145/3532512.3535224","This paper describes our experiences in building a live collaborative programming environment on top of the JavaScript version of the Croquet shared experience platform. Croquet provides a clean substrate for building real-time collaborative applications. We created an application framework that supports live programming, and used that framework to build the Greenlight collaborative application, then in turn, modified it to do live programming experiments. The environment allows multiple users to modify the running application from within, with changes taking effect immediately. The experiment was inspired by earlier work including Douglas Engelbart‚Äôs oN-Line System (NLS) and the Kansas system in Self. Analogically, the system is like the Smalltalk environment made collaborative. In this paper we explain the Croquet architecture, its library and framework, and the Greenlight application used to make the live programming environment. The standard version of Greenlight is available at https://croquet.io/greenlight, and the modified demo system is available at https://croquet.io/scripting.",1388
1303,Natural Language Processing,David Smith,"February 27th, 2021",Text mining Mill: Computationally detecting influence in the writings of John Stuart Mill from library records,https://doi.org/10.1093/llc/fqab010," Helen O'Neill, Anne Welsh, David A. Smith, Glenn Roe, Melissa Terras. (2021). Text mining Mill: Computationally detecting influence in the writings of John Stuart Mill from library records Digit. Scholarsh. Humanit., 36, 1013-1029. https://doi.org/10.1093/llc/fqab010","How can computational methods illuminate the relationship between a leading intellectual, and their lifetime library membership? We report here on an international collaboration that explored the interrelation between the reading record and the publications of the British philosopher and economist John Stuart Mill, focusing on his relationship with the London Library, an independent lending library of which Mill was a member for 32 years. Building on detailed archival research of the London Library‚Äôs lending and book donation records, a digital library of texts borrowed, and publications produced was assembled, which enabled natural language processing approaches to detect textual reuse and similarity, establishing the relationship between Mill and the Library. Text mining the books Mill borrowed and donated against his published outputs demonstrates that the collections of the London Library influenced his thought, transferred into his published oeuvre, and featured in his role as political commentator and public moralist. We reconceive archival library issue registers as data for triangulating against the growing body of digitized historical texts and the output of leading intellectual figures. We acknowledge, however, that this approach is dependent on the resources and permissions to transcribe extant library registers, and on access to previously digitized sources. Related copyright and privacy restrictions mean our approach is most likely to succeed for other leading eighteenth- and nineteenth-century figures. Open in new tab Download slide Open in new tab Download slide",1389
1304,Natural Language Processing,David Smith,"January 1st, 2021",Content-based Models of Quotation,https://doi.org/10.18653/v1/2021.eacl-main.195," Ansel MacLaughlin, David A. Smith. (2021). Content-based Models of Quotation EACL, 2296-2314. https://doi.org/10.18653/v1/2021.eacl-main.195","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract We explore the task of quotability identification, in which, given a document, we aim to identify which of its passages are the most quotable, i.e. the most likely to be directly quoted by later derived documents. We approach quotability identification as a passage ranking problem and evaluate how well both feature-based and BERT-based (Devlin et al., 2019) models rank the passages in a given document by their predicted quotability. We explore this problem through evaluations on five datasets that span multiple languages (English, Latin) and genres of literature (e.g. poetry, plays, novels) and whose corresponding derived documents are of multiple types (news, journal articles). Our experiments confirm the relatively strong performance of BERT-based models on this task, with the best model, a RoBERTA sequential sentence tagger, achieving an average rho of 0.35 and NDCG@1, 5, 50 of 0.26, 0.31 and 0.40, respectively, across all five datasets.",1390
1305,Natural Language Processing,David Smith,"February 8th, 2018",Contrastive Training for Models of Information Cascades,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17086," Shaobin Xu, David A. Smith. (2018). Contrastive Training for Models of Information Cascades AAAI, 483-490. https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17086","AAAI Association for the Advancement of Artificial Intelligence AAAI Association for the Advancement of Artificial Intelligence March 15, 2023",1391
1306,Natural Language Processing,Byron Wallace,"November 1st, 2024",Learning from Natural Language Explanations for Generalizable Entity Matching,https://aclanthology.org/2024.emnlp-main.352," Somin Wadhwa, Adit Krishnan, Runhui Wang, Byron C. Wallace, Luyang Kong. (2024). Learning from Natural Language Explanations for Generalizable Entity Matching EMNLP, 6114-6129. https://aclanthology.org/2024.emnlp-main.352","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Entity matching is the task of linking records from different sources that refer to the same real-world entity. Past work has primarily treated entity linking as a standard supervised learning problem. However, supervised entity matching models often do not generalize well to new data, and collecting exhaustive labeled training data is often cost prohibitive. Further, recent efforts have adopted LLMs for this task in few/zero-shot settings, exploiting their general knowledge. But LLMs are prohibitively expensive for performing inference at scale for real-world entity matching tasks.As an efficient alternative, we re-cast entity matching as a conditional generation task as opposed to binary classification. This enables us to ‚Äúdistill‚Äù LLM reasoning into smaller entity matching models via natural language explanations. This approach achieves strong performance, especially on out-of-domain generalization tests (10.85% F-1) where standalone generative methods struggle. We perform ablations that highlight the importance of explanations, both for performance and model robustness.",1392
1307,Natural Language Processing,Byron Wallace,"November 1st, 2024",Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs,https://aclanthology.org/2024.emnlp-main.543," Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs EMNLP, 9727-9739. https://aclanthology.org/2024.emnlp-main.543","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b‚Äôs tokenizer splits the word ‚Äúpatrolling‚Äù into two tokens, ‚Äúpat‚Äù and ‚Äúrolling‚Äù, neither of which correspond to semantically meaningful units like ‚Äúpatrol‚Äù or ""-ing.‚Äù Similarly, the overall meanings of named entities like ‚ÄúNeil Young‚Äù and multi-word expressions like ‚Äúbreak a leg‚Äù cannot be directly inferred from their constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups of tokens into useful higher-level representations? In this work, we find that last token representations of named entities and multi-token words exhibit a pronounced ‚Äúerasure‚Äù effect, where information about previous and current tokens is rapidly forgotten in early layers. Using this observation, we propose a method to ‚Äúread out‚Äù the implicit vocabulary of an autoregressive LLM by examining differences in token representations across layers, and present results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is the first attempt to probe the implicit vocabulary of an LLM.",1393
1308,Natural Language Processing,Byron Wallace,"August 1st, 2024",Open (Clinical) LLMs are Sensitive to Instruction Phrasings,https://aclanthology.org/2024.bionlp-1.5," Alberto Mario Ceballos-Arroyo, Monica Munnangi, Jiuding Sun, Karen Y. C. Zhang, Denis Jered McInerney, Byron C. Wallace, Silvio Amir. (2024). Open (Clinical) LLMs are Sensitive to Instruction Phrasings BioNLP@ACL, 50-71. https://aclanthology.org/2024.bionlp-1.5","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain. This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs‚Äîsome general, others specialized‚Äîto natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that‚Äîperhaps surprisingly‚Äîdomain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",1394
1309,Natural Language Processing,Byron Wallace,"August 1st, 2024",FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence,https://aclanthology.org/2024.acl-long.459," Sebastian Joseph, Lily Chen, Jan Trienes, Hannah Louisa G√∂ke, Monika Coers, Wei Xu , Byron C. Wallace, Junyi Jessy Li. (2024). FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence ACL (1), 8437-8464. https://aclanthology.org/2024.acl-long.459","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment. FactPICO consists of 345 plain language summaries of RCT abstracts generated from three LLMs (i.e., GPT-4, Llama-2, and Alpaca), with fine-grained evaluation and natural language rationales from experts. We assess the factuality of critical elements of RCTs in those summaries: Populations, Interventions, Comparators, Outcomes (PICO), as well as the reported findings concerning these. We also evaluate the correctness of the extra information (e.g., explanations) added by LLMs. Using FactPICO, we benchmark a range of existing factuality metrics, including the newly devised ones based on LLMs. We find that plain language summarization of medical evidence is still challenging, especially when balancing between simplicity and factuality, and that existing metrics correlate poorly with expert judgments on the instance level.",1395
1310,Natural Language Processing,Byron Wallace,"August 1st, 2024",InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification,https://aclanthology.org/2024.acl-long.234," Jan Trienes, Sebastian Joseph, J√∂rg Schl√∂tterer, Christin Seifert, Kyle Lo, Wei Xu , Byron C. Wallace, Junyi Jessy Li. (2024). InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification ACL (1), 4263-4294. https://aclanthology.org/2024.acl-long.234","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of English medical study abstracts. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pairs and their linguistic suitability, our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss.",1396
1311,Natural Language Processing,Byron Wallace,"June 20th, 2024",Investigating Mysteries of CoT-Augmented Distillation,https://doi.org/10.48550/arXiv.2406.14511," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2024). Investigating Mysteries of CoT-Augmented Distillation CoRR, abs/2406.14511. https://doi.org/10.48550/arXiv.2406.14511","Eliciting ""chain of thought"" (CoT) rationales -- sequences of token that convey a ""reasoning"" process -- has been shown to consistently improve LLM performance on tasks like question answering. More recent efforts have shown that such rationales can also be used for model distillation: Including CoT sequences (elicited from a large ""teacher"" model) in addition to target labels when fine-tuning a small student model yields (often substantial) improvements. In this work we ask: Why and how does this additional training signal help in model distillation? We perform ablations to interrogate this, and report some potentially surprising results. Specifically: (1) Placing CoT sequences after labels (rather than before) realizes consistently better downstream performance -- this means that no student ""reasoning"" is necessary at test time to realize gains. (2) When rationales are appended in this way, they need not be coherent reasoning sequences to yield improvements; performance increases are robust to permutations of CoT tokens, for example. In fact, (3) a small number of key tokens are sufficient to achieve improvements equivalent to those observed when full rationales are used in model distillation.",1397
1312,Natural Language Processing,Byron Wallace,"June 1st, 2024",Towards Reducing Diagnostic Errors with Interpretable Risk Prediction,https://doi.org/10.18653/v1/2024.naacl-long.399," Denis Jered McInerney, William Dickinson, Lucy C. Flynn, Andrea Young, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace. (2024). Towards Reducing Diagnostic Errors with Interpretable Risk Prediction NAACL-HLT, 7193-7210. https://doi.org/10.18653/v1/2024.naacl-long.399","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Many diagnostic errors occur because clinicians cannot easily access relevant information in patient Electronic Health Records (EHRs). In this work we propose a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses; our ultimate aim is to increase access to evidence and reduce diagnostic errors. In particular, we propose a Neural Additive Model to make predictions backed by evidence with individualized risk estimates at time-points where clinicians are still uncertain, aiming to specifically mitigate delays in diagnosis and errors stemming from an incomplete differential. To train such a model, it is necessary to infer temporally fine-grained retrospective labels of eventual ‚Äútrue‚Äù diagnoses. We do so with LLMs, to ensure that the input text is from before a confident diagnosis can be made. We use an LLM to retrieve an initial pool of evidence, but then refine this set of evidence according to correlations learned by the model. We conduct an in-depth evaluation of the usefulness of our approach by simulating how it might be used by a clinician to decide between a pre-defined list of differential diagnoses.",1398
1313,Natural Language Processing,Byron Wallace,"March 29th, 2024",On-the-fly Definition Augmentation of LLMs for Biomedical NER,https://doi.org/10.48550/arXiv.2404.00152," Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik. (2024). On-the-fly Definition Augmentation of LLMs for Biomedical NER CoRR, abs/2404.00152. https://doi.org/10.48550/arXiv.2404.00152","Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code atthis https URL.",1399
1314,Natural Language Processing,Byron Wallace,"January 16th, 2024",Function Vectors in Large Language Models,https://openreview.net/forum?id=AwyxtyMwaG," Eric Todd, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. (2024). Function Vectors in Large Language Models ICLR. https://openreview.net/forum?id=AwyxtyMwaG",This paper delves into the concept of function vectors (FVs) within autoregressive transformer language models (LLMs) FVs encapsulate task-specific information and exhibit robustness across various contexts. The study uncovers that FVs don't directly execute tasks but trigger the model to perform them through complex computations.,1400
1315,Natural Language Processing,Byron Wallace,"January 16th, 2024",Evaluating the Zero-shot Robustness of Instruction-tuned Language Models,https://openreview.net/forum?id=g9diuvxN6D," Jiuding Sun, Chantal Shaib, Byron C. Wallace. (2024). Evaluating the Zero-shot Robustness of Instruction-tuned Language Models ICLR. https://openreview.net/forum?id=g9diuvxN6D","Using novel (unobserved) but appropriate instruction phrasings consistently degrades model performance. Such natural instructions yield a wide variance in downstream performance, despite their semantic equivalence. We propose a simple method to mitigate this issue by introducing ``soft prompt'' embedding parameters and optimizing these to maximize the similarity between representations of semantically equivalent instructions.",1401
1316,Natural Language Processing,Byron Wallace,"December 1st, 2023",Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews,https://aclanthology.org/2023.emnlp-main.626," Hye Sun Yun, Iain James Marshall, Thomas A. Trikalinos, Byron C. Wallace. (2023). Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews EMNLP, 10122-10139. https://aclanthology.org/2023.emnlp-main.626","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Medical systematic reviews play a vital role in healthcare decision making and policy. However, their production is time-consuming, limiting the availability of high-quality and up-to-date evidence summaries. Recent advancements in LLMs offer the potential to automatically generate literature reviews on demand, addressing this issue. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucination or omission. In healthcare, this can make LLMs unusable at best and dangerous at worst. We conducted 16 interviews with international systematic review experts to characterize the perceived utility and risks of LLMs in the specific context of medical evidence reviews. Experts indicated that LLMs can assist in the writing process by drafting summaries, generating templates, distilling information, and crosschecking information. They also raised concerns regarding confidently composed but inaccurate LLM outputs and other potential downstream harms, including decreased accountability and proliferation of low-quality reviews. Informed by this qualitative analysis, we identify criteria for rigorous evaluation of biomedical LLMs aligned with domain expert views.",1402
1317,Natural Language Processing,Byron Wallace,"November 8th, 2023",Future Lens: Anticipating Subsequent Tokens from a Single Hidden State,https://arxiv.org/abs/2311.04897," Pal, K., Sun, J., Yuan, A., Wallace, B.C., & Bau, D. (2023). Future Lens: Anticipating Subsequent Tokens from a Single Hidden State. ArXiv, abs/2311.04897.","We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at positiontin an input, can we reliably anticipate the tokens that will appear at positions‚â•t+2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a ""Future Lens"" visualization that uses these methods to create a new view of transformer states.",1403
1318,Natural Language Processing,Byron Wallace,"May 23rd, 2023",Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations,https://aclanthology.org/2023.acl-long.549," Lucy Lu Wang, Yulia Otmakhova , Jay DeYoung, Thinh Hung Truong, Bailey Kuehl, Erin Bransom, Byron C. Wallace. (2023). Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations ACL (1), 9871-9889. https://aclanthology.org/2023.acl-long.549","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Evaluating multi-document summarization (MDS) quality is difficult. This is especially true in the case of MDS for biomedical literature reviews, where models must synthesize contradicting evidence reported across different documents. Prior work has shown that rather than performing the task, models may exploit shortcuts that are difficult to detect using standard n-gram similarity metrics such as ROUGE. Better automated evaluation metrics are needed, but few resources exist to assess metrics when they are proposed. Therefore, we introduce a dataset of human-assessed summary quality facets and pairwise preferences to encourage and support the development of better automated evaluation methods for literature review MDS. We take advantage of community submissions to the Multi-document Summarization for Literature Review (MSLR) shared task to compile a diverse and representative sample of generated summaries. We analyze how automated summarization evaluation metrics correlate with lexical features of generated summaries, to other automated metrics including several we propose in this work, and to aspects of human-assessed summary quality. We find that not only do automated metrics fail to capture aspects of quality as assessed by humans, in many cases the system rankings produced by these metrics are anti-correlated with rankings according to human annotators.",1404
1319,Natural Language Processing,Byron Wallace,"May 10th, 2023","Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",https://aclanthology.org/2023.acl-short.119," Chantal Shaib, Millicent L. Li, Sebastian Joseph, Iain James Marshall, Junyi Jessy Li, Byron C. Wallace. (2023). Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success) ACL (2), 1387-1407. https://aclanthology.org/2023.acl-short.119","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Large language models, particularly GPT-3, are able to produce high quality summaries ofgeneral domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized domains such as biomedicine. In this paper we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given no supervision. We consider bothsingle- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in thelatter, we assess the degree to which GPT-3 is able to synthesize evidence reported acrossa collection of articles. We design an annotation scheme for evaluating model outputs, withan emphasis on assessing the factual accuracy of generated summaries. We find that whileGPT-3 is able to summarize and simplify single biomedical articles faithfully, it strugglesto provide accurate aggregations of findings over multiple documents. We release all data,code, and annotations used in this work.",1405
1320,Natural Language Processing,Byron Wallace,"May 8th, 2023",Revisiting Relation Extraction in the era of Large Language Models,https://doi.org/10.48550/arXiv.2305.05003," Somin Wadhwa, Silvio Amir, Byron C. Wallace. (2023). Revisiting Relation Extraction in the era of Large Language Models CoRR, abs/2305.05003. https://doi.org/10.48550/arXiv.2305.05003","Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a \emph{sequence-to-sequence} task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA results. We release this model as a new baseline for RE tasks.",1406
1321,Natural Language Processing,Byron Wallace,"December 7th, 2022",That‚Äôs the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data,https://aclanthology.org/2022.emnlp-main.238," Jered Jered McInerney, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace. (2022). That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data EMNLP, 3626-3648. https://aclanthology.org/2022.emnlp-main.238","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Pretraining multimodal models on Electronic Health Records (EHRs) provides a means of learning representations that can transfer to downstream tasks with minimal supervision. Recent multimodal models induce soft local alignments between image regions and sentences. This is of particular interest in the medical domain, where alignments might highlight regions in an image relevant to specific phenomena described in free-text. While past work has suggested that attention ‚Äúheatmaps‚Äù can be interpreted in this manner, there has been little evaluation of such alignments. We compare alignments from a state-of-the-art multimodal (image and text) model for EHR with human annotations that link image regions to sentences. Our main finding is that the text has an often weak or unintuitive influence on attention; alignments do not consistently reflect basic anatomical information. Moreover, synthetic modifications ‚Äî such as substituting ‚Äúleft‚Äù for ‚Äúright‚Äù ‚Äî do not substantially influence highlights. Simple techniques such as allowing the model to opt out of attending to the image and few-shot finetuning show promise in terms of their ability to improve alignments with very little or no supervision. We make our code and checkpoints open-source.",1407
1322,Natural Language Processing,Byron Wallace,"January 1st, 2022",Evaluating Factuality in Text Simplification,https://doi.org/10.18653/v1/2022.acl-long.506," Ashwin Devaraj, William Sheffield, Byron C. Wallace, Junyi Jessy Li. (2022). Evaluating Factuality in Text Simplification ACL (1), 7331-7345. https://doi.org/10.18653/v1/2022.acl-long.506","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Automated simplification models aim to make input texts more readable. Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader. However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information. Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all. The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated. We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs. We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models.",1408
1323,Natural Language Processing,Byron Wallace,"January 1st, 2022",PHEE: A Dataset for Pharmacovigilance Event Extraction from Text,https://aclanthology.org/2022.emnlp-main.376," Zhaoyue Sun, Jiazheng Li , Gabriele Pergola, Byron C. Wallace, Bino John, Nigel Greene, Joseph Kim, Yulan He . (2022). PHEE: A Dataset for Pharmacovigilance Event Extraction from Text EMNLP, 5571-5587. https://aclanthology.org/2022.emnlp-main.376","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract The primary goal of drug safety researchers and regulators is to promptly identify adverse drug reactions. Doing so may in turn prevent or reduce the harm to patients and ultimately improve public health. Evaluating and monitoring drug safety (i.e., pharmacovigilance) involves analyzing an ever growing collection of spontaneous reports from health professionals, physicians, and pharmacists, and information voluntarily submitted by patients. In this scenario, facilitating analysis of such reports via automation has the potential to rapidly identify safety signals. Unfortunately, public resources for developing natural language models for this task are scant. We present PHEE, a novel dataset for pharmacovigilance comprising over 5000 annotated events from medical case reports and biomedical literature, making it the largest such public dataset to date. We describe the hierarchical event schema designed to provide coarse and fine-grained information about patients‚Äô demographics, treatments and (side) effects. Along with the discussion of the dataset, we present a thorough experimental evaluation of current state-of-the-art approaches for biomedical event extraction, point out their limitations, and highlight open challenges to foster future research in this area.",1409
1324,Natural Language Processing,Byron Wallace,"June 6th, 2021",On the Impact of Random Seeds on the Fairness of Clinical Classifiers,https://doi.org/10.18653/v1/2021.naacl-main.299," Silvio Amir, Jan-Willem van de Meent, Byron C. Wallace. (2021). On the Impact of Random Seeds on the Fairness of Clinical Classifiers NAACL-HLT, 3808-3823. https://doi.org/10.18653/v1/2021.naacl-main.299","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III ‚Äî‚Äî the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of minority groups and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from stochasticity and small sample sizes.",1410
1325,Network Science,Albert-L√°szl√≥ Barab√°si,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1411
1326,Network Science,Albert-L√°szl√≥ Barab√°si,"October 30th, 2023",iGEM: a model system for team science and innovation,https://doi.org/10.48550/arXiv.2310.19858," Marc Santolini, Leo Blondel, Megan J. Palmer, Robert N. Ward, Rathin Jeyaram, Kathryn R. Brink, Abhijeet Krishna, Albert-L√°szl√≥ Barab√°si. (2023). iGEM: a model system for team science and innovation CoRR, abs/2310.19858. https://doi.org/10.48550/arXiv.2310.19858","Teams are a primary source of innovation in science and technology. Rather than examining the lone genius, scholarly and policy attention has shifted to understanding how team interactions produce new and useful ideas. Yet the organizational roots of innovation remain unclear, in part because of the limitations of current data. This paper introduces the international Genetically Engineered Machine (iGEM) competition, a model system for studying team science and innovation. By combining digital laboratory notebooks with performance data from 2,406 teams over multiple years of participation, we reveal shared dynamical and organizational patterns across teams and identify features associated with team performance and success. This dataset makes visible organizational behavior that is typically hidden, and thus understudied, creating new opportunities for the science of science and innovation.",1412
1327,Network Science,Albert-L√°szl√≥ Barab√°si,"October 24th, 2023",Hidden Citations Obscure True Impact in Science,https://doi.org/10.48550/arXiv.2310.16181," Xiangyi Meng, Onur Varol, Albert-L√°szl√≥ Barab√°si. (2023). Hidden Citations Obscure True Impact in Science CoRR, abs/2310.16181. https://doi.org/10.48550/arXiv.2310.16181","References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate that bibliometric measures offer a limited perspective on quantifying the true impact of a discovery, raising the need to extract knowledge from the full text of the scientific corpus.",1413
1328,Network Science,Albert-L√°szl√≥ Barab√°si,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",1414
1329,Network Science,Albert-L√°szl√≥ Barab√°si,"January 25th, 2023",The Clinical Trials Puzzle: How Network Effects Limit Drug Discovery,https://doi.org/10.48550/arXiv.2301.10709," Kishore Vasan, Deisy Morselli Gysi, Albert-L√°szl√≥ Barab√°si. (2023). The Clinical Trials Puzzle: How Network Effects Limit Drug Discovery CoRR, abs/2301.10709. https://doi.org/10.48550/arXiv.2301.10709","The depth of knowledge offered by post-genomic medicine has carried the promise of new drugs, and cures for multiple diseases. To explore the degree to which this capability has materialized, we extract meta-data from 356,403 clinical trials spanning four decades, aiming to offer mechanistic insights into the innovation practices in drug discovery. We find that convention dominates over innovation, as over 96% of the recorded trials focus on previously tested drug targets, and the tested drugs target only 12% of the human interactome. If current patterns persist, it would take 170 years to target all druggable proteins. We uncover two network-based fundamental mechanisms that currently limit target discovery: preferential attachment, leading to the repeated exploration of previously targeted proteins; and local network effects, limiting exploration to proteins interacting with highly explored proteins. We build on these insights to develop a quantitative network-based model of drug discovery. We demonstrate that the model is able to accurately recreate the exploration patterns observed in clinical trials. Most importantly, we show that a network-based search strategy can widen the scope of drug discovery by guiding exploration to novel proteins that are part of under explored regions in the human interactome.",1415
1330,Network Science,Albert-L√°szl√≥ Barab√°si,"June 9th, 2022",Mapping Philanthropic Support of Science,https://doi.org/10.48550/arXiv.2206.10661," Louis M. Shekhtman, Alexander J. Gates, Albert-L√°szl√≥ Barab√°si. (2022). Mapping Philanthropic Support of Science CoRR, abs/2206.10661. https://doi.org/10.48550/arXiv.2206.10661","While philanthropic support for science has increased in the past decade, there is limited quantitative knowledge about the patterns that characterize it and the mechanisms that drive its distribution. Here, we map philanthropic funding to universities and research institutions based on IRS tax forms from 685,397 non-profit organizations. We identify nearly one million grants supporting institutions involved in science and higher education, finding that in volume and scope, philanthropic funding has grown to become comparable to federal research funding. Yet, distinct from government support, philanthropic funders tend to focus locally, indicating that criteria beyond research excellence play an important role in funding decisions. We also show evidence of persistence, i.e., once a grant-giving relationship begins, it tends to continue in time. Finally, we leverage the bipartite network of supporters and recipients to help us demonstrate the predictive power of the underlying network in foreseeing future funder-recipient relationships. The developed toolset could offer funding recommendations to organizations and help funders diversify their portfolio. We discuss the policy implications of our findings for philanthropic funders, individual researchers, and quantitative understanding of philanthropy.",1416
1331,Network Science,Albert-L√°szl√≥ Barab√°si,"December 25th, 2021",AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands,https://arxiv.org/abs/2112.13168," Ayan Chatterjee, Omair Shafi Ahmed, Robin Walters, Zohair Shafi, Deisy Morselli Gysi, Rose Yu, Tina Eliassi-Rad, Albert-L√°szl√≥ Barab√°si, Giulia Menichetti. (2021). AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands CoRR, abs/2112.13168. https://arxiv.org/abs/2112.13168","Identifying novel drug-target interactions (DTI) is a critical and rate limiting step in drug discovery. While deep learning models have been proposed to accelerate the identification process, we show that state-of-the-art models fail to generalize to novel (i.e., never-before-seen) structures. We first unveil the mechanisms responsible for this shortcoming, demonstrating how models rely on shortcuts that leverage the topology of the protein-ligand bipartite network, rather than learning the node features. Then, we introduce AI-Bind, a pipeline that combines network-based sampling strategies with unsupervised pre-training, allowing us to limit the annotation imbalance and improve binding predictions for novel proteins and ligands. We illustrate the value of AI-Bind by predicting drugs and natural compounds with binding affinity to SARS-CoV-2 viral proteins and the associated human proteins. We also validate these predictions via docking simulations and comparison with recent experimental evidence, and step up the process of interpreting machine learning prediction of protein-ligand binding by identifying potential active binding sites on the amino acid sequence. Overall, AI-Bind offers a powerful high-throughput approach to identify drug-target combinations, with the potential of becoming a powerful tool in drug discovery.",1417
1332,Network Science,Albert-L√°szl√≥ Barab√°si,"January 1st, 2019",Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology,https://proceedings.neurips.cc/paper/2019/hash/73bf6c41e241e28b89d0fb9e0c82f9ce-Abstract.html," Nima Dehmamy, Albert-L√°szl√≥ Barab√°si, Rose Yu. (2019). Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology NeurIPS, 15387-15397. https://proceedings.neurips.cc/paper/2019/hash/73bf6c41e241e28b89d0fb9e0c82f9ce-Abstract.html","Part of Advances in Neural Information Processing Systems 32 (NeurIPS 2019) Nima Dehmamy, Albert-Laszlo Barabasi, Rose Yu To deepen our understanding of graph neural networks, we investigate the representation power of Graph Convolutional Networks (GCN) through the looking glass of graph moments, a key property of graph topology encoding path of various lengths. We find that GCNs are rather restrictive in learning graph moments. Without careful design, GCNs can fail miserably even with multiple layers and nonlinear activation functions. We analyze theoretically the expressiveness of GCNs, arriving at a modular GCN design, using different propagation rules. Our modular design is capable of distinguishing graphs from different graph generation models for surprisingly small graphs, a notoriously difficult problem in network science. Our investigation suggests that, depth is much more influential than width and deeper GCNs are more capable of learning higher order graph moments. Additionally, combining GCN modules with different propagation rules is critical to the representation power of GCNs.",1418
1333,Network Science,Tina Eliassi-Rad,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1419
1334,Network Science,Tina Eliassi-Rad,"August 5th, 2024",Using overlapping methods to counter adversaries in community detection,https://doi.org/10.1093/comnet/cnae030," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Using overlapping methods to counter adversaries in community detection J. Complex Networks, 12. https://doi.org/10.1093/comnet/cnae030","Community detection is a useful data triage tool that can identify subsets of the network that a data analyst should investigate. In an adversarial scenario, the graph may be manipulated to avoid scrutiny of certain nodes by the analyst. Robustness to such behaviour is an important consideration for data analysts in high-stakes scenarios such as cyber defense and counterterrorism. We find that, when the attacker has a sufficient budget, overlapping community detection methods outperform non-overlapping methods, often overwhelmingly so. Our extensible analytic framework enables network data analysts to take these attacks into account and use them to make better decisions about which nodes to focus on.",1420
1335,Network Science,Tina Eliassi-Rad,"May 30th, 2024",Distributed constrained combinatorial optimization leveraging hypergraph neural networks,https://doi.org/10.1038/s42256-024-00833-7," Nasimeh Heydaribeni, Xinrui Zhan, Ruisi Zhang, Tina Eliassi-Rad, Farinaz Koushanfar. (2024). Distributed constrained combinatorial optimization leveraging hypergraph neural networks Nat. Mac. Intell., 6, 664-672. https://doi.org/10.1038/s42256-024-00833-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1421
1336,Network Science,Tina Eliassi-Rad,"February 21st, 2024",Complex network effects on the robustness of graph convolutional networks,https://doi.org/10.1007/s41109-024-00611-9," Benjamin A. Miller, Kevin S. Chan, Tina Eliassi-Rad. (2024). Complex network effects on the robustness of graph convolutional networks Appl. Netw. Sci., 9, 5. https://doi.org/10.1007/s41109-024-00611-9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1422
1337,Network Science,Tina Eliassi-Rad,"January 16th, 2024","A Survey on Hypergraph Mining: Patterns, Tools, and Generators",https://doi.org/10.48550/arXiv.2401.08878," Geon Lee, Fanchen Bu, Tina Eliassi-Rad, Kijung Shin. (2024). A Survey on Hypergraph Mining: Patterns, Tools, and Generators CoRR, abs/2401.08878. https://doi.org/10.48550/arXiv.2401.08878","Hypergraphs, which belong to the family of higher-order networks, are a natural and powerful choice for modeling group interactions in the real world. For example, when modeling collaboration networks, which may involve not just two but three or more people, the use of hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for hypergraph mining. The goal of hypergraph mining is to find structural properties recurring in real-world hypergraphs across different domains, which we call patterns. To find patterns, we need tools. We divide hypergraph mining tools into three categories: (1) null models (which help test the significance of observed patterns), (2) structural elements (i.e., substructures in a hypergraph such as open and closed triangles), and (3) structural quantities (i.e., numerical tools for computing hypergraph patterns such as transitivity). There are also hypergraph generators, whose objective is to produce synthetic hypergraphs that are a faithful representation of real-world hypergraphs. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for each and offer in-depth discussions for future research on hypergraph mining.",1423
1338,Network Science,Tina Eliassi-Rad,"December 18th, 2023",Using sequences of life-events to predict human lives,https://doi.org/10.1038/s43588-023-00573-5," Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Hvas Mortensen, Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann. (2024). Using sequences of life-events to predict human lives Nat. Comput. Sci., 4, 43-56. https://doi.org/10.1038/s43588-023-00573-5","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1424
1339,Network Science,Tina Eliassi-Rad,"November 14th, 2023",Attacking Shortest Paths by Cutting Edges,https://doi.org/10.1145/3622941," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2024). Attacking Shortest Paths by Cutting Edges ACM Trans. Knowl. Discov. Data, 18, 35:1-35:42. https://doi.org/10.1145/3622941","Identifying shortest paths between nodes in a network is a common graph analysis problem that is important for many applications involving routing of resources. An adversary that can manipulate the graph structure could alter traffic patterns to gain some benefit (e.g., make more money by directing traffic to a toll road). This article presents the Force Path Cut problem, in which an adversary removes edges from a graph to make a particular path the shortest between its terminal nodes. We prove that the optimization version of this problem is APX-hard but introduce PATHATTACK , a polynomial-time approximation algorithm that guarantees a solution within a logarithmic factor of the optimal value. In addition, we introduce the Force Edge Cut and Force Node Cut problems, in which the adversary targets a particular edge or node, respectively, rather than an entire path. We derive a nonconvex optimization formulation for these problems and derive a heuristic algorithm that uses PATHATTACK as a subroutine. We demonstrate all of these algorithms on a diverse set of real and synthetic networks, illustrating where the proposed algorithms provide the greatest improvement over baseline methods.",1425
1340,Network Science,Tina Eliassi-Rad,"August 21st, 2023",TenGAN: adversarially generating multiplex tensor graphs,https://doi.org/10.1007/s10618-023-00947-3," William Shiao, Benjamin A. Miller, Kevin Chan , Paul L. Yu, Tina Eliassi-Rad, Evangelos E. Papalexakis. (2024). TenGAN: adversarially generating multiplex tensor graphs Data Min. Knowl. Discov., 38, 1-21. https://doi.org/10.1007/s10618-023-00947-3","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",1426
1341,Network Science,Tina Eliassi-Rad,"August 18th, 2023",Modeling self-propagating malware with epidemiological models,https://doi.org/10.1007/s41109-023-00578-z," Alesia Chernikova, Nicol√≤ Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. (2023). Modeling self-propagating malware with epidemiological models Appl. Netw. Sci., 8, 52. https://doi.org/10.1007/s41109-023-00578-z","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1427
1342,Network Science,Tina Eliassi-Rad,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",1428
1343,Network Science,Tina Eliassi-Rad,"May 30th, 2023",Defense Against Shortest Path Attacks,https://doi.org/10.48550/arXiv.2305.19083," Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld. (2023). Defense Against Shortest Path Attacks CoRR, abs/2305.19083. https://doi.org/10.48550/arXiv.2305.19083","Identifying shortest paths between nodes in a network is an important task in applications involving routing of resources. Recent work has shown that a malicious actor can manipulate a graph to make traffic between two nodes of interest follow their target path. In this paper, we develop a defense against such attacks by modifying the weights of the graph that users observe. The defender must balance inhibiting the attacker against any negative effects of the defense on benign users. Specifically, the defender's goals are: (a) to recommend the shortest paths possible to users, (b) for the lengths of the shortest paths in the published graph to be close to those of the same paths in the true graph, and (c) to minimize the probability of an attack. We formulate the defense as a Stackelberg game in which the defender is the leader and the attacker is the follower. In this context, we also consider a zero-sum version of the game, in which the defender's goal is to minimize cost while achieving the minimum possible attack probability. We show that this problem is NP-hard and propose heuristic solutions based on increasing edge weights along target paths in both the zero-sum and non-zero-sum settings. Relaxing some constraints of the original problem, we formulate a linear program for local optimization around a feasible point. We present defense results with both synthetic and real network datasets and show that these methods often reach the lower bound of the defender's cost.",1429
1344,Network Science,Tina Eliassi-Rad,"April 12th, 2023",STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core,https://doi.org/10.1137/1.9781611977653.ch46," David Liu, Tina Eliassi-Rad. (2023). STABLE: Identifying and Mitigating Instability in Embeddings of the Degenerate Core SDM, 406-414. https://doi.org/10.1137/1.9781611977653.ch46","Are the embeddings of a graph's degenerate core stable? What happens to the embeddings of nodes in the degenerate core as we systematically remove periphery nodes (by repeatedly peeling off Œ∫ -cores)? We discover three patterns w.r.t. instability in degenerate-core embeddings across a variety of popular graph embedding algorithms and datasets. We correlate instability with an increase in edge density, and then theoretically show that in the case of Erd√∂s-R√©nyi graphs embedded with Laplacian Eigenmaps, the best and worst possible embeddings become less distinguishable as density increases. Furthermore, we present the STABLE algorithm, which takes an existing graph embedding algorithm and makes it stable. We show the effectiveness of STABLE in terms of making the degenerate-core embedding stable and still producing state-of-the-art link prediction performance.",1430
1345,Network Science,Tina Eliassi-Rad,"September 10th, 2021",PATHATTACK: Attacking Shortest Paths in Complex Networks,https://doi.org/10.1007/978-3-030-86520-7_33," B.A. Miller, Z. Shafi, W. Ruml, Y. Vorobeychik, T. Eliassi-Rad, S. Alfeld. ""PATHATTACK: Attacking Shortest Paths in Complex Networks"". In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD), September 2021.","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1431
1346,Network Science,David Lazer,"January 14th, 2025",DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter,https://doi.org/10.48550/arXiv.2501.09035," Kai-Cheng Yang, Pranav Goel, Alexi Quintana Math√©, Luke Horgan, Stefan D. McCabe, Nir Grinberg, Kenneth Joseph, David Lazer. (2025). DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter CoRR, abs/2501.09035. https://doi.org/10.48550/arXiv.2501.09035","Social media play a pivotal role in disseminating web content, particularly during elections, yet our understanding of the association between demographic factors and political discourse online remains limited. Here, we introduce a unique dataset, DomainDemo, linking domains shared on Twitter (X) with the demographic characteristics of associated users, including age, gender, race, political affiliation, and geolocation, from 2011 to 2022. This new resource was derived from a panel of over 1.5 million Twitter users matched against their U.S. voter registration records, facilitating a better understanding of a decade of information flows on one of the most prominent social media platforms and trends in political and public discourse among registered U.S. voters from different sociodemographic groups. By aggregating user demographic information onto the domains, we derive five metrics that provide critical insights into over 129,000 websites. In particular, the localness and partisan audience metrics quantify the domains' geographical reach and ideological orientation, respectively. These metrics show substantial agreement with existing classifications, suggesting the effectiveness and reliability of DomainDemo's approach.",1432
1347,Network Science,David Lazer,"November 12th, 2024",When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions,https://doi.org/10.48550/arXiv.2411.07907," Allison Wan, Christoph Riedl, David Lazer. (2024). When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions CoRR, abs/2411.07907. https://doi.org/10.48550/arXiv.2411.07907","How does social network structure amplify or stifle behavior diffusion? Existing theory suggests that when social reinforcement makes the adoption of behavior more likely, it should spread more -- both farther and faster -- on clustered networks with redundant ties. Conversely, if adoption does not benefit from social reinforcement, then it should spread more on random networks without such redundancies. We develop a novel model of behavior diffusion with tunable probabilistic adoption and social reinforcement parameters to systematically evaluate the conditions under which clustered networks better spread a behavior compared to random networks. Using both simulations and analytical techniques we find precise boundaries in the parameter space where either network type outperforms the other or performs equally. We find that in most cases, random networks spread a behavior equally as far or farther compared to clustered networks despite strong social reinforcement. While there are regions in which clustered networks better diffuse contagions with social reinforcement, this only holds when the diffusion process approaches that of a deterministic threshold model and does not hold for all socially reinforced behaviors more generally. At best, clustered networks only outperform random networks by at least a five percent margin in 18\% of the parameter space, and when social reinforcement is large relative to the baseline probability of adoption.",1433
1348,Network Science,David Lazer,"August 12th, 2023",Mainstream News Articles Co-Shared with Fake News Buttress Misinformation Narratives,https://doi.org/10.48550/arXiv.2308.06459," Pranav Goel, Jon Green, David Lazer, Philip Resnik. (2023). Mainstream News Articles Co-Shared with Fake News Buttress Misinformation Narratives CoRR, abs/2308.06459. https://doi.org/10.48550/arXiv.2308.06459","Most prior and current research examining misinformation spread on social media focuses on reports published by 'fake' news sources. These approaches fail to capture another potential form of misinformation with a much larger audience: factual news from mainstream sources ('real' news) repurposed to promote false or misleading narratives. We operationalize narratives using an existing unsupervised NLP technique and examine the narratives present in misinformation content. We find that certain articles from reliable outlets are shared by a disproportionate number of users who also shared fake news on Twitter. We consider these 'real' news articles to be co-shared with fake news. We show that co-shared articles contain existing misinformation narratives at a significantly higher rate than articles from the same reliable outlets that are not co-shared with fake news. This holds true even when articles are chosen following strict criteria of reliability for the outlets and after accounting for the alternative explanation of partisan curation of articles. For example, we observe that a recent article published by The Washington Post titled ""Vaccinated people now make up a majority of COVID deaths"" was disproportionately shared by Twitter users with a history of sharing anti-vaccine false news reports. Our findings suggest a strategic repurposing of mainstream news by conveyors of misinformation as a way to enhance the reach and persuasiveness of misleading narratives. We also conduct a comprehensive case study to help highlight how such repurposing can happen on Twitter as a consequence of the inclusion of particular narratives in the framing of mainstream news.",1434
1349,Network Science,David Lazer,"July 27th, 2023",Enhancing the ethics of user-sourced online data collection and sharing,https://doi.org/10.1038/s43588-023-00490-7," Michelle N. Meyer, John Basl, David R. Choffnes, Christo Wilson, David M. J. Lazer. (2023). Enhancing the ethics of user-sourced online data collection and sharing Nat. Comput. Sci., 3, 660-664. https://doi.org/10.1038/s43588-023-00490-7","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1435
1350,Network Science,David Lazer,"July 15th, 2023",The science of fake news,https://doi.org/10.48550/arXiv.2307.07903," David M. J. Lazer, Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan, Gordon Pennycook, David M. Rothschild, Michael Schudson, Steven A. Sloman, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts, Jonathan L. Zittrain. (2023). The science of fake news CoRR, abs/2307.07903. https://doi.org/10.48550/arXiv.2307.07903","Fake news emerged as an apparent global problem during the 2016 U.S. Presidential election. Addressing it requires a multidisciplinary effort to define the nature and extent of the problem, detect fake news in real time, and mitigate its potentially harmful effects. This will require a better understanding of how the Internet spreads content, how people process news, and how the two interact. We review the state of knowledge in these areas and discuss two broad potential mitigation strategies: better enabling individuals to identify fake news, and intervention within the platforms to reduce the attention given to fake news. The cooperation of Internet platforms (especially Facebook, Google, and Twitter) with researchers will be critical to understanding the scale of the issue and the effectiveness of possible interventions.",1436
1351,Network Science,David Lazer,"December 31st, 2021",Engagement Outweighs Exposure to Partisan and Unreliable News within Google Search,https://arxiv.org/abs/2201.00074," Ronald E. Robertson, Jon Green, Damian Ruck, Katya Ognyanova, Christo Wilson, David Lazer. (2022). Engagement Outweighs Exposure to Partisan and Unreliable News within Google Search CoRR, abs/2201.00074. https://arxiv.org/abs/2201.00074","If popular online platforms systematically expose their users to partisan and unreliable news, they could potentially contribute to societal issues like rising political polarization. This concern is central to the echo chamber and filter bubble debates, which critique the roles that user choice and algorithmic curation play in guiding users to different online information sources. These roles can be measured in terms of exposure, the URLs seen while using an online platform, and engagement, the URLs selected while on that platform or browsing the web more generally. However, due to the challenges of obtaining ecologically valid exposure data--what real users saw during their regular platform use--studies in this vein often only examine engagement data, or estimate exposure via simulated behavior or inference. Despite their centrality to the contemporary information ecosystem, few such studies have focused on web search, and even fewer have examined both exposure and engagement on any platform. To address these gaps, we conducted a two-wave study pairing surveys with ecologically valid measures of exposure and engagement on Google Search during the 2018 and 2020 US elections. We found that participants' partisan identification had a small and inconsistent relationship with the amount of partisan and unreliable news they were exposed to on Google Search, a more consistent relationship with the search results they chose to follow, and the most consistent relationship with their overall engagement. That is, compared to the news sources our participants were exposed to on Google Search, we found more identity-congruent and unreliable news sources in their engagement choices, both within Google Search and overall. These results suggest that exposure and engagement with partisan or unreliable news on Google Search are not primarily driven by algorithmic curation, but by users' own choices.",1437
1352,Network Science,David Lazer,"September 4th, 2021",(Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys,https://doi.org/10.18653/v1/2021.emnlp-main.27," Kenneth Joseph, Sarah Shugars, Ryan J. Gallagher, Jon Green, Alexi Quintana Math√©, Zijian An, David Lazer. (2021). (Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys EMNLP (1), 312-324. https://doi.org/10.18653/v1/2021.emnlp-main.27","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Stance detection, which aims to determine whether an individual is for or against a target concept, promises to uncover public opinion from large streams of social media data. Yet even human annotation of social media content does not always capture ‚Äústance‚Äù as measured by public opinion polls. We demonstrate this by directly comparing an individual‚Äôs self-reported stance to the stance inferred from their social media data. Leveraging a longitudinal public opinion survey with respondent Twitter handles, we conducted this comparison for 1,129 individuals across four salient targets. We find that recall is high for both ‚ÄúPro‚Äô‚Äô and ‚ÄúAnti‚Äô‚Äô stance classifications but precision is variable in a number of cases. We identify three factors leading to the disconnect between text and author stance: temporal inconsistencies, differences in constructs, and measurement errors from both survey respondents and annotators. By presenting a framework for assessing the limitations of stance detection models, this work provides important insight into what stance detection truly measures.",1438
1353,Network Science,David Lazer,"June 2nd, 2020","Misinformation in action: Fake news exposure is linked to lower trust in media, higher trust in government when your side is in power",https://doi.org/10.37016/mr-2020-024%20," K. Ognyanova, D. Lazer, R. E. Robertson, and C. Wilson. (2020). ""Misinformation in action: Fake news exposure is linked to lower trust in media, higher trust in government when your side is in power"". Harvard Kennedy School (HKS) Misinformation Review. DOI: 10.37016/mr-2020-024","Peer Reviewed One major concern about fake news is that it could damage the public trust in democratic institutions. We examined this possibility using longitudinal survey data combined with records of online behavior. Our study found that online misinformation was linked to lower trust in mainstream media across party lines. However, for moderates and conservatives, exposure to fake news predicted a higher confidence in political institutions. The mostly right-leaning fake news accessed by our moderate-to-conservative respondents could strengthen their trust in a Republican government. This was not true for liberals who could be biased against such content and less likely to believe its claims. School of Communication & Information, Rutgers University, USA Network Science Institute, Northeastern University, USA Network Science Institute, Northeastern University, USA",1439
1354,Network Science,David Lazer,"April 23rd, 2018",Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages,https://doi.org/10.1145/3178876.3186143," Ronald E. Robertson, David Lazer, and Christo Wilson. 2018. Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages. In Proceedings of the 2018 World Wide Web Conference (WWW '18). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 955‚Äì965. DOI: 10.1145/3178876.3186143","Search engines are a primary means through which people obtain information in today¬ªs connected world. Yet, apart from the search engine companies themselves, little is known about how their algorithms filter, rank, and present the web to users. This question is especially pertinent with respect to political queries, given growing concerns about filter bubbles, and the recent finding that bias or favoritism in search rankings can influence voting behavior. In this study, we conduct a targeted algorithm audit of Google Search using a dynamic set of political queries. We designed a Chrome extension to survey participants and collect the Search Engine Results Pages (SERPs) and autocomplete suggestions that they would have been exposed to while searching our set of political queries during the month after Donald Trump¬ªs Presidential inauguration. Using this data, we found significant differences in the composition and personalization of politically-related SERPs by query type, subjects¬ª characteristics, and date.",1440
1355,Network Science,Christoph Riedl,"November 12th, 2024",When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions,https://doi.org/10.48550/arXiv.2411.07907," Allison Wan, Christoph Riedl, David Lazer. (2024). When Randomness Beats Redundancy: Insights into the Diffusion of Complex Contagions CoRR, abs/2411.07907. https://doi.org/10.48550/arXiv.2411.07907","How does social network structure amplify or stifle behavior diffusion? Existing theory suggests that when social reinforcement makes the adoption of behavior more likely, it should spread more -- both farther and faster -- on clustered networks with redundant ties. Conversely, if adoption does not benefit from social reinforcement, then it should spread more on random networks without such redundancies. We develop a novel model of behavior diffusion with tunable probabilistic adoption and social reinforcement parameters to systematically evaluate the conditions under which clustered networks better spread a behavior compared to random networks. Using both simulations and analytical techniques we find precise boundaries in the parameter space where either network type outperforms the other or performs equally. We find that in most cases, random networks spread a behavior equally as far or farther compared to clustered networks despite strong social reinforcement. While there are regions in which clustered networks better diffuse contagions with social reinforcement, this only holds when the diffusion process approaches that of a deterministic threshold model and does not hold for all socially reinforced behaviors more generally. At best, clustered networks only outperform random networks by at least a five percent margin in 18\% of the parameter space, and when social reinforcement is large relative to the baseline probability of adoption.",1441
1356,Network Science,Christoph Riedl,"April 26th, 2024",Cooperation in the Gig Economy: Insights from Upwork Freelancers,https://doi.org/10.1145/3637314," Zachary Fulker, Christoph Riedl. (2024). Cooperation in the Gig Economy: Insights from Upwork Freelancers Proc. ACM Hum. Comput. Interact., 8, 1-20. https://doi.org/10.1145/3637314","Existing literature on online labor markets predominantly focuses on how freelancers individually complete tasks and projects. Our study examines freelancers' willingness to work collaboratively. We report results from a survey of 122 freelancers on a leading online labor market platform (Upwork) that examine freelancers' preferences for collaborative work arrangements, and that explore several antecedents of cooperative behaviors. We then test if actual cooperative behavior matches with freelancers' stated preferences through an incentivized social dilemma experiment. We find that respondents cooperate at a higher rate (85%) than reported in previous comparable studies (between 50-75%). This high rate of cooperation may be explained by an ingroup bias. Using a sequential mediation model, we demonstrate the importance of a sense of shared expectations and accountability for cooperation. We contribute to a better understanding of the potential for collaborative work on online labor market platforms by assessing if and what social factors and collective culture exist among freelancers. We discuss the implications of our results for platform designers by highlighting the importance of platform features that promote shared expectations and improve accountability. Overall, contrary to existing literature and predictions, our results suggest that freelancers in our sample display traits that are more consistent with belonging to a coherent group with a shared collective culture, rather than being anonymous actors in a transaction-based market.",1442
1357,Network Science,Christoph Riedl,"April 22nd, 2024",Competition and Collaboration in Crowdsourcing Communities: What happens when peers evaluate each other?,https://doi.org/10.48550/arXiv.2404.14141," Christoph Riedl, Tom Grad, Christopher Lettl. (2024). Competition and Collaboration in Crowdsourcing Communities: What happens when peers evaluate each other? CoRR, abs/2404.14141. https://doi.org/10.48550/arXiv.2404.14141","Crowdsourcing has evolved as an organizational approach to distributed problem solving and innovation. As contests are embedded in online communities and evaluation rights are assigned to the crowd, community members face a tension: they find themselves exposed to both competitive motives to win the contest prize and collaborative participation motives in the community. The competitive motive suggests they may evaluate rivals strategically according to their self-interest, the collaborative motive suggests they may evaluate their peers truthfully according to mutual interest. Using field data from Threadless on 38 million peer evaluations of more than 150,000 submissions across 75,000 individuals over 10 years and two natural experiments to rule out alternative explanations, we answer the question of how community members resolve this tension. We show that as their skill level increases, they become increasingly competitive and shift from using self-promotion to sabotaging their closest competitors. However, we also find signs of collaborative behavior when high-skilled members show leniency toward those community members who do not directly threaten their chance of winning. We explain how the individual-level use of strategic evaluations translates into important organizational-level outcomes by affecting the community structure through individuals' long-term participation. While low-skill targets of sabotage are less likely to participate in future contests, high-skill targets are more likely. This suggests a feedback loop between competitive evaluation behavior and future participation. These findings have important implications for the literature on crowdsourcing design, and the evolution and sustainability of crowdsourcing communities.",1443
1358,Network Science,Christoph Riedl,"April 2nd, 2024",Cash or Non-Cash? Unveiling Ideators‚Äô Incentive Preferences in Crowdsourcing Contests,https://doi.org/10.48550/arXiv.2404.01997," Christoph Riedl, Johann F√ºller, Katja Hutter, Gerard J. Tellis. (2024). Cash or Non-Cash? Unveiling Ideators' Incentive Preferences in Crowdsourcing Contests CoRR, abs/2404.01997. https://doi.org/10.48550/arXiv.2404.01997","Even though research has repeatedly shown that non-cash incentives can be effective, cash incentives are the de facto standard in crowdsourcing contests. In this multi-study research, we quantify ideators' preferences for non-cash incentives and investigate how allowing ideators to self-select their preferred incentive -- offering ideators a choice between cash and non-cash incentives -- affects their creative performance. We further explore whether the market context of the organization hosting the contest -- social (non-profit) or monetary (for-profit) -- moderates incentive preferences and their effectiveness. We find that individuals exhibit heterogeneous incentive preferences and often prefer non-cash incentives, even in for-profit contexts. Offering ideators a choice of incentives can enhance creative performance. Market context moderates the effect of incentives, such that ideators who receive non-cash incentives in for-profit contexts tend to exert less effort. We show that heterogeneity of ideators' preferences (and the ability to satisfy diverse preferences with suitably diverse incentive options) is a critical boundary condition to realizing benefits from offering ideators a choice of incentives. We provide managers with guidance to design effective incentives by improving incentive-preference fit for ideators.",1444
1359,Network Science,Christoph Riedl,"January 26th, 2024",Multimodality in Group Communication Research,https://doi.org/10.48550/arXiv.2401.15194," Robin Lange, Brooke Foucault Welles, Gyanendra Sharma, Richard J. Radke, Javier O. Garcia, Christoph Riedl. (2024). Multimodality in Group Communication Research CoRR, abs/2401.15194. https://doi.org/10.48550/arXiv.2401.15194","Team interactions are often multisensory, requiring members to pick up on verbal, visual, spatial and body language cues. Multimodal research, research that captures multiple modes of communication such as audio and visual signals, is therefore integral to understanding these multisensory group communication processes. This type of research has gained traction in biomedical engineering and neuroscience, but it is unclear the extent to which communication and management researchers conduct multimodal research. Our study finds that despite its' utility, multimodal research is underutilized in the communication and management literature's. This paper then covers introductory guidelines for creating new multimodal research including considerations for sensors, data integration and ethical considerations.",1445
1360,Network Science,Christoph Riedl,"August 22nd, 2023",Building Better Human-Agent Teams: Tradeoffs in Helpfulness and Humanness in Voice,https://doi.org/10.48550/arXiv.2308.11786," Samuel Westby, Richard J. Radke, Christoph Riedl, Brooke Foucault Welles. (2023). Building Better Human-Agent Teams: Tradeoffs in Helpfulness and Humanness in Voice CoRR, abs/2308.11786. https://doi.org/10.48550/arXiv.2308.11786","Voice assistants are increasingly prevalent, from personal devices to team environments. This study explores how voice type and contribution quality influence human-agent team performance and perceptions of anthropomorphism, animacy, intelligence, and trustworthiness. By manipulating both, we reveal mechanisms of perception and clarify ambiguity in previous work. Our results show that the human resemblance of a voice assistant's voice negatively interacts with the helpfulness of an agent's contribution to flip its effect on perceived anthropomorphism and perceived animacy. This means human teammates interpret the agent's contributions differently depending on its voice. Our study found no significant effect of voice on perceived intelligence, trustworthiness, or team performance. We find differences in these measures are caused by manipulating the helpfulness of an agent. These findings suggest that function matters more than form when designing agents for high-performing human-agent teams, but controlling perceptions of anthropomorphism and animacy can be unpredictable even with high human resemblance.",1446
1361,Network Science,Christoph Riedl,"March 27th, 2023",How creative versus technical constraints affect individual learning in an online innovation community,https://doi.org/10.48550/arXiv.2303.15163," Victor P. Seidel, Christoph Riedl. (2023). How creative versus technical constraints affect individual learning in an online innovation community CoRR, abs/2303.15163. https://doi.org/10.48550/arXiv.2303.15163","Online innovation communities allow for a search for novel solutions within a design space bounded by constraints. Past research has focused on the effect of creative constraints on individual projects, but less is known about how constraints affect learning from repeated design submissions and the effect of the technical constraints that are integral to online platforms. How do creative versus technical constraints affect individual learning in exploring a design space in online communities? We analyzed ten years of data from an online innovation community that crowdsourced 136,989 design submissions from 33,813 individuals. We leveraged data from two types of design contests-creatively constrained and unconstrained-running in parallel on the platform, and we evaluated a natural experiment where a platform change reduced technical constraints. We find that creative constraints lead to high rates of learning only if technical constraints are sufficiently relaxed. Our findings have implications for the management of creative design work and the downstream effects of the technical constraints of the information systems that support online innovation communities.",1447
1362,Network Science,Christoph Riedl,"January 20th, 2023",Who wants to cooperate-and why? Attitude and perception of crowd workers in online labor markets,https://doi.org/10.48550/arXiv.2301.08808," Zachary Fulker, Christoph Riedl. (2023). Who wants to cooperate-and why? Attitude and perception of crowd workers in online labor markets CoRR, abs/2301.08808. https://doi.org/10.48550/arXiv.2301.08808","Existing literature predominantly focuses on how freelancers individually complete tasks and projects. Our study examines freelancers' willingness to work collaboratively. We report results from a survey of 122 freelancers on a leading online labor market platform (Upwork) and examine freelancers' preferences for collaboration and explore several antecedents of cooperative behaviors. We then test if actual cooperative behavior matches with freelancers' stated preferences through an incentivized social dilemma experiment. We find that respondents cooperate at a higher rate (85%) than reported in previous comparable studies (between 50-75%). This high rate of cooperation may be explained by an ingroup bias. Using a sequential mediation model we demonstrate the importance of a sense of shared expectations and accountability for cooperation. We contribute to a better understanding of the potential for collaborative work on online labor market platforms by assessing if and what social factors and collective culture exist among freelancers. We discuss the implications of our results for platform designers by highlighting the importance of platform features that promote shared expectations and improve accountability. Overall, contrary to existing literature and predictions, our results suggest that freelancers in our sample display traits that are more consistent with belonging to a coherent group with a shared collective culture, rather than being anonymous actors in a transaction-based market.",1448
1363,Network Science,Christoph Riedl,"October 22nd, 2022",Spontaneous emergence of groups and signaling diversity in dynamic networks,https://doi.org/10.48550/arXiv.2210.17309," Zachary Fulker, Patrick Forber, Rory Smead, Christoph Riedl. (2022). Spontaneous emergence of groups and signaling diversity in dynamic networks CoRR, abs/2210.17309. https://doi.org/10.48550/arXiv.2210.17309","We study the coevolution of network structure and signaling behavior. We model agents who can preferentially associate with others in a dynamic network while they also learn to play a simple sender-receiver game. We have four major findings. First, signaling interactions in dynamic networks are sufficient to cause the endogenous formation of distinct signaling groups, even in an initially homogeneous population. Second, dynamic networks allow the emergence of novel {\em hybrid} signaling groups that do not converge on a single common signaling system but are instead composed of different yet complementary signaling strategies. We show that the presence of these hybrid groups promotes stable diversity in signaling among other groups in the population. Third, we find important distinctions in information processing capacity of different groups: hybrid groups diffuse information more quickly initially but at the cost of taking longer to reach all group members. Fourth, our findings pertain to all common interest signaling games, are robust across many parameters, and mitigate known problems of inefficient communication.",1449
1364,Network Science,Christoph Riedl,"August 24th, 2022",Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach,https://doi.org/10.48550/arXiv.2208.11660," Samuel Westby, Christoph Riedl. (2022). Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach CoRR, abs/2208.11660. https://doi.org/10.48550/arXiv.2208.11660","We develop a network of Bayesian agents that collectively model the mental states of teammates from the observed communication. Using a generative computational approach to cognition, we make two contributions. First, we show that our agent could generate interventions that improve the collective intelligence of a human-AI team beyond what humans alone would achieve. Second, we develop a real-time measure of human's theory of mind ability and test theories about human cognition. We use data collected from an online experiment in which 145 individuals in 29 human-only teams of five communicate through a chat-based system to solve a cognitive task. We find that humans (a) struggle to fully integrate information from teammates into their decisions, especially when communication load is high, and (b) have cognitive biases which lead them to underweight certain useful, but ambiguous, information. Our theory of mind ability measure predicts both individual- and team-level performance. Observing teams' first 25% of messages explains about 8% of the variation in final team performance, a 170% improvement compared to the current state of the art.",1450
1365,Network Science,Christoph Riedl,"May 7th, 2021","Online Mingling: Supporting Ad Hoc, Private Conversations at Virtual Conferences",https://doi.org/10.1145/3411764.3445776," Jaeyoon Song , Christoph Riedl, Thomas W. Malone. (2021). Online Mingling: Supporting Ad Hoc, Private Conversations at Virtual Conferences CHI, 340:1-340:10. https://doi.org/10.1145/3411764.3445776","Even though today‚Äôs videoconferencing systems are often very useful, these systems do not provide support for one of the most important aspects of in-person meetings: the ad hoc, private conversations that happen before, after, and during the breaks of scheduled events‚Äìthe proverbial hallway conversations. Here we describe our design of a simple system, called Minglr, which supports this kind of interaction by facilitating the matching of conversational partners. We describe two studies of this system‚Äôs use at two virtual conferences with over 450 total participants. Our results provide evidence for the usefulness of this capability, showing that, for example, 81% of people who used the system successfully thought that future virtual conferences should include a tool with similar functionality. We believe that similar functionality is likely to be widely implemented in many videoconferencing systems and to increase the feasibility and desirability of many kinds of remote work and socializing.",1451
1366,Network Science,Christoph Riedl,"April 7th, 2021",Avoiding the bullies: the resilience of cooperation among unequals,https://doi.org/10.1371/journal.pcbi.1008847," M. Foley, R. Smead, P. Forber, C. Riedl. (2021). ‚ÄúAvoiding the Bullies: Resilience of Cooperation among Unequals,‚Äù PLoS Computational Biology, 17(4): e1008847.","Can egalitarian norms or conventions survive the presence of dominant individuals who are ensured of victory in conflicts? We investigate the interaction of power asymmetry and partner choice in games of conflict over a contested resource. Partner choice counteracts the hyper dominance of bullies who are isolated in the network and eliminate the need for others to coordinate in a coalition. Our results have important implications: in our modeled scenario the rich do notalways get richer, the dominance of bullying individuals can be broken, and inequality in accrued resources can be eliminated. The study was published in the Journal of Game Theory and Behavior. The work provides new insight into potential sources of, and strategies for avoiding, resource inequality.",1452
1367,Network Science,Christoph Riedl,"January 11th, 2021",Spite is contagious in dynamic networks,https://doi.org/10.1038/s41467-020-20436-1," Z Fulker, P Forber, R Smead, C Riedl. ""Spite is contagious in dynamic networks"". Nature Communications 12, 260 (2021). DOI: 10.1038/s41467-020-20436-1","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1453
1368,Network Science,Christoph Riedl,"March 21st, 2018",Conflict and convention in dynamic networks,http://rsif.royalsocietypublishing.org/content/15/140/20170835," Foley, M., Forber, P., Smead, R., Riedl, C. Journal of the Royal Society Interface, 15(140), 20170835, 2018","An important way to resolve games of conflict (snowdrift, hawk‚Äìdove, chicken) involves adopting a convention. We model the emergence of conventions as correlated equilibria in dynamic networks. Our results show that networks have the tendency to break the symmetry between the two conventional solutions in a strongly biased way.",1454
1369,Network Science,Alessandro Vespignani,"February 1st, 2025",Human-AI coevolution,https://doi.org/10.1016/j.artint.2024.104244," Dino Pedreschi, Luca Pappalardo, Emanuele Ferragina, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2025). Human-AI coevolution Artif. Intell., 339, 104244. https://doi.org/10.1016/j.artint.2024.104244","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1455
1370,Network Science,Alessandro Vespignani,"August 4th, 2023",Deep Bayesian Active Learning for Accelerating Stochastic Simulation,https://doi.org/10.1145/3580305.3599300," Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An Ma, Rose Yu. (2023). Deep Bayesian Active Learning for Accelerating Stochastic Simulation KDD, 2559-2569. https://doi.org/10.1145/3580305.3599300","Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic models are computationally expensive at fine-grained resolution. While deep surrogate models can speed up the simulations, doing so for stochastic simulations and with active learning approaches is an underexplored area. We propose Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP consists of two components, a spatiotemporal surrogate model built upon Neural Process (NP) family and an acquisition function for active learning. For surrogate modeling, we develop Spatiotemporal Neural Process (STNP) to mimic the simulator dynamics. For active learning, we propose a novel acquisition function, Latent Information Gain (LIG), calculated in the latent space of NP based models. We perform a theoretical analysis and demonstrate that LIG reduces sample complexity compared with random sampling in high dimensions. We also conduct empirical studies on three complex spatiotemporal simulators for reaction diffusion, heat flow, and infectious disease. The results demonstrate that STNP outperforms the baselines in the offline learning setting and LIG achieves the state-of-the-art for Bayesian active learning.",1456
1371,Network Science,Alessandro Vespignani,"June 23rd, 2023",Social AI and the Challenges of the Human-AI Ecosystem,https://doi.org/10.48550/arXiv.2306.13723," Dino Pedreschi, Luca Pappalardo, Ricardo Baeza-Yates, Albert-L√°szl√≥ Barab√°si, Frank Dignum, Virginia Dignum, Tina Eliassi-Rad, Fosca Giannotti, J√°nos Kert√©sz, Alistair Knott, Yannis E. Ioannidis, Paul Lukowicz, Andrea Passarella, Alex 'Sandy' Pentland, John Shawe-Taylor, Alessandro Vespignani. (2023). Social AI and the Challenges of the Human-AI Ecosystem CoRR, abs/2306.13723. https://doi.org/10.48550/arXiv.2306.13723","Human-AI coevolution, defined as a process in which humans and AI algorithms continuously influence each other, increasingly characterises our society, but is understudied in artificial intelligence and complexity science literature. Recommender systems and assistants play a prominent role in human-AI coevolution, as they permeate many facets of daily life and influence human choices on online platforms. The interaction between users and AI results in a potentially endless feedback loop, wherein users' choices generate data to train AI models, which, in turn, shape subsequent user preferences. This human-AI feedback loop has peculiar characteristics compared to traditional human-machine interaction and gives rise to complex and often ``unintended'' social outcomes. This paper introduces Coevolution AI as the cornerstone for a new field of study at the intersection between AI and complexity science focused on the theoretical, empirical, and mathematical investigation of the human-AI feedback loop. In doing so, we: (i) outline the pros and cons of existing methodologies and highlight shortcomings and potential ways for capturing feedback loop mechanisms; (ii) propose a reflection at the intersection between complexity science, AI and society; (iii) provide real-world examples for different human-AI ecosystems; and (iv) illustrate challenges to the creation of such a field of study, conceptualising them at increasing levels of abstraction, i.e., technical, epistemological, legal and socio-political.",1457
1372,Personal Health Informatics,Timothy W. Bickmore,"February 25th, 2025",Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations,https://doi.org/10.48550/arXiv.2502.18673," Ian Steenstra, Farnaz Nouraei, Timothy W. Bickmore. (2025). Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations CoRR, abs/2502.18673. https://doi.org/10.48550/arXiv.2502.18673","Learning therapeutic counseling involves significant role-play experience with mock patients, with current manual training methods providing only intermittent granular feedback. We seek to accelerate and optimize counselor training by providing frequent, detailed feedback to trainees as they interact with a simulated patient. Our first application domain involves training motivational interviewing skills for counselors. Motivational interviewing is a collaborative counseling style in which patients are guided to talk about changing their behavior, with empathetic counseling an essential ingredient. We developed and evaluated an LLM-powered training system that features a simulated patient and visualizations of turn-by-turn performance feedback tailored to the needs of counselors learning motivational interviewing. We conducted an evaluation study with professional and student counselors, demonstrating high usability and satisfaction with the system. We present design implications for the development of automated systems that train users in counseling skills and their generalizability to other types of social skills training.",1458
1373,Personal Health Informatics,Timothy W. Bickmore,"December 26th, 2024",Exploring the Potential of Virtual Agents in Atrial Fibrillation Management: Insights from a Randomized Trial,https://doi.org/10.1145/3652988.3673955," Mina Fallah, Timothy W. Bickmore, Stefan Olafsson, Michael K. Paasche-Orlow, Andrew Joseph Mrkva, Jared W. Magnani. (2024). Exploring the Potential of Virtual Agents in Atrial Fibrillation Management: Insights from a Randomized Trial IVA, 8:1-8:9. https://doi.org/10.1145/3652988.3673955","Smartphone-based conversational agents offer a convenient way to deliver health education, particularly for managing complex health conditions such as chronic diseases. The present study explores using a smartphone-based virtual agent system to aid patients with a chronic heart condition‚Äîatrial fibrillation‚Äîto manage their health by encouraging the use of a heart rhythm sensor integrated with their smartphones. We report the results of a randomized clinical trial with 240 patients experiencing atrial fibrillation who were provided with smartphones and heart rhythm sensors for 4 months. Participants in the intervention group interacted with a virtual agent, while the control group received general health education via the WebMD app. Intervention participants completed a median 91 interactions with the agent over the 4 months of the study period, and agent features designed to increase engagement‚Äìsuch as storytelling‚Äìwere effective at increasing use. The agent‚Äôs promotion of heart rhythm sensor use was effective, with intervention participants taking significantly more heart rhythm readings compared to those in the control group. Participants were followed for 8 months thereafter to assess the sustainability of the effects, specifically focusing on medication adherence.",1459
1374,Personal Health Informatics,Timothy W. Bickmore,"July 8th, 2024",Investigating User Perceptions of Collaborative Agenda Setting in Virtual Health Counseling Session,https://doi.org/10.48550/arXiv.2407.06123," Mina Fallah, Farnaz Nouraei, Hye Sun Yun, Timothy W. Bickmore. (2024). Investigating User Perceptions of Collaborative Agenda Setting in Virtual Health Counseling Session CoRR, abs/2407.06123. https://doi.org/10.48550/arXiv.2407.06123","Virtual health counselors offer the potential to provide users with information and counseling in complex areas such as disease management and health education. However, ensuring user engagement is challenging, particularly when the volume of information and length of counseling sessions increase. Agenda setting a clinical counseling technique where a patient and clinician collaboratively decide on session topics is an effective approach to tailoring discussions for individual patient needs and sustaining engagement. We explore the effectiveness of agenda setting in a virtual counselor system designed to counsel women for breast cancer genetic testing. In a between subjects study, we assessed three versions of the system with varying levels of user control in the system's agenda setting approach. We found that participants' knowledge improved across all conditions. Although our results showed that any type of agenda setting was perceived as useful, regardless of user control, interviews revealed a preference for more collaboration and user involvement in the agenda setting process. Our study highlights the importance of using patient-centered approaches, such as tailored discussions, when using virtual counselors in healthcare.",1460
1375,Personal Health Informatics,Timothy W. Bickmore,"July 1st, 2024",Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents,https://doi.org/10.48550/arXiv.2407.01824," Mehdi Arjmand, Farnaz Nouraei, Ian Steenstra, Timothy W. Bickmore. (2024). Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents CoRR, abs/2407.01824. https://doi.org/10.48550/arXiv.2407.01824","We introduce the concept of ""empathic grounding"" in conversational agents as an extension of Clark's conceptualization of grounding in conversation in which the grounding criterion includes listener empathy for the speaker's affective state. Empathic grounding is generally required whenever the speaker's emotions are foregrounded and can make the grounding process more efficient and reliable by communicating both propositional and affective understanding. Both speaker expressions of affect and listener empathic grounding can be multimodal, including facial expressions and other nonverbal displays. Thus, models of empathic grounding for embodied agents should be multimodal to facilitate natural and efficient communication. We describe a multimodal model that takes as input user speech and facial expression to generate multimodal grounding moves for a listening agent using a large language model. We also describe a testbed to evaluate approaches to empathic grounding, in which a humanoid robot interviews a user about a past episode of pain and then has the user rate their perception of the robot's empathy. We compare our proposed model to one that only generates non-affective grounding cues in a between-subjects experiment. Findings demonstrate that empathic grounding increases user perceptions of empathy, understanding, emotional intelligence, and trust. Our work highlights the role of emotion awareness and multimodality in generating appropriate grounding moves for conversational agents.",1461
1376,Personal Health Informatics,Timothy W. Bickmore,"May 11th, 2024",‚ÄòSomething I Can Lean On‚Äô: A Qualitative Evaluation of a Virtual Palliative Care Counselor for Patients with Life-Limiting Illnesses,https://doi.org/10.1145/3613905.3651106," Teresa K. O'Leary, Michael K. Paasche-Orlow, Timothy W. Bickmore. (2024). 'Something I Can Lean On': A Qualitative Evaluation of a Virtual Palliative Care Counselor for Patients with Life-Limiting Illnesses CHI Extended Abstracts, 380:1-380:7. https://doi.org/10.1145/3613905.3651106","Palliative care is essential for maintaining the highest quality of life for patients with life-limiting illnesses. Although the benefits of palliative care are well supported, palliative care services are often offered late in the trajectory of the patient‚Äôs disease, limiting the beneficial role these services play in mitigating patient suffering. Digital health tools represent a promising approach for expanding access to palliative care. We report findings from interviews with twenty patients who used a virtual palliative care counselor over a six-month study period and provide guidelines for developers based on these results. Through their use of the system, patients characterized how using a digital palliative care counselor that intervenes on multiple dimensions of well-being benefited their experience of illness and quality of life.",1462
1377,Personal Health Informatics,Timothy W. Bickmore,"May 11th, 2024",Engaging and Entertaining Adolescents in Health Education Using LLM-Generated Fantasy Narrative Games and Virtual Agents,https://doi.org/10.1145/3613905.3650983," Ian Steenstra, Prasanth Murali, Rebecca B. Perkins, Natalie Joseph, Michael K. Paasche-Orlow, Timothy W. Bickmore. (2024). Engaging and Entertaining Adolescents in Health Education Using LLM-Generated Fantasy Narrative Games and Virtual Agents CHI Extended Abstracts, 126:1-126:8. https://doi.org/10.1145/3613905.3650983","Games have been successfully used to provide engaging health interventions for adolescents. However, translating health education goals into a playable game has historically taken many person-months of effort, involving game designers, scriptwriters, and artists. This work presents an exploratory study into rapidly developing physician-validated health education games for adolescents using virtual agents and LLMs. We evaluated this approach in an intervention to promote Human Papillomavirus (HPV) vaccination among adolescents, as lack of knowledge and vaccine hesitancy contribute to suboptimal HPV vaccination rates. We conducted a between-subjects randomized study comparing a fantasy narrative game to a non-gamified pedagogical virtual agent, with both interventions conveying the same HPV information. Among our study‚Äôs 9-12-year-old adolescent participants, our findings demonstrate large pre-to-post improvements in HPV knowledge for both conditions. The gamified intervention showed higher engagement and entertainment than the pedagogical agent based on participant interviews, demonstrating that gamification enriched the educational experience for adolescents.",1463
1378,Personal Health Informatics,Timothy W. Bickmore,"September 14th, 2021",A Friendly Face in the Crowd: Reducing Public Speaking Anxiety with an Emotional Support Agent in the Audience,https://dl.acm.org/doi/abs/10.1145/3472306.3478364," Murali, P., Trinh, A. and Bickmore, T. A Friendly Face in the Crowd: Reducing Public Speaking Anxiety with an Emotional Support Agent in the Audience. In Proceedings of the ACM International Conference on Intelligent Virtual Agents (IVA) (2021).","We present Friendly Face - a virtual agent designed to reduce public speaking anxiety by standing within an audience. The agent senses the speaker's behavior during an oral presentation and provides emotional and instrumental support. The system unobtrusively tracks the motion, speech, and prosody of the presenter and provides an intuitive interface to give supportive feedback whenever the presenter looks at the agent, attentive listening behavior through agent gaze and backchannel listening behavior, and time and topic cueing based on real-time analysis of speech content compared to presentation slide contents. An evaluation of Friendly Face agent with a functionally equivalent control system demonstrated that the agent system led to significant reductions in public speaking anxiety compared to a control condition, assessed both objectively with physiological measures and validated self-report instruments.",1464
1379,Personal Health Informatics,Timothy W. Bickmore,"September 14th, 2021",Diversity Informatics: Reducing Racial and Gender Bias with Virtual Agents,https://dl.acm.org/doi/abs/10.1145/3472306.3478365?sid=SCITRUS," Bickmore, T., Parmar, D., Kimani, E. and Olafsson, S. Diversity Informatics: Reducing Racial and Gender Bias with Virtual Agents. In Proceedings of the ACM International Conference on Intelligent Virtual Agents (IVA) (2021).","Job advertisements in white male-dominated organizations are often biased in ways that discourage female and minority candidates from applying. We explored the use of a female African American virtual agent who provides a first-person reaction to a biased job advertisement, providing an impassioned, vivid description of her feelings about the advertisement, the position, and the organization offering the job, and how the position---as described---would impact her life were she to take the job. We evaluate the impact interactions with this agent have on the effort study participants invest in editing the job advertisement following their interaction with the agent, compared to reading a page of standard educational text on diversity in hiring. Participants who interacted with the agent spent significantly more effort correcting the job ad, as measured both by the number of edit operations and the number of biased phrases removed, compared to participants in the control condition. Implications and a future research agenda for increasing diversity using virtual agents are presented.",1465
1380,Personal Health Informatics,Timothy W. Bickmore,"May 8th, 2021",‚ÄòMore like a person than reading text in a machine‚Äô: Characterizing User Choice of Embodied Agents vs. Conventional GUIs on Smartphones,https://doi.org/10.1145/3411763.3451664," S. Olafsson, D. Parmar, E. Kimani, T.K. O'Leary, T.W. Bickmore. ""‚ÄòMore like a person than reading text in a machine‚Äô: Characterizing User Choice of Embodied Agents vs. Conventional GUIs on Smartphones."" CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, 2021. DOI: 10.1145/3411763.3451664","Embodied conversational agents (ECAs) provide an interface modality on smartphones that may be particularly effective for tasks with significant social, affective, reflective, and narrative aspects, such as health education and behavior change counseling. However, the conversational medium is significantly slower than conventional graphical user interfaces (GUIs) for brief, time-sensitive tasks. We conducted a randomized experiment to determine user preferences in performing two kinds of health-related tasks‚Äîone affective and narrative in nature and one transactional‚Äîand gave participants a choice of a conventional GUI or a functionally equivalent ECA on a smartphone to complete the task. We found significant main effects of task type and user preference on user choice of modality, with participants choosing the conventional GUI more often for transactional and time-sensitive tasks.",1466
1381,Personal Health Informatics,Timothy W. Bickmore,"May 6th, 2021","Examining the Intersections of Race, Religion & Community Technologies: A Photovoice Study",https://doi.org/10.1145/3411764.3445418," T.K. O‚ÄôLeary, E. Stowell, J. Hoffman, M.K. Paasche-Orlow, T.W. Bickmore, A.G. Parker. ‚ÄúExamining the Intersections of Race, Religion & Community Technologies: A Photovoice Study.‚Äù ACM Conference on Human Factors in Computing (CHI 2021), 2021. DOI: 10.1145/3411764.3445418","Churches have historically played an important role in Black American communities, catalyzing the pursuit of aims such as social justice, community organization, and health promotion. However, researchers have rarely examined how technology can support an assets-based approach to these efforts, nor the implications of race, traditions, and history when creating such systems. Addressing this gap, we conducted research with two predominantly Black churches to explore health promotion design opportunities. We used photovoice, a research method where participants led their own data collection and analysis. Participants provided nuanced descriptions of the racial and ethnic identities of their communities, and how church history and aspirations for the future impacted these identities. Our findings characterize tensions between tradition and ‚Äòmodernization,‚Äô implications for technology design, and the need for a temporal approach to understanding communities. We conclude with broader implications for studying the intersection of race and religion in community technology design.",1467
1382,Personal Health Informatics,Timothy W. Bickmore,"October 20th, 2020",Community-Based Cultural Tailoring of Virtual Agents,https://doi.org/10.1145/3383652.3423875," T.K. O‚ÄôLeary, E. Stowell, E. Kimani, D. Parmar, S. Olafsson, J. Hoffman, A.G. Parker, M.K. Paasche-Orlow,  T.W. Bickmore. ‚ÄúCommunity-Based Cultural Tailoring of Virtual Agents.‚Äù IVA ‚Äô20: Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, 2020. DOI: 10.1145/3383652.3423875","Culturally informed design for virtual agents has been shown to positively impact health outcomes when tailored to target audiences. We present a participatory design methodology for culturally tailoring virtual agents. Investigators worked with key informants from our target population, members of predominantly Black church communities, to design culturally-relevant and sensitive virtual agent health promotion interventions. In the first participatory session, key informants designed agents to assist them with different aspects of their lives, providing input on agent appearance and agent functionality. In a second design session, participants re-wrote the content of a health conversation with an agent, to include personally-relevant content related to their community (e.g., religious and scriptural references). We report design principles for religious tailoring derived from these studies. We conducted a validation study to assess the effects of applying these principles to agents that promoted two health behaviors, finding that participants responded very positively to the tailored agents.",1468
1383,Personal Health Informatics,Timothy W. Bickmore,"September 18th, 2020",Improving the health of young African American women in the preconception period using health information technology: a randomised controlled trial,https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2820%2930189-8/fulltext," Jack, B., Bickmore, T., Yinusa-Nyahkoon, L., Reichert, M., Julce, C., Sidduri, N., Martin-Howard, J., Zhang, Z., Woodhams, E., Fernandez, J., Loafman, M. and Cabral, H. Improving the health of young African American women in the preconception period using health information technology: a randomised controlled trial. The Lancet, Digital Health, 2, 9 (2020)",The aim of this research was to assess the impact of an embodied conversational agent system on preconception risks among African American and Black women. The Gabby system has the potential to improve women's preconception health. Further research is needed to determine if improving preconception. risks impacts outcomes such as preterm delivery.,1469
1384,Personal Health Informatics,Timothy W. Bickmore,"September 8th, 2020",Effects of Counseling by Peer Human Advisors vs Computers to Increase Walking in Underserved Populations: The COMPASS Randomized Clinical Trial,https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2771193," King, A. C., Campero, M. I., Sheats, J. L., Castro Sweet, C. M., Hauser, M. E., Garcia, D., Chazaro, A., Blanco, G., Banda, J., Ahn, D. K., Fernandez, J. and Bickmore, T. Effects of Counseling by Peer Human Advisors vs Computers to Increase Walking in Underserved Populations: The COMPASS Randomized Clinical Trial. JAMA Intern Med (Sep 28 2020).","Walking represents a popular physical activity that can produce a range of desirable health effects, particularly as people age. To test the hypothesis that counseling by a computer-based virtual advisor is no worse than (ie, noninferior to) counseling by trained human advisors, a cluster-randomized, parallel trial enrolled 245 adults. Improvements emerged in both arms for relevant clinical risk factors, sedentary behavior, and well-being measures.",1470
1385,Personal Health Informatics,Timothy W. Bickmore,"April 21st, 2020",Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study,https://doi.org/10.1145/3313831.3376833," E. Stowell, T.K. O‚ÄôLeary, E. Kimani, M.K. Paasche-Orlow, T.W. Bickmore, A.G. Parker. ‚ÄúInvestigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study.‚Äù ACM Conference on Human Factors in Computing Systems, 2020. DOI: 10.1145/3313831.3376833","Churches play a major role in providing social support to address health inequities within Black communities, in part by connecting members to key organizations and services. While public health has a history of disseminating interventions in faith communities, little work has explored the use of crowdsourcing to tailor interventions to the unique culture of each church community. Following Community Based Participatory Research principles, we partnered with two predominantly Black churches, and report on a series of three participatory design sessions with nine participants. We developed a novel storyboarding method to explore how crowdsourcing could promote health in these faith-based communities. Our findings characterize existing supports within the church community, and how church social structures impact member access to these supports. We further identify motivations to engage with a church-situated health application, and how these motivations translate to crowdsourcing tasks. Finally, we discuss considerations for public health crowdsourcing tasks.",1471
1386,Personal Health Informatics,Kevin Fu,"January 10th, 2025",Learning Flexible Heterogeneous Coordination with Capability-Aware Shared Hypernetworks,https://doi.org/10.48550/arXiv.2501.06058," Kevin Fu, Pierce Howell, Shalin Jain, Harish Ravichandar. (2025). Learning Flexible Heterogeneous Coordination with Capability-Aware Shared Hypernetworks CoRR, abs/2501.06058. https://doi.org/10.48550/arXiv.2501.06058","Recent advances have enabled heterogeneous multi-robot teams to learn complex and effective coordination. However, existing architectural designs that support heterogeneous teams tend to force a trade-off between expressivity and efficiency. Some attempt to encode diverse behaviors within a single shared architecture by appending the input with an ID unique to each robot or robot type. These designs improve sample and parameter efficiency but tend to limit behavioral diversity. Others use a separate policy for each robot, enabling greater diversity at the cost of efficiency and generalization. We view these two designs as ends of a spectrum and explore a middle-ground approach that enables efficient learning of diverse behaviors. Inspired by work in transfer learning and meta RL, and building upon prior work in trait-based task allocation, we propose Capability-Aware Shared Hypernetworks (CASH), a general-purpose soft weight sharing architecture that uses hypernetworks to enable a single architecture to dynamically adapt to each robot and the current context. Intuitively, CASH encodes shared decision making strategies that can be adapted to each robot based on local observations and the robots' individual and collective capabilities (e.g., speed and payload). CASH explicitly captures the impact of capabilities on collective behavior, enabling zero-shot generalization to unseen robots or team compositions. We conducted experiments across four heterogeneous coordination tasks and three learning paradigms (imitation learning, value-based, and policy-gradient RL) using SOTA multi-robot simulation (JaxMARL) and hardware (Robotarium) platforms. Across all conditions, CASH generates appropriately diverse behaviors and outperforms baseline architectures in task performance and sample efficiency during training and zero-shot generalization while utilizing 60%-80% fewer learnable parameters.",1472
1387,Personal Health Informatics,Kevin Fu,"November 28th, 2023",Adversarial Computer Vision via Acoustic Manipulation of Camera Sensors,https://doi.org/10.1109/TDSC.2023.3334618," Yushi Cheng, Xiaoyu Ji , Wenjun Zhu, Shibo Zhang, Kevin Fu, Wenyuan Xu . (2024). Adversarial Computer Vision via Acoustic Manipulation of Camera Sensors IEEE Trans. Dependable Secur. Comput., 21, 3734-3750. https://doi.org/10.1109/TDSC.2023.3334618","Autonomous vehicles increasingly rely on camera-based computer vision systems to perceive environments and make critical driving decisions. To improve image quality, image stabilizers with inertial sensors are added to reduce image blurring caused by camera jitters. This trend creates a new attack surface. By emitting deliberately designed acoustic signals, an adversary can control the output of an inertial sensor, which triggers unnecessary motion compensation and results in a blurred image. These blurred images can induce object misclassification, affecting safety-critical decision-making. We model the feasibility of such acoustic manipulation and design an attack framework that can accomplish three types of attacks.",1473
1388,Personal Health Informatics,Matthew Goodwin,"March 25th, 2024",Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic,https://doi.org/10.48550/arXiv.2403.17165," Jessilyn Dunn, Varun Mishra , Md. Mobashir Hasan Shandhi, Hayoung Jeong, Natasha Yamane, Yuna Watanabe, Bill Chen, Matthew S. Goodwin. (2024). Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic CoRR, abs/2403.17165. https://doi.org/10.48550/arXiv.2403.17165","Smartphones and wearable sensors offer an unprecedented ability to collect peripheral psychophysiological signals across diverse timescales, settings, populations, and modalities. However, open-source software development has yet to keep pace with rapid advancements in hardware technology and availability, creating an analytical barrier that limits the scientific usefulness of acquired data. We propose a community-driven, open-source peripheral psychophysiological signal pre-processing and analysis software framework that could advance biobehavioral health by enabling more robust, transparent, and reproducible inferences involving autonomic nervous system data.",1474
1389,Personal Health Informatics,Matthew Goodwin,"December 21st, 2023",Wearable biosensing to predict imminent aggressive behaviors in psychiatric inpatient youths with autism,https://doi.org/10.1001%2Fjamanetworkopen.2023.48898," Imbiriba, T, Demirkaya, A, Singh, A, Erdogmus, D, Goodwin, MS (2023). Wearable biosensing to predict imminent aggressive behaviors in psychiatric inpatient youths with autism. JAMA Network Open, 6(12):e2348898.",Data were analyzed from March 2020 through October 2023 from 4 primary care psychiatric inpatient hospitals. Logistic regression was the best-performing overall classifier across all experiments. Further research will explore clinical implications and the potential for personalized interventions in inpatient youths with autistic children and adults. The findings were published in the Journal of Autism and Developmental Disorder.,1475
1390,Personal Health Informatics,Matthew Goodwin,"November 29th, 2023",Multiple Toddler Tracking in Indoor Videos,https://doi.org/10.48550/arXiv.2311.17656," Somaieh Amraee, Bishoy Galoaa, Matthew S. Goodwin, Elaheh Hatamimajoumerd, Sarah Ostadabbas. (2023). Multiple Toddler Tracking in Indoor Videos CoRR, abs/2311.17656. https://doi.org/10.48550/arXiv.2311.17656","Multiple toddler tracking (MTT) involves identifying and differentiating toddlers in video footage. While conventional multi-object tracking (MOT) algorithms are adept at tracking diverse objects, toddlers pose unique challenges due to their unpredictable movements, various poses, and similar appearance. Tracking toddlers in indoor environments introduces additional complexities such as occlusions and limited fields of view. In this paper, we address the challenges of MTT and propose MTTSort, a customized method built upon the DeepSort algorithm. MTTSort is designed to track multiple toddlers in indoor videos accurately. Our contributions include discussing the primary challenges in MTT, introducing a genetic algorithm to optimize hyperparameters, proposing an accurate tracking algorithm, and curating the MTTrack dataset using unbiased AI co-labeling techniques. We quantitatively compare MTTSort to state-of-the-art MOT methods on MTTrack, DanceTrack, and MOT15 datasets. In our evaluation, the proposed method outperformed other MOT methods, achieving 0.98, 0.68, and 0.98 in multiple object tracking accuracy (MOTA), higher order tracking accuracy (HOTA), and iterative and discriminative framework 1 (IDF1) metrics, respectively.",1476
1391,Personal Health Informatics,Matthew Goodwin,"May 11th, 2023",A user-based information rating scale to evaluate the design of technology-based supports for autism,https://doi.org/10.1007/s10209-023-00995-y," Vanessa Zervogianni, Sue Fletcher-Watson, Gerardo Herrera, Matthew S. Goodwin, Elise Triquell, Patricia P√©rez-Fuster, Mark J. Brosnan, Ouriel Grynszpan. (2024). A user-based information rating scale to evaluate the design of technology-based supports for autism Univers. Access Inf. Soc., 23, 1739-1749. https://doi.org/10.1007/s10209-023-00995-y","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. You have full access to this open access article",1477
1392,Personal Health Informatics,Matthew Goodwin,"March 29th, 2023",A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants,https://doi.org/10.48550/arXiv.2303.16867," Shaotong Zhu, Michael Wan, Elaheh Hatamimajoumerd, Kashish Jain, Samuel Zlota, Cholpady Vikram Kamath, Cassandra B. Rowan, Emma C. Grace, Matthew S. Goodwin, Marie J. Hayes, Rebecca A. Schwartz-Mette, Emily Zimmerman, Sarah Ostadabbas. (2023). A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants CoRR, abs/2303.16867. https://doi.org/10.48550/arXiv.2303.16867","We present an end-to-end computer vision pipeline to detect non-nutritive sucking (NNS) -- an infant sucking pattern with no nutrition delivered -- as a potential biomarker for developmental delays, using off-the-shelf baby monitor video footage. One barrier to clinical (or algorithmic) assessment of NNS stems from its sparsity, requiring experts to wade through hours of footage to find minutes of relevant activity. Our NNS activity segmentation algorithm solves this problem by identifying periods of NNS with high certainty -- up to 94.0\% average precision and 84.9\% average recall across 30 heterogeneous 60 s clips, drawn from our manually annotated NNS clinical in-crib dataset of 183 hours of overnight baby monitor footage from 19 infants. Our method is based on an underlying NNS action recognition algorithm, which uses spatiotemporal deep learning networks and infant-specific pose estimation, achieving 94.9\% accuracy in binary classification of 960 2.5 s balanced NNS vs. non-NNS clips. Tested on our second, independent, and public NNS in-the-wild dataset, NNS recognition classification reaches 92.3\% accuracy, and NNS segmentation achieves 90.8\% precision and 84.2\% recall.",1478
1393,Personal Health Informatics,Matthew Goodwin,"November 7th, 2022",Real-time Public Speaking Anxiety Prediction Model for Oral Presentations,https://doi.org/10.1145/3536220.3563686," Everlyne Kimani, Timothy W. Bickmore, Rosalind W. Picard, Matthew S. Goodwin, Holly Jimison. (2022). Real-time Public Speaking Anxiety Prediction Model for Oral Presentations ICMI Companion, 30-35. https://doi.org/10.1145/3536220.3563686","Oral presentation skills are essential for most people‚Äôs academic and career development. However, due to public speaking anxiety, many people find oral presentations challenging and often avoid them to the detriment of their careers. Public speaking anxiety interventions that help presenters manage their anxiety as it occurs during a presentation can help many presenters. In this paper, we present a model for assessing public speaking anxiety during a presentation‚Äîa first step towards developing real-time anxiety interventions. We present our method for ground truth data collection and the results of neural network models for real-time anxiety detection using audio data. Our results show that using an LSTM model we can predict moments of speaking anxiety during a presentation.",1479
1394,Personal Health Informatics,Matthew Goodwin,"July 9th, 2021",Automated Pain Assessment in Children Using Electrodermal Activity and Video Data Fusion via Machine Learning,https://doi.org/10.1109/TBME.2021.3096137," Busra T. Susam, Nathan T. Riek, Murat Ak√ßakaya, Xiaojing Xu, Virginia R. de Sa, Hooman Nezamfar, Damaris Diaz, Kenneth D. Craig, Matthew S. Goodwin, Jeannie S. Huang. (2022). Automated Pain Assessment in Children Using Electrodermal Activity and Video Data Fusion via Machine Learning IEEE Trans. Biomed. Eng., 69, 422-431. https://doi.org/10.1109/TBME.2021.3096137","Pain assessment in children continues to challenge clinicians and researchers, as subjective experiences of pain require inference through observable behaviors. The presented approach supplements the subjective self-report-based method by fusing electrodermal activity (EDA) recordings with video facial expressions to develop an objective pain assessment metric. Findings indicate that EDA and facial expression data independently provide above chance sensitivities and specificities, but their fusion for classifying clinically significant pain vs. clinically nonsignificant pain achieved substantial improvement, yielding 90.91% accuracy, with 100% sensitivity and 81.82% specificity. The multimodal measures capitalize upon different features of the complex pain response.",1480
1395,Personal Health Informatics,Matthew Goodwin,"June 30th, 2020",Biosensor prediction of aggression in youth with autism using kernel-based methods,https://doi.org/10.1145/3389189.3389199," Tales Imbiriba, Diana Catalina Cumpanasoiu, James Heathers, Stratis Ioannidis, Deniz Erdogmus, Matthew S. Goodwin. (2020). Biosensor prediction of aggression in youth with autism using kernel-based methods PETRA, 13:1-13:6. https://doi.org/10.1145/3389189.3389199","Aggression to others by youth with autism is a significant problem since their difficulties self-reporting distress can lead to behaviors that appear to occur without warning. To address this issue, we recently demonstrated that biosensor data combined with linear classification algorithms (i.e., ridge-regularized logistic regression) can be used to predict aggression up to 1 minute before it occurs using 3 minutes of data from the past with an average area under the curve (AUC) of 0.71-0.84 depending on whether population versus individual models are used. In the present study, we both extend and enhance these prior results through the use of principal component analysis and a nonlinear kernel-based classifier (Support Vector Machines). Our results illustrate that these newly applied methods yield significant improvements, predicting aggression up to 3 minutes before it occurs with an average AUC of 0.98 in both population and individual models. Furthermore, we extend our prior work by evaluating aggression prediction performance across varying observed aggression intensities and find that moderate and high intensity aggression episodes are detectable with 2 to 5% higher average AUC than low-intensity aggression episodes.",1481
1396,Personal Health Informatics,Matthew Goodwin,"September 15th, 2018",Applications of sparse recovery and dictionary learning to enhance analysis of ambulatory electrodermal activity data,https://doi.org/10.1016/j.bspc.2017.08.024," Malia Kelsey, Murat Ak√ßakaya, Ian R. Kleckner, Richard Vincent Palumbo, Lisa Feldman Barrett, Karen S. Quigley, Matthew S. Goodwin. (2018). Applications of sparse recovery and dictionary learning to enhance analysis of ambulatory electrodermal activity data Biomed. Signal Process. Control., 40, 58-70. https://doi.org/10.1016/j.bspc.2017.08.024","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1482
1397,Personal Health Informatics,Matthew Goodwin,"July 1st, 2015",Automated Assessment of Children‚Äôs Postoperative Pain Using Computer Vision,http://www.ncbi.nlm.nih.gov/pubmed/26034245," Sikka, K., Ahmed, A. A., Diaz, D., Goodwin, M. S., Craig, K. D., Bartlett, M. S., & Huang, J. S. (2015). Automated Assessment of Children‚Äôs Postoperative Pain Using Computer Vision. Pediatrics, peds-2015.","Abstract Background: Current pain assessment methods in youth are suboptimal and vulnerable to bias and underrecognition of clinical pain. Facial expressions are a sensitive, specific biomarker of the presence and severity of pain, and computer vision (CV) and machine-learning (ML) techniques enable reliable, valid measurement of pain-related facial expressions from video. We developed and evaluated a CVML approach to measure pain-related facial expressions for automated pain assessment in youth. Methods: A CVML-based model for assessment of pediatric postoperative pain was developed from videos of 50 neurotypical youth 5 to 18 years old in both endogenous/ongoing and exogenous/transient pain conditions after laparoscopic appendectomy. Model accuracy was assessed for self-reported pain ratings in children and time since surgery, and compared with by-proxy parent and nurse estimates of observed pain in youth. Results: Model detection of pain versus no-pain demonstrated good-to-excellent accuracy (Area under the receiver operating characteristic curve 0.84-0.94) in both ongoing and transient pain conditions. Model detection of pain severity demonstrated moderate-to-strong correlations (r = 0.65-0.86 within; r = 0.47-0.61 across subjects) for both pain conditions. The model performed equivalently to nurses but not as well as parents in detecting pain versus no-pain conditions, but performed equivalently to parents in estimating pain severity. Nurses were more likely than the model to underestimate youth self-reported pain ratings. Demographic factors did not affect model performance. Conclusions: CVML pain assessment models derived from automatic facial expression measurements demonstrated good-to-excellent accuracy in binary pain classifications, strong correlations with patient self-reported pain ratings, and parent-equivalent estimation of children's pain levels over typical pain trajectories in youth after appendectomy.",1483
1398,Personal Health Informatics,Matthew Goodwin,"May 10th, 2014",A non-homogeneous poisson process model of Skin Conductance Responses integrated with observed regulatory behaviors for Autism intervention,http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6853870," Chaspari, T., Goodwin, M., Wilder-Smith, O., Gulsrud, A., Mucchetti, C., Kasari, C., & Narayanan, S. (2014, May). A non-homogeneous Poisson process model of skin conductance responses integrated with observed regulatory behaviors for Autism intervention. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 1611-1615). IEEE.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1484
1399,Personal Health Informatics,Matthew Goodwin,"January 2nd, 2010",iCalm: Wearable Sensor and Network Architecture for Wirelessly Communicating and Logging Autonomic Activity,http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5373932," Fletcher R.R., Dobson K., Goodwin M.S., Eydgahi H., Wilder-Smith O., Fernholz D., Kuboyama Y., Hedman E., Poh M.-Z., Picard R.W. iCalm: wearable sensor and network architecture for wirelessly communicating and logging autonomic activity ‚Äî IEEE Transactions on Information Technology in Biomedicine, 2010 14(2): 215‚Äê223.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1485
1400,Personal Health Informatics,Stephen Intille,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1486
1401,Personal Health Informatics,Stephen Intille,"November 21st, 2024","Ask Less, Learn More: Adapting Ecological Momentary Assessment Survey Length by Modeling Question-Answer Information Gain",https://doi.org/10.1145/3699735," Jixin Li, Aditya Ponnada, Wei-Lin Wang, Genevieve F. Dunton, Stephen S. Intille. (2024). Ask Less, Learn More: Adapting Ecological Momentary Assessment Survey Length by Modeling Question-Answer Information Gain Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 166:1-166:32. https://doi.org/10.1145/3699735","Ecological momentary assessment (EMA) is an approach to collect self-reported data repeatedly on mobile devices in natural settings. EMAs allow for temporally dense, ecologically valid data collection, but frequent interruptions with lengthy surveys on mobile devices can burden users, impacting compliance and data quality. We propose a method that reduces the length of each EMA question set measuring interrelated constructs, with only modest information loss. By estimating the potential information gain of each EMA question using question-answer prediction models, this method can prioritize the presentation of the most informative question in a question-by-question sequence and skip uninformative questions. We evaluated the proposed method by simulating question omission using four real-world datasets from three different EMA studies. When compared against the random question omission approach that skips 50% of the questions, our method reduces imputation errors by 15%-52%. In surveys with five answer options for each question, our method can reduce the mean survey length by 34%-56% with a real-time prediction accuracy of 72%-95% for the skipped questions. The proposed method may either allow more constructs to be surveyed without adding user burden or reduce response burden for more sustainable longitudinal EMA data collection.",1487
1402,Personal Health Informatics,Stephen Intille,"September 9th, 2024",Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment,https://doi.org/10.1145/3678584," Ha Le, Rithika Lakshminarayanan, Jixin Li, Varun Mishra , Stephen S. Intille. (2024). Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 111:1-111:35. https://doi.org/10.1145/3678584","ŒºEMA is a data collection method that prompts research participants with quick, answer-at-a-glance, single-multiple-choice self-report behavioral questions, thus enabling high-temporal-density self-report of up to four times per hour when implemented on a smartwatch. However, due to the small watch screen, ŒºEMA is better used to select among 2 to 5 multiple-choice answers versus allowing the collection of open-ended responses. We introduce an alternative and novel form of micro-interaction self-report using speech input - audio-ŒºEMA- where a short beep or vibration cues participants to verbally report their behavioral states, allowing for open-ended, temporally dense self-reports. We conducted a one-hour usability study followed by a within-subject, 6-day to 21-day free-living feasibility study in which participants self-reported their physical activities and postures once every 2 to 5 minutes. We qualitatively explored the usability of the system and identified factors impacting the response rates of this data collection method. Despite being interrupted 12 to 20 times per hour, participants in the free-living study were highly engaged with the system, with an average response rate of 67.7% for audio-ŒºEMA for up to 14 days. We discuss the factors that impacted feasibility; some implementation, methodological, and participant challenges we observed; and important considerations relevant to deploying audio-ŒºEMA in real-time activity recognition systems.",1488
1403,Personal Health Informatics,Stephen Intille,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1489
1404,Personal Health Informatics,Stephen Intille,"November 11th, 2022",Exploring Opportunities to Improve Physical Activity in Individuals with Spinal Cord Injury Using Context-Aware Messaging,https://doi.org/10.1145/3555628," Rithika Lakshminarayanan, Alexandra Canori, Aditya Ponnada, Melissa Nunn, Mary Schmidt Read, Shivayogi V. Hiremath, Stephen S. Intille. (2022). Exploring Opportunities to Improve Physical Activity in Individuals with Spinal Cord Injury Using Context-Aware Messaging Proc. ACM Hum. Comput. Interact., 6, 1-27. https://doi.org/10.1145/3555628","Spinal cord injury (SCI) affects the mobility of 250,000 people per year worldwide. Physical activity (PA) in individuals with SCI is positively associated with improved mental and physical health outcomes. Mobile technologies have been developed to motivate individuals with SCI to increase PA using activity tracking and real-time feedback. We conducted semi-structured interviews and participatory design sessions with 15 manual wheelchair users with SCI and eight of their family members/friends to investigate user impressions of future technologies that might use computer-mediated, sensor-triggered communication to motivate PA. We assessed barriers to PA and how context-aware communication could help overcome them. Participants with SCI expressed that PA tracking and communication technologies must be tailored to their specific needs. Further analysis revealed that context-aware messaging could help participants with SCI connect with others to initiate timely conversations about overcoming PA barriers, and to provide encouragement to meet their PA goals. We discuss opportunities to empower individuals with SCI with regards to PA using tailored, context-aware communication.",1490
1405,Personal Health Informatics,Stephen Intille,"September 26th, 2022",Grand Challenges,https://doi.org/10.1109/MPRV.2022.3198813," Sarah Clinch, Stephen S. Intille. (2022). Grand Challenges IEEE Pervasive Comput., 21, 7-8. https://doi.org/10.1109/MPRV.2022.3198813","Abstract: The articles in this special section focus on new applications for pervasive computing. Metadata Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Page(s): 7 - 8 Date of Publication: 26 September 2022 ISSN Information: DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE Abstract: The articles in this special section focus on new applications for pervasive computing. Metadata Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Page(s): 7 - 8 Date of Publication: 26 September 2022 ISSN Information: DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE Abstract: The articles in this special section focus on new applications for pervasive computing. Published in: IEEE Pervasive Computing ( Volume: 21 , Issue: 3 , 01 July-Sept. 2022 ) Date of Publication: 26 September 2022 DOI: 10.1109/MPRV.2022.3198813 Publisher: IEEE",1491
1406,Personal Health Informatics,Stephen Intille,"March 29th, 2022",Contextual Biases in Microinteraction Ecological Momentary Assessment (ŒºEMA) Non-response,https://doi.org/10.1145/3517259," Aditya Ponnada, Jixin Li, Shirlene Wang, Wei-Lin Wang, Bridgette Do, Genevieve F. Dunton, Stephen S. Intille. (2022). Contextual Biases in Microinteraction Ecological Momentary Assessment (ŒºEMA) Non-response Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 6, 26:1-26:24. https://doi.org/10.1145/3517259","Ecological momentary assessment (EMA) is used to gather in-situ self-report on behaviors using mobile devices. Microinteraction EMA (ŒºEMA), is a type of EMA where each survey is only one single question that can be answered with a glanceable microinteraction on a smartwatch. Prior work shows that even when ŒºEMA interrupts far more frequently than smartphone-EMA, ŒºEMA yields higher response rates with lower burden. We examined the contextual biases associated with non-response of ŒºEMA prompts on a smartwatch. Based on prior work on EMA non-response and smartwatch use, we identified 10 potential contextual biases from three categories: temporal (time of the day, parts of waking day, day of the week, and days in study), device use (screen state, charging status, battery mode, and phone usage), and activity (wrist motion and location). We used data from a longitudinal study where 131 participants (Mean age 22.9 years, SD = 3.0) responded to ŒºEMA surveys on a smartwatch for at least six months. Using mixed-effects logistic regression, we found that all temporal, activity/mobility, and device use variables had a statistically significant (p<0.001) association with momentary ŒºEMA non-response. We discuss the implication of these results for future use of context-aware ŒºEMA methodology.",1492
1407,Personal Health Informatics,Stephen Intille,"March 20th, 2021",Signaligner Pro: A Tool to Explore and Annotate Multi-day Raw Accelerometer Data,https://ieeexplore.ieee.org/abstract/document/9431110," A. Ponnada et al., ""Signaligner Pro: A Tool to Explore and Annotate Multi-day Raw Accelerometer Data,"" 2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), 2021, pp. 475-480, doi: 10.1109/PerComWorkshops51409.2021.9431110.","Human activity recognition using wearable accelerometers can enable in-situ detection of physical activities to support novel human-computer interfaces. Many of the machine-learning-based activity recognition algorithms require multi-person, multi-day, carefully annotated training data. To date, there is a dearth of usable tools that enable researchers to conveniently visualize and annotate multiple days of high-sampling-rate raw accelerometer data. We developed Signaligner Pro to enable researchers. to conveniently explore and annotated multi- day high-Sampling rate raw accelerometers data.",1493
1408,Personal Health Informatics,Stephen Intille,"July 25th, 2019",Classifier personalization for activity recognition using wrist accelerometers,https://ieeexplore.ieee.org/document/8462755," A. Mannini and S. S. Intille, ""Classifier Personalization for Activity Recognition Using Wrist Accelerometers,"" in IEEE Journal of Biomedical and Health Informatics, vol. 23, no. 4, pp. 1585-1594, July 2019.","Intersubject variability in accelerometer-based activity recognition may significantly affect classification accuracy. In this paper, we propose an approach for personalizing classification rules to a single person. The method improves activity detection from wrist-worn accelerometer data on a four-class recognition problem of interest to the exercise science community. The new method improved overall recognition accuracy up to 11% on average, with some large person-specific improvements (ranging from -2% to +36%).",1494
1409,Personal Health Informatics,Stephen Intille,"October 18th, 2018",The Association Between Engagement and Weight Loss Through Personal Coaching and Cell Phone Interventions in Young Adults: Randomized Controlled Trial,https://www.ncbi.nlm.nih.gov/pubmed/30341051," P.-H. Lin, S. Grambow, S. Intille, J. Gallis, T. Lazenka, H. Bosworth, C. Voils, G. Bennett, B. Batch, J. Allen, L. Corsino, C. Tyson, and L. Svetkey, ""The association between engagement and weight loss through personal coaching and cell phone interventions in young adults: Randomized controlled trial,"" JMIR mHealth and uHealth, vol. 6, p. e10471, 2018.","The CITY trial tested two 24-month weight loss interventions. One was delivered with a smartphone app (cell phone) containing 24 components. The other was delivered by a coach via monthly calls (personal coaching) The cell phone arm used the apps an average of 5.3 times/day (SD 3.1), whereas the personal coaching participants used them 1.7 times/ day (SD 1.2)",1495
1410,Personal Health Informatics,Stephen Intille,"September 1st, 2017",Microinteraction ecological momentary assessment response rates: Effect of microinteractions or the smartwatch?,https://dl.acm.org/citation.cfm?id=3130957," A. Ponnada, C. Haynes, D. Maniar, J. Manjourides, and S. Intille, ""Microinteraction ecological momentary assessment response rates: Effect of microinteractions or the smartwatch?,"" Proc. of the ACM Journal on Interactive, Mobile, Wearable, and Ubiquitous Technology vol. 1, 2017","Mobile-based ecological-momentary-assessment (EMA) is an in-situ measurement methodology where an electronic device prompts a person to answer questions of research interest. EMA has a key limitation: interruption burden. Microinteraction-EMA(¬µEMA) may reduce burden without sacrificing high temporal density of measurement. In ¬µEMA, all EMA prompts can be answered with ‚Äòat a glance' microinteractions. In a prior 4-week pilot study comparing standard EMA delivered on a phone (phone-EMA) vs. ¬µEMA delivered on a smartwatch (watch-¬µEMA), watch-¬µEMA demonstrated higher response rates and lower perceived burden than phone-EMA, even when the watch-¬µEMA interruption rate was 8 times more than phone-EMA. A new 4-week dataset was gathered on smartwatch-based EMA (i.e., watch-EMA with 6 back-to-back, multiple-choice questions on a watch) to compare whether the high response rates of watch-¬µEMA previously observed were a result of using microinteractions, or due to the novelty and accessibility of the smartwatch. No statistically significant differences in compliance, completion, and first-prompt response rates were observed between phone-EMA and watch-EMA. However, watch-¬µEMA response rates were significantly higher than watch-EMA. This pilot suggests that (1) the high compliance and low burden previously observed in watch-¬µEMA is likely due to the microinteraction question technique, not simply the use of the watch versus the phone, and that (2) compliance with traditional EMA (with long surveys) may not improve simply by moving survey delivery from the phone to a smartwatch.",1496
1411,Personal Health Informatics,Holly Jimison,"July 24th, 2018",Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review,https://dl.acm.org/citation.cfm?id=3173589," Elizabeth Stowell, Mercedes C. Lyson, Herman Saksono, Rene√© C. Wurth, Holly Jimison, Misha Pavel, Andrea G. Parker. 2018. Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Diverse disciplines, including Human-Computer Interaction have explored how mobile health (mHealth) applications can transform healthcare and health promotion. Increasingly, research has explored how mHealth tools can promote healthy behaviors within vulnerable populations-groups that disproportionately experience barriers to wellness. We conducted a systematic review of 83 papers from diverse disciplines to characterize the design and impact of mHealth tools in low-socioeconomic (low-SES) and racial/ethnic minority individuals. Our findings highlight that the diversity within low-SES and racial/ethnic minority groups was not reflected in the populations studied. Most studies focused on improving the health of individuals, often neglecting factors at the community and society levels that influence health disparities. Moreover, few improvements in health outcomes were demonstrated. We further discuss factors that acted as barriers and facilitators of mHealth intervention adoption. Our findings highlight trends that can drive critically needed digital health innovations for vulnerable populations.",1497
1412,Personal Health Informatics,Holly Jimison,"December 1st, 2015",Behavioral Informatics and Computational Modeling in Support of Proactive Health Management and Care,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=7283558," Pavel M, Jimison HB, Korhonen I, Gordon CM, Saranummi N. ""Behavioral Informatics and Computational Modeling in Support of Proactive Health Management and Care."" IEEE Transactions on Biomedical Engineering, Vol. 62, No. 12, December 2015.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1498
1413,Personal Health Informatics,Varun Mishra,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1499
1414,Personal Health Informatics,Varun Mishra,"September 9th, 2024",Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment,https://doi.org/10.1145/3678584," Ha Le, Rithika Lakshminarayanan, Jixin Li, Varun Mishra , Stephen S. Intille. (2024). Collecting Self-reported Physical Activity and Posture Data Using Audio-based Ecological Momentary Assessment Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 111:1-111:35. https://doi.org/10.1145/3678584","ŒºEMA is a data collection method that prompts research participants with quick, answer-at-a-glance, single-multiple-choice self-report behavioral questions, thus enabling high-temporal-density self-report of up to four times per hour when implemented on a smartwatch. However, due to the small watch screen, ŒºEMA is better used to select among 2 to 5 multiple-choice answers versus allowing the collection of open-ended responses. We introduce an alternative and novel form of micro-interaction self-report using speech input - audio-ŒºEMA- where a short beep or vibration cues participants to verbally report their behavioral states, allowing for open-ended, temporally dense self-reports. We conducted a one-hour usability study followed by a within-subject, 6-day to 21-day free-living feasibility study in which participants self-reported their physical activities and postures once every 2 to 5 minutes. We qualitatively explored the usability of the system and identified factors impacting the response rates of this data collection method. Despite being interrupted 12 to 20 times per hour, participants in the free-living study were highly engaged with the system, with an average response rate of 67.7% for audio-ŒºEMA for up to 14 days. We discuss the factors that impacted feasibility; some implementation, methodological, and participant challenges we observed; and important considerations relevant to deploying audio-ŒºEMA in real-time activity recognition systems.",1500
1415,Personal Health Informatics,Varun Mishra,"August 14th, 2024",Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices,https://doi.org/10.48550/arXiv.2408.07784," Jiachen Li, Justin Steinberg, Elizabeth D. Mynatt, Varun Mishra . (2024). Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices CoRR, abs/2408.07784. https://doi.org/10.48550/arXiv.2408.07784","Mental health has become a growing concern among university students. While medication is a common treatment, understanding how university students manage their medication for mental health symptoms in real-world practice has not been fully explored. In this study, we conducted semi-structured interviews with university students to understand the unique challenges in the mental health medication management process and their coping strategies, particularly examining the role of various technologies in this process. We discovered that due to struggles with self-acceptance and the interdependent relationship between medication, symptoms, schedules, and life changes, the medication management process for students was a highly dynamic journey involving frequent dosage changes. Thus, students adopted flexible strategies of using minimal technology to manage their medication in different situations while maintaining a high degree of autonomy. Based on our findings, we propose design implications for future technologies to seamlessly integrate into their daily lives and assist students in managing their mental health medications.",1501
1416,Personal Health Informatics,Varun Mishra,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1502
1417,Personal Health Informatics,Varun Mishra,"March 25th, 2024",Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic,https://doi.org/10.48550/arXiv.2403.17165," Jessilyn Dunn, Varun Mishra , Md. Mobashir Hasan Shandhi, Hayoung Jeong, Natasha Yamane, Yuna Watanabe, Bill Chen, Matthew S. Goodwin. (2024). Building an Open-Source Community to Enhance Autonomic Nervous System Signal Analysis: DBDP-Autonomic CoRR, abs/2403.17165. https://doi.org/10.48550/arXiv.2403.17165","Smartphones and wearable sensors offer an unprecedented ability to collect peripheral psychophysiological signals across diverse timescales, settings, populations, and modalities. However, open-source software development has yet to keep pace with rapid advancements in hardware technology and availability, creating an analytical barrier that limits the scientific usefulness of acquired data. We propose a community-driven, open-source peripheral psychophysiological signal pre-processing and analysis software framework that could advance biobehavioral health by enabling more robust, transparent, and reproducible inferences involving autonomic nervous system data.",1503
1418,Personal Health Informatics,Varun Mishra,"March 11th, 2024",SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild,https://doi.org/10.1109/JIOT.2024.3375299," Kobiljon Toshnazarov, Uichin Lee, Byung Hyung Kim, Varun Mishra , Lismer Andres Caceres Najarro, Youngtae Noh. (2024). SOSW: Stress Sensing With Off-the-Shelf Smartwatches in the Wild IEEE Internet Things J., 11, 21527-21545. https://doi.org/10.1109/JIOT.2024.3375299","We propose SOSW, a comprehensive methodology for robust sensor data processing by considering both physiological and contextual data. SOSW employs a two-layer machine learning (ML) architecture. The results are comparable to those achieved by the state-of-the-art methods that rely on dedicated wearables. The study was published in IEEE Internet of Things Journal ( Volume: 11 , Issue: 12 , 15 June 2024 ) The results indicate that our methodology can successfully detect stressful events with an F-1 score of up to 0.84 in laboratory conditions.",1504
1419,Personal Health Informatics,Varun Mishra,"January 16th, 2024",Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping,https://doi.org/10.1109/ACIIW59127.2023.10388164," Ohida Binte Amin, Varun Mishra , Aarti Sathyanarayana. (2023). Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping ACIIW, 1-4. https://doi.org/10.1109/ACIIW59127.2023.10388164","Depression is a prevalent mental health concern among students. Students with high neuroticism and increased depression exhibit greater variability in the number of social contacts. This may be because these students possess more emotional instability, self-esteem, and negative self-perception. Understanding the dynamic interplay between personality traits, social interactions, and depression can aid in developing targeted interventions to promote mental well-being for students.",1505
1420,Personal Health Informatics,Varun Mishra,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1506
1421,Personal Health Informatics,Varun Mishra,"August 5th, 2023",Detecting Receptivity for mHealth Interventions,https://doi.org/10.1145/3614214.3614221," Varun Mishra , Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, David Kotz. (2023). Detecting Receptivity for mHealth Interventions GetMobile Mob. Comput. Commun., 27, 23-28. https://doi.org/10.1145/3614214.3614221","Just-In-Time Adaptive Interventions (JITAI) have the potential to provide effective support for health behavior by delivering the right type and amount of intervention at the right time. The timing of interventions is crucial to ensure that users are receptive and able to use the support provided. Previous research has explored the association of context and user-specific traits on receptivity and built machine-learning models to detect receptivity after the study was completed. However, for effective intervention delivery, JITAI systems need to make in-the-moment decisions about a user's receptivity. In this study, we deployed machinelearning models in a chatbot-based digital coach to predict receptivity for physical-activity interventions. We included a static model that was built before the study and an adaptive model that continuously updated itself during the study. Compared to a control model that sent intervention messages randomly, the machine-learning models improved receptivity by up to 36%. Receptivity to messages from the adaptive model increased over time.",1507
1422,Personal Health Informatics,Varun Mishra,"November 1st, 2021",FLIRT: A Feature Generation Toolkit for Wearable Data,https://www.sciencedirect.com/science/article/pii/S0169260721005356," F√∂ll, Simon, Martin Maritsch, Federica Spinola, Varun Mishra, Filipe Barata, Tobias Kowatsch, Elgar Fleisch, and Felix Wortmann. ""FLIRT: A Feature Generation Toolkit for Wearable Data."" Computer Methods and Programs in Biomedicine (2021): 106461.","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1508
1423,Personal Health Informatics,Varun Mishra,"September 24th, 2021",6th International Workshop on Mental Health and Well-being: Sensing and Intervention,https://doi.org/10.1145/3460418.3479264," Varun Mishra , Akane Sano, Sahiti Kunchay, Saeed Abdullah, Jakob E. Bardram, Elizabeth L. Murnane, Tanzeem Choudhury, Mirco Musolesi, Giovanna Nunes Vilaza, Rajalakshmi Nandakumar, Tauhidur Rahman. (2021). 6th International Workshop on Mental Health and Well-being: Sensing and Intervention UbiComp/ISWC Adjunct, 185-187. https://doi.org/10.1145/3460418.3479264","Mental health issues affect a significant portion of the world‚Äôs population and can result in debilitating and life-threatening outcomes. To address this increasingly pressing healthcare challenge, there is a need to research novel approaches for early detection and prevention. Toward this, ubiquitous systems can play a central role in revealing and tracking clinically relevant behaviors, contexts, and symptoms. Further, such systems can passively detect relapse onset and enable the opportune delivery of effective intervention strategies. However, despite their clear potential, the uptake of ubiquitous technologies into clinical mental healthcare is slow, and a number of challenges still face the overall efficacy of such technology-based solutions. The goal of this workshop is to bring together researchers interested in identifying, articulating, and addressing such issues and opportunities. Following the success of this workshop for the last five years, we aim to continue facilitating the UbiComp community in developing a holistic approach for sensing and intervention in the context of mental health.",1509
1424,Personal Health Informatics,Varun Mishra,"June 24th, 2021",Detecting Receptivity for mHealth Interventions in the Natural Environment,https://dl.acm.org/doi/10.1145/3463492," Varun Mishra, Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, and David Kotz. 2021. Detecting Receptivity for mHealth Interventions in the Natural Environment. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2, Article 74 (June 2021), 24 pages. DOI: https://doi.org/10.1145/3463492","Just-In-Time Adaptive Intervention (JITAI) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. A crucial aspect of JITAIs is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. Some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. For effective intervention delivery, however, a JITAI system needs to make in-the-moment decisions about a user's receptivity. To this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions. We leveraged prior work regarding receptivity to JITAIs and deployed a chatbot-based digital coach - Ally - that provided physical-activity interventions and motivated participants to achieve their step goals. We extended the original Ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. For comparison, we included a control model that sent intervention messages at random times. The app randomly selected a delivery model for each intervention message. We observed that the machine-learning models led up to a 40% improvement in receptivity as compared to the control model. Further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study.",1510
1425,Personal Health Informatics,Varun Mishra,"March 29th, 2021",When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads,https://dl.acm.org/doi/abs/10.1145/3448116," Kevin Koch, Varun Mishra, Shu Liu, Thomas Berger, Elgar Fleisch, David Kotz, and Felix Wortmann. 2021. When Do Drivers Interact with In-Vehicle Well-being Interventions? An Exploratory Analysis of a Longitudinal Study on Public Roads. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 1, Article 19 (March 2021), 30 pages. DOI:https://doi.org/10.1145/3448116","Recent developments of novel in-vehicle interventions show the potential to transform the otherwise routine and mundane task of commuting into opportunities to improve the drivers' health and well-being. Prior research has explored the effectiveness of various in-vehicle interventions and has identified moments in which drivers could be interruptible to interventions. All the previous studies, however, were conducted in either simulated or constrained real-world driving scenarios on a pre-determined route. In this paper, we take a step forward and evaluate when drivers interact with in-vehicle interventions in unconstrained free-living conditions. To this end, we conducted a two-month longitudinal study with 10 participants, in which each participant was provided with a study car for their daily driving needs. We delivered two in-vehicle interventions - each aimed at improving affective well-being - and simultaneously recorded the participants' driving behavior. In our analysis, we found that several pre-trip characteristics (like trip length, traffic flow, and vehicle occupancy) and the pre-trip affective state of the participants had significant associations with whether the participants started an intervention or canceled a started intervention. Next, we found that several in-the-moment driving characteristics (like current road type, past average speed, and future brake behavior) showed significant associations with drivers' responsiveness to the intervention. Further, we identified several driving behaviors that ""negated"" the effectiveness of interventions and highlight the potential of using such ""negative"" driving characteristics to better inform intervention delivery. Finally, we compared trips with and without intervention and found that both interventions employed in our study did not have a negative effect on driving behavior. Based on our analyses, we provide solid recommendations on how to deliver interventions to maximize responsiveness and effectiveness and minimize the burden on the drivers.",1511
1426,Personal Health Informatics,Varun Mishra,"December 17th, 2020",Evaluating the Reproducibility of Physiological Stress Detection Models,https://dl.acm.org/doi/abs/10.1145/3432220," Varun Mishra, Sougata Sen, Grace Chen, Tian Hao, Jeffrey Rogers, Ching-Hua Chen, and David Kotz. 2020. Evaluating the Reproducibility of Physiological Stress Detection Models. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 4, Article 147 (December 2020), 29 pages. DOI:https://doi.org/10.1145/3432220","Recent advances in wearable sensor technologies have led to a variety of approaches for detecting physiological stress. Even with over a decade of research in the domain, there still exist many significant challenges, including a near-total lack of reproducibility across studies. Researchers often use some physiological sensors (custom-made or off-the-shelf), conduct a study to collect data, and build machine-learning models to detect stress. There is little effort to test the applicability of the model with similar physiological data collected from different devices, or the efficacy of the model on data collected from different studies, populations, or demographics. This paper takes the first step towards testing reproducibility and validity of methods and machine-learning models for stress detection. To this end, we analyzed data from 90 participants, from four independent controlled studies, using two different types of sensors, with different study protocols and research goals. We started by evaluating the performance of models built using data from one study and tested on data from other studies. Next, we evaluated new methods to improve the performance of stress-detection models and found that our methods led to a consistent increase in performance across all studies, irrespective of the device type, sensor type, or the type of stressor. Finally, we developed and evaluated a clustering approach to determine the stressed/not-stressed classification when applying models on data from different studies, and found that our approach performed better than selecting a threshold based on training data. This paper's thorough exploration of reproducibility in a controlled environment provides a critical foundation for deeper study of such methods, and is a prerequisite for tackling reproducibility in free-living conditions.",1512
1427,Personal Health Informatics,Elizabeth Mynatt,"January 12th, 2025",A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place,https://doi.org/10.1145/3688828.3699640," Niharika Mathur, Tamara Zubatiy, Elizabeth D. Mynatt. (2025). A Research Through Design Study on AI Explanations for Collaborative Everyday Tasks for Older Adults Aging in Place GROUP Companion, 48-53. https://doi.org/10.1145/3688828.3699640","Designing explainable and personalized AI systems to provide support to older adults aging in place requires an understanding of their motivations and expectations for the explanations. This poster presents our ongoing work in exploring explanation preferences within AI systems for older adults aging in place with their carepartners. We do so by leveraging the speculative and iterative benefits of the Research through Design (RtD) approach in HCI, and explore variations in explanation requirements for different users by understanding their needs, goals and motivations for the different sources of information within the home. We illustrate an example for employing a Research through Design inquiry for the design of AI applications, adopting speculative methods to probe into future possibilities of Explainable AI (XAI) using a human-centered design framework. Through a Speed Dating study and a Co-Design activity, we investigate different explanation types and scenarios and argue for a shift in the algorithmic focus of Explainable AI research toward user-centered requirements, positioning explanation as a collaborative process between AI systems and users.",1513
1428,Personal Health Informatics,Elizabeth Mynatt,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1514
1429,Personal Health Informatics,Elizabeth Mynatt,"August 14th, 2024",Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices,https://doi.org/10.48550/arXiv.2408.07784," Jiachen Li, Justin Steinberg, Elizabeth D. Mynatt, Varun Mishra . (2024). Navigating the Paradox: Challenges and Strategies of University Students Managing Mental Health Medication in Real-World Practices CoRR, abs/2408.07784. https://doi.org/10.48550/arXiv.2408.07784","Mental health has become a growing concern among university students. While medication is a common treatment, understanding how university students manage their medication for mental health symptoms in real-world practice has not been fully explored. In this study, we conducted semi-structured interviews with university students to understand the unique challenges in the mental health medication management process and their coping strategies, particularly examining the role of various technologies in this process. We discovered that due to struggles with self-acceptance and the interdependent relationship between medication, symptoms, schedules, and life changes, the medication management process for students was a highly dynamic journey involving frequent dosage changes. Thus, students adopted flexible strategies of using minimal technology to manage their medication in different situations while maintaining a high degree of autonomy. Based on our findings, we propose design implications for future technologies to seamlessly integrate into their daily lives and assist students in managing their mental health medications.",1515
1430,Personal Health Informatics,Elizabeth Mynatt,"July 7th, 2024",Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place,https://doi.org/10.48550/arXiv.2406.05111," Niharika Mathur, Tamara Zubatiy, Elizabeth D. Mynatt. (2024). Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place CoRR, abs/2406.05111. https://doi.org/10.48550/arXiv.2406.05111","As the permeability of AI systems in interpersonal domains like the home expands, their technical capabilities of generating explanations are required to be aligned with user expectations for transparency and reasoning. This paper presents insights from our ongoing work in understanding the effectiveness of explanations in Conversational AI systems for older adults aging in place and their family caregivers. We argue that in collaborative and multi-user environments like the home, AI systems will make recommendations based on a host of information sources to generate explanations. These sources may be more or less salient based on user mental models of the system and the specific task. We highlight the need for cross technological collaboration between AI systems and other available sources of information in the home to generate multiple explanations for a single user query. Through example scenarios in a caregiving home setting, this paper provides an initial framework for categorizing these sources and informing a potential design space for AI explanations surrounding everyday tasks in the home.",1516
1431,Personal Health Informatics,Elizabeth Mynatt,"February 23rd, 2024",AI-CARING: National AI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups,https://doi.org/10.1002/aaai.12162," Sonia Chernova, Elizabeth D. Mynatt, Agata Rozga, Reid G. Simmons, Holly A. Yanco. (2024). AI-CARING: National AI Institute for Collaborative Assistance and Responsive Interaction for Networked Groups AI Mag., 45, 124-130. https://doi.org/10.1002/aaai.12162","Abstract Over 13 million Americans aged 65 and older are currently living with a diagnosis of mild cognitive impairment (MCI), a common precursor to dementia. These individuals largely rely on a network of informal caregivers‚Äîfamily, friends, and community members‚Äîwho work together with professional healthcare and social service providers to provide care and support in home settings. The AI-CARING Institute contributes foundational AI research focused on developing personalized collaborative AI systems that improve the quality of life and independence of aging adults living at¬†home. Abstract Over 13 million Americans aged 65 and older are currently living with a diagnosis of mild cognitive impairment (MCI), a common precursor to dementia. These individuals largely rely on a network of informal caregivers‚Äîfamily, friends, and community members‚Äîwho work together with professional healthcare and social service providers to provide care and support in home settings. The AI-CARING Institute contributes foundational AI research focused on developing personalized collaborative AI systems that improve the quality of life and independence of aging adults living at¬†home.",1517
1432,Personal Health Informatics,Elizabeth Mynatt,"November 25th, 2023",A Distributed Cognition Approach to Understanding Compensatory Calendaring Cognitive Systems of Older Adults with Mild Cognitive Impairment and Their Care Partners,https://doi.org/10.1007/978-3-031-48306-6_19," Tamara Zubatiy, Kayci L. Vickers, Jessica L. Saurman, Felicia Goldstein, Amy D. Rodriguez, Niharika Mathur, Elizabeth D. Mynatt. (2023). A Distributed Cognition Approach to Understanding Compensatory Calendaring Cognitive Systems of Older Adults with Mild Cognitive Impairment and Their Care Partners UCAmI (1), 190-201. https://doi.org/10.1007/978-3-031-48306-6_19","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1518
1433,Personal Health Informatics,Elizabeth Mynatt,"November 25th, 2023",‚ÄúWhy Did You Say That?‚Äù: Understanding Explainability in Conversational AI Systems for Older Adults with Mild Cognitive Impairment (MCI),https://doi.org/10.1007/978-3-031-48306-6_21," Niharika Mathur, Tamara Zubatiy, Agata Rozga, Elizabeth D. Mynatt. (2023). ""Why Did You Say That?"": Understanding Explainability in Conversational AI Systems for Older Adults with Mild Cognitive Impairment (MCI) UCAmI (1), 208-214. https://doi.org/10.1007/978-3-031-48306-6_21","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1519
1434,Personal Health Informatics,Elizabeth Mynatt,"October 9th, 2023","‚ÄúMango Mango, How to Let The Lettuce Dry Without A Spinner?‚Äù: Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner",https://doi.org/10.48550/arXiv.2310.05853," Szeyi Chan, Jiachen Li, Bingsheng Yao, Amama Mahmood, Chien-Ming Huang , Holly Jimison, Elizabeth D. Mynatt, Dakuo Wang. (2023). ""Mango Mango, How to Let The Lettuce Dry Without A Spinner?"": Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner CoRR, abs/2310.05853. https://doi.org/10.48550/arXiv.2310.05853","The rapid advancement of the Large Language Model (LLM) has created numerous potentials for integration with conversational assistants (CAs) assisting people in their daily tasks, particularly due to their extensive flexibility. However, users' real-world experiences interacting with these assistants remain unexplored. In this research, we chose cooking, a complex daily task, as a scenario to investigate people's successful and unsatisfactory experiences while receiving assistance from an LLM-based CA, Mango Mango. We discovered that participants value the system's ability to provide extensive information beyond the recipe, offer customized instructions based on context, and assist them in dynamically planning the task. However, they expect the system to be more adaptive to oral conversation and provide more suggestive responses to keep users actively involved. Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development.",1520
1435,Personal Health Informatics,Elizabeth Mynatt,"October 4th, 2023",‚ÄúI don‚Äôt know how to help with that‚Äù ‚Äì Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks,https://doi.org/10.1145/3610170," Tamara Zubatiy, Niharika Mathur, Larry Heck, Kayci L. Vickers, Agata Rozga, Elizabeth D. Mynatt. (2023). ""I don't know how to help with that"" - Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks Proc. ACM Hum. Comput. Interact., 7, 1-28. https://doi.org/10.1145/3610170","While commercial conversational agents (CA) (i.e. Google assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization and overall dialogue management that are amplified in care coordination settings. In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10 week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.",1521
1436,Personal Health Informatics,Elizabeth Mynatt,"October 4th, 2023",Privacy vs. Awareness: Relieving the Tension between Older Adults and Adult Children When Sharing In-home Activity Data,https://doi.org/10.1145/3610202," Jiachen Li, Bingrui Zong, Tingyu Cheng, Yunzhi Li, Elizabeth D. Mynatt, Ashutosh Dhekne. (2023). Privacy vs. Awareness: Relieving the Tension between Older Adults and Adult Children When Sharing In-home Activity Data Proc. ACM Hum. Comput. Interact., 7, 1-30. https://doi.org/10.1145/3610202","While aging adults frequently prefer to ""age in place"", their children can worry about their well-being, especially when they live at a distance. Many in-home systems are designed to monitor the real-time status of seniors at home and provide information to their adult children. However, we observed that the needs and concerns of both sides in the information sharing process are often not aligned. In this research, we examined the design of a system that mitigates the privacy needs of aging adults in light of the information desires of adult children. We apply an iterative process to design and evaluate a visualization of indoor location data and compare its benefits to displaying raw video from cameras. We elaborate on the tradeoffs surrounding privacy and awareness made by older adults and their children, and synthesize design criteria for designing a visualization system to manage these tensions and tradeoffs.",1522
1437,Personal Health Informatics,Elizabeth Mynatt,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1523
1438,Personal Health Informatics,Elizabeth Mynatt,"October 22nd, 2022",A Collaborative Approach to Support Medication Management in Older Adults with Mild Cognitive Impairment Using Conversational Assistants (CAs),https://doi.org/10.1145/3517428.3544830," Niharika Mathur, Kunal Dhodapkar, Tamara Zubatiy, Jiachen Li, Brian Jones, Elizabeth D. Mynatt. (2022). A Collaborative Approach to Support Medication Management in Older Adults with Mild Cognitive Impairment Using Conversational Assistants (CAs) ASSETS, 42:1-42:14. https://doi.org/10.1145/3517428.3544830","Improving medication management for older adults with Mild Cognitive Impairment (MCI) requires designing systems that support functional independence and provide compensatory strategies as their abilities change. Traditional medication management interventions emphasize forming new habits alongside the traditional path of learning to use new technologies. In this study, we navigate designing for older adults with gradual cognitive decline by creating a conversational ‚Äúcheck-in‚Äù system for routine medication management. We present the design of MATCHA - Medication Action To Check-In for Health Application, informed by exploratory focus groups and design sessions conducted with older adults with MCI and their caregivers, alongside our evaluation based on a two-phased deployment period of 20 weeks. Our results indicate that a conversational ‚Äúcheck-in‚Äù medication management assistant increased system acceptance while also potentially decreasing the likelihood of accidental over-medication, a common concern for older adults dealing with MCI.",1524
1439,Personal Health Informatics,Elizabeth Mynatt,"April 29th, 2022",Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education,https://doi.org/10.1145/3491102.3501824," Georgianna E. Lin, Elizabeth D. Mynatt, Neha Kumar. (2022). Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education CHI, 437:1-437:15. https://doi.org/10.1145/3491102.3501824","Human-Computer Interaction (HCI) research on menstrual tracking has emphasized the need for more inclusive design of mechanisms for tracking and sharing information on menstruation. We investigate menstrual tracking and data-sharing attitudes and practices in educated, young (20-30 years old) menstruating individuals based in the United States, with self-identified minimal menstrual education backgrounds. Using interviews (N=18), a survey (N=62), and participatory design (N=7), we find that existing mechanisms for tracking and sharing data on menstruation are not adequately responsive to the needs of those who seek relevant menstrual education, are not in the sexual majority, and/or wish to customize what menstrual data they share and with whom. Our analysis highlights a design gap for participants with minimal sexual education backgrounds who wish to better understand their cycles. We also contribute a deepened understanding of structural health inequities that impact menstrual tracking and sharing practices, making recommendations for technology-mediated menstrual care.",1525
1440,Personal Health Informatics,Elizabeth Mynatt,"January 14th, 2022",Pivoting an MCI Empowerment Program to Online Engagement,https://doi.org/10.1145/3492851," Elizabeth D. Mynatt, Kayci L. Vickers, Salimah LaForce, Sarah Farmer, Jeremy M. Johnson, Matthew Doiron, Aparna Ramesh, W. Bradley Fain, Tamara Zubatiy, Amy D. Rodriguez. (2022). Pivoting an MCI Empowerment Program to Online Engagement Proc. ACM Hum. Comput. Interact., 6, 32:1-32:26. https://doi.org/10.1145/3492851","In the Spring of 2020, closures and safe distancing orders swept much of the United States due to the COVID-19 pandemic. This paper presents a case study of pivoting an in-person empowerment program focused on lifestyle interventions for people newly diagnosed with Mild Cognitive Impairment (MCI) to an online program. Working as rapidly as possible to sustain participant engagement, our design decisions and subsequent iterations point to initial constraints in telehealth capabilities, as well as learning on the fly as new capabilities and requirements emerged. We present the discovery of emergent practices by family members and healthcare providers to meet the new requirements for successful online engagement. For some participants, the online program led to greater opportunities for empowerment while others were hampered by the lack of in-person program support. Providers experienced a sharp learning curve and likewise missed the benefits of in-person interaction, but also discovered new benefits of online collaboration. This work lends insights and potential new avenues for understanding how lifestyle interventions can empower people with MCI and the role of technology in that process.",1526
1441,Personal Health Informatics,Elizabeth Mynatt,"January 14th, 2022",Cultivating the Community: Inferring Influence within Eating Disorder Networks on Twitter,https://doi.org/10.1145/3492826," Fayika Farhat Nova, Amanda Coupe, Elizabeth D. Mynatt, Shion Guha, Jessica Pater. (2022). Cultivating the Community: Inferring Influence within Eating Disorder Networks on Twitter Proc. ACM Hum. Comput. Interact., 6, 7:1-7:33. https://doi.org/10.1145/3492826","A growing body of HCI research has sought to understand how online networks are utilized in the adoption and maintenance of disordered activities and behaviors associated with mental illness, including eating habits. However, individual-level influences over discrete online eating disorder (ED) communities are not yet well understood. This study reports results from a comprehensive network and content analysis (combining computational topic modeling and qualitative thematic analysis) of over 32,000 public tweets collected using popular ED-related hashtags during May 2020. Our findings indicate that this ED network in Twitter consists of multiple smaller ED communities where a majority of the nodes are exposed to unhealthy ED contents through retweeting certain influential central nodes. The emergence of novel linguistic indicators and trends (e.g., ""#meanspo"") also demonstrates the evolving nature of the ED network. This paper contextualizes ED influence in online communities through node-level participation and engagement, as well as relates emerging ED contents with established online behaviors, such as self-harassment.",1527
1442,Personal Health Informatics,Misha Pavel,"November 5th, 2024",A Unified Dynamic Model for the Decomposition of Skin Conductance and the Inference of Sudomotor Nerve Activities,https://doi.org/10.1109/TBME.2024.3492112," Hui S. Wang, Stacy Marsella, Misha Pavel. (2025). A Unified Dynamic Model for the Decomposition of Skin Conductance and the Inference of Sudomotor Nerve Activities IEEE Trans. Biomed. Eng., 72, 1178-1187. https://doi.org/10.1109/TBME.2024.3492112"," Electrodermal activity (EDA), commonly measured as skin conductance (SC), is a widely used physiological signal in psychological research and behavioral health applications. EDA is considered an indicator of arousal, a key aspect of emotion and stress. This work lays the foundation for numerous behavioral health. applications and paves the road for designing physiology-based interventions aimed at regulating arousal. The study was published in: IEEE Transactions on Biomedical Engineering ( Volume: 72 , Issue: 3 , March 2025 )",1528
1443,Personal Health Informatics,Misha Pavel,"July 24th, 2018",Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review,https://dl.acm.org/citation.cfm?id=3173589," Elizabeth Stowell, Mercedes C. Lyson, Herman Saksono, Rene√© C. Wurth, Holly Jimison, Misha Pavel, Andrea G. Parker. 2018. Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Diverse disciplines, including Human-Computer Interaction have explored how mobile health (mHealth) applications can transform healthcare and health promotion. Increasingly, research has explored how mHealth tools can promote healthy behaviors within vulnerable populations-groups that disproportionately experience barriers to wellness. We conducted a systematic review of 83 papers from diverse disciplines to characterize the design and impact of mHealth tools in low-socioeconomic (low-SES) and racial/ethnic minority individuals. Our findings highlight that the diversity within low-SES and racial/ethnic minority groups was not reflected in the populations studied. Most studies focused on improving the health of individuals, often neglecting factors at the community and society levels that influence health disparities. Moreover, few improvements in health outcomes were demonstrated. We further discuss factors that acted as barriers and facilitators of mHealth intervention adoption. Our findings highlight trends that can drive critically needed digital health innovations for vulnerable populations.",1529
1444,Personal Health Informatics,Misha Pavel,"December 1st, 2015",Behavioral Informatics and Computational Modeling in Support of Proactive Health Management and Care,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=7283558," Pavel M, Jimison HB, Korhonen I, Gordon CM, Saranummi N. ""Behavioral Informatics and Computational Modeling in Support of Proactive Health Management and Care."" IEEE Transactions on Biomedical Engineering, Vol. 62, No. 12, December 2015.","About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A public charity, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. ¬© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1530
1445,Personal Health Informatics,Herman Saksono,"August 30th, 2024",Socio-Cognitive Framework for Personal Informatics: A Preliminary Framework for Socially-Enabled Health Technologies,https://doi.org/10.1145/3674504," Herman Saksono, Andrea G. Parker. (2024). Socio-Cognitive Framework for Personal Informatics: A Preliminary Framework for Socially-Enabled Health Technologies ACM Trans. Comput. Hum. Interact., 31, 42:1-42:41. https://doi.org/10.1145/3674504","Personal health informatics systems have been centered around individual efforts, overlooking the role of social factors in health. Over seven years of research ( n = 153), we examined how socially-enabled personal informatics systems can support physical activity‚Äîa behavior critical in promoting physical and mental health. We prioritized exploring this topic with families in low-socioeconomic status (SES) neighborhoods because they face increased barriers to being active due to inequities. Through our systems development, qualitative studies, and theoretical foundation, we developed the Socio-Cognitive Framework for Personal Health Informatics systems that shows how five socio-cognitive concepts (aspirations, data exposure, stories, belongingness, and impediments) influence self-efficacy and outcome expectations that are linked to health behavior. We then provide recommendations on how to design and evaluate such systems. We further argue that socially-enabled health informatics tools can support marginalized communities in reducing health disparities through the collective efforts of families, neighbors, and peers.",1531
1446,Personal Health Informatics,Herman Saksono,"May 1st, 2021",StoryMap: Using Social Modeling and Self-Modeling to Support Physical Activity Among Families of Low-SES Backgrounds,https://dl.acm.org/doi/10.1145/3411764.3445087," Herman Saksono, Carmen Castaneda-Sceppa, Jessica A. Hoffman, Magy Seif El-Nasr, and Andrea Parker. 2021. StoryMap: Using Social Modeling and Self-Modeling to Support Physical Activity Among Families of Low-SES Backgrounds. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 203, 1‚Äì14. https://doi.org/10.1145/3411764.3445087","Physical activity (PA) is crucial for reducing the risk of obesity, an epidemic that disproportionately burdens families of low-socioeconomic status (SES). While fitness tracking tools can increase PA awareness, more work is needed to examine (1) how such tools can help people benefit from their social environment, and (2) how reflections can help enhance PA attitudes. We investigated how fitness tracking tools for families can support social modeling and self-modeling (through reflection), two critical processes in Social Cognitive Theory. We developed StoryMap, a novel fitness tracking app for families aimed at supporting both modes of modeling. Then, we conducted a five-week qualitative study evaluating StoryMap with 16 low-SES families. Our findings contribute an understanding of how social and self-modeling can be implemented in fitness tracking tools and how both modes of modeling can enhance key PA attitudes: self-efficacy and outcome expectations. Finally, we propose design recommendations for social personal informatics tools.",1532
1447,Personal Health Informatics,Herman Saksono,"October 15th, 2020",Go&Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia,https://doi.org/10.1145/3415222," Xin Yao Lin, Herman Saksono, Elizabeth Stowell, Margie E. Lachman, Carmen Castaneda-Sceppa, Andrea G. Parker. (2020). Go&Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia Proc. ACM Hum. Comput. Interact., 4, 151:1-151:28. https://doi.org/10.1145/3415222","Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.",1533
1448,Personal Health Informatics,Herman Saksono,"April 1st, 2020",Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection,https://dl.acm.org/doi/abs/10.1145/3313831.3376686," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Vivien Morris, Magy Seif El-Nasr, and Andrea G. Parker. 2020. Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). Association for Computing Machinery, New York, NY, USA, 1‚Äì13. https://doi.org/10.1145/3313831.3376686","Physical activity (PA) is critical for reducing the risk of obesity, a prevalent health concern that burdens low-socioeconomic status (SES) households. While self-tracking apps can increase PA, encouraging app engagement remains a challenge, thus limiting the app's efficacy. To understand how to better support caregiver's motivation to use family health apps, we designed and evaluated Storywell?a mobile app for promoting family PA. Guided by Self-Determination Theory, Storywell provides social rewards (e.g., storybooks with interactive reflective questions) aimed at supporting relatedness and motivation. Our 3-month qualitative study with 18 families revealed satisfying moments that can affect caregiver's motivation. We contribute new knowledge on designing satisfying moments that heighten the motivation to use health apps, especially for low-SES families who face many barriers to using such systems.",1534
1449,Personal Health Informatics,Herman Saksono,"August 5th, 2019",Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods,https://doi.org/10.1145/3290605.3300543," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Magy Seif El-Nasr, Vivien Morris, and Andrea G. Parker. 2019. Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19). ACM, New York, NY, USA, Paper 313, 14 pages. DOI","Wearable activity trackers can encourage physical activity (PA)-a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active-wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data.",1535
1450,Personal Health Informatics,Herman Saksono,"July 24th, 2018",Family Health Promotion in Low-SES Neighborhoods: A Two-Month Study of Wearable Activity Tracking,https://dl.acm.org/citation.cfm?id=3173883," Herman Saksono, Carmen Castaneda-Sceppa, Jessica Hoffman, Magy Seif El-Nasr, Vivien Morris, Andrea G. Parker. 2018. Family Health Promotion in Low-SES Neighborhoods: A Two-Month Study of Wearable Activity Tracking. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Low-socioeconomic status (SES) families face increased barriers to physical activity (PA)-a behavior critical for reducing and preventing chronic disease. Research has explored how wearable PA trackers can encourage increased activity, and how the adoption of such trackers is driven by people's emotions and social needs. However, more work is needed to understand how PA trackers are perceived and adopted by low-SES families, where PA may be deprioritized due to economic stresses, limited resources, and perceived crime. Accordingly, we conducted a two-month, in-depth qualitative study, exploring low-SES caregivers' perspectives on PA tracking and promotion. Our findings show how PA tracking was impacted by caregivers' attitudes toward safety, which were influenced by how they perceived social connections within their neighborhoods; and cognitive-emotional processes. We conclude that PA tracking tools for low-SES families should help caregivers and children to experience and celebrate progress.",1536
1451,Personal Health Informatics,Herman Saksono,"July 24th, 2018",Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review,https://dl.acm.org/citation.cfm?id=3173589," Elizabeth Stowell, Mercedes C. Lyson, Herman Saksono, Rene√© C. Wurth, Holly Jimison, Misha Pavel, Andrea G. Parker. 2018. Designing and Evaluating mHealth Interventions for Vulnerable Populations: A Systematic Review. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô18). ACM.","Diverse disciplines, including Human-Computer Interaction have explored how mobile health (mHealth) applications can transform healthcare and health promotion. Increasingly, research has explored how mHealth tools can promote healthy behaviors within vulnerable populations-groups that disproportionately experience barriers to wellness. We conducted a systematic review of 83 papers from diverse disciplines to characterize the design and impact of mHealth tools in low-socioeconomic (low-SES) and racial/ethnic minority individuals. Our findings highlight that the diversity within low-SES and racial/ethnic minority groups was not reflected in the populations studied. Most studies focused on improving the health of individuals, often neglecting factors at the community and society levels that influence health disparities. Moreover, few improvements in health outcomes were demonstrated. We further discuss factors that acted as barriers and facilitators of mHealth intervention adoption. Our findings highlight trends that can drive critically needed digital health innovations for vulnerable populations.",1537
1452,Personal Health Informatics,Herman Saksono,"May 6th, 2017",Reflective Informatics Through Family Storytelling: Self-discovering Physical Activity Predictors,http://doi.org/10.1145/3025453.3025651," Herman Saksono and Andrea Grimes Parker. 2017. Reflective Informatics Through Family Storytelling: Self-discovering Physical Activity Predictors. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ‚Äô17, ACM.","HCI research has increasingly examined how sensing technologies can help people capture and visualize data about their health-related behaviors. Yet, few systems help people reflect more fundamentally on the factors that influence behaviors such as physical activity (PA). To address this research gap, we take a novel approach, examining how such reflections can be stimulated through a medium that generations of families have used for reflection and teaching: storytelling. Through observations and interviews, we studied how 13 families interacted with a low-fidelity prototype, and their attitudes towards this tool. Our prototype used storytelling and interactive prompts to scaffold reflection on factors that impact children's PA. We contribute to HCI research by characterizing how families interacted with a story-driven reflection tool, and how such a tool can encourage critical processes for behavior change. Informed by the Transtheoretical Model, we present design implications for reflective informatics systems.",1538
1453,Personal Health Informatics,Herman Saksono,"May 7th, 2016",Youth Advocacy in SNAs: Challenges for Addressing Health Disparities,https://dl.acm.org/citation.cfm?id=2858492," Farnaz Irannejad Bisafar, Herman Saksono, Priscilla Baquerizo, Dana Moore, and Andrea G Parker. 2016. Youth Advocacy in SNAs: Challenges for Addressing Health Disparities. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ‚Äô16: 3620‚Äì3624.","Social networking applications (SNAs) have been touted as promising platforms for activism: they provide a platform by which voices can be heard and collective action mobilized. Yet, little work has studied the suitability of existing SNAs for enabling youth advocacy efforts. We conducted an intensive 5-week qualitative study with 10th graders to understand how existing SNAs support and inhibit youth advocacy. We contribute to the field of Human-Computer Interaction (HCI) by explicating several themes regarding the barriers youth face when using SNAs for advocacy, features in existing SNAs that are not suitable for youth advocacy, and the peer pressure youth perceive when advocating for serious issues in these environments. We conclude with recommendations for how existing SNA features could be reformed to better support youth advocacy.",1539
1454,Personal Health Informatics,Herman Saksono,"February 28th, 2015",Spaceship Launch: Designing a Collaborative Exergame for Families,http://dl.acm.org/citation.cfm?id=2675159&dl=ACM&coll=DL," Saksono, H., Ranade, A., Kamarthi, G., Castaneda-Sceppa, C., Hoffman, J.A., Wirth, C. and Parker, A.G., ""Spaceship Launch: Designing a Collaborative Exergame for Families,"" Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing (2015), 1776-1787.","Parents play a critical role in facilitating children's physical activity, as they are an important source of modeling and support. While Human-Computer Interaction (HCI) researchers have explored exergame design for children or adults separately, an important open area of work is identifying design guidelines for family exergames. One question that researchers have increasingly posed is, how can exergames be designed to avoid potential negative consequences of competition? To address these questions we designed Spaceship Launch, an exergame for parents and kids in lower income neighborhoods, where obesity is most prevalent. We describe our iterative design process: the formative study to identify design opportunities, our resulting system, and our field evaluation of the tool. Our findings highlight the impact of SL on physical activity intentions, and how parental preferences for in-game competition were aligned with the psychological needs of relatedness and competence. We conclude with design recommendations for future family-focused exergames.",1540
1455,Personal Health Informatics,Aarti Sathyanarayana,"November 12th, 2024",Sleep Staging from Airflow Signals Using Fourier Approximations of Persistence Curves,https://doi.org/10.48550/arXiv.2411.07964," Shashank Manjunath, Hau-Tieng Wu, Aarti Sathyanarayana. (2024). Sleep Staging from Airflow Signals Using Fourier Approximations of Persistence Curves CoRR, abs/2411.07964. https://doi.org/10.48550/arXiv.2411.07964","Sleep staging is a challenging task, typically manually performed by sleep technologists based on electroencephalogram and other biosignals of patients taken during overnight sleep studies. Recent work aims to leverage automated algorithms to perform sleep staging not based on electroencephalogram signals, but rather based on the airflow signals of subjects. Prior work uses ideas from topological data analysis (TDA), specifically Hermite function expansions of persistence curves (HEPC) to featurize airflow signals. However, finite order HEPC captures only partial information. In this work, we propose Fourier approximations of persistence curves (FAPC), and use this technique to perform sleep staging based on airflow signals. We analyze performance using an XGBoost model on 1155 pediatric sleep studies taken from the Nationwide Children's Hospital Sleep DataBank (NCHSDB), and find that FAPC methods provide complimentary information to HEPC methods alone, leading to a 4.9% increase in performance over baseline methods.",1541
1456,Personal Health Informatics,Aarti Sathyanarayana,"May 8th, 2024",Detection of Sleep Oxygen Desaturations from Electroencephalogram Signals,https://doi.org/10.48550/arXiv.2405.09566," Shashank Manjunath, Aarti Sathyanarayana. (2024). Detection of Sleep Oxygen Desaturations from Electroencephalogram Signals CoRR, abs/2405.09566. https://doi.org/10.48550/arXiv.2405.09566","In this work, we leverage machine learning techniques to identify potential biomarkers of oxygen desaturation during sleep exclusively from electroencephalogram (EEG) signals in pediatric patients with sleep apnea. Development of a machine learning technique which can successfully identify EEG signals from patients with sleep apnea as well as identify latent EEG signals which come from subjects who experience oxygen desaturations but do not themselves occur during oxygen desaturation events would provide a strong step towards developing a brain-based biomarker for sleep apnea in order to aid with easier diagnosis of this disease. We leverage a large corpus of data, and show that machine learning enables us to classify EEG signals as occurring during oxygen desaturations or not occurring during oxygen desaturations with an average 66.8% balanced accuracy. We furthermore investigate the ability of machine learning models to identify subjects who experience oxygen desaturations from EEG data that does not occur during oxygen desaturations. We conclude that there is a potential biomarker for oxygen desaturation in EEG data.",1542
1457,Personal Health Informatics,Aarti Sathyanarayana,"January 16th, 2024",Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping,https://doi.org/10.1109/ACIIW59127.2023.10388164," Ohida Binte Amin, Varun Mishra , Aarti Sathyanarayana. (2023). Investigating Social Interaction Patterns with Depression Severity across Different Personality Traits Using Digital Phenotyping ACIIW, 1-4. https://doi.org/10.1109/ACIIW59127.2023.10388164","Depression is a prevalent mental health concern among students. Students with high neuroticism and increased depression exhibit greater variability in the number of social contacts. This may be because these students possess more emotional instability, self-esteem, and negative self-perception. Understanding the dynamic interplay between personality traits, social interactions, and depression can aid in developing targeted interventions to promote mental well-being for students.",1543
1458,Personal Health Informatics,Aarti Sathyanarayana,"January 15th, 2024",Modeling Messaging Metadata to Identify Digital Disagreements among Non-incarcerated Adolescents in the Juvenile Justice System,https://doi.org/10.1109/ACII59096.2023.10388170," Harshit Pandey, Christie Rizzo, Charlene Collibee, Aarti Sathyanarayana. (2023). Modeling Messaging Metadata to Identify Digital Disagreements among Non-incarcerated Adolescents in the Juvenile Justice System ACII, 1-8. https://doi.org/10.1109/ACII59096.2023.10388170","The psychological wellbeing of adolescents, including their relationships with their parents and friends, is highly affected by romantic relationship conflict. At-risk youth - who are involved with the juvenile justice system and are especially vulnerable to aggression, defiance, and behavioral problems - experience relationship conflict at rates that exceed those of youth in the community. This study investigates the potential of utilizing text messaging metadata from conversations with parental figures, friends, and other social connections for scalable early identification of moments of disagreement in romantic relationships in non-incarcerated, justice-involved youth. When comparing our predicted disagreement times to the current standard of intervention delivery, at random, we found statistically significant improvements in predicting disagreements with romantic partners.",1544
1459,Personal Health Informatics,Aarti Sathyanarayana,"April 28th, 2023",Topological Data Analysis of Electroencephalogram Signals for Pediatric Obstructive Sleep Apnea,https://doi.org/10.48550/arXiv.2304.14853," Shashank Manjunath, Jose A. Perea, Aarti Sathyanarayana. (2023). Topological Data Analysis of Electroencephalogram Signals for Pediatric Obstructive Sleep Apnea CoRR, abs/2304.14853. https://doi.org/10.48550/arXiv.2304.14853","Topological data analysis (TDA) is an emerging technique for biological signal processing. TDA leverages the invariant topological features of signals in a metric space for robust analysis of signals even in the presence of noise. In this paper, we leverage TDA on brain connectivity networks derived from electroencephalogram (EEG) signals to identify statistical differences between pediatric patients with obstructive sleep apnea (OSA) and pediatric patients without OSA. We leverage a large corpus of data, and show that TDA enables us to see a statistical difference between the brain dynamics of the two groups.",1545
1460,Personal Health Informatics,Aarti Sathyanarayana,"June 6th, 2021",Measuring the Effects of Sleep on Epileptogenicity with Multiscale Entropy,https://doi.org/10.1016/j.clinph.2021.06.001," Sathyanarayana, Aarti, Rima El Atrache, Michele Jackson, Kenneth Mandl, Tobias Loddenkemper, William Bosl. ‚ÄúMeasuring the Effects of Sleep on Epileptogenicity with Multiscale Entropy.‚Äù Clinical Neurophysiology 132.9 (2021). doi:10.1016/j.clinph.2021.06.001","Please contact our support team for more information and provide the details below. Cookies are used by this site. Cookie Settings All content on this site: Copyright ¬© 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.",1546
1461,Personal Health Informatics,Aarti Sathyanarayana,"May 21st, 2020",Nonlinear Analysis of Visually Normal EEGs to Differentiate Benign Childhood Epilepsy with Centrotemporal Spikes,https://doi.org/10.1038/s41598-020-65112-y," Sathyanarayana, Aarti, Rima El Atrache, Michele Jackson, Aliza Alter, Kenneth Mandl, Tobias Loddenkemper, William Bosl. ‚ÄúNonlinear Analysis of Visually Normal EEGs to Differentiate Benign Childhood Epilepsy with Centrotemporal Spikes.‚Äù Scientific Reports (2020). doi:10.1038/s41598-020-65112-y","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1547
1462,Personal Health Informatics,Aarti Sathyanarayana,"June 7th, 2019",Benchmark on a large cohort for sleep-wake classification with machine learning techniques,https://doi.org/10.1038/s41746-019-0126-9," Jo√£o R. M. Palotti, Raghvendra Mall, Micha√´l Aupetit , Michael Rueschman, Meghna Singh, Aarti Sathyanarayana, Shahrad Taheri, Luis Fern√°ndez-Luque. (2019). Benchmark on a large cohort for sleep-wake classification with machine learning techniques npj Digit. Medicine, 2. https://doi.org/10.1038/s41746-019-0126-9","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",1548
1463,Personal Health Informatics,Aarti Sathyanarayana,"January 1st, 2019",A Digital Biomarker for Detection of Benign Childhood Epilepsy with Centrotemporal Spikes,https://knowledge.amia.org/69862-amia-1.4570936/t006-1.4574499/t006-1.4574500/3201516-1.4574576/3202070-1.4574573," Aarti Sathyanarayana, Rima El Atrache, Michele Jackson, Ivan Sanchez Fernandez, Kenneth D. Mandl, Tobias Loddenkemper, William J. Bosl. (2019). A Digital Biomarker for Detection of Benign Childhood Epilepsy with Centrotemporal Spikes AMIA. https://knowledge.amia.org/69862-amia-1.4570936/t006-1.4574499/t006-1.4574500/3201516-1.4574576/3202070-1.4574573",This site was produced by Omnipress . Copyright 2025 | Duplication of this product and its content in print or digital form for the purpose of sharing with others is prohibited without permission from American Medical Informatics Association,1549
1464,Personal Health Informatics,Aarti Sathyanarayana,"March 28th, 2017",The Science of Sweet Dreams: Predicting Sleep Efficiency from Wearable Device Data,https://doi.org/10.1109/MC.2017.91," Sathyanarayana, Aarti, Luis Fernandez-Luque, Jaideep Srivastava. ‚ÄúThe Science of Sweet Dreams: Wearable Devices and Sleep Medicine.‚Äù IEEE Computer Magazine (March 2017). doi:10.1109/MC.2017.91","Lack of sleep can erode mental and physical well-being, often exacerbating health problems such as obesity. Wearable devices that capture and analyze sleep quality through predictive methodologies can help patients and medical practitioners make behavioral health decisions that can lead to better sleep and improved health.",1550
1465,Personal Health Informatics,Aarti Sathyanarayana,"November 4th, 2016",Sleep Quality Prediction From Wearable Data Using Deep Learning,https://doi.org/10.2196/mhealth.6562," Sathyanarayana, Aarti, Shafiq Joty, Luis Fernandez-Luque, Ferda Ofli, Jaideep Srivastava, Ahmed Elmagarmid, Teresa Arora, and Shahrad Taheri. ‚ÄúSleep Quality Prediction From Wearable Data Using Deep Learning.‚Äù JMIR mHealth and uHealth 4, no. 4 (2016) doi:10.2196/mhealth.6562","Insufficient sleep can impede physical, emotional, and mental well-being. Moderate sleep deprivation produces impairments in cognitive and motor performance equivalent to legally prescribed levels of alcohol intoxication. Sleep disturbances in depression can lead to increased risk of depression and anxiety. Short sleep duration is associated with reduced leptin, elevated ghrelin, and increased body mass index. Sleep efficiency is a metric to measure the quality of a person's sleep, and it can be as important as sleep quantity or quality. We tested the feasibility of predicting poor or good sleep efficiency based on physical activity data from the awake periods from a wearable device (ie, actigraphy) We took a detour from classical methods and proposed deep learning approaches to modeling the relationship between sleep and physical activity. The deidentified data used in this study were collected by Weill Cornell Medical College-Qatar for a research study called Qatar‚Äôs Ultimate Education for Sleep in Teenagers. The aim of the study was to determine different sleep patterns in adolescents residing in Qatar and how these related to body weight status. After agreeing to participate in the study, the adolescent participants were provided with an ActiGraph GT3X+ device, placed on their nondominant wrist, and were instructed to wear it at all times for 7 consecutive days and nights. The raw accelerometer data was aggregated into minute-by-minute epochs using a script written in R version 3.3.1. We compared the results of our deep learning models to those of logistic regression. Time-batched LSTM, CNN, and MLP performed the best with AUC scores showing an improvement over LR by 50%, 46%, and 46%, respectively. ‚ÄúOnly the simple RNN performed worse than logistic regression in both F1-score (harmonic mean of precision and recall) and accuracy,‚Äù the authors wrote in the paper. The deep learning methods of CNN and TB-lSTM were the best performers overall. Their sensitivity (0.97 and 1) showed that these models were able to detect nearly all the cases of ‚Äúgood-quality sleep‚Äù The sensitivity (also known as recall), and specificity of each of the models are reported in Table 2. This classification is consequently not an indicator of sleep patterns, but the prediction of a sleep quality parameter that might indicate a potential sleep problem. Deep learning performed better than classical methods in terms of learning useful patterns from raw accelerometer data for the task of sleep quality prediction. Our focus on predicting and forecasting can help design new eHealth applications where predictions are made to personalize coaching for patients or to facilitate decision making of professionals. The expansion of eHealth into sleep is not limited to sleep disorders, but also to improve sleep for people living with chronic conditions such as cancer. To maximize the potential of the wearable mass adoption for sleep health, we need research on not only the reliability of consumer-grade devices but also their data processing and modeling techniques. The study provided an early example of how advanced deep learning methods could be used to infer new insights from raw actigraphY data. It is hoped that this research will lead to a paradigm shift in the study of lifestyle behaviors such as sleep and physical activity.  Activity theory as a theoretical framework for health self-quantification: a systematic review of empirical studies. integrated in the broader context of quantified self. J Med Internet Res 2016 May 27;18(5):e131 [ FREE Full text ]",1551
1466,Personal Health Informatics,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1552
1467,Personal Health Informatics,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",1553
1468,Personal Health Informatics,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1554
1469,Personal Health Informatics,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",1555
1470,Personal Health Informatics,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1556
1471,Personal Health Informatics,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1557
1472,Personal Health Informatics,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",1558
1473,Personal Health Informatics,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1559
1474,Programming Languages,Amal Ahmed,"October 8th, 2024",Realistic Realizability: Specifying ABIs You Can Count On,https://doi.org/10.1145/3689755," Andrew Wagner, Zachary Eisbach, Amal Ahmed . (2024). Realistic Realizability: Specifying ABIs You Can Count On Proc. ACM Program. Lang., 8, 1249-1278. https://doi.org/10.1145/3689755","The Application Binary Interface (ABI) for a language defines the interoperability rules for its target platforms, including data layout and calling conventions, such that compliance with the rules ensures ‚Äúsafe‚Äù execution and perhaps certain resource usage guarantees. These rules are relied upon by compilers, libraries, and foreign-function interfaces. Unfortunately, ABIs are typically specified in prose, and while type systems for source languages have evolved, ABIs have comparatively stalled, lacking advancements in expressivity and safety. We propose a vision for richer, semantic ABIs to improve interoperability and library integration, supported by a methodology for formally specifying ABIs using realizability models. These semantic ABIs connect abstract, high-level types to unwieldy, but well-behaved, low-level code. We illustrate our approach with a case study formalizing the ABI of a functional source language in terms of a reference-counting implementation in a C-like target language. A key contribution supporting this case study is a graph-based model of separation logic that captures the ownership and accessibility of reference-counted resources using modalities inspired by hybrid logic. To highlight the flexibility of our methodology, we show how various design decisions can be interpreted into the semantic ABI. Finally, we provide the first formalization of library evolution, a distinguishing feature of Swift‚Äôs ABI.",1560
1475,Programming Languages,Amal Ahmed,"July 8th, 2024",A Nominal Approach to Probabilistic Separation Logic,https://doi.org/10.1145/3661814.3662135," John M. Li, Jon Aytac, Philip Johnson-Freyd, Amal Ahmed , Steven Holtzen. (2024). A Nominal Approach to Probabilistic Separation Logic LICS, 55:1-55:14. https://doi.org/10.1145/3661814.3662135","Currently, there is a gap between the tools used by probability theorists and those used in formal reasoning about probabilistic programs. On the one hand, a probability theorist decomposes probabilistic state along the simple and natural product of probability spaces. On the other hand, recently developed probabilistic separation logics decompose state via relatively unfamiliar measure-theoretic constructions for computing unions of sigma-algebras and probability measures. We bridge the gap between these two perspectives by showing that these two methods of decomposition are equivalent up to a suitable equivalence of categories. Our main result is a probabilistic analog of the classic equivalence between the category of nominal sets and the Schanuel topos. Through this equivalence, we validate design decisions in prior work on probabilistic separation logic and create new connections to nominal-setlike models of probability.",1561
1476,Programming Languages,Amal Ahmed,"April 29th, 2024",Gradually Typed Languages Should Be Vigilant!,https://doi.org/10.1145/3649842," Olek Gierczak, Lucy Menon, Christos Dimoulas, Amal Ahmed . (2024). Gradually Typed Languages Should Be Vigilant! Proc. ACM Program. Lang., 8, 864-892. https://doi.org/10.1145/3649842","In gradual typing, different languages perform different dynamic type checks for the same program even though the languages have the same static type system. This raises the question of whether, given a gradually typed language, the combination of the translation that injects checks in well-typed terms and the dynamic semantics that determines their behavior sufficiently enforce the static type system of the language. Neither type soundness, nor complete monitoring, nor any other meta-theoretic property of gradually typed languages to date provides a satisfying answer. In response, we present vigilance, a semantic analytical instrument that defines when the check-injecting translation and dynamic semantics of a gradually typed language are adequate for its static type system. Technically, vigilance asks if a given translation-and-semantics combination enforces the complete run-time typing history of a value, which consists of all of the types associated with the value. We show that the standard combination for so-called Natural gradual typing is vigilant for the standard simple type system, but the standard combination for Transient gradual typing is not. At the same time, the standard combination for Transient is vigilant for a tag type system but the standard combination for Natural is not. Hence, we clarify the comparative type-level reasoning power between the two most studied approaches to sound gradual typing. Furthermore, as an exercise that demonstrates how vigilance can guide design, we introduce and examine a new theoretical static gradual type system, dubbed truer, that is stronger than tag typing and more faithfully reflects the type-level reasoning power that the dynamic semantics of Transient gradual typing can guarantee.",1562
1477,Programming Languages,Amal Ahmed,"January 16th, 2024","RichWasm: Bringing Safe, Fine-Grained, Shared-Memory Interoperability Down to WebAssembly",https://doi.org/10.48550/arXiv.2401.08287," Zoe Paraskevopoulou, Michael Fitzgibbons, Michelle Thalakottur, Noble Mushtak, Jose Sulaiman Mazur, Amal Ahmed . (2024). RichWasm: Bringing Safe, Fine-Grained, Shared-Memory Interoperability Down to WebAssembly CoRR, abs/2401.08287. https://doi.org/10.48550/arXiv.2401.08287","Safe, shared-memory interoperability between languages with different type systems and memory-safety guarantees is an intricate problem as crossing language boundaries may result in memory-safety violations. In this paper, we present RichWasm, a novel richly typed intermediate language designed to serve as a compilation target for typed high-level languages with different memory-safety guarantees. RichWasm is based on WebAssembly and enables safe shared-memory interoperability by incorporating a variety of type features that support fine-grained memory ownership and sharing. RichWasm is rich enough to serve as a typed compilation target for both typed garbage-collected languages and languages with an ownership-based type system and manually managed memory. We demonstrate this by providing compilers from core ML and L3, a type-safe language with strong updates, to RichWasm. RichWasm is compiled to regular Wasm, allowing for use in existing environments. We formalize RichWasm in Coq and prove type safety.",1563
1478,Programming Languages,Amal Ahmed,"August 31st, 2023",Semantic Encapsulation using Linking Types,https://doi.org/10.1145/3609027.3609405," Daniel Patterson , Andrew Wagner, Amal Ahmed . (2023). Semantic Encapsulation using Linking Types TyDe@ICFP, 14-28. https://doi.org/10.1145/3609027.3609405","Interoperability pervades nearly all mainstream language implementations, as most systems leverage subcomponents written in different languages. And yet, such linking can expose a language to foreign behaviors that are internally inexpressible, which poses a serious threat to safety invariants and programmer reasoning. To preserve such invariants, a language may try to add features to limit the reliance on external libraries, but endless extensions can obscure the core abstractions the language was designed to provide. In this paper, we outline an approach that encapsulates foreign code in a sound way‚Äîi.e., without disturbing the invariants promised by types of the core language. First, one introduces novel linking types that characterize the behaviors of foreign libraries that are inexpressible in the core language. To reason about the soundness of linking, one constructs a realizability model that captures the meaning of both core types and linking types as sets of target-language terms. Using this model, one can formally prove when foreign behavior is encapsulated ; that is, unobservable to core code. We show one way to discharge such proofs automatically by augmenting the compiler to insert verified encapsulation wrappers around components that use foreign libraries. Inspired by existing approaches to FFIs, we develop a pair of case studies that extend a pure, functional language: one extension for state, and another for exceptions. The first allows us to implement mutable references via a library, whereas the second allows us to implement try and catch as library functions. Both extensions and the overall system are proven sound using logical relations that use realizability techniques.",1564
1479,Programming Languages,Amal Ahmed,"April 3rd, 2023",Lilac: a Modal Separation Logic for Conditional Probability,https://doi.org/10.48550/arXiv.2304.01339," John M. Li, Amal Ahmed , Steven Holtzen. (2023). Lilac: a Modal Separation Logic for Conditional Probability CoRR, abs/2304.01339. https://doi.org/10.48550/arXiv.2304.01339","We present Lilac, a separation logic for reasoning about probabilistic programs where separating conjunction captures probabilistic independence. Inspired by an analogy with mutable state where sampling corresponds to dynamic allocation, we show how probability spaces over a fixed, ambient sample space appear to be the natural analogue of heap fragments, and present a new combining operation on them such that probability spaces behave like heaps and measurability of random variables behaves like ownership. This combining operation forms the basis for our model of separation, and produces a logic with many pleasant properties. In particular, Lilac has a frame rule identical to the ordinary one, and naturally accommodates advanced features like continuous random variables and reasoning about quantitative properties of programs. Then we propose a new modality based on disintegration theory for reasoning about conditional probability. We show how the resulting modal logic validates examples from prior work, and give a formal verification of an intricate weighted sampling algorithm whose correctness depends crucially on conditional independence structure.",1565
1480,Programming Languages,Amal Ahmed,"September 16th, 2022",ANF preserves dependent types up to extensional equality,https://doi.org/10.1017/S0956796822000090," Paulette Koronkevich, Ramon Rakow, Amal Ahmed , William J. Bowman. (2022). ANF preserves dependent types up to extensional equality J. Funct. Program., 32, e12. https://doi.org/10.1017/S0956796822000090","Many programmers use dependently typed languages such as Coq to machine-verify high-assurance software. Existing compilers for these languages provide no guarantees after compiling, nor when linking after compilation. We develop an A-normal form (ANF) translation with join-point optimization from the Extended Calculus of Constructions with dependent elimination of booleans and natural numbers. This is the first ANF translation for dependent types. Unlike related translations, it supports the universe hierarchy, and does not rely on parametricity or impredicativity.",1566
1481,Programming Languages,Amal Ahmed,"June 9th, 2022",Semantic soundness for language interoperability,https://doi.org/10.1145/3519939.3523703," Daniel Patterson , Noble Mushtak, Andrew Wagner, Amal Ahmed . (2022). Semantic soundness for language interoperability PLDI, 609-624. https://doi.org/10.1145/3519939.3523703","Programs are rarely implemented in a single language, and thus questions of type soundness should address how it interacts with others. Even between type-safe languages, disparate features can frustrate interoperability. In this paper, we present a novel framework for the design and verification of sound language interoperability that follows an interoperation-after-compilation strategy.",1567
1482,Programming Languages,Amal Ahmed,"June 11th, 2018",Typed closure conversion for the calculus of constructions,https://doi.org/10.1145/3192366.3192372," William J. Bowman, Amal Ahmed . (2018). Typed closure conversion for the calculus of constructions PLDI, 797-811. https://doi.org/10.1145/3192366.3192372","Dependently typed languages such as Coq are used to specify and verify the full functional correctness of source programs. Type-preserving compilation can be used to preserve these specifications and proofs of correctness through compilation into the generated target-language programs. Unfortunately, type-preserving compilation of dependent types is hard. In essence, the problem is that dependent type systems are designed around high-level compositional abstractions to decide type checking, but compilation interferes with the type-system rules for reasoning about run-time terms. We develop a type-preserving closure-conversion translation from the Calculus of Constructions (CC) with strong dependent pairs (Œ£ types)‚Äîa subset of the core language of Coq‚Äîto a type-safe, dependently typed compiler intermediate language named CC-CC. The central challenge in this work is how to translate the source type-system rules for reasoning about functions into target type-system rules for reasoning about closures. To justify these rules, we prove soundness of CC-CC by giving a model in CC. In addition to type preservation, we prove correctness of separate compilation.",1568
1483,Programming Languages,Jonathan Bell,"September 11th, 2024",An Empirical Examination of Fuzzer Mutator Performance,https://doi.org/10.1145/3650212.3680387," James Kukucka, Lu√≠s Pina, Paul Ammann, Jonathan Bell . (2024). An Empirical Examination of Fuzzer Mutator Performance ISSTA, 1631-1642. https://doi.org/10.1145/3650212.3680387","Over the past decade, hundreds of fuzzers have been published in top-tier security and software engineering conferences. Fuzzers are used to automatically test programs, ideally creating high-coverage input corpora and finding bugs. Modern ‚Äúgreybox‚Äù fuzzers evolve a corpus of inputs by applying mutations to inputs and then executing those new inputs while collecting coverage. New inputs that are ‚Äúinteresting‚Äù (e.g. reveal new coverage) are saved to the corpus. Given their non-deterministic nature, the impact of each design decision on the fuzzer‚Äôs performance can be difficult to predict. Some design decisions (e.g., ‚Äù Should the fuzzer perform deterministic mutations of inputs? ‚Äù) are exposed to end-users as configuration flags, but others (e.g., ‚Äù What kinds of random mutations to apply to inputs?‚Äù) are typically baked into the fuzzer code itself. This paper describes our over 12.5-CPU-year evaluation of the set of mutation operators employed by the popular AFL++ fuzzer, including the havoc phase, splicing, and, exploring the impact of adjusting some of those unexposed configurations. In this experience paper, we propose a methodology for determining different fuzzers‚Äô behavioral diversity with respect to branch coverage and bug detection using rigorous statistical methods. Our key finding is that, across a range of targets, disabling certain mutation operators (some of which were previously ‚Äúbaked-in‚Äù to the fuzzer) resulted in inputs that cover different lines of code and reveal different bugs. A surprising result is disabling certain mutators leads to more diverse coverage and allows the fuzzer to find more bugs faster . We call for researchers to investigate seemingly simple design decisions in fuzzers more thoroughly and encourage fuzzer developers to expose more configuration parameters pertaining to these design decisions to end users.",1569
1484,Programming Languages,Jonathan Bell,"April 12th, 2024",Crossover in Parametric Fuzzing,https://doi.org/10.1145/3597503.3639160," Katherine Hough, Jonathan Bell . (2024). Crossover in Parametric Fuzzing ICSE, 129:1-129:12. https://doi.org/10.1145/3597503.3639160","Parametric fuzzing combines evolutionary and generator-based fuzzing to create structured test inputs that exercise unique execution behaviors. Parametric fuzzers internally represent inputs as bit strings referred to as ""parameter sequences"". Interesting parameter sequences are saved by the fuzzer and perturbed to create new inputs without the need for type-specific operators. However, existing work on parametric fuzzing only uses mutation operators, which modify a single input; it does not incorporate crossover, an evolutionary operator that blends multiple inputs together. Crossover operators aim to combine advantageous traits from multiple inputs. However, the nature of parametric fuzzing limits the effectiveness of traditional crossover operators. In this paper, we propose linked crossover, an approach for using dynamic execution information to identify and exchange analogous portions of parameter sequences. We created an implementation of linked crossover for Java and evaluated linked crossover's ability to preserve advantageous traits. We also evaluated linked crossover's impact on fuzzer performance on seven real-world Java projects and found that linked crossover consistently performed as well as or better than three state-of-the-art parametric fuzzers and two other forms of crossover on both long and short fuzzing campaigns.",1570
1485,Programming Languages,Jonathan Bell,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1571
1486,Programming Languages,Jonathan Bell,"November 9th, 2022",A retrospective study of one decade of artifact evaluations,https://doi.org/10.1145/3540250.3549172," Stefan Winter , Christopher Steven Timperley, Ben Hermann , J√ºrgen Cito, Jonathan Bell , Michael Hilton, Dirk Beyer . (2022). A retrospective study of one decade of artifact evaluations ESEC/SIGSOFT FSE, 145-156. https://doi.org/10.1145/3540250.3549172","Most software engineering research involves the development of a prototype, a proof of concept, or a measurement apparatus. Together with the data collected in the research process, they are collectively referred to as research artifacts and are subject to artifact evaluation (AE) at scientific conferences. Since its initiation in the SE community at ESEC/FSE 2011, both the goals and the process of AE have evolved and today expectations towards AE are strongly linked with reproducible research results and reusable tools that other researchers can build their work on. However, to date little evidence has been provided that artifacts which have passed AE actually live up to these high expectations, i.e., to which degree AE processes contribute to AE's goals and whether the overhead they impose is justified. We aim to fill this gap by providing an in-depth analysis of research artifacts from a decade of software engineering (SE) and programming languages (PL) conferences, based on which we reflect on the goals and mechanisms of AE in our community. In summary, our analyses (1) suggest that articles with artifacts do not generally have better visibility in the community, (2) provide evidence how evaluated and not evaluated artifacts differ with respect to different quality criteria, and (3) highlight opportunities for further improving AE processes.",1572
1487,Programming Languages,Jonathan Bell,"July 5th, 2022",CONFETTI: Amplifying Concolic Guidance for Fuzzers,https://doi.org/10.1145/3510003.3510628," James Kukucka, Lu√≠s Pina, Paul Ammann, Jonathan Bell . (2022). CONFETTI: Amplifying Concolic Guidance for Fuzzers ICSE, 438-450. https://doi.org/10.1145/3510003.3510628","Fuzz testing (fuzzing) allows developers to detect bugs and vulnerabilities in code by automatically generating defect-revealing inputs. Most fuzzers operate by generating inputs for applications and mutating the bytes of those inputs, guiding the fuzzing process with branch coverage feedback via instrumentation. Whitebox guidance (e.g., taint tracking or concolic execution) is sometimes integrated with coverage-guided fuzzing to help cover tricky-to-reach branches that are guarded by complex conditions (so-called ""magic values""). This integration typically takes the form of a targeted input mutation, e.g. , placing particular byte values at a specific offset of some input in order to cover a branch. However, these dynamic analysis techniques are not perfect in practice, which can result in the loss of important relationships between input bytes and branch predicates, thus reducing the effective power of the technique. We introduce a new, surprisingly simple, but effective technique, global hinting , which allows the fuzzer to insert these interesting bytes not only at a targeted position, but in any position of any input. We implemented this idea in Java, creating Confetti, which uses both targeted and global hints for fuzzing. In an empirical comparison with two baseline approaches, a state-of-the-art greybox Java fuzzer and a version of Confetti without global hinting, we found that Confetti covers more branches and finds 15 previously unreported bugs, including 9 that neither baseline could find. By conducting a post-mortem analysis of Confetti's execution, we determined that global hinting was at least as effective at revealing new coverage as traditional, targeted hinting.",1573
1488,Programming Languages,Jonathan Bell,"March 25th, 2022",Flexible and Optimal Dependency Management via Max-SMT,https://doi.org/10.1109/ICSE48619.2023.00124," Donald Pinckney, Federico Cassano, Arjun Guha, Jonathan Bell , Massimiliano Culpo, Todd Gamblin. (2023). Flexible and Optimal Dependency Management via Max-SMT ICSE, 1418-1429. https://doi.org/10.1109/ICSE48619.2023.00124","NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. NPM dependency solver has several shortcomings. We present Pacsolve, a unifying framework and implementation for dependency solving. We then build Maxnpm, a complete, drop-in replacement for NPM. We are presenting our findings at the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) All our code and data is open and available. Back to Mail Online home. Back To the page you came from.""Maxnpm: A Drop-in Replacement For NPM""",1574
1489,Programming Languages,Jonathan Bell,"May 7th, 2021",FlakeFlagger: Predicting Flakiness Without Rerunning Tests,https://doi.org/10.1109/ICSE43902.2021.00140," Abdulrahman Alshammari, Christopher Morris , Michael Hilton, Jonathan Bell . (2021). FlakeFlagger: Predicting Flakiness Without Rerunning Tests ICSE, 1572-1584. https://doi.org/10.1109/ICSE43902.2021.00140","FlakeFlagger collects a set of features describing the behavior of each test. It then predicts tests that are likely to be flaky based on similar behavioral features. We found that FlakeFlagger correctly labeled as flaky at least as many tests as a state-of-the-art flaky test classifier, but that Flake flagger reported far fewer false positives. This lower false positive rate translates directly to saved time for researchers and developers who use the classification result to guide more expensive flakytest detection processes. We conducted a very large empirical study looking for flaky tests by rerunning the test suites of 24 projects 10,000 times each. Some previously identified flaky Tests were still not detected.",1575
1490,Programming Languages,Matthias Felleisen,"March 21st, 2023",Injecting Language Workbench Technology into Mainstream Languages,https://doi.org/10.4230/OASIcs.EVCS.2023.3," Michael Ballantyne, Matthias Felleisen. (2023). Injecting Language Workbench Technology into Mainstream Languages Eelco Visser Commemorative Symposium, 3:1-3:11. https://doi.org/10.4230/OASIcs.EVCS.2023.3","Abstract Eelco Visser envisioned a future where DSLs become a commonplace abstraction in software development. He took strides towards implementing this vision with the Spoofax language workbench. However, his vision is far from the mainstream of programming today. How will the many mainstream programmers encounter and adopt language workbench technology? We propose that the macro systems found in emerging industrial languages open a path towards delivering language workbenches as easy-to-adopt libraries. To develop the idea, we sketch an implementation of a language workbench as a macro-library atop Racket and identify the key features of the macro system needed to enable this evolution path.",1576
1491,Programming Languages,Matthias Felleisen,"March 5th, 2023",Typed-Untyped Interactions: A Comparative Analysis,https://doi.org/10.1145/3579833," Ben Greenman, Christos Dimoulas, Matthias Felleisen. (2023). Typed-Untyped Interactions: A Comparative Analysis ACM Trans. Program. Lang. Syst., 45, 4:1-4:54. https://doi.org/10.1145/3579833",The literature presents many strategies for enforcing the integrity of types when typed code interacts with untyped code. This article presents a uniform evaluation framework that characterizes the differences among some major existing semantics for typed‚Äìuntyped interaction. Type system designers can use this framework to analyze the guarantees of their own dynamic semantics.,1577
1492,Programming Languages,Matthias Felleisen,"November 19th, 2021",A Transient Semantics for Typed Racket,https://arxiv.org/abs/2111.10411," Ben Greenman, Lukas Lazarek, Christos Dimoulas, Matthias Felleisen. (2021). A Transient Semantics for Typed Racket CoRR, abs/2111.10411. https://arxiv.org/abs/2111.10411","Mixed-typed languages enable programmers to link typed and untyped components in various ways. Some offer rich type systems to facilitate the smooth migration of untyped code to the typed world; others merely provide a convenient form of type Dynamic together with a conventional structural type system. Orthogonal to this dimension, Natural systems ensure the integrity of types with a sophisticated contract system, while Transient systems insert simple first-order checks at strategic places within typed code. Furthermore, each method of ensuring type integrity comes with its own blame-assignment strategy.Typed Racket has a rich migratory type system and enforces the types with a Natural semantics. Reticulated Python has a simple structural type system extended with Dynamic and enforces types with a Transient semantics. While Typed Racket satisfies the most stringent gradual-type soundness properties at a significant performance cost, Reticulated Python seems to limit the performance penalty to a tolerable degree and is nevertheless type sound. This comparison raises the question of whether Transient checking is applicable to and beneficial for a rich migratory type system.This paper reports on the surprising difficulties of adapting the Transient semantics of Reticulated Python to the rich migratory type system of Typed Racket. The resulting implementation, Shallow Typed Racket, is faster than the standard Deep Typed Racket but only when the Transient blame assignment strategy is disabled. For language designers, this report provides valuable hints on how to equip an existing compiler to support a Transient semantics. For theoreticians, the negative experience with Transient blame calls for a thorough investigation of this strategy.",1578
1493,Programming Languages,Joshua Gancher,"October 8th, 2024",FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions,https://doi.org/10.1145/3689729," Zhengyao Lin, Joshua Gancher, Bryan Parno. (2024). FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions Proc. ACM Program. Lang., 8, 499-526. https://doi.org/10.1145/3689729","Coarse-grained reconfigurable arrays (CGRAs) have gained attention in recent years due to their promising power efficiency compared to traditional von Neumann architectures. To program these architectures using ordinary languages such as C, a dataflow compiler must transform the original sequential, imperative program into an equivalent dataflow graph, composed of dataflow operators running in parallel. This transformation is challenging since the asynchronous nature of dataflow graphs allows out-of-order execution of operators, leading to behaviors not present in the original imperative programs. We address this challenge by developing a translation validation technique for dataflow compilers to ensure that the dataflow program has the same behavior as the original imperative program on all possible inputs and schedules of execution. We apply this method to a state-of-the-art dataflow compiler targeting the RipTide CGRA architecture. Our tool uncovers 8 compiler bugs where the compiler outputs incorrect dataflow graphs, including a data race that is otherwise hard to discover via testing. After repairing these bugs, our tool verifies the correct compilation of all programs in the RipTide benchmark suite.",1579
1494,Programming Languages,Joshua Gancher,"September 20th, 2024",Secure Synthesis of Distributed Cryptographic Applications,https://doi.org/10.1109/CSF61375.2024.00021," Cosku Acay, Joshua Gancher, Rolph Recto, Andrew C. Myers. (2024). Secure Synthesis of Distributed Cryptographic Applications CSF, 433-448. https://doi.org/10.1109/CSF61375.2024.00021","Developing secure distributed systems is difficult, and even harder when advanced cryptography must be used to achieve security goals. We advocate using secure program partitioning to synthesize cryptographic applications. Instead of implementing a system of communicating processes, the programmer implements a centralized, sequential program, which is automatically compiled into a secure distributed version that uses cryptography. We prove that our result guarantees robust hyperproperty preservation, an important criterion for compiler correctness that preserves all source-level security properties in target programs. The proof targets hybrid protocols, which abstract cryptographic mechanisms as idealized functionalities. It relies on a novel unification of simulation-based security, information-flow control, choreographic programming, and sequentialization techniques for concurrent programs.",1580
1495,Programming Languages,Joshua Gancher,"January 11th, 2023",A Core Calculus for Equational Proofs of Cryptographic Protocols,https://doi.org/10.1145/3571223," Joshua Gancher, Kristina Sojakova, Xiong Fan, Elaine Shi, Greg Morrisett. (2023). A Core Calculus for Equational Proofs of Cryptographic Protocols Proc. ACM Program. Lang., 7, 866-892. https://doi.org/10.1145/3571223","Many proofs of interactive cryptographic protocols (e.g., as in Universal Composability) operate by proving the protocol at hand to be observationally equivalent to an idealized specification. While pervasive, formal tool support for observational equivalence of cryptographic protocols is still a nascent area of research. Current mechanization efforts tend to either focus on diff-equivalence, which establishes observational equivalence between protocols with identical control structures, or require an explicit witness for the observational equivalence in the form of a bisimulation relation. Our goal is to simplify proofs for cryptographic protocols by introducing a core calculus, IPDL, for cryptographic observational equivalences. Via IPDL, we aim to address a number of theoretical issues for cryptographic proofs in a simple manner, including probabilistic behaviors, distributed message-passing, and resource-bounded adversaries and simulators. We demonstrate IPDL on a number of case studies, including a distributed coin toss protocol, Oblivious Transfer, and the GMW multi-party computation protocol. All proofs of case studies are mechanized via an embedding of IPDL into the Coq proof assistant.",1581
1496,Programming Languages,Joshua Gancher,"June 18th, 2021","Viaduct: an extensible, optimizing compiler for secure distributed programs",https://doi.org/10.1145/3453483.3454074," Cosku Acay, Rolph Recto, Joshua Gancher, Andrew C. Myers, Elaine Shi. (2021). Viaduct: an extensible, optimizing compiler for secure distributed programs PLDI, 740-755. https://doi.org/10.1145/3453483.3454074","Modern distributed systems involve interactions between principals with limited trust, so cryptographic mechanisms are needed to protect confidentiality and integrity. At the same time, most developers lack the training to securely employ cryptography. We present Viaduct, a compiler that transforms high-level programs into secure, efficient distributed realizations. Viaduct's source language allows developers to declaratively specify security policies by annotating their programs with information flow labels. The compiler uses these labels to synthesize distributed programs that use cryptography efficiently while still defending the source-level security policy. The Viaduct approach is general, and can be easily extended with new security mechanisms. Our implementation of the Viaduct compiler comes with an extensible runtime system that includes plug-in support for multiparty computation, commitments, and zero-knowledge proofs. We have evaluated the system on a set of benchmarks, and the results indicate that our approach is feasible and can use cryptography in efficient, nontrivial ways.",1582
1497,Programming Languages,Arjun Guha,"October 31st, 2024",SelfCodeAlign: Self-Alignment for Code Generation,http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html," Yuxiang Wei , Federico Cassano, Jiawei Liu , Yifeng Ding, Naman Jain, Zachary Mueller, Harm de Vries, Leandro von Werra, Arjun Guha, Lingming Zhang . (2024). SelfCodeAlign: Self-Alignment for Code Generation NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html","Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models to follow human instructions. Most models are finetuned with costly human-annotated instruction-response pairs. We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs.",1583
1498,Programming Languages,Arjun Guha,"October 8th, 2024",Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs,https://doi.org/10.1145/3689735," Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Anders Freeman, Carolyn Jane Anderson, Molly Q. Feldman, Michael Greenberg , Abhinav Jangda, Arjun Guha. (2024). Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs Proc. ACM Program. Lang., 8, 677-708. https://doi.org/10.1145/3689735","Large Language Models of Code have started to have a significant impact on programming practice. The quality of code produced by a Code LLM varies significantly by programming language. This paper presents an effective approach for boosting the performance of Code LLMs on low-resource languages using semi-synthetic data. The MultiPL-T approach is easy to apply to new languages, and is significantly more efficient and effective than alternatives such as training longer.",1584
1499,Programming Languages,Arjun Guha,"March 25th, 2022",Flexible and Optimal Dependency Management via Max-SMT,https://doi.org/10.1109/ICSE48619.2023.00124," Donald Pinckney, Federico Cassano, Arjun Guha, Jonathan Bell , Massimiliano Culpo, Todd Gamblin. (2023). Flexible and Optimal Dependency Management via Max-SMT ICSE, 1418-1429. https://doi.org/10.1109/ICSE48619.2023.00124","NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. NPM dependency solver has several shortcomings. We present Pacsolve, a unifying framework and implementation for dependency solving. We then build Maxnpm, a complete, drop-in replacement for NPM. We are presenting our findings at the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) All our code and data is open and available. Back to Mail Online home. Back To the page you came from.""Maxnpm: A Drop-in Replacement For NPM""",1585
1500,Programming Languages,Arjun Guha,"October 15th, 2021",Solver-based gradual type migration,https://doi.org/10.1145/3485488," Luna Phipps-Costin, Carolyn Jane Anderson, Michael Greenberg, and Arjun Guha. 2021. ‚ÄúSolver-based gradual type migration‚Äù. Proc. ACM Program. Lang. 5, OOPSLA, Article 111 (October 2021), 27 pages. DOI: 10.1145/3485488","Gradually typed languages allow programmers to mix statically and dynamically typed code, enabling them to incrementally reap the benefits of static typing as they add type annotations to their code. However, this type migration process is typically a manual effort with limited tool support. This paper examines the problem of automated type migration: given a dynamic program, infer additional or improved type annotations. Existing type migration algorithms prioritize different goals, such as maximizing type precision, maintaining compatibility with unmigrated code, and preserving the semantics of the original program. We argue that the type migration problem involves fundamental compromises: optimizing for a single goal often comes at the expense of others. Ideally, a type migration tool would flexibly accommodate a range of user priorities. We present TypeWhich, a new approach to automated type migration for the gradually-typed lambda calculus with some extensions. Unlike prior work, which relies on custom solvers, TypeWhich produces constraints for an off-the-shelf MaxSMT solver. This allows us to easily express objectives, such as minimizing the number of necessary syntactic coercions, and constraining the type of the migration to be compatible with unmigrated code. We present the first comprehensive evaluation of GTLC type migration algorithms, and compare TypeWhich to four other tools from the literature. Our evaluation uses prior benchmarks, and a new set of ""challenge problems."" Moreover, we design a new evaluation methodology that highlights the subtleties of gradual type migration. In addition, we apply TypeWhich to a suite of benchmarks for Grift, a programming language based on the GTLC. TypeWhich is able to reconstruct all human-written annotations on all but one program.",1586
1501,Programming Languages,Arjun Guha,"September 27th, 2021",Iterative Program Synthesis for Adaptable Social Navigation,https://doi.org/10.1109/IROS51168.2021.9636540," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Iterative Program Synthesis for Adaptable Social Navigation,"" 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021, pp. 6256-6261. DOI: 10.1109/IROS51168.2021.9636540","Robot social navigation is influenced by human preferences and environment-specific scenarios such as elevators and doors. State-of-the-art approaches to social navigation fall into two categories: model-based social constraints and learning-based approaches. We propose Iterative Dimension Informed Program Synthesis (IDIPS) to address these limitations by learning and adapting social navigation in the form of human-readable symbolic programs. IDIPS works by combining pro-gram synthesis, parameter optimization, predicate repair, and iterative human demonstration to learn and adapt model-free action selection policies. and generates policies that can be transferred from simulation to real-world robots with minimal effort.",1587
1502,Programming Languages,Arjun Guha,"April 21st, 2021",Accelerating graph sampling for graph machine learning using GPUs,https://doi.org/10.1145/3447786.3456244," Abhinav Jangda, Sandeep Polisetty, Arjun Guha, and Marco Serafini. 2021. Accelerating graph sampling for graph machine learning using GPUs. In Proceedings of the Sixteenth European Conference on Computer Systems (EuroSys ‚Äô21). Association for Computing Machinery, New York, NY, USA, 311‚Äì326. DOI: 10.1145/3447786.3456244","Representation learning algorithms automatically learn the features of data. Several representation learning algorithms for graph data, such as DeepWalk, node2vec, and Graph-SAGE, sample the graph to produce mini-batches that are suitable for training a DNN. However, sampling time can be a significant fraction of training time, and existing systems do not efficiently parallelize sampling. Sampling is an ""embarrassingly parallel"" problem and may appear to lend itself to GPU acceleration, but the irregularity of graphs makes it hard to use GPU resources effectively. This paper presents NextDoor, a system designed to effectively perform graph sampling on GPUs. NextDoor employs a new approach to graph sampling that we call transit-parallelism, which allows load balancing and caching of edges. NextDoor provides end-users with a high-level abstraction for writing a variety of graph sampling algorithms. We implement several graph sampling applications, and show that NextDoor runs them orders of magnitude faster than existing systems.",1588
1503,Programming Languages,Arjun Guha,"November 15th, 2020",Wasm/k: delimited continuations for WebAssembly,https://doi.org/10.1145/3426422.3426978," Donald Pinckney, Arjun Guha, and Yuriy Brun. 2020. Wasm/k: delimited continuations for WebAssembly. In Proceedings of the 16th ACM SIGPLAN International Symposium on Dynamic Languages(DLS 2020). Association for Computing Machinery, New York, NY, USA, 16‚Äì28. DOI: 10.1145/3426422.3426978","WebAssembly is designed to be an alternative to JavaScript that is a safe, portable, and efficient compilation target for a variety of languages. The performance of high-level languages depends not only on the underlying performance of WebAssembly, but also on the quality of the generated WebAssembly code. In this paper, we identify several features of high-level languages that current approaches can only compile to WebAssembly by generating complex and inefficient code. We argue that these problems could be addressed if WebAssembly natively supported first-class continuations. We then present Wasm/k, which extends WebAssembly with delimited continuations. Wasm/k introduces no new value types, and thus does not require significant changes to the WebAssembly type system (validation). Wasm/k is safe, even in the presence of foreign function calls (e.g., to and from JavaScript). Finally, Wasm/k is amenable to efficient implementation: we implement Wasm/k as a local change to Wasmtime, an existing WebAssembly JIT. We evaluate Wasm/k by implementing C/k, which adds delimited continuations to C/C++. C/k uses Emscripten and its implementation serves as a case study on how to use Wasm/k in a compiler that targets WebAssembly. We present several case studies using C/k, and show that on implementing green threads, it can outperform the state-of-the-art approach Asyncify with an 18% improvement in performance and a 30% improvement in code size.",1589
1504,Programming Languages,Arjun Guha,"November 13th, 2020",TacTok: semantics-aware proof synthesis,https://doi.org/10.1145/3428299," Emily First, Yuriy Brun, and Arjun Guha. ""TacTok: semantics-aware proof synthesis."" Proceedings of the ACM on Programming Languages, v.4 , 2020. DOI: 10.1145/3428299","TacTok outperforms WeightedRandom and WeightedGreedy, and is complementary to CoqHammer and ASTactic. For 24 out of the 26 projects, TacTok can synthesize proof scripts for some theorem the prior tools cannot. Together with TacTok, 11.5% more theoresms can be proven automatically than by CoquHammer alone.",1590
1505,Programming Languages,Arjun Guha,"November 12th, 2020",Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,https://doi.org/10.48550/arXiv.2008.04133," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,"" Conference on Robot Learning (CoRL), 2020. DOI: 10.48550/arXiv.2008.04133","Action selection policies (ASPs), used to compose low-level robot skills into complex high-level tasks are commonly represented as neural networks (NNs) in the state of the art. Such a paradigm, while very effective, suffers from a few key problems: 1) NNs are opaque to the user and hence not amenable to verification, 2) they require significant amounts of training data, and 3) they are hard to repair when the domain changes. We present two key insights about ASPs for robotics. First, ASPs need to reason about physically meaningful quantities derived from the state of the world, and second, there exists a layered structure for composing these policies. Leveraging these insights, we introduce layered dimension-informed program synthesis (LDIPS) - by reasoning about the physical dimensions of state variables, and dimensional constraints on operators, LDIPS directly synthesizes ASPs in a human-interpretable domain-specific language that is amenable to program repair. We present empirical results to demonstrate that LDIPS 1) can synthesize effective ASPs for robot soccer and autonomous driving domains, 2) requires two orders of magnitude fewer training examples than a comparable NN representation, and 3) can repair the synthesized ASPs with only a small number of corrections when transferring from simulation to real robots.",1591
1506,Programming Languages,Arjun Guha,"April 3rd, 2020",Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing,https://ojs.aaai.org/index.php/AAAI/article/view/7065," Joseph Spitzer, Joydeep Biswas, Arjun Guha. (2020). Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing AAAI, 13412-13419. https://ojs.aaai.org/index.php/AAAI/article/view/7065","Abstract Robots are a popular platform for introducing computing and artificial intelligence to novice programmers. However, programming state-of-the-art robots is very challenging, and requires knowledge of concurrency, operation safety, and software engineering skills, which can take years to teach. In this paper, we present an approach to introducing computing that allows students to safely and easily program high-performance robots. We develop a platform for students to program RoboCup Small Size League robots using JavaScript. The platform 1) ensures physical safety at several levels of abstraction, 2) allows students to program robots using JavaScript in the browser, without the need to install software, and 3) presents a simplified JavaScript semantics that shields students from confusing language features. We discuss our experience running a week-long workshop using this platform, and analyze over 3,000 student-written program revisions to provide empirical evidence that our approach does help students.",1592
1507,Programming Languages,Arjun Guha,"February 15th, 2019",Formal Foundations of Serverless Computing,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2019-jangda-lambda-lambda.html," Abhinav Jangda, Donald Pinckney, Yuriy Brun, and Arjun Guha. Formal Foundations of Serverless Computing. ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages and Applications (OOPSLA), 2019. Distinguished Paper Award","Serverless computing (also known as functions as a service) is a new cloud computing abstraction that makes it easier to write robust, large-scale web services. In serverless computing, programmers write what are called serverless functions, and the cloud platform transparently manages the operating system, resource allocation, load-balancing, and fault tolerance. When demand for the service spikes, the platform automatically allocates additional hardware to the service and manages load-balancing; when demand falls, the platform silently deallocates idle resources; and when the platform detects a failure, it transparently retries affected requests. In 2014, Amazon Web Services introduced the first serverless platform, AWS Lambda, and similar abstractions are now available on all major cloud computing platforms. Unfortunately, the serverless computing abstraction exposes several low-level operational details that make it hard for programmers to write and reason about their code. This paper sheds light on this problem by presenting Œª Œõ , an operational semantics of the essence of serverless computing. Despite being a small (half a page) core calculus, Œª Œõ models all the low-level details that serverless functions can observe. To show that Œª Œõ is useful, we present three applications. First, to ease reasoning about code, we present a simplified naive semantics of serverless execution and precisely characterize when the naive semantics and Œª Œõ coincide. Second, we augment Œª Œõ with a key-value store to allow reasoning about stateful serverless functions. Third, since a handful of serverless platforms support serverless function composition, we show how to extend Œª Œõ with a composition language. We have implemented this composition language and show that it outperforms prior work. The latest version of this paper, corrects an error in Definition 4.2 and thus the proof of Theorem 4.3, which were found in the published version. PDF available on arXiv",1593
1508,Programming Languages,Arjun Guha,"February 5th, 2018",Interactive Robot Transition Repair With SMT,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2018-holtz-srtr.html," Jarrett Holtz, Arjun Guha, and Joydeep Biswas. Interactive Robot Transition Repair with SMT. International Joint Conference on Artificial Intelligence and the European Conference on Artificial Intelligence (IJCAI-ECAI), 2018","Complex robot behaviors are often structured as state machines, where states encapsulate actions and a transition function switches between states. Since transitions depend on physical parameters, when the environment changes, a roboticist has to painstakingly readjust the parameters to work in the new environment. We present interactive SMT-based Robot Transition Repair* (SRTR): instead of manually adjusting parameters, we ask the roboticist to identify a few instances where the robot is in a wrong state and what the right state should be. An automated analysis of the transition function 1) identifies adjustable parameters, 2) converts the transition function into a system of logical constraints, and 3) formulates the constraints and user-supplied corrections as a MaxSMT problem that yields new parameter values. We show that finds new parameters 1) quickly, 2) with few corrections, and 3) that the parameters generalize to new scenarios. We also show that a SRTR-corrected state machine can outperform a more complex, expert-tuned state machine. PDF available on arXiv",1594
1509,Programming Languages,Arjun Guha,"September 17th, 2015",Rehearsal: A Configuration Verification Tool for Puppet,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2016-rehearsal.html," Rian Shambaugh, Aaron Weiss, and Arjun Guha. Rehearsal: A Configuration Verification Tool for Puppet. ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2016","Large-scale data centers and cloud computing have turned system configuration into a challenging problem. Several widely-publicized outages have been blamed not on software bugs, but on configuration bugs. To cope, thousands of organizations use system configuration languages to manage their computing infrastructure. Of these, Puppet is the most widely used with thousands of paying customers and many more open-source users. The heart of Puppet is a domain-specific language that describes the state of a system. Puppet already performs some basic static checks, but they only prevent a narrow range of errors. Furthermore, testing is ineffective because many errors are only triggered under specific machine states that are difficult to predict and reproduce. With several examples, we show that a key problem with Puppet is that configurations can be non-deterministic. This paper presents Rehearsal, a verification tool for Puppet configurations. Rehearsal implements a sound, complete, and scalable determinacy analysis for Puppet. To develop it, we (1) present a formal semantics for Puppet, (2) use several analyses to shrink our models to a tractable size, and (3) frame determinism-checking as decidable formulas for an SMT solver. Rehearsal then leverages the determinacy analysis to check other important properties, such as idempotency. Finally, we apply Rehearsal to several real-world Puppet configurations. PLDI Artifact Virtual Machine PDF available on arXiv",1595
1510,Programming Languages,Steve Holtzen,"July 8th, 2024",A Nominal Approach to Probabilistic Separation Logic,https://doi.org/10.1145/3661814.3662135," John M. Li, Jon Aytac, Philip Johnson-Freyd, Amal Ahmed , Steven Holtzen. (2024). A Nominal Approach to Probabilistic Separation Logic LICS, 55:1-55:14. https://doi.org/10.1145/3661814.3662135","Currently, there is a gap between the tools used by probability theorists and those used in formal reasoning about probabilistic programs. On the one hand, a probability theorist decomposes probabilistic state along the simple and natural product of probability spaces. On the other hand, recently developed probabilistic separation logics decompose state via relatively unfamiliar measure-theoretic constructions for computing unions of sigma-algebras and probability measures. We bridge the gap between these two perspectives by showing that these two methods of decomposition are equivalent up to a suitable equivalence of categories. Our main result is a probabilistic analog of the classic equivalence between the category of nominal sets and the Schanuel topos. Through this equivalence, we validate design decisions in prior work on probabilistic separation logic and create new connections to nominal-setlike models of probability.",1596
1511,Programming Languages,Steve Holtzen,"July 5th, 2024",Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces,https://doi.org/10.1145/3649921.3656986," Abdelrahman Madkour, Ross Mawhorter, Stacy Marsella, Adam M. Smith , Steven Holtzen. (2024). Ahead-of-time Compilation for Diverse Samplers of Constrained Design Spaces FDG, 54. https://doi.org/10.1145/3649921.3656986","We introduce a new approach to deploying constraint-based content generators that better supports online generation. Constraint-based generators ensure that certain properties hold in each design they output. However, when deployed a general-purpose solver is often required, thus guarantees come with unpredictable search times and little control over sequentially-generated outputs. In this paper, we outline how we can encode design constraints into a compact circuit representation that affords generation without search. These generators yield samples that are distributed uniformly over the space of valid designs. We illustrate our approach with binary decision diagrams (BDDs) in comparison to the traditional approach with answer-set programming (ASP) in two scenarios: a grid-based tile placement scenario inspired by WaveFunctionCollapse, and a playable platformer level design scenario. These compiled design-space models make constraint-based methods easier to deploy by improving on both the running time and diversity of previous constraint-based methods.",1597
1512,Programming Languages,Steve Holtzen,"October 6th, 2023",Probabilistic Logic Programming Semantics For Procedural Content Generation,https://doi.org/10.1609/aiide.v19i1.27525," Abdelrahman Madkour, Chris Martens , Steven Holtzen, Casper Harteveld, Stacy Marsella. (2023). Probabilistic Logic Programming Semantics For Procedural Content Generation AIIDE, 295-305. https://doi.org/10.1609/aiide.v19i1.27525","Abstract Research in procedural content generation (PCG) has recently heralded two major methodologies: machine learning (PCGML) and declarative programming. The former shows promise by automating the specification of quality criteria through latent patterns in data, while the latter offers significant advantages for authorial control. In this paper we propose the use of probabilistic logic as a unifying framework that combines the benefits of both methodologies. We propose a Bayesian formalization of content generators as probability distributions and show how common PCG tasks map naturally to operations on the distribution. Further, through a series of experiments with maze generation, we demonstrate how probabilistic logic semantics allows us to leverage the authorial control of declarative programming and the flexibility of learning from data.",1598
1513,Programming Languages,Steve Holtzen,"July 25th, 2023",Scaling integer arithmetic in probabilistic programs,https://proceedings.mlr.press/v216/cao23b.html," William X. Cao, Poorva Garg, Ryan Tjoa, Steven Holtzen, Todd D. Millstein, Guy Van den Broeck. (2023). Scaling integer arithmetic in probabilistic programs UAI, 260-270. https://proceedings.mlr.press/v216/cao23b.html","Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today‚Äôs probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today‚Äôs PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.",1599
1514,Programming Languages,Steve Holtzen,"April 3rd, 2023",Lilac: a Modal Separation Logic for Conditional Probability,https://doi.org/10.48550/arXiv.2304.01339," John M. Li, Amal Ahmed , Steven Holtzen. (2023). Lilac: a Modal Separation Logic for Conditional Probability CoRR, abs/2304.01339. https://doi.org/10.48550/arXiv.2304.01339","We present Lilac, a separation logic for reasoning about probabilistic programs where separating conjunction captures probabilistic independence. Inspired by an analogy with mutable state where sampling corresponds to dynamic allocation, we show how probability spaces over a fixed, ambient sample space appear to be the natural analogue of heap fragments, and present a new combining operation on them such that probability spaces behave like heaps and measurability of random variables behaves like ownership. This combining operation forms the basis for our model of separation, and produces a logic with many pleasant properties. In particular, Lilac has a frame rule identical to the ordinary one, and naturally accommodates advanced features like continuous random variables and reasoning about quantitative properties of programs. Then we propose a new modality based on disintegration theory for reasoning about conditional probability. We show how the resulting modal logic validates examples from prior work, and give a formal verification of an intricate weighted sampling algorithm whose correctness depends crucially on conditional independence structure.",1600
1515,Programming Languages,Steve Holtzen,"June 30th, 2021",Model Checking Finite-Horizon Markov Chains with Probabilistic Inference,https://arxiv.org/abs/2105.12326," Model Checking Finite-Horizon Markov Chains with Probabilistic Inference. Steven Holtzen, Sebastian Junges, Marcell Vazquez-Chanlatte, Todd Millstein, Sanjit A. Seshia, and Guy Van den Broeck. In International Conference on Computer-Aided Verification (CAV), 2021.","We revisit the symbolic verification of Markov chains with respect to finite horizon reachability properties. The prevalent approach iteratively computes step-bounded state reachability probabilities. By contrast, recent advances in probabilistic inference suggest symbolically representing all horizon-length paths through the Markov chain. We ask whether this perspective advances the state-of-the-art in probabilistic model checking. First, we formally describe both approaches in order to highlight their key differences. Then, using these insights we develop Rubicon, a tool that transpiles Prism models to the probabilistic inference tool Dice. Finally, we demonstrate better scalability compared to probabilistic model checkers on selected benchmarks. All together, our results suggest that probabilistic inference is a valuable addition to the probabilistic model checking portfolio -- with Rubicon as a first step towards integrating both perspectives.",1601
1516,Programming Languages,Steve Holtzen,"March 31st, 2021",Logical Abstractions for Noisy Variational Quantum Algorithm Simulation,https://arxiv.org/abs/2103.17226," Yipeng Huang , Steven Holtzen, Todd D. Millstein, Guy Van den Broeck, Margaret Martonosi. (2021). Logical Abstractions for Noisy Variational Quantum Algorithm Simulation CoRR, abs/2103.17226. https://arxiv.org/abs/2103.17226","Due to the unreliability and limited capacity of existing quantum computer prototypes, quantum circuit simulation continues to be a vital tool for validating next generation quantum computers and for studying variational quantum algorithms, which are among the leading candidates for useful quantum computation. Existing quantum circuit simulators do not address the common traits of variational algorithms, namely: 1) their ability to work with noisy qubits and operations, 2) their repeated execution of the same circuits but with different parameters, and 3) the fact that they sample from circuit final wavefunctions to drive a classical optimization routine. We present a quantum circuit simulation toolchain based on logical abstractions targeted for simulating variational algorithms. Our proposed toolchain encodes quantum amplitudes and noise probabilities in a probabilistic graphical model, and it compiles the circuits to logical formulas that support efficient repeated simulation of and sampling from quantum circuits for different parameters. Compared to state-of-the-art state vector and density matrix quantum circuit simulators, our simulation approach offers greater performance when sampling from noisy circuits with at least eight to 20 qubits and with around 12 operations on each qubit, making the approach ideal for simulating near-term variational quantum algorithms. And for simulating noise-free shallow quantum circuits with 32 qubits, our simulation approach offers a66√óreduction in sampling cost versus quantum circuit simulation techniques based on tensor network contraction.",1602
1517,Programming Languages,Steve Holtzen,"November 13th, 2020",Scaling Exact Inference for Discrete Probabilistic Programs,https://dl.acm.org/doi/10.1145/3428208," Steven Holtzen, Guy Van den Broeck, and Todd Millstein. 2020. Scaling exact inference for discrete probabilistic programs. Proc. ACM Program. Lang. 4, OOPSLA, Article 140 (November 2020), 31 pages. DOI:https://doi.org/10.1145/3428208","Probabilistic programming languages (PPLs) are an expressive means of representing and reasoning about probabilistic models. The computational challenge of probabilistic inference remains the primary roadblock for applying PPLs in practice. Inference is fundamentally hard, so there is no one-size-fits all solution. In this work, we target scalable inference for an important class of probabilistic programs: those whose probability distributions are discrete . Discrete distributions are common in many fields, including text analysis, network verification, artificial intelligence, and graph analysis, but they prove to be challenging for existing PPLs. We develop a domain-specific probabilistic programming language called Dice that features a new approach to exact discrete probabilistic program inference. Dice exploits program structure in order to factorize inference, enabling us to perform exact inference on probabilistic programs with hundreds of thousands of random variables. Our key technical contribution is a new reduction from discrete probabilistic programs to weighted model counting (WMC). This reduction separates the structure of the distribution from its parameters, enabling logical reasoning tools to exploit that structure for probabilistic inference. We (1) show how to compositionally reduce Dice inference to WMC, (2) prove this compilation correct with respect to a denotational semantics, (3) empirically demonstrate the performance benefits over prior approaches, and (4) analyze the types of structure that allow Dice to scale to large probabilistic programs.",1603
1518,Programming Languages,Steve Holtzen,"June 30th, 2019",Generating and Sampling Orbits for Lifted Probabilistic Inference,http://proceedings.mlr.press/v115/holtzen20a.html," Generating and Sampling Orbits for Lifted Probabilistic Inference Steven Holtzen, Todd Millstein, Guy Van den Broeck Proceedings of The 35th Uncertainty in Artificial Intelligence Conference, PMLR 115:985-994, 2020.",A key goal in the design of probabilistic inference algorithms is identifying and exploit- ing properties of the distribution that make inference tractable. Lifted inference algorithms identify symmetry as a property that enables efficient inference and seek to scale with the degree of symmetry of a probability model. A limitation of existing exact lifted inference techniques is that they do not apply to non- relational representations like factor graphs. In this work we provide the first example of an exact lifted inference algorithm for arbitrary discrete factor graphs. In addition we describe a lifted Markov-Chain Monte-Carlo algorithm that provably mixes rapidly in the degree of symmetry of the distribution.,1604
1519,Programming Languages,Steve Holtzen,"June 6th, 2018",Sound Abstraction and Decomposition of Probabilistic Programs,http://proceedings.mlr.press/v80/holtzen18a.html," Sound Abstraction and Decomposition of Probabilistic Programs. Steven Holtzen, Guy Van den Broeck, and Todd Millstein. In International Conference on Machine Learning (ICML), 2018.","Probabilistic programming languages are a flexible tool for specifying statistical models, but this flexibility comes at the cost of efficient analysis. It is currently difficult to compactly represent the subtle independence properties of a probabilistic program, and exploit independence properties to decompose inference. Classical graphical model abstractions do capture some properties of the underlying distribution, enabling inference algorithms to operate at the level of the graph topology. However, we observe that graph-based abstractions are often too coarse to capture interesting properties of programs. We propose a form of sound abstraction for probabilistic programs wherein the abstractions are themselves simplified programs. We provide a theoretical foundation for these abstractions, as well as an algorithm to generate them. Experimentally, we also illustrate the practical benefits of our framework as a tool to decompose probabilistic program inference.",1605
1520,Programming Languages,Chris Martens,"July 5th, 2024",Authoring Games with Tile Rewrite Rule Behavior Trees,https://doi.org/10.1145/3649921.3656979," Jiayi Zhou, Chris Martens , Seth Cooper. (2024). Authoring Games with Tile Rewrite Rule Behavior Trees FDG, 47. https://doi.org/10.1145/3649921.3656979","Game authoring can be a difficult, technical process; exploring new ways to describe games and game mechanics may help make game authoring more accessible. In this work, we present Tile Rewrite Rule Behavior Trees (TRRBTs): a concept for a domain-specific language for authoring tile-based, turn-based games. The approach combines tile rewrite rules and behavior trees. Using TRRBTs, a game‚Äôs state is represented as a grid of tiles, the behavior trees describe the overall flow of the game, and the rewrite rules at leaf nodes describe changes in game state. We include transform nodes, which apply transformations to other nodes in the behavior tree, allowing more complex mechanics to be expressed in a compact way. We demonstrate a text-based approach to using TRRBTs to create several simple games, show how the approach allows re-use of trees to build on existing games, and show how they can provide a unified representation for procedural content generation and enemy AI along with game mechanics.",1606
1521,Programming Languages,Chris Martens,"October 6th, 2023",Probabilistic Logic Programming Semantics For Procedural Content Generation,https://doi.org/10.1609/aiide.v19i1.27525," Abdelrahman Madkour, Chris Martens , Steven Holtzen, Casper Harteveld, Stacy Marsella. (2023). Probabilistic Logic Programming Semantics For Procedural Content Generation AIIDE, 295-305. https://doi.org/10.1609/aiide.v19i1.27525","Abstract Research in procedural content generation (PCG) has recently heralded two major methodologies: machine learning (PCGML) and declarative programming. The former shows promise by automating the specification of quality criteria through latent patterns in data, while the latter offers significant advantages for authorial control. In this paper we propose the use of probabilistic logic as a unifying framework that combines the benefits of both methodologies. We propose a Bayesian formalization of content generators as probability distributions and show how common PCG tasks map naturally to operations on the distribution. Further, through a series of experiments with maze generation, we demonstrate how probabilistic logic semantics allows us to leverage the authorial control of declarative programming and the flexibility of learning from data.",1607
1522,Programming Languages,Daniel Patterson,"August 31st, 2023",Semantic Encapsulation using Linking Types,https://doi.org/10.1145/3609027.3609405," Daniel Patterson , Andrew Wagner, Amal Ahmed . (2023). Semantic Encapsulation using Linking Types TyDe@ICFP, 14-28. https://doi.org/10.1145/3609027.3609405","Interoperability pervades nearly all mainstream language implementations, as most systems leverage subcomponents written in different languages. And yet, such linking can expose a language to foreign behaviors that are internally inexpressible, which poses a serious threat to safety invariants and programmer reasoning. To preserve such invariants, a language may try to add features to limit the reliance on external libraries, but endless extensions can obscure the core abstractions the language was designed to provide. In this paper, we outline an approach that encapsulates foreign code in a sound way‚Äîi.e., without disturbing the invariants promised by types of the core language. First, one introduces novel linking types that characterize the behaviors of foreign libraries that are inexpressible in the core language. To reason about the soundness of linking, one constructs a realizability model that captures the meaning of both core types and linking types as sets of target-language terms. Using this model, one can formally prove when foreign behavior is encapsulated ; that is, unobservable to core code. We show one way to discharge such proofs automatically by augmenting the compiler to insert verified encapsulation wrappers around components that use foreign libraries. Inspired by existing approaches to FFIs, we develop a pair of case studies that extend a pure, functional language: one extension for state, and another for exceptions. The first allows us to implement mutable references via a library, whereas the second allows us to implement try and catch as library functions. Both extensions and the overall system are proven sound using logical relations that use realizability techniques.",1608
1523,Programming Languages,Daniel Patterson,"June 9th, 2022",Semantic soundness for language interoperability,https://doi.org/10.1145/3519939.3523703," Daniel Patterson , Noble Mushtak, Andrew Wagner, Amal Ahmed . (2022). Semantic soundness for language interoperability PLDI, 609-624. https://doi.org/10.1145/3519939.3523703","Programs are rarely implemented in a single language, and thus questions of type soundness should address how it interacts with others. Even between type-safe languages, disparate features can frustrate interoperability. In this paper, we present a novel framework for the design and verification of sound language interoperability that follows an interoperation-after-compilation strategy.",1609
1524,Programming Languages,Daniel Patterson,"August 1st, 2019",The Next 700 Compiler Correctness Theorems (Functional Pearl),https://doi.org/10.1145/3341689," Daniel Patterson and Amal Ahmed. The Next 700 Compiler Correctness Theorems (Functional Pearl). In 24th ACM SIGPLAN International Conference on Functional Programming (ICFP '19), Berlin, Germany, August 2019.","Compiler correctness is an old problem, with results stretching back beyond the last half-century. Founding the field, John McCarthy and James Painter set out to build a ""completely trustworthy compiler"". And yet, until quite recently, even despite truly impressive verification efforts, the theorems being proved were only about the compilation of whole programs, a theoretically quite appealing but practically unrealistic simplification. For a compiler correctness theorem to assure complete trust, the theorem must reflect the reality of how the compiler will be used. There has been much recent work on more realistic ""compositional"" compiler correctness aimed at proving correct compilation of components while supporting linking with components compiled from different languages using different compilers. However, the variety of theorems, stated in remarkably different ways, raises questions about what researchers even mean by a ""compiler is correct."" In this pearl, we develop a new framework with which to understand compiler correctness theorems in the presence of linking, and apply it to understanding and comparing this diversity of results. In doing so, not only are we better able to assess their relative strengths and weaknesses, but gain insight into what we as a community should expect from compiler correctness theorems of the future.",1610
1525,Programming Languages,Olin Shivers,"August 31st, 2023",The Verse Calculus: A Core Calculus for Deterministic Functional Logic Programming,https://doi.org/10.1145/3607845," Lennart Augustsson, Joachim Breitner, Koen Claessen, Ranjit Jhala, Simon Peyton Jones, Olin Shivers, Guy L. Steele Jr., Tim Sweeney. (2023). The Verse Calculus: A Core Calculus for Deterministic Functional Logic Programming Proc. ACM Program. Lang., 7, 417-447. https://doi.org/10.1145/3607845","Functional logic languages have a rich literature, but it is tricky to give them a satisfying semantics. In this paper we describe the Verse calculus, VC, a new core calculus for deterministic functional logic programming. Our main contribution is to equip VC with a small-step rewrite semantics, so that we can reason about a VC program in the same way as one does with lambda calculus; that is, by applying successive rewrites to it. We also show that the rewrite system is confluent for well-behaved terms.",1611
1526,Programming Languages,Olin Shivers,"November 10th, 2022",3CPS: The Design of an Environment-Focussed Intermediate Representation,https://doi.org/10.1145/3544885.3544889," Benjamin Quiring, John H. Reppy, Olin Shivers. (2021). 3CPS: The Design of an Environment-Focussed Intermediate Representation IFL, 20-28. https://doi.org/10.1145/3544885.3544889","We describe the design of 3CPS, a compiler intermediate representation (IR) we have developed for use in compiling call-by-value functional languages such as SML, OCaml, Scheme, and Lisp. The language is a low-level form designed in tandem with a matching suite of static analyses. It reflects our belief that the core task of an optimising compiler for a functional language is to reason about the environment structure of the program. Our IR is distinguished by the presence of extent annotations, added to all variables (and verified by static analysis). These annotations are defined in terms of the semantics of the IR, but they directly tell the compiler what machine resources are needed to implement the environment structure of each annotated variable.",1612
1527,Programming Languages,Olin Shivers,"August 31st, 2022",Analyzing binding extent in 3CPS,https://doi.org/10.1145/3547645," Benjamin Quiring, John H. Reppy, Olin Shivers. (2022). Analyzing binding extent in 3CPS Proc. ACM Program. Lang., 6, 650-678. https://doi.org/10.1145/3547645","To date, the most effective approach to compiling strict, higher-order functional languages (such as OCaml, Scheme, and SML) has been to use whole-program techniques to convert the program to a first-order monomorphic representation that can be optimized using traditional compilation techniques. This approach, popularized by MLton, has limitations, however. We are interested in exploring a different approach to compiling such languages, one that preserves the higher-order and polymorphic character of the program throughout optimization. To enable such an approach, we must have effective analyses that both provide precise information about higher-order programs and that scale to larger units of compilation. This paper describes one such analysis for determining the extent of variable bindings. We classify the extent of variables as either register (only one binding instance can be live at any time), stack (the lifetimes of binding instances obey a LIFO order), or heap (binding lifetimes are arbitrary). These extents naturally connect variables to the machine resources required to represent them. We believe that precise information about binding extents will enable efficient management of environments, which is a key problem in the efficient compilation of higher-order programs. At the core of the paper is the 3CPS intermediate representation, which is a factored CPS-based intermediate representation (IR) that statically marks variables to indicate their binding extent. We formally specify the management of this binding structure by means of a small-step operational semantics and define a static analysis that determines the extents of the variables in a program. We evaluate our analysis using a standard suite of SML benchmark programs. Our implementation gets surprisingly high yield and exhibits scalable performance. While this paper uses a CPS-based IR, the algorithm and results are easily transferable to other Œª-calculus IRs, such as ANF.",1613
1528,Programming Languages,Frank Tip,"November 30th, 2023",Code Coverage Criteria for Asynchronous Programs,https://doi.org/10.1145/3611643.3616292," Mohammad Ganji, Saba Alimadadi, Frank Tip. (2023). Code Coverage Criteria for Asynchronous Programs ESEC/SIGSOFT FSE, 1307-1319. https://doi.org/10.1145/3611643.3616292","Asynchronous software often exhibits complex and error-prone behaviors that should be tested thoroughly. Code coverage has been the most popular metric to assess test suite quality. However, traditional code coverage criteria do not adequately reflect completion, interactions, and error handling of asynchronous operations. This paper proposes novel test adequacy criteria for measuring: (i) completion of asynchronous operations in terms of both successful and exceptional execution, (ii) registration of reactions for handling both possible outcomes, and (iii) execution of said reactions through tests. We implement JScope, a tool for automatically measuring coverage according to these criteria in JavaScript applications, as an interactive plug-in for Visual Studio Code. An evaluation of JScope on 20 JavaScript applications shows that the proposed criteria can help improve assessment of test adequacy, complementing traditional criteria. According to our investigation of 15 real GitHub issues concerned with asynchrony, the new criteria can help reveal faulty asynchronous behaviors that are untested yet are deemed covered by traditional coverage criteria. We also report on a controlled experiment with 12 participants to investigate the usefulness of JScope in realistic settings, demonstrating its effectiveness in improving programmers‚Äô ability to assess test adequacy and detect untested behavior of asynchronous code.",1614
1529,Programming Languages,Frank Tip,"November 8th, 2023",Increasing the Responsiveness of Web Applications by Introducing Lazy Loading,https://doi.org/10.1109/ASE56229.2023.00192," Alexi Turcotte, Satyajit Gokhale, Frank Tip. (2023). Increasing the Responsiveness of Web Applications by Introducing Lazy Loading ASE, 459-470. https://doi.org/10.1109/ASE56229.2023.00192","Front-end developers want their applications to contain no more code than is needed in order to minimize the amount of time that elapses between visiting a web page and the page becoming responsive. Support was added to JavaScript in 2020 when asynchronous, dynamic imports were added to the language standard. Unfortunately, migrating existing projects to take advantage of this feature is nontrivial, as the code changes required to introduce asynchrony may involve complex, non-local transformations. Our approach relies on static analysis to identify external packages that can be loaded lazily and generates the code transformations required to lazily load those packages. Since the static analysis is unsound, these transformations are presented as suggestions that programmers should review and test carefully.",1615
1530,Programming Languages,Frank Tip,"July 13th, 2023",That‚Äôs a Tough Call: Studying the Challenges of Call Graph Construction for WebAssembly,https://doi.org/10.1145/3597926.3598104," Daniel Lehmann , Michelle Thalakottur, Frank Tip, Michael Pradel. (2023). That's a Tough Call: Studying the Challenges of Call Graph Construction for WebAssembly ISSTA, 892-903. https://doi.org/10.1145/3597926.3598104","WebAssembly is a low-level bytecode format that powers applications and libraries running in browsers, on the server side, and in standalone runtimes. Call graphs are at the core of many interprocedural static analysis and optimization techniques. However, WebAssembly poses some unique challenges for static call graph construction. Currently, these challenges are neither well understood, nor is it clear to what extent existing techniques address them. This paper presents the first systematic study of WebAssembly-specific challenges for static call graph construction and of the state-of-the-art in call graph analysis. We identify and classify 12 challenges, encode them into a suite of 24 executable microbenchmarks, and measure their prevalence in real-world binaries. These challenges reflect idiosyncrasies of WebAssembly, such as indirect calls via a mutable function table, interactions with the host environment, and unmanaged linear memory. We show that they commonly occur across a set of more than 8,000 real-world binaries. Based on our microbenchmarks and a set of executable real-world binaries, we then study the soundness and precision of four existing static analyses. Our findings include that, surprisingly, all of the existing techniques are unsound, without this being documented anywhere. We envision our work to provide guidance for improving static call graph construction for WebAssembly. In particular, the presented microbenchmarks will enable future work to check whether an analysis supports challenging language features, and to quantify its soundness and precision.",1616
1531,Robotics,Robert Platt,"August 8th, 2024",Symmetric Models for Visual Force Policy Learning,https://doi.org/10.1109/ICRA57147.2024.10610728," Colin Kohler, Anuj Shrivatsav Srikanth, Eshan Arora, Robert Platt . (2024). Symmetric Models for Visual Force Policy Learning ICRA, 3101-3107. https://doi.org/10.1109/ICRA57147.2024.10610728",Symmetric Visual Force Learning (SVFL) is a novel method for robotic control which leverages visual and force feedback. We demonstrate that SVFL can significantly outperform state of the art baselines for visual force learning. We report several interesting empirical findings related to the utility of learning force feedback control policies in both general manipulation tasks and scenarios with low visual acuity.,1617
1532,Robotics,Robert Platt,"January 16th, 2024",Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D,https://openreview.net/forum?id=UulwvAU1W0," Haojie Huang, Owen Howell, Dian Wang , Xupeng Zhu, Robert Platt , Robin Walters . (2024). Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D ICLR. https://openreview.net/forum?id=UulwvAU1W0",FourTran is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks. The paper presents a novel approach in robotic manipulation using Wigner D-matrices for fast cross-correlations in 3D pick and place tasks.,1618
1533,Robotics,Robert Platt,"July 4th, 2023",SEIL: Simulation-augmented Equivariant Imitation Learning,https://doi.org/10.1109/ICRA48891.2023.10161252," Mingxi Jia, Dian Wang , Guanang Su, David Klee, Xupeng Zhu, Robin Walters, Robert Platt. (2023). SEIL: Simulation-augmented Equivariant Imitation Learning ICRA, 1845-1851. https://doi.org/10.1109/ICRA48891.2023.10161252","Simulation-augmented Equivariant Imitation Learning (SEIL) combines a novel augmentation strategy of supplementing expert trajectories with simulated transitions. SEIL can learn non-trivial manipulation tasks within ten demonstrations and outperform the baselines by a significant margin. IEEE Conference will be held in London, UK, on July 4, 2023.",1619
1534,Robotics,Robert Platt,"July 4th, 2023",Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection,https://doi.org/10.1109/ICRA48891.2023.10160728," Haojie Huang, Dian Wang , Xupeng Zhu, Robin Walters, Robert Platt. (2023). Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection ICRA, 3882-3888. https://doi.org/10.1109/ICRA48891.2023.10160728",The problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. Here we propose a novel method and neural network model that enables better grasp success rates. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions.,1620
1535,Robotics,Michael Everett,"December 6th, 2021",Reachability analysis of neural feedback loops,https://doi.org/10.1109/ACCESS.2021.3133370," M. Everett, G. Habibi, C. Sun and J. P. How. ""Reachability Analysis of Neural Feedback Loops."" In IEEE Access, vol. 9, pp. 163938-163953, 2021. DOI: 10.1109/ACCESS.2021.3133370.","This work focuses on estimating the forward reachable set of neural feedback loops (closed-loop systems with NN controllers) Recent work provides bounds on these reachable sets, but the computationally tractable approaches yield overly conservative bounds. The new framework is developed for systems with uncertainty (e.g., measurement and process noise) and nonlinearities. The objective is to ensure a system that starts in an initial set (yellow) ends in the goal set (green) a... Show More Published in: IEEE Access ( Volume: 9 ) Page(s): 163938 - 163953 Date of Publication: 06 December 2021 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2021.3133370",1621
1536,Robotics,Michael Everett,"January 8th, 2021",Collision avoidance in pedestrian-rich environments with deep reinforcement learning,https://doi.org/10.1109/ACCESS.2021.3050338," M. Everett, Y. F. Chen and J. P. How. ""Collision Avoidance in Pedestrian-Rich Environments With Deep Reinforcement Learning."" In IEEE Access, vol. 9, pp. 10357-10377, 2021. DOI: 10.1109/ACCESS.2021.3050338.","This work proposes using deep reinforcement (RL) learning as a framework to model the complex interactions and cooperation with nearby, decision-making agents. Existing RL-based works assume homogeneity of agent properties, use specific motion models over short timescales, or lack a principled method to handle a large, possibly varying number of agents. This work develops an algorithm that learns collision avoidance among a variety of heterogeneous, non-communicating, dynamic agents without assuming they follow any particular behavior rules. It extends our previous work by introducing a strategy using Long Short-Term Memory (LSTM) that enables the algorithm to use observations of an arbitrary number of other agents.",1622
1537,Robotics,Christopher Amato,"December 10th, 2024",SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html," Ethan Rathbun, Christopher Amato, Alina Oprea. (2024). SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/cb03b5108f1c3a38c990ef0b45bc8b31-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 37 (NeurIPS 2024) Main Conference Track Ethan Rathbun, Christopher Amato, Alina Oprea Reinforcement learning (RL) is an actively growing field that is seeing increased usage in real-world, safety-critical applications -- making it paramount to ensure the robustness of RL algorithms against adversarial attacks. In this work we explore a particularly stealthy form of training-time attacks against RL -- backdoor poisoning. Here the adversary intercepts the training of an RL agent with the goal of reliably inducing a particular action when the agent observes a pre-determined trigger at inference time. We uncover theoretical limitations of prior work by proving their inability to generalize across domains and MDPs. Motivated by this, we formulate a novel poisoning attack framework which interlinks the adversary's objectives with those of finding an optimal policy -- guaranteeing attack success in the limit. Using insights from our theoretical analysis we develop ""SleeperNets"" as a universal backdoor attack which exploits a newly proposed threat model and leverages dynamic reward poisoning techniques. We evaluate our attack in 6 environments spanning multiple domains and demonstrate significant improvements in attack success over existing methods, while preserving benign episodic return.",1623
1538,Robotics,Christopher Amato,"August 8th, 2024",Robot Navigation in Unseen Environments using Coarse Maps,https://doi.org/10.1109/ICRA57147.2024.10611256," Chengguang Xu, Christopher Amato, Lawson L. S. Wong. (2024). Robot Navigation in Unseen Environments using Coarse Maps ICRA, 2932-2938. https://doi.org/10.1109/ICRA57147.2024.10611256","Can an autonomous robot directly navigate in previously unseen environments using coarse maps? We propose the Coarse Map Navigator (CMN), a navigation framework that can perform robot navigation in unseen environments. Empirical results demonstrate that CMN achieves high navigation success rates in unseen. environments. The study was presented at the 2024 IEEE International Conference on Robotics and Automation (ICRA) in Yokohama, Japan. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",1624
1539,Robotics,Christopher Amato,"December 13th, 2023",On-Robot Bayesian Reinforcement Learning for POMDPs,https://doi.org/10.1109/IROS55552.2023.10342114," Hai Nguyen, Sammie Katt, Yuchen Xiao, Christopher Amato. (2023). On-Robot Bayesian Reinforcement Learning for POMDPs IROS, 9480-9487. https://doi.org/10.1109/IROS55552.2023.10342114","Bayesian reinforcement learning (BRL) is uniquely positioned as such a solution method. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach can, for example, utilize typical low-level robot simulators and handle uncertainty over unknown dynamics of the environment. We empirically demonstrate its efficiency by performing on-robot learning in two human-ro Bot interaction tasks with uncertainty about human behavior, achieving near-optimal performance after only a handful of real-world episodes.",1625
1540,Robotics,Christopher Amato,"May 31st, 2023",Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning,https://proceedings.mlr.press/v202/daley23a.html," Brett Daley, Martha White, Christopher Amato, Marlos C. Machado. (2023). Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning ICML, 6818-6835. https://proceedings.mlr.press/v202/daley23a.html","Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across Œª Œª -values in an off-policy control task.",1626
1541,Robotics,Christopher Amato,"June 28th, 2022",A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning,https://ojs.aaai.org/index.php/AAAI/article/view/21171," Xueguang Lyu, Andrea Baisero, Yuchen Xiao, Christopher Amato. (2022). A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning AAAI, 9396-9404. https://ojs.aaai.org/index.php/AAAI/article/view/21171","Abstract Centralized Training for Decentralized Execution, where training is done in a centralized offline fashion, has become a popular solution paradigm in Multi-Agent Reinforcement Learning. Many such methods take the form of actor-critic with state-based critics, since centralized training allows access to the true system state, which can be useful during training despite not being available at execution time. State-based critics have become a common empirical choice, albeit one which has had limited theoretical justification or analysis. In this paper, we show that state-based critics can introduce bias in the policy gradient estimates, potentially undermining the asymptotic guarantees of the algorithm. We also show that, even if the state-based critics do not introduce any bias, they can still result in a larger gradient variance, contrary to the common intuition. Finally, we show the effects of the theories in practice by comparing different forms of centralized critics on a wide range of common benchmarks, and detail how various environmental properties are related to the effectiveness of different types of critics.",1627
1542,Robotics,Christopher Amato,"August 11th, 2021",Reconciling Rewards with Predictive State Representations,https://doi.org/10.24963/ijcai.2021/299," Andrea Baisero, Christopher Amato. (2021). Reconciling Rewards with Predictive State Representations IJCAI, 2170-2176. https://doi.org/10.24963/ijcai.2021/299","Copyright ¬© 2025,",1628
1543,Robotics,Christopher Amato,"January 1st, 2020",To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots,https://doi.org/10.1109/IROS45743.2020.9341607," Balint Gucsi, Danesh S. Tarapore, William Yeoh , Christopher Amato, Long Tran-Thanh. (2020). To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots IROS, 7935-7940. https://doi.org/10.1109/IROS45743.2020.9341607","Social robots can efficiently gather user preferences without exceeding the allowed user annoyance threshold. To do so, we use a Gazebo based simulated office environment with a TIAGo Steel robot. We then test our approach on the aforementioned simulated environment and demonstrate that it can accurately estimate user preferences.",1629
1544,Robotics,Christopher Amato,"September 19th, 2019",Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net,https://arxiv.org/abs/1909.08776," Xiao, Yuchen & Hoffman, Joshua & Xia, Tian & Amato, Christopher. (2020). Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net.","In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec-MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near-centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.",1630
1545,Robotics,Megan Hofmann,"October 11th, 2024",KODA: Knit-program Optimization by Dependency Analysis,https://doi.org/10.1145/3654777.3676405," Megan Hofmann. (2024). KODA: Knit-program Optimization by Dependency Analysis UIST, 64:1-64:15. https://doi.org/10.1145/3654777.3676405","Digital knitting machines have the capability to reliably manufacture seamless, textured, and multi-material garments, but these capabilities are obscured by limiting CAD tools. Recent innovations in computational knitting build on emerging programming infrastructure that gives full access to the machine‚Äôs capabilities but requires an extensive understanding of machine operations and execution. In this paper, we contribute a critical missing piece of the knitting-machine programming pipeline‚Äìa program optimizer. Program optimization allows programmers to focus on developing novel algorithms that produce desired fabrics while deferring concerns of efficient machine operations to the optimizer. We present KODA, the Knit-program Optimization by Dependency Analysis method. KODA re-orders and reduces machine instructions to reduce knitting time, increase knitting reliability, and manage boilerplate operations that adjust the machine state. The result is a system that enables programmers to write readable and intuitive knitting algorithms while producing efficient and verified programs.",1631
1546,Robotics,Megan Hofmann,"April 29th, 2022",Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs,https://doi.org/10.1145/3491102.3517436," Megan Hofmann, Kelly Mack, Jessica Birchfield, Jerry Cao, Autumn G Hughes, Shriya Kurpad, Kathryn J Lum, Emily Warnock, Anat Caspi, Scott E Hudson, and Jennifer Mankoff. (2022). ""Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs"". In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 592, 1‚Äì15. DOI: 10.1145/3491102.3517436","Tactile maps can help people who are blind or have low-vision navigate and familiarize themselves with unfamiliar locations. Ideally, tactile maps can be customized to an individual‚Äôs unique needs and abilities because of their limited space for representation. We present Maptimizer, a tool that generates tactile maps based on users‚Äô preferences and requirements. Maptimizer uses a two stage optimization process to pair representations with geographic information and tune those representations to present that information more clearly. In a small user study, Maptimizer helped participants more successfully and efficiently identify locations of interest in unknown areas. These results demonstrate the utility of optimization techniques and generative design in complex accessibility domains.",1632
1547,Robotics,Megan Hofmann,"April 7th, 2022",Making a Medical Maker‚Äôs Playbook: An Ethnographic Study of Safety-Critical Collective Design by Makers in Response to COVID-19,https://doi.org/10.1145/3512948," Megan Hofmann, Udaya Lakshmi, Kelly Mack, Rosa I. Arriaga, Scott E. Hudson, and Jennifer Mankoff. (2022). ""Making a Medical Maker's Playbook: An Ethnographic Study of Safety-Critical Collective Design by Makers in Response to COVID-19"". Proc. ACM Hum.-Comput. Interact. 6, CSCW1, Article 101 (April 2022), 26 pages. DOI: 10.1145/3512948","We present an ethnographic study of a maker community that conducted safety-driven medical making to deliver over 80,000 devices for use at medical facilities in response to the COVID-19 pandemic. To achieve this, the community had to balance their clinical value of safety with the maker value of broadened participation in design and production. We analyse their struggles and achievement through the artifacts they produced and the labors of key facilitators between diverse community members. Based on this analysis we provide insights into how medical maker communities, which are necessarily risk-averse and safety-oriented, can still support makers' grassroots efforts to care for their communities. Based on these findings, we recommend that design tools enable adaptation to a wider set of domains, rather than exclusively presenting information relevant to manufacturing. Further, we call for future work on the portability of designs across different types of printers which could enable broader participation in future maker efforts at this scale.",1633
1548,Robotics,Huaizu Jiang,"December 25th, 2024","NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices",https://doi.org/10.1109/IROS58592.2024.10802353," Zhiyong Zhang, Huaizu Jiang, Hanumant Singh. (2024). NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices IROS, 5048-5055. https://doi.org/10.1109/IROS58592.2024.10802353","Real-time high-accuracy optical flow estimation is a crucial component in various applications, including localization and mapping in robotics. While recent learning-based optical flow methods have achieved high accuracy, they often come with heavy computation costs. We propose a highly efficient optical flow architecture, called NeuFlow, that addresses both high accuracy and computational cost concerns. We achieve a notable 10-80 speedup compared to several state-of-the-art methods, while maintaining comparable accuracy. Our approach achieves around 30 FPS on edge computing platforms, which represents a significant breakthrough in deploying complex computer vision tasks.",1634
1549,Robotics,Huaizu Jiang,"September 30th, 2024",SMooDi: Stylized Motion Diffusion Model,https://doi.org/10.1007/978-3-031-73232-4_23," Lei Zhong, Yiming Xie, Varun Jampani, Deqing Sun, Huaizu Jiang. (2024). SMooDi: Stylized Motion Diffusion Model ECCV (1), 405-421. https://doi.org/10.1007/978-3-031-73232-4_23","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1635
1550,Robotics,Huaizu Jiang,"September 16th, 2024",Zero-Shot Referring Expression Comprehension via Structural Similarity Between Images and Captions,https://doi.org/10.1109/CVPR52733.2024.01362," Zeyu Han, Fangrui Zhu, Qianru Lao, Huaizu Jiang. (2024). Zero-Shot Referring Expression Comprehension via Structural Similarity Between Images and Captions CVPR, 14364-14375. https://doi.org/10.1109/CVPR52733.2024.01362","Zero-shot referring expression comprehension aims at localizing bounding boxes in an image corresponding to provided textual prompts. We leverage large foundation models to disentangle both images and texts into triplets in the for-mat of (subject, predicate, object) After that, grounding is accomplished by calculating the structural similarity matrix between visual and textual triplets with a VLA model. Experiments demonstrate that our visual grounding performance increase of up to 19.5% over the SOTA zero-shot model on RefCOCO/g.",1636
1551,Robotics,Huaizu Jiang,"January 16th, 2024",OmniControl: Control Any Joint at Any Time for Human Motion Generation,https://openreview.net/forum?id=gd0lAEtWso," Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, Huaizu Jiang. (2024). OmniControl: Control Any Joint at Any Time for Human Motion Generation ICLR. https://openreview.net/forum?id=gd0lAEtWso","OmniControl is a novel approach for incorporating flexible spatial control signals into a text-conditioned human motion generation model. The method employs spatial and realism guidance in an effort to achieve a balance between motion that is both accurate and natural. One limitation of the method is the relatively high cost of inference, which several reviewers point out.",1637
1552,Robotics,Huaizu Jiang,"January 15th, 2024",Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection,https://doi.org/10.1109/ICCV51070.2023.01684," Yiming Xie, Huaizu Jiang, Georgia Gkioxari, Julian Straub. (2023). Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection ICCV, 18324-18334. https://doi.org/10.1109/ICCV51070.2023.01684",Parq is a multi-view 3D object detector with transformer and pixel-aligned recurrent queries. PARQ outperforms prior best methods on the ScanNet and ARKitScenes datasets. Code is available on GitHub at http://www.ymingxi.com/parq.,1638
1553,Robotics,Huaizu Jiang,"July 4th, 2023",StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks,https://doi.org/10.1109/ICRA48891.2023.10160924," Hongyu Li, Zhengang Li, Neset √únver Akmandor, Huaizu Jiang, Yanzhi Wang, Taskin Padir. (2023). StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks ICRA, 4826-4833. https://doi.org/10.1109/ICRA48891.2023.10160924"," Obstacle detection is a safety-critical problem in robot navigation, where stereo matching is a popular vision-based approach. This paper proposes a computationally efficient method that employs a deep neural network to detect occupancy from stereo images directly. Instead of learning the point cloud correspondence from the stereo data, our approach extracts the compact obstacle distribution based on volumetric representations. Our approach detects obstacles accurately in the range of 32 meters and achieves better IoU (Intersection over Union) and CD (Chamfer Distance) scores with only 2% of the computation cost of the state-of-the-art stereo model.",1639
1554,Robotics,Huaizu Jiang,"September 27th, 2022",PlanarRecon: Realtime 3D Plane Detection and Reconstruction from Posed Monocular Videos,https://doi.org/10.1109/CVPR52688.2022.00612," Yiming Xie, Matheus Gadelha, Fengting Yang, Xiaowei Zhou, Huaizu Jiang. (2022). PlanarRecon: Realtime 3D Plane Detection and Reconstruction from Posed Monocular Videos CVPR, 6209-6218. https://doi.org/10.1109/CVPR52688.2022.00612","PlanarRecon is a novel framework for globally coherent detection and reconstruction of 3D planes from a posed monocular video. It incrementally detects planes in 3D for each video fragment, which consists of a set of key frames, from a volumetric representation of the scene using neural networks. Experiments show that the proposed approach achieves state-of-the-art performances on the ScanNet dataset while being real-time.",1640
1555,Robotics,Huaizu Jiang,"September 27th, 2022",Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions,https://doi.org/10.1109/CVPR52688.2022.01847," Huaizu Jiang, Xiaojian Ma, Weili Nie, Zhiding Yu, Yuke Zhu, Anima Anandkumar. (2022). Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions CVPR, 19034-19043. https://doi.org/10.1109/CVPR52688.2022.01847","A significant gap remains between today's visual pattern recognition models and humanlevel visual cognition. We introduce Bongard-HOI, a new visual reasoning benchmark that focuses on compositional learning of humanobject interactions (HOIs) from natural images. The state-of-the-art HOI detection model achieves only 62% accuracy on fewshot binary prediction while even amateur human testers on MTurk have 91% accuracy. We hope to further advance research efforts in visual reasoning, especially in holistic perception-reasoning systems and better representation learning.",1641
1556,Robotics,Huaizu Jiang,"January 1st, 2020",In Defense of Grid Features for Visual Question Answering,https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_In_Defense_of_Grid_Features_for_Visual_Question_Answering_CVPR_2020_paper.html," Huaizu Jiang, Ishan Misra, Marcus Rohrbach, Erik G. Learned-Miller, Xinlei Chen. (2020). In Defense of Grid Features for Visual Question Answering CVPR, 10264-10273. https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_In_Defense_of_Grid_Features_for_Visual_Question_Answering_CVPR_2020_paper.html","Popularized as `bottom-up' attention, bounding box (or region) based visual features have recently surpassed vanilla grid-based convolutional features as the de facto standard for vision and language tasks like visual question answering (VQA). However, it is not clear whether the advantages of regions (e.g. better localization) are the key reasons for the success of bottom-up attention. In this paper, we revisit grid features for VQA, and find they can work surprisingly well -- running more than an order of magnitude faster with the same accuracy (e.g. if pre-trained in a similar fashion). Through extensive experiments, we verify that this observation holds true across different VQA models (reporting a state-of-the-art accuracy on VQA 2.0 test-std, 72.71), datasets, and generalizes well to other tasks like image captioning. As grid features make the model design and training process much simpler, this enables us to train them end-to-end and also use a more flexible network design. We learn VQA models end-to-end, from pixels directly to answers, and show that strong performance is achievable without using any region annotations in pre-training. We hope our findings help further improve the scientific understanding and the practical application of VQA. Code and features will be made available.",1642
1557,Robotics,Huaizu Jiang,"January 1st, 2019",Automatic Adaptation of Object Detectors to New Domains Using Self-Training,http://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html," Aruni RoyChowdhury, Prithvijit Chakrabarty, Ashish Singh, SouYoung Jin, Huaizu Jiang, Liangliang Cao, Erik G. Learned-Miller. (2019). Automatic Adaptation of Object Detectors to New Domains Using Self-Training CVPR, 780-790. http://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html","This work addresses the unsupervised adaptation of an existing object detector to a new target domain. We assume that a large number of unlabeled videos from this domain are readily available. We automatically obtain labels on the target data by using high-confidence detections from the existing detector, augmented with hard (misclassified) examples acquired by exploiting temporal cues using a tracker. These automatically-obtained labels are then used for re-training the original model. A modified knowledge distillation loss is proposed, and we investigate several ways of assigning soft-labels to the training examples from the target domain. Our approach is empirically evaluated on challenging face and pedestrian detection tasks: a face detector trained on WIDER-Face, which consists of high-quality images crawled from the web, is adapted to a large-scale surveillance data set; a pedestrian detector trained on clear, daytime images from the BDD-100K driving data set is adapted to all other scenarios such as rainy, foggy, night-time. Our results demonstrate the usefulness of incorporating hard examples obtained from tracking, the advantage of using soft-labels via distillation loss versus hard-labels, and show promising performance as a simple method for unsupervised domain adaptation of object detectors, with minimal dependence on hyper-parameters.",1643
1558,Robotics,Robin Walters,"June 16th, 2024",Improving Convergence and Generalization Using Parameter Symmetries,https://openreview.net/forum?id=L0r0GphlIL," Bo Zhao, Robert M. Gower, Robin Walters , Rose Yu. (2024). Improving Convergence and Generalization Using Parameter Symmetries ICLR. https://openreview.net/forum?id=L0r0GphlIL","In many neural networks, different values of the parameters may result in the same loss value. We show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization. The reviewers are unanimous that this is a good submission and that it should be accepted.",1644
1559,Robotics,Robin Walters,"May 1st, 2024",Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution,https://openreview.net/forum?id=59oXyDTLJv," Rui Wang , Elyssa F. Hofgard, Hang Gao , Robin Walters , Tess E. Smidt. (2024). Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution ICML. https://openreview.net/forum?id=59oXyDTLJv","Modeling symmetry breaking is essential for understanding the fundamental changes in the behaviors and properties of physical systems, from microscopic particle interactions to macroscopic phenomena like fluid dynamics and cosmic structures. Thus, identifying sources of asymmetry is an important tool for understanding physical systems. In this paper, we focus on learning asymmetries of data using relaxed group convolutions. We provide both theoretical and empirical evidence that this flexible convolution technique allows the model to maintain the highest level of equivariance that is consistent with data and discover the subtle symmetry-breaking factors in various physical systems. We employ various relaxed group convolution architectures to uncover various symmetry-breaking factors that are interpretable and physically meaningful in different physical systems, including the phase transition of crystal structure, the isotropy and homogeneity breaking in turbulent flow, and the time-reversal symmetry breaking in pendulum systems. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",1645
1560,Robotics,Robin Walters,"May 1st, 2024",Latent Space Symmetry Discovery,https://openreview.net/forum?id=qstt2OguvM," Jianke Yang, Nima Dehmamy, Robin Walters , Rose Yu. (2024). Latent Space Symmetry Discovery ICML. https://openreview.net/forum?id=qstt2OguvM","Equivariant neural networks require explicit knowledge of the symmetry group. Automatic symmetry discovery methods aim to relax this constraint and learn invariance and equivariance from data. However, existing symmetry discovery methods are limited to simple linear symmetries and cannot handle the complexity of real-world data. We propose a novel generative model, Latent LieGAN (LaLiGAN), which can discover symmetries of nonlinear group actions. It learns a mapping from the data space to a latent space where the symmetries become linear and simultaneously discovers symmetries in the latent space. Theoretically, we show that our model can express nonlinear symmetries under some conditions about the group action. Experimentally, we demonstrate that our method can accurately discover the intrinsic symmetry in high-dimensional dynamical systems. LaLiGAN also results in a well-structured latent space that is useful for downstream tasks including equation discovery and long-term forecasting. OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . ¬© 2025 OpenReview Enter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository: Report an issue",1646
1561,Robotics,Robin Walters,"January 16th, 2024",Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D,https://openreview.net/forum?id=UulwvAU1W0," Haojie Huang, Owen Howell, Dian Wang , Xupeng Zhu, Robert Platt , Robin Walters . (2024). Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D ICLR. https://openreview.net/forum?id=UulwvAU1W0",FourTran is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks. The paper presents a novel approach in robotic manipulation using Wigner D-matrices for fast cross-correlations in 3D pick and place tasks.,1647
1562,Robotics,Robin Walters,"July 4th, 2023",SEIL: Simulation-augmented Equivariant Imitation Learning,https://doi.org/10.1109/ICRA48891.2023.10161252," Mingxi Jia, Dian Wang , Guanang Su, David Klee, Xupeng Zhu, Robin Walters, Robert Platt. (2023). SEIL: Simulation-augmented Equivariant Imitation Learning ICRA, 1845-1851. https://doi.org/10.1109/ICRA48891.2023.10161252","Simulation-augmented Equivariant Imitation Learning (SEIL) combines a novel augmentation strategy of supplementing expert trajectories with simulated transitions. SEIL can learn non-trivial manipulation tasks within ten demonstrations and outperform the baselines by a significant margin. IEEE Conference will be held in London, UK, on July 4, 2023.",1648
1563,Robotics,Robin Walters,"July 4th, 2023",Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection,https://doi.org/10.1109/ICRA48891.2023.10160728," Haojie Huang, Dian Wang , Xupeng Zhu, Robin Walters, Robert Platt. (2023). Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection ICRA, 3882-3888. https://doi.org/10.1109/ICRA48891.2023.10160728",The problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. Here we propose a novel method and neural network model that enables better grasp success rates. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions.,1649
1564,Robotics,Robin Walters,"February 1st, 2023",Generative Adversarial Symmetry Discovery,https://doi.org/10.48550/arXiv.2302.00236," Jianke Yang, Robin Walters, Nima Dehmamy, Rose Yu. (2023). Generative Adversarial Symmetry Discovery CoRR, abs/2302.00236. https://doi.org/10.48550/arXiv.2302.00236","Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation groupSO(n), restricted Lorentz groupSO(1,3)+in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.",1650
1565,Robotics,Robin Walters,"July 17th, 2022",Toward Compositional Generalization in Object-Oriented World Modeling,https://proceedings.mlr.press/v162/zhao22b.html," Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2022). Toward Compositional Generalization in Object-Oriented World Modeling ICML, 26841-26864. https://proceedings.mlr.press/v162/zhao22b.html","Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves soft but more efficient compositional generalization.",1651
1566,Robotics,Robin Walters,"May 4th, 2022",Probabilistic Symmetry for Multi-Agent Dynamics,https://proceedings.mlr.press/v211/sun23a.html," Sophia Huiwen Sun, Robin Walters, Jinxi Li, Rose Yu. (2023). Probabilistic Symmetry for Multi-Agent Dynamics L4DC, 1231-1244. https://proceedings.mlr.press/v211/sun23a.html","Learning multi-agent dynamics is a core AI problem with broad applications in robotics and autonomous driving. While most existing works focus on deterministic prediction, producing probabilistic forecasts to quantify uncertainty and assess risks is critical for downstream decision-making tasks such as motion planning and collision avoidance. Multi-agent dynamics often contains internal symmetry. By leveraging symmetry, specifically rotation equivariance, we can improve not only the prediction accuracy but also uncertainty calibration. We introduce Energy Score, a proper scoring rule, to evaluate probabilistic predictions. We propose a novel deep dynamics model, Probabilistic Equivariant Continuous COnvolution (PECCO) for probabilistic prediction of multi-agent trajectories. PECCO extends equivariant continuous convolution to model the joint velocity distribution of multiple agents. It uses dynamics integration to propagate the uncertainty from velocity to position. On both synthetic and real-world datasets, PECCO shows significant improvements in accuracy and calibration compared to non-equivariant baselines.",1652
1567,Robotics,Robin Walters,"January 1st, 2022",Learning Symmetric Embeddings for Equivariant World Models,https://proceedings.mlr.press/v162/park22a.html," Jung Yeon Park, Ondrej Biza, Linfeng Zhao, Jan-Willem van de Meent, Robin Walters. (2022). Learning Symmetric Embeddings for Equivariant World Models ICML, 17372-17389. https://proceedings.mlr.press/v162/park22a.html","Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.",1653
1568,Robotics,Lawson Wong,"August 8th, 2024",A Hierarchical Framework for Robot Safety using Whole-body Tactile Sensors,https://doi.org/10.1109/ICRA57147.2024.10610834," Shuo Jiang, Lawson L. S. Wong. (2024). A Hierarchical Framework for Robot Safety using Whole-body Tactile Sensors ICRA, 8021-8028. https://doi.org/10.1109/ICRA57147.2024.10610834","Using tactile signal is a natural way to perceive potential dangers and safeguard robots. One possible method is to use full-body tactile sensors on the robot and perform safety maneuvers when dangerous stimuli are detected. The results showed that our system dramatically reduced the overall collision chance compared with several baselines, and intelligently handled current collisions. Our proposed framework is generalizable to a wide variety of robots, enabling them to predict and avoid dangerous collisions.",1654
1569,Robotics,Lawson Wong,"August 8th, 2024",Robot Navigation in Unseen Environments using Coarse Maps,https://doi.org/10.1109/ICRA57147.2024.10611256," Chengguang Xu, Christopher Amato, Lawson L. S. Wong. (2024). Robot Navigation in Unseen Environments using Coarse Maps ICRA, 2932-2938. https://doi.org/10.1109/ICRA57147.2024.10611256","Can an autonomous robot directly navigate in previously unseen environments using coarse maps? We propose the Coarse Map Navigator (CMN), a navigation framework that can perform robot navigation in unseen environments. Empirical results demonstrate that CMN achieves high navigation success rates in unseen. environments. The study was presented at the 2024 IEEE International Conference on Robotics and Automation (ICRA) in Yokohama, Japan. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.",1655
1570,Robotics,Lawson Wong,"August 8th, 2024",Snake Robot with Tactile Perception Navigates on Large-scale Challenging Terrain,https://doi.org/10.1109/ICRA57147.2024.10611384," Shuo Jiang, Adarsh Salagame, Alireza Ramezani, Lawson L. S. Wong. (2024). Snake Robot with Tactile Perception Navigates on Large-scale Challenging Terrain ICRA, 5090-5096. https://doi.org/10.1109/ICRA57147.2024.10611384","This study proposed a locomotion control framework for snake robots that integrates tactile perception to augment their adaptability to various terrains. Our approach embraces a hierarchical reinforcement learning (HRL) architecture, wherein the high-level orchestrates global navigation strategies and the low-level uses curriculum learning for local navigation maneuvers. We evaluated the navigation performance of the snake robot in complex large-scale cave exploration with challenging terrains to exhibit improvements in motion efficiency.",1656
1571,Robotics,Lawson Wong,"October 30th, 2023",Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing,http://papers.nips.cc/paper_files/paper/2023/hash/317470b3fde29f3bb8d6dee563afffc4-Abstract-Conference.html," Jung Yeon Park, Lawson L. S. Wong, Robin Walters. (2023). Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing NeurIPS. http://papers.nips.cc/paper_files/paper/2023/hash/317470b3fde29f3bb8d6dee563afffc4-Abstract-Conference.html","Part of Advances in Neural Information Processing Systems 36 (NeurIPS 2023) Main Conference Track Jung Yeon Park, Lawson Wong, Robin Walters Data over non-Euclidean manifolds, often discretized as surface meshes, naturally arise in computer graphics and biological and physical systems. In particular, solutions to partial differential equations (PDEs) over manifolds depend critically on the underlying geometry. While graph neural networks have been successfully applied to PDEs, they do not incorporate surface geometry and do not consider local gauge symmetries of the manifold. Alternatively, recent works on gauge equivariant convolutional and attentional architectures on meshes leverage the underlying geometry but underperform in modeling surface PDEs with complex nonlinear dynamics. To address these issues, we introduce a new gauge equivariant architecture using nonlinear message passing. Our novel architecture achieves higher performance than either convolutional or attentional networks on domains with highly complex and nonlinear dynamics. However, similar to the non-mesh case, design trade-offs favor convolutional, attentional, or message passing networks for different tasks; we investigate in which circumstances our message passing method provides the most benefit.",1657
1572,Robotics,Lawson Wong,"December 26th, 2022",Active Tactile Exploration using Shape-Dependent Reinforcement Learning,https://doi.org/10.1109/IROS47612.2022.9982266," Shuo Jiang, Lawson L. S. Wong. (2022). Active Tactile Exploration using Shape-Dependent Reinforcement Learning IROS, 8995-9002. https://doi.org/10.1109/IROS47612.2022.9982266", Tactile signals provide rich information about objects via touch and are essential for a robot to perform dex-terous manipulation. Exploring actively via tactile perception collects important information about the workspace. The Shape-Belief Encoder leverages the newly collected contact points to update the surface model and guides future exploration. We validate the proposed algorithm on simulated and real robots. The paper will be presented at the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1658
1573,Robotics,Lawson Wong,"July 17th, 2022",Toward Compositional Generalization in Object-Oriented World Modeling,https://proceedings.mlr.press/v162/zhao22b.html," Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2022). Toward Compositional Generalization in Object-Oriented World Modeling ICML, 26841-26864. https://proceedings.mlr.press/v162/zhao22b.html","Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves soft but more efficient compositional generalization.",1659
1574,Robotics,Lawson Wong,"November 18th, 2020",Hierarchical Robot Navigation in Novel Environments Using Rough 2-D Maps,https://corlconf.github.io/corl2020/paper_442/," Xu, Chengguang, Chris Amato and Lawson L. S. Wong. ‚ÄúHierarchical Robot Navigation in Novel Environments using Rough 2-D Maps.‚Äù ArXiv abs/2106.03665 (2021): n. pag.",Abstract,1660
1575,Robotics,Lawson Wong,"October 11th, 2020",Deep Imitation Learning for Bimanual Robotic Manipulation,https://proceedings.neurips.cc/paper/2020/hash/18a010d2a9813e91907ce88cd9143fdf-Abstract.html," Xie, Fan, A. M. Masum Bulbul Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson L. S. Wong and Rose Yu. ‚ÄúDeep Imitation Learning for Bimanual Robotic Manipulation.‚Äù ArXiv abs/2010.05134 (2020): n. pag.","Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) Fan Xie, Alexander Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson Wong, Rose Yu We present a deep imitation learning framework for robotic bimanual manipulation in a continuous state-action space. A core challenge is to generalize the manipulation skills to objects in different locations. We hypothesize that modeling the relational information in the environment can significantly improve generalization. To achieve this, we propose to (i) decompose the multi-modal dynamics into elemental movement primitives, (ii) parameterize each primitive using a recurrent graph neural network to capture interactions, and (iii) integrate a high-level planner that composes primitives sequentially and a low-level controller to combine primitive dynamics and inverse kinematics control. Our model is a deep, hierarchical, modular architecture. Compared to baselines, our model generalizes better and achieves higher success rates on several simulated bimanual robotic manipulation tasks. We open source the code for simulation, data, and models at: https://github.com/Rose-STL-Lab/HDR-IL.",1661
1576,Software Engineering,Jonathan Bell,"September 11th, 2024",An Empirical Examination of Fuzzer Mutator Performance,https://doi.org/10.1145/3650212.3680387," James Kukucka, Lu√≠s Pina, Paul Ammann, Jonathan Bell . (2024). An Empirical Examination of Fuzzer Mutator Performance ISSTA, 1631-1642. https://doi.org/10.1145/3650212.3680387","Over the past decade, hundreds of fuzzers have been published in top-tier security and software engineering conferences. Fuzzers are used to automatically test programs, ideally creating high-coverage input corpora and finding bugs. Modern ‚Äúgreybox‚Äù fuzzers evolve a corpus of inputs by applying mutations to inputs and then executing those new inputs while collecting coverage. New inputs that are ‚Äúinteresting‚Äù (e.g. reveal new coverage) are saved to the corpus. Given their non-deterministic nature, the impact of each design decision on the fuzzer‚Äôs performance can be difficult to predict. Some design decisions (e.g., ‚Äù Should the fuzzer perform deterministic mutations of inputs? ‚Äù) are exposed to end-users as configuration flags, but others (e.g., ‚Äù What kinds of random mutations to apply to inputs?‚Äù) are typically baked into the fuzzer code itself. This paper describes our over 12.5-CPU-year evaluation of the set of mutation operators employed by the popular AFL++ fuzzer, including the havoc phase, splicing, and, exploring the impact of adjusting some of those unexposed configurations. In this experience paper, we propose a methodology for determining different fuzzers‚Äô behavioral diversity with respect to branch coverage and bug detection using rigorous statistical methods. Our key finding is that, across a range of targets, disabling certain mutation operators (some of which were previously ‚Äúbaked-in‚Äù to the fuzzer) resulted in inputs that cover different lines of code and reveal different bugs. A surprising result is disabling certain mutators leads to more diverse coverage and allows the fuzzer to find more bugs faster . We call for researchers to investigate seemingly simple design decisions in fuzzers more thoroughly and encourage fuzzer developers to expose more configuration parameters pertaining to these design decisions to end users.",1662
1577,Software Engineering,Jonathan Bell,"April 12th, 2024",Crossover in Parametric Fuzzing,https://doi.org/10.1145/3597503.3639160," Katherine Hough, Jonathan Bell . (2024). Crossover in Parametric Fuzzing ICSE, 129:1-129:12. https://doi.org/10.1145/3597503.3639160","Parametric fuzzing combines evolutionary and generator-based fuzzing to create structured test inputs that exercise unique execution behaviors. Parametric fuzzers internally represent inputs as bit strings referred to as ""parameter sequences"". Interesting parameter sequences are saved by the fuzzer and perturbed to create new inputs without the need for type-specific operators. However, existing work on parametric fuzzing only uses mutation operators, which modify a single input; it does not incorporate crossover, an evolutionary operator that blends multiple inputs together. Crossover operators aim to combine advantageous traits from multiple inputs. However, the nature of parametric fuzzing limits the effectiveness of traditional crossover operators. In this paper, we propose linked crossover, an approach for using dynamic execution information to identify and exchange analogous portions of parameter sequences. We created an implementation of linked crossover for Java and evaluated linked crossover's ability to preserve advantageous traits. We also evaluated linked crossover's impact on fuzzer performance on seven real-world Java projects and found that linked crossover consistently performed as well as or better than three state-of-the-art parametric fuzzers and two other forms of crossover on both long and short fuzzing campaigns.",1663
1578,Software Engineering,Jonathan Bell,"September 24th, 2023","‚ÄúAlways Nice and Confident, Sometimes wrong‚Äù: Developer‚Äôs Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms",https://doi.org/10.48550/arXiv.2309.13684," Jiachen Li, Elizabeth D. Mynatt, Varun Mishra , Jonathan Bell. (2023). ""Always Nice and Confident, Sometimes wrong"": Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q&A Platforms CoRR, abs/2309.13684. https://doi.org/10.48550/arXiv.2309.13684","Software engineers have historically relied on human-powered Q&A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q&A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences.",1664
1579,Software Engineering,Jonathan Bell,"November 9th, 2022",A retrospective study of one decade of artifact evaluations,https://doi.org/10.1145/3540250.3549172," Stefan Winter , Christopher Steven Timperley, Ben Hermann , J√ºrgen Cito, Jonathan Bell , Michael Hilton, Dirk Beyer . (2022). A retrospective study of one decade of artifact evaluations ESEC/SIGSOFT FSE, 145-156. https://doi.org/10.1145/3540250.3549172","Most software engineering research involves the development of a prototype, a proof of concept, or a measurement apparatus. Together with the data collected in the research process, they are collectively referred to as research artifacts and are subject to artifact evaluation (AE) at scientific conferences. Since its initiation in the SE community at ESEC/FSE 2011, both the goals and the process of AE have evolved and today expectations towards AE are strongly linked with reproducible research results and reusable tools that other researchers can build their work on. However, to date little evidence has been provided that artifacts which have passed AE actually live up to these high expectations, i.e., to which degree AE processes contribute to AE's goals and whether the overhead they impose is justified. We aim to fill this gap by providing an in-depth analysis of research artifacts from a decade of software engineering (SE) and programming languages (PL) conferences, based on which we reflect on the goals and mechanisms of AE in our community. In summary, our analyses (1) suggest that articles with artifacts do not generally have better visibility in the community, (2) provide evidence how evaluated and not evaluated artifacts differ with respect to different quality criteria, and (3) highlight opportunities for further improving AE processes.",1665
1580,Software Engineering,Jonathan Bell,"July 5th, 2022",CONFETTI: Amplifying Concolic Guidance for Fuzzers,https://doi.org/10.1145/3510003.3510628," James Kukucka, Lu√≠s Pina, Paul Ammann, Jonathan Bell . (2022). CONFETTI: Amplifying Concolic Guidance for Fuzzers ICSE, 438-450. https://doi.org/10.1145/3510003.3510628","Fuzz testing (fuzzing) allows developers to detect bugs and vulnerabilities in code by automatically generating defect-revealing inputs. Most fuzzers operate by generating inputs for applications and mutating the bytes of those inputs, guiding the fuzzing process with branch coverage feedback via instrumentation. Whitebox guidance (e.g., taint tracking or concolic execution) is sometimes integrated with coverage-guided fuzzing to help cover tricky-to-reach branches that are guarded by complex conditions (so-called ""magic values""). This integration typically takes the form of a targeted input mutation, e.g. , placing particular byte values at a specific offset of some input in order to cover a branch. However, these dynamic analysis techniques are not perfect in practice, which can result in the loss of important relationships between input bytes and branch predicates, thus reducing the effective power of the technique. We introduce a new, surprisingly simple, but effective technique, global hinting , which allows the fuzzer to insert these interesting bytes not only at a targeted position, but in any position of any input. We implemented this idea in Java, creating Confetti, which uses both targeted and global hints for fuzzing. In an empirical comparison with two baseline approaches, a state-of-the-art greybox Java fuzzer and a version of Confetti without global hinting, we found that Confetti covers more branches and finds 15 previously unreported bugs, including 9 that neither baseline could find. By conducting a post-mortem analysis of Confetti's execution, we determined that global hinting was at least as effective at revealing new coverage as traditional, targeted hinting.",1666
1581,Software Engineering,Jonathan Bell,"March 25th, 2022",Flexible and Optimal Dependency Management via Max-SMT,https://doi.org/10.1109/ICSE48619.2023.00124," Donald Pinckney, Federico Cassano, Arjun Guha, Jonathan Bell , Massimiliano Culpo, Todd Gamblin. (2023). Flexible and Optimal Dependency Management via Max-SMT ICSE, 1418-1429. https://doi.org/10.1109/ICSE48619.2023.00124","NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. NPM dependency solver has several shortcomings. We present Pacsolve, a unifying framework and implementation for dependency solving. We then build Maxnpm, a complete, drop-in replacement for NPM. We are presenting our findings at the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) All our code and data is open and available. Back to Mail Online home. Back To the page you came from.""Maxnpm: A Drop-in Replacement For NPM""",1667
1582,Software Engineering,Jonathan Bell,"May 7th, 2021",FlakeFlagger: Predicting Flakiness Without Rerunning Tests,https://doi.org/10.1109/ICSE43902.2021.00140," Abdulrahman Alshammari, Christopher Morris , Michael Hilton, Jonathan Bell . (2021). FlakeFlagger: Predicting Flakiness Without Rerunning Tests ICSE, 1572-1584. https://doi.org/10.1109/ICSE43902.2021.00140","FlakeFlagger collects a set of features describing the behavior of each test. It then predicts tests that are likely to be flaky based on similar behavioral features. We found that FlakeFlagger correctly labeled as flaky at least as many tests as a state-of-the-art flaky test classifier, but that Flake flagger reported far fewer false positives. This lower false positive rate translates directly to saved time for researchers and developers who use the classification result to guide more expensive flakytest detection processes. We conducted a very large empirical study looking for flaky tests by rerunning the test suites of 24 projects 10,000 times each. Some previously identified flaky Tests were still not detected.",1668
1583,Software Engineering,Ian Gorton,"December 26th, 2024",Technical Credit,https://doi.org/10.1145/3690043," Ian Gorton, Alessio Bucaioni, Patrizio Pelliccione. (2025). Technical Credit Commun. ACM, 68, 30-33. https://doi.org/10.1145/3690043","In this paper we study an economy with a high degree of financialization in which (non-financial) firms need loans from commercial banks to finance production, service debt, and make long-term investments. Along the business cycle, the economy follows a ... This paper tests firms' financing trend that the causal relation between trade credit and bank credit around the time of the global financial crises. We find that greater financial crisis would cause firms to increasingly turn to their suppliers as a ... This paper formulates and solves the selection problem for a portfolio of credit swaps. The problem is cast as a goal program that entails a constrained optimization of preference-weighted moments of the portfolio value at the investment horizon. The ...",1669
1584,Software Engineering,Ian Gorton,"September 18th, 2024",Integrated Safety and Security by Design in the IT/OT Convergence of Industrial Systems: A Graph-Based Approach,https://doi.org/10.1109/SSE62657.2024.00029," Amirali Amiri, Gernot Steindl, Ian Gorton, Siegfried Hollerer, Wolfgang Kastner, Thilo Sauter. (2024). Integrated Safety and Security by Design in the IT/OT Convergence of Industrial Systems: A Graph-Based Approach SSE, 123-129. https://doi.org/10.1109/SSE62657.2024.00029","The convergence of Information Technology (IT) and Operational Technology (OT) in Industry 4.0 poses fresh challenges. With the increasing significance of production system integrity, any security breaches can lead to severe consequences like production downtime, equipment damage, or human harm. This paper presents an approach of Model-Based Systems Engineering (MBSE) for the integrated safety and security by design of industrial systems. The approach is extensible and supports reusability already after covering two standards. We define metadata information that are used as tags for SysML 2.0 model instances. Afterwards, we create a graph-based model of the system.",1670
1585,Software Engineering,Ian Gorton,"August 21st, 2024",Distributed Systems ‚Äì Concepts Every Software Architect Should Know,https://doi.org/10.1109/ICSA-C63560.2024.00069," Ian Gorton, Yingyi Tong, Siyu Yao. (2024). Distributed Systems - Concepts Every Software Architect Should Know ICSA-C, 377-378. https://doi.org/10.1109/ICSA-C63560.2024.00069","To be successful, it is essential that architects understand the inherent complexity of distributed system. The topics covered include communications reliability and latencies, message delivery semantics, state management, idempotence, data safety, consistency, time, distributed consensus, cascading failures and failover and recovery. The tutorial will be suitable for graduate students, engineers and architects who have no or minimal exposure to distributed systems concepts. It will combine interactive sessions with short technical explanations and examples to illustrate each distributed systems concept. a concept using the example, I'll move on to show how the concept manifests itself in a software system and its effects on quality attributes requirements and inherent trade-offs.",1671
1586,Software Engineering,Ian Gorton,"December 22nd, 2023",Observability Q&A,https://doi.org/10.1109/MS.2023.3330234," Ian Gorton, Liz Fong-Jones, Alf Larsson. (2024). Observability Q&A IEEE Softw., 41, 50-54. https://doi.org/10.1109/MS.2023.3330234",Observability is the ability to monitor the state of a system and take corrective actions based on insights derived from this monitoring. In this article we survey the thoughts of two experts in the area of observable. They provide deep insights into the current state of the art and future directions in observability practices and technology.,1672
1587,Software Engineering,Arjun Guha,"October 31st, 2024",SelfCodeAlign: Self-Alignment for Code Generation,http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html," Yuxiang Wei , Federico Cassano, Jiawei Liu , Yifeng Ding, Naman Jain, Zachary Mueller, Harm de Vries, Leandro von Werra, Arjun Guha, Lingming Zhang . (2024). SelfCodeAlign: Self-Alignment for Code Generation NeurIPS. http://papers.nips.cc/paper_files/paper/2024/hash/72da102da91a8042a0b2aa968429a9f9-Abstract-Conference.html","Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models to follow human instructions. Most models are finetuned with costly human-annotated instruction-response pairs. We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs.",1673
1588,Software Engineering,Arjun Guha,"October 8th, 2024",Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs,https://doi.org/10.1145/3689735," Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Anders Freeman, Carolyn Jane Anderson, Molly Q. Feldman, Michael Greenberg , Abhinav Jangda, Arjun Guha. (2024). Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs Proc. ACM Program. Lang., 8, 677-708. https://doi.org/10.1145/3689735","Large Language Models of Code have started to have a significant impact on programming practice. The quality of code produced by a Code LLM varies significantly by programming language. This paper presents an effective approach for boosting the performance of Code LLMs on low-resource languages using semi-synthetic data. The MultiPL-T approach is easy to apply to new languages, and is significantly more efficient and effective than alternatives such as training longer.",1674
1589,Software Engineering,Arjun Guha,"March 25th, 2022",Flexible and Optimal Dependency Management via Max-SMT,https://doi.org/10.1109/ICSE48619.2023.00124," Donald Pinckney, Federico Cassano, Arjun Guha, Jonathan Bell , Massimiliano Culpo, Todd Gamblin. (2023). Flexible and Optimal Dependency Management via Max-SMT ICSE, 1418-1429. https://doi.org/10.1109/ICSE48619.2023.00124","NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. NPM dependency solver has several shortcomings. We present Pacsolve, a unifying framework and implementation for dependency solving. We then build Maxnpm, a complete, drop-in replacement for NPM. We are presenting our findings at the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) All our code and data is open and available. Back to Mail Online home. Back To the page you came from.""Maxnpm: A Drop-in Replacement For NPM""",1675
1590,Software Engineering,Arjun Guha,"October 15th, 2021",Solver-based gradual type migration,https://doi.org/10.1145/3485488," Luna Phipps-Costin, Carolyn Jane Anderson, Michael Greenberg, and Arjun Guha. 2021. ‚ÄúSolver-based gradual type migration‚Äù. Proc. ACM Program. Lang. 5, OOPSLA, Article 111 (October 2021), 27 pages. DOI: 10.1145/3485488","Gradually typed languages allow programmers to mix statically and dynamically typed code, enabling them to incrementally reap the benefits of static typing as they add type annotations to their code. However, this type migration process is typically a manual effort with limited tool support. This paper examines the problem of automated type migration: given a dynamic program, infer additional or improved type annotations. Existing type migration algorithms prioritize different goals, such as maximizing type precision, maintaining compatibility with unmigrated code, and preserving the semantics of the original program. We argue that the type migration problem involves fundamental compromises: optimizing for a single goal often comes at the expense of others. Ideally, a type migration tool would flexibly accommodate a range of user priorities. We present TypeWhich, a new approach to automated type migration for the gradually-typed lambda calculus with some extensions. Unlike prior work, which relies on custom solvers, TypeWhich produces constraints for an off-the-shelf MaxSMT solver. This allows us to easily express objectives, such as minimizing the number of necessary syntactic coercions, and constraining the type of the migration to be compatible with unmigrated code. We present the first comprehensive evaluation of GTLC type migration algorithms, and compare TypeWhich to four other tools from the literature. Our evaluation uses prior benchmarks, and a new set of ""challenge problems."" Moreover, we design a new evaluation methodology that highlights the subtleties of gradual type migration. In addition, we apply TypeWhich to a suite of benchmarks for Grift, a programming language based on the GTLC. TypeWhich is able to reconstruct all human-written annotations on all but one program.",1676
1591,Software Engineering,Arjun Guha,"September 27th, 2021",Iterative Program Synthesis for Adaptable Social Navigation,https://doi.org/10.1109/IROS51168.2021.9636540," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Iterative Program Synthesis for Adaptable Social Navigation,"" 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021, pp. 6256-6261. DOI: 10.1109/IROS51168.2021.9636540","Robot social navigation is influenced by human preferences and environment-specific scenarios such as elevators and doors. State-of-the-art approaches to social navigation fall into two categories: model-based social constraints and learning-based approaches. We propose Iterative Dimension Informed Program Synthesis (IDIPS) to address these limitations by learning and adapting social navigation in the form of human-readable symbolic programs. IDIPS works by combining pro-gram synthesis, parameter optimization, predicate repair, and iterative human demonstration to learn and adapt model-free action selection policies. and generates policies that can be transferred from simulation to real-world robots with minimal effort.",1677
1592,Software Engineering,Arjun Guha,"April 21st, 2021",Accelerating graph sampling for graph machine learning using GPUs,https://doi.org/10.1145/3447786.3456244," Abhinav Jangda, Sandeep Polisetty, Arjun Guha, and Marco Serafini. 2021. Accelerating graph sampling for graph machine learning using GPUs. In Proceedings of the Sixteenth European Conference on Computer Systems (EuroSys ‚Äô21). Association for Computing Machinery, New York, NY, USA, 311‚Äì326. DOI: 10.1145/3447786.3456244","Representation learning algorithms automatically learn the features of data. Several representation learning algorithms for graph data, such as DeepWalk, node2vec, and Graph-SAGE, sample the graph to produce mini-batches that are suitable for training a DNN. However, sampling time can be a significant fraction of training time, and existing systems do not efficiently parallelize sampling. Sampling is an ""embarrassingly parallel"" problem and may appear to lend itself to GPU acceleration, but the irregularity of graphs makes it hard to use GPU resources effectively. This paper presents NextDoor, a system designed to effectively perform graph sampling on GPUs. NextDoor employs a new approach to graph sampling that we call transit-parallelism, which allows load balancing and caching of edges. NextDoor provides end-users with a high-level abstraction for writing a variety of graph sampling algorithms. We implement several graph sampling applications, and show that NextDoor runs them orders of magnitude faster than existing systems.",1678
1593,Software Engineering,Arjun Guha,"November 15th, 2020",Wasm/k: delimited continuations for WebAssembly,https://doi.org/10.1145/3426422.3426978," Donald Pinckney, Arjun Guha, and Yuriy Brun. 2020. Wasm/k: delimited continuations for WebAssembly. In Proceedings of the 16th ACM SIGPLAN International Symposium on Dynamic Languages(DLS 2020). Association for Computing Machinery, New York, NY, USA, 16‚Äì28. DOI: 10.1145/3426422.3426978","WebAssembly is designed to be an alternative to JavaScript that is a safe, portable, and efficient compilation target for a variety of languages. The performance of high-level languages depends not only on the underlying performance of WebAssembly, but also on the quality of the generated WebAssembly code. In this paper, we identify several features of high-level languages that current approaches can only compile to WebAssembly by generating complex and inefficient code. We argue that these problems could be addressed if WebAssembly natively supported first-class continuations. We then present Wasm/k, which extends WebAssembly with delimited continuations. Wasm/k introduces no new value types, and thus does not require significant changes to the WebAssembly type system (validation). Wasm/k is safe, even in the presence of foreign function calls (e.g., to and from JavaScript). Finally, Wasm/k is amenable to efficient implementation: we implement Wasm/k as a local change to Wasmtime, an existing WebAssembly JIT. We evaluate Wasm/k by implementing C/k, which adds delimited continuations to C/C++. C/k uses Emscripten and its implementation serves as a case study on how to use Wasm/k in a compiler that targets WebAssembly. We present several case studies using C/k, and show that on implementing green threads, it can outperform the state-of-the-art approach Asyncify with an 18% improvement in performance and a 30% improvement in code size.",1679
1594,Software Engineering,Arjun Guha,"November 13th, 2020",TacTok: semantics-aware proof synthesis,https://doi.org/10.1145/3428299," Emily First, Yuriy Brun, and Arjun Guha. ""TacTok: semantics-aware proof synthesis."" Proceedings of the ACM on Programming Languages, v.4 , 2020. DOI: 10.1145/3428299","TacTok outperforms WeightedRandom and WeightedGreedy, and is complementary to CoqHammer and ASTactic. For 24 out of the 26 projects, TacTok can synthesize proof scripts for some theorem the prior tools cannot. Together with TacTok, 11.5% more theoresms can be proven automatically than by CoquHammer alone.",1680
1595,Software Engineering,Arjun Guha,"November 12th, 2020",Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,https://doi.org/10.48550/arXiv.2008.04133," J. Holtz, S. Andrews, A. Guha and J. Biswas, ""Robot Action Selection Learning via Layered Dimension Informed Program Synthesis,"" Conference on Robot Learning (CoRL), 2020. DOI: 10.48550/arXiv.2008.04133","Action selection policies (ASPs), used to compose low-level robot skills into complex high-level tasks are commonly represented as neural networks (NNs) in the state of the art. Such a paradigm, while very effective, suffers from a few key problems: 1) NNs are opaque to the user and hence not amenable to verification, 2) they require significant amounts of training data, and 3) they are hard to repair when the domain changes. We present two key insights about ASPs for robotics. First, ASPs need to reason about physically meaningful quantities derived from the state of the world, and second, there exists a layered structure for composing these policies. Leveraging these insights, we introduce layered dimension-informed program synthesis (LDIPS) - by reasoning about the physical dimensions of state variables, and dimensional constraints on operators, LDIPS directly synthesizes ASPs in a human-interpretable domain-specific language that is amenable to program repair. We present empirical results to demonstrate that LDIPS 1) can synthesize effective ASPs for robot soccer and autonomous driving domains, 2) requires two orders of magnitude fewer training examples than a comparable NN representation, and 3) can repair the synthesized ASPs with only a small number of corrections when transferring from simulation to real robots.",1681
1596,Software Engineering,Arjun Guha,"April 3rd, 2020",Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing,https://ojs.aaai.org/index.php/AAAI/article/view/7065," Joseph Spitzer, Joydeep Biswas, Arjun Guha. (2020). Making High-Performance Robots Safe and Easy to Use For an Introduction to Computing AAAI, 13412-13419. https://ojs.aaai.org/index.php/AAAI/article/view/7065","Abstract Robots are a popular platform for introducing computing and artificial intelligence to novice programmers. However, programming state-of-the-art robots is very challenging, and requires knowledge of concurrency, operation safety, and software engineering skills, which can take years to teach. In this paper, we present an approach to introducing computing that allows students to safely and easily program high-performance robots. We develop a platform for students to program RoboCup Small Size League robots using JavaScript. The platform 1) ensures physical safety at several levels of abstraction, 2) allows students to program robots using JavaScript in the browser, without the need to install software, and 3) presents a simplified JavaScript semantics that shields students from confusing language features. We discuss our experience running a week-long workshop using this platform, and analyze over 3,000 student-written program revisions to provide empirical evidence that our approach does help students.",1682
1597,Software Engineering,Arjun Guha,"February 15th, 2019",Formal Foundations of Serverless Computing,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2019-jangda-lambda-lambda.html," Abhinav Jangda, Donald Pinckney, Yuriy Brun, and Arjun Guha. Formal Foundations of Serverless Computing. ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages and Applications (OOPSLA), 2019. Distinguished Paper Award","Serverless computing (also known as functions as a service) is a new cloud computing abstraction that makes it easier to write robust, large-scale web services. In serverless computing, programmers write what are called serverless functions, and the cloud platform transparently manages the operating system, resource allocation, load-balancing, and fault tolerance. When demand for the service spikes, the platform automatically allocates additional hardware to the service and manages load-balancing; when demand falls, the platform silently deallocates idle resources; and when the platform detects a failure, it transparently retries affected requests. In 2014, Amazon Web Services introduced the first serverless platform, AWS Lambda, and similar abstractions are now available on all major cloud computing platforms. Unfortunately, the serverless computing abstraction exposes several low-level operational details that make it hard for programmers to write and reason about their code. This paper sheds light on this problem by presenting Œª Œõ , an operational semantics of the essence of serverless computing. Despite being a small (half a page) core calculus, Œª Œõ models all the low-level details that serverless functions can observe. To show that Œª Œõ is useful, we present three applications. First, to ease reasoning about code, we present a simplified naive semantics of serverless execution and precisely characterize when the naive semantics and Œª Œõ coincide. Second, we augment Œª Œõ with a key-value store to allow reasoning about stateful serverless functions. Third, since a handful of serverless platforms support serverless function composition, we show how to extend Œª Œõ with a composition language. We have implemented this composition language and show that it outperforms prior work. The latest version of this paper, corrects an error in Definition 4.2 and thus the proof of Theorem 4.3, which were found in the published version. PDF available on arXiv",1683
1598,Software Engineering,Arjun Guha,"February 5th, 2018",Interactive Robot Transition Repair With SMT,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2018-holtz-srtr.html," Jarrett Holtz, Arjun Guha, and Joydeep Biswas. Interactive Robot Transition Repair with SMT. International Joint Conference on Artificial Intelligence and the European Conference on Artificial Intelligence (IJCAI-ECAI), 2018","Complex robot behaviors are often structured as state machines, where states encapsulate actions and a transition function switches between states. Since transitions depend on physical parameters, when the environment changes, a roboticist has to painstakingly readjust the parameters to work in the new environment. We present interactive SMT-based Robot Transition Repair* (SRTR): instead of manually adjusting parameters, we ask the roboticist to identify a few instances where the robot is in a wrong state and what the right state should be. An automated analysis of the transition function 1) identifies adjustable parameters, 2) converts the transition function into a system of logical constraints, and 3) formulates the constraints and user-supplied corrections as a MaxSMT problem that yields new parameter values. We show that finds new parameters 1) quickly, 2) with few corrections, and 3) that the parameters generalize to new scenarios. We also show that a SRTR-corrected state machine can outperform a more complex, expert-tuned state machine. PDF available on arXiv",1684
1599,Software Engineering,Arjun Guha,"September 17th, 2015",Rehearsal: A Configuration Verification Tool for Puppet,https://www.khoury.northeastern.edu/~arjunguha/main/papers/2016-rehearsal.html," Rian Shambaugh, Aaron Weiss, and Arjun Guha. Rehearsal: A Configuration Verification Tool for Puppet. ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2016","Large-scale data centers and cloud computing have turned system configuration into a challenging problem. Several widely-publicized outages have been blamed not on software bugs, but on configuration bugs. To cope, thousands of organizations use system configuration languages to manage their computing infrastructure. Of these, Puppet is the most widely used with thousands of paying customers and many more open-source users. The heart of Puppet is a domain-specific language that describes the state of a system. Puppet already performs some basic static checks, but they only prevent a narrow range of errors. Furthermore, testing is ineffective because many errors are only triggered under specific machine states that are difficult to predict and reproduce. With several examples, we show that a key problem with Puppet is that configurations can be non-deterministic. This paper presents Rehearsal, a verification tool for Puppet configurations. Rehearsal implements a sound, complete, and scalable determinacy analysis for Puppet. To develop it, we (1) present a formal semantics for Puppet, (2) use several analyses to shrink our models to a tractable size, and (3) frame determinism-checking as decidable formulas for an SMT solver. Rehearsal then leverages the determinacy analysis to check other important properties, such as idempotency. Finally, we apply Rehearsal to several real-world Puppet configurations. PLDI Artifact Virtual Machine PDF available on arXiv",1685
1600,Software Engineering,Karl Lieberherr,"July 7th, 2022",Towards Tackling QSAT Problems with Deep Learning and Monte Carlo Tree Search,https://doi.org/10.1007/978-3-031-10464-0_4," Ruiyang Xu, Karl J. Lieberherr. (2022). Towards Tackling QSAT Problems with Deep Learning and Monte Carlo Tree Search SAI (2), 45-58. https://doi.org/10.1007/978-3-031-10464-0_4","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1686
1601,Software Engineering,Karl Lieberherr,"May 20th, 2022",On-the-Fly Model Checking with Neural MCTS,https://doi.org/10.1007/978-3-031-06773-0_30," Ruiyang Xu, Karl J. Lieberherr. (2022). On-the-Fly Model Checking with Neural MCTS NFM, 557-575. https://doi.org/10.1007/978-3-031-06773-0_30","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1687
1602,Software Engineering,Karl Lieberherr,"March 21st, 2021",Dual Monte Carlo Tree Search,https://arxiv.org/abs/2103.11517," Prashank Kadam, Ruiyang Xu, Karl J. Lieberherr. (2021). Dual Monte Carlo Tree Search CoRR, abs/2103.11517. https://arxiv.org/abs/2103.11517","AlphaZero, using a combination of Deep Neural Networks and Monte Carlo Tree Search (MCTS), has successfully trained reinforcement learning agents in a tabula-rasa way. The neural MCTS algorithm has been successful in finding near-optimal strategies for games through self-play. However, the AlphaZero algorithm has a significant drawback; it takes a long time to converge and requires high computational power due to complex neural networks for solving games like Chess, Go, Shogi, etc. Owing to this, it is very difficult to pursue neural MCTS research without cutting-edge hardware, which is a roadblock for many aspiring neural MCTS researchers. In this paper, we propose a new neural MCTS algorithm, called Dual MCTS, which helps overcome these drawbacks. Dual MCTS uses two different search trees, a single deep neural network, and a new update technique for the search trees using a combination of the PUCB, a sliding-window, and the epsilon-greedy algorithm. This technique is applicable to any MCTS based algorithm to reduce the number of updates to the tree. We show that Dual MCTS performs better than one of the most widely used neural MCTS algorithms, AlphaZero, for various symmetric and asymmetric games.",1688
1603,Software Engineering,Karl Lieberherr,"January 17th, 2021",Solving QSAT problems with neural MCTS,https://arxiv.org/abs/2101.06619," Ruiyang Xu, Karl J. Lieberherr. (2021). Solving QSAT problems with neural MCTS CoRR, abs/2101.06619. https://arxiv.org/abs/2101.06619","Recent achievements from AlphaZero using self-play has shown remarkable performance on several board games. It is plausible to think that self-play, starting from zero knowledge, can gradually approximate a winning strategy for certain two-player games after an amount of training. In this paper, we try to leverage the computational power of neural Monte Carlo Tree Search (neural MCTS), the core algorithm from AlphaZero, to solve Quantified Boolean Formula Satisfaction (QSAT) problems, which are PSPACE complete. Knowing that every QSAT problem is equivalent to a QSAT game, the game outcome can be used to derive the solutions of the original QSAT problems. We propose a way to encode Quantified Boolean Formulas (QBFs) as graphs and apply a graph neural network (GNN) to embed the QBFs into the neural MCTS. After training, an off-the-shelf QSAT solver is used to evaluate the performance of the algorithm. Our result shows that, for problems within a limited size, the algorithm learns to solve the problem correctly merely from self-play.",1689
1604,Software Engineering,Karl Lieberherr,"January 11th, 2021",First-Order Problem Solving through Neural MCTS based Reinforcement Learning,https://arxiv.org/abs/2101.04167," Ruiyang Xu, Prashank Kadam, Karl J. Lieberherr. (2021). First-Order Problem Solving through Neural MCTS based Reinforcement Learning CoRR, abs/2101.04167. https://arxiv.org/abs/2101.04167","The formal semantics of an interpreted first-order logic (FOL) statement can be given in Tarskian Semantics or a basically equivalent Game Semantics. The latter maps the statement and the interpretation into a two-player semantic game. Many combinatorial problems can be described using interpreted FOL statements and can be mapped into a semantic game. Therefore, learning to play a semantic game perfectly leads to the solution of a specific instance of a combinatorial problem. We adapt the AlphaZero algorithm so that it becomes better at learning to play semantic games that have different characteristics than Go and Chess. We propose a general framework, Persephone, to map the FOL description of a combinatorial problem to a semantic game so that it can be solved through a neural MCTS based reinforcement learning algorithm. Our goal for Persephone is to make it tabula-rasa, mapping a problem stated in interpreted FOL to a solution without human intervention.",1690
1605,Software Engineering,Olin Shivers,"August 31st, 2023",The Verse Calculus: A Core Calculus for Deterministic Functional Logic Programming,https://doi.org/10.1145/3607845," Lennart Augustsson, Joachim Breitner, Koen Claessen, Ranjit Jhala, Simon Peyton Jones, Olin Shivers, Guy L. Steele Jr., Tim Sweeney. (2023). The Verse Calculus: A Core Calculus for Deterministic Functional Logic Programming Proc. ACM Program. Lang., 7, 417-447. https://doi.org/10.1145/3607845","Functional logic languages have a rich literature, but it is tricky to give them a satisfying semantics. In this paper we describe the Verse calculus, VC, a new core calculus for deterministic functional logic programming. Our main contribution is to equip VC with a small-step rewrite semantics, so that we can reason about a VC program in the same way as one does with lambda calculus; that is, by applying successive rewrites to it. We also show that the rewrite system is confluent for well-behaved terms.",1691
1606,Software Engineering,Olin Shivers,"November 10th, 2022",3CPS: The Design of an Environment-Focussed Intermediate Representation,https://doi.org/10.1145/3544885.3544889," Benjamin Quiring, John H. Reppy, Olin Shivers. (2021). 3CPS: The Design of an Environment-Focussed Intermediate Representation IFL, 20-28. https://doi.org/10.1145/3544885.3544889","We describe the design of 3CPS, a compiler intermediate representation (IR) we have developed for use in compiling call-by-value functional languages such as SML, OCaml, Scheme, and Lisp. The language is a low-level form designed in tandem with a matching suite of static analyses. It reflects our belief that the core task of an optimising compiler for a functional language is to reason about the environment structure of the program. Our IR is distinguished by the presence of extent annotations, added to all variables (and verified by static analysis). These annotations are defined in terms of the semantics of the IR, but they directly tell the compiler what machine resources are needed to implement the environment structure of each annotated variable.",1692
1607,Software Engineering,Olin Shivers,"August 31st, 2022",Analyzing binding extent in 3CPS,https://doi.org/10.1145/3547645," Benjamin Quiring, John H. Reppy, Olin Shivers. (2022). Analyzing binding extent in 3CPS Proc. ACM Program. Lang., 6, 650-678. https://doi.org/10.1145/3547645","To date, the most effective approach to compiling strict, higher-order functional languages (such as OCaml, Scheme, and SML) has been to use whole-program techniques to convert the program to a first-order monomorphic representation that can be optimized using traditional compilation techniques. This approach, popularized by MLton, has limitations, however. We are interested in exploring a different approach to compiling such languages, one that preserves the higher-order and polymorphic character of the program throughout optimization. To enable such an approach, we must have effective analyses that both provide precise information about higher-order programs and that scale to larger units of compilation. This paper describes one such analysis for determining the extent of variable bindings. We classify the extent of variables as either register (only one binding instance can be live at any time), stack (the lifetimes of binding instances obey a LIFO order), or heap (binding lifetimes are arbitrary). These extents naturally connect variables to the machine resources required to represent them. We believe that precise information about binding extents will enable efficient management of environments, which is a key problem in the efficient compilation of higher-order programs. At the core of the paper is the 3CPS intermediate representation, which is a factored CPS-based intermediate representation (IR) that statically marks variables to indicate their binding extent. We formally specify the management of this binding structure by means of a small-step operational semantics and define a static analysis that determines the extents of the variables in a program. We evaluate our analysis using a standard suite of SML benchmark programs. Our implementation gets surprisingly high yield and exhibits scalable performance. While this paper uses a CPS-based IR, the algorithm and results are easily transferable to other Œª-calculus IRs, such as ANF.",1693
1608,Software Engineering,Frank Tip,"November 30th, 2023",Code Coverage Criteria for Asynchronous Programs,https://doi.org/10.1145/3611643.3616292," Mohammad Ganji, Saba Alimadadi, Frank Tip. (2023). Code Coverage Criteria for Asynchronous Programs ESEC/SIGSOFT FSE, 1307-1319. https://doi.org/10.1145/3611643.3616292","Asynchronous software often exhibits complex and error-prone behaviors that should be tested thoroughly. Code coverage has been the most popular metric to assess test suite quality. However, traditional code coverage criteria do not adequately reflect completion, interactions, and error handling of asynchronous operations. This paper proposes novel test adequacy criteria for measuring: (i) completion of asynchronous operations in terms of both successful and exceptional execution, (ii) registration of reactions for handling both possible outcomes, and (iii) execution of said reactions through tests. We implement JScope, a tool for automatically measuring coverage according to these criteria in JavaScript applications, as an interactive plug-in for Visual Studio Code. An evaluation of JScope on 20 JavaScript applications shows that the proposed criteria can help improve assessment of test adequacy, complementing traditional criteria. According to our investigation of 15 real GitHub issues concerned with asynchrony, the new criteria can help reveal faulty asynchronous behaviors that are untested yet are deemed covered by traditional coverage criteria. We also report on a controlled experiment with 12 participants to investigate the usefulness of JScope in realistic settings, demonstrating its effectiveness in improving programmers‚Äô ability to assess test adequacy and detect untested behavior of asynchronous code.",1694
1609,Software Engineering,Frank Tip,"November 8th, 2023",Increasing the Responsiveness of Web Applications by Introducing Lazy Loading,https://doi.org/10.1109/ASE56229.2023.00192," Alexi Turcotte, Satyajit Gokhale, Frank Tip. (2023). Increasing the Responsiveness of Web Applications by Introducing Lazy Loading ASE, 459-470. https://doi.org/10.1109/ASE56229.2023.00192","Front-end developers want their applications to contain no more code than is needed in order to minimize the amount of time that elapses between visiting a web page and the page becoming responsive. Support was added to JavaScript in 2020 when asynchronous, dynamic imports were added to the language standard. Unfortunately, migrating existing projects to take advantage of this feature is nontrivial, as the code changes required to introduce asynchrony may involve complex, non-local transformations. Our approach relies on static analysis to identify external packages that can be loaded lazily and generates the code transformations required to lazily load those packages. Since the static analysis is unsound, these transformations are presented as suggestions that programmers should review and test carefully.",1695
1610,Software Engineering,Frank Tip,"July 13th, 2023",That‚Äôs a Tough Call: Studying the Challenges of Call Graph Construction for WebAssembly,https://doi.org/10.1145/3597926.3598104," Daniel Lehmann , Michelle Thalakottur, Frank Tip, Michael Pradel. (2023). That's a Tough Call: Studying the Challenges of Call Graph Construction for WebAssembly ISSTA, 892-903. https://doi.org/10.1145/3597926.3598104","WebAssembly is a low-level bytecode format that powers applications and libraries running in browsers, on the server side, and in standalone runtimes. Call graphs are at the core of many interprocedural static analysis and optimization techniques. However, WebAssembly poses some unique challenges for static call graph construction. Currently, these challenges are neither well understood, nor is it clear to what extent existing techniques address them. This paper presents the first systematic study of WebAssembly-specific challenges for static call graph construction and of the state-of-the-art in call graph analysis. We identify and classify 12 challenges, encode them into a suite of 24 executable microbenchmarks, and measure their prevalence in real-world binaries. These challenges reflect idiosyncrasies of WebAssembly, such as indirect calls via a mutable function table, interactions with the host environment, and unmanaged linear memory. We show that they commonly occur across a set of more than 8,000 real-world binaries. Based on our microbenchmarks and a set of executable real-world binaries, we then study the soundness and precision of four existing static analyses. Our findings include that, surprisingly, all of the existing techniques are unsound, without this being documented anywhere. We envision our work to provide guidance for improving static call graph construction for WebAssembly. In particular, the presented microbenchmarks will enable future work to check whether an analysis supports challenging language features, and to quantify its soundness and precision.",1696
1611,Software Engineering,Jan Vitek,"June 20th, 2024",Decidable Subtyping of Existential Types for Julia,https://doi.org/10.1145/3656421," Julia Belyakova, Benjamin Chung, Ross Tate, Jan Vitek. (2024). Decidable Subtyping of Existential Types for Julia Proc. ACM Program. Lang., 8, 1091-1114. https://doi.org/10.1145/3656421","Julia is a modern scientific-computing language that relies on multiple dispatch to implement generic libraries. While the language does not have a static type system, method declarations are decorated with expressive type annotations to determine when they are applicable. To find applicable methods, the implementation uses subtyping at run-time. We show that Julia's subtyping is undecidable, and we propose a restriction on types to recover decidability by stratifying types into method signatures over value types---where the former can freely use bounded existential types but the latter are restricted to use-site variance. A corpus analysis suggests that nearly all Julia programs written in practice already conform to this restriction.",1697
1612,Software Engineering,Jan Vitek,"October 16th, 2023",Reusing Just-in-Time Compiled Code,https://doi.org/10.1145/3622839," Meetesh Kalpesh Mehta, Sebasti√°n Krynski, Hugo Musso Gualandi, Manas Thakur, Jan Vitek. (2023). Reusing Just-in-Time Compiled Code Proc. ACM Program. Lang., 7, 1176-1197. https://doi.org/10.1145/3622839","Most code is executed more than once. If not entire programs then libraries remain unchanged from one run to the next. Just-in-time compilers expend considerable effort gathering insights about code they compiled many times, and often end up generating the same binary over and over again. We explore how to reuse compiled code across runs of different programs to reduce warm-up costs of dynamic languages. We propose to use speculative contextual dispatch to select versions of functions from an off-line curated code repository . That repository is a persistent database of previously compiled functions indexed by the context under which they were compiled. The repository is curated to remove redundant code and to optimize dispatch. We assess practicality by extending ≈ò, a compiler for the R language, and evaluating its performance. Our results suggest that the approach improves warmup times while preserving peak performance.",1698
1613,Software Engineering,Jan Vitek,"December 1st, 2022",signatr: A Data-Driven Fuzzing Tool for R,https://doi.org/10.1145/3567512.3567530," Alexi Turcotte, Pierre Donat-Bouillud, Filip Krikava, Jan Vitek. (2022). signatr: A Data-Driven Fuzzing Tool for R SLE, 216-221. https://doi.org/10.1145/3567512.3567530","The fast-and-loose, permissive semantics of dynamic programming languages limit the power of static analyses. For that reason, soundness is often traded for precision through dynamic program analysis. Dynamic analysis is only as good as the available runnable code, and relying solely on test suites is fraught as they do not cover the full gamut of possible behaviors. Fuzzing is an approach for automatically exercising code, and could be used to obtain more runnable code. However, the shape of user-defined data in dynamic languages is difficult to intuit, limiting a fuzzer's reach. We propose a feedback-driven blackbox fuzzing approach which draws inputs from a database of values recorded from existing code. We implement this approach in a tool called signatr for the R language. We present the insights of its design and implementation, and assess signatr's ability to uncover new behaviors by fuzzing 4,829 R functions from 100 R packages, revealing 1,195,184 new signatures.",1699
1614,Software Engineering,Jan Vitek,"June 9th, 2022",Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations,https://doi.org/10.48550/arXiv.2203.02340," Olivier Fl√ºckiger, Jan Jecmen, Sebasti√°n Krynski, Jan Vitek. (2022). Deoptless: Speculation with Dispatched On-Stack Replacement and Specialized Continuations CoRR, abs/2203.02340. https://doi.org/10.48550/arXiv.2203.02340","Just-in-time compilation provides significant performance improvements for programs written in dynamic languages. These benefits come from the ability of the compiler to speculate about likely cases and generate optimized code for these. Unavoidably, speculations sometimes fail and the optimizations must be reverted. In some pathological cases, this can leave the program stuck with suboptimal code. In this paper we propose deoptless, a technique that replaces deoptimization points with dispatched specialized continuations. The goal of deoptless is to take a step towards providing users with a more transparent performance model in which mysterious slowdowns are less frequent and grave.",1700
1615,Software Engineering,Jan Vitek,"October 15th, 2021",Promises are made to be broken: migrating R to strict semantics,https://doi.org/10.1145/3485478," Aviral Goel, Jan Jecmen, Sebasti√°n Krynski, Olivier Fl√ºckiger, Jan Vitek. (2021). Promises are made to be broken: migrating R to strict semantics Proc. ACM Program. Lang., 5, 1-20. https://doi.org/10.1145/3485478","Function calls in the R language do not evaluate their arguments, these are passed to the callee as suspended computations and evaluated if needed. After 25 years of experience with the language, there are very few cases where programmers leverage delayed evaluation intentionally and laziness comes at a price in performance and complexity. This paper explores how to evolve the semantics of a lazy language towards strictness-by-default and laziness-on-demand. To provide a migration path, it is necessary to provide tooling for developers to migrate libraries without introducing errors. This paper reports on a dynamic analysis that infers strictness signatures for functions to capture both intentional and accidental laziness. Over 99% of the inferred signatures were correct when tested against clients of the libraries.",1701
1616,Software Engineering,Jan Vitek,"July 12th, 2018",Tests from traces: automated unit test extraction for R,https://doi.org/10.1145/3213846.3213863," Filip Krikava, Jan Vitek. (2018). Tests from traces: automated unit test extraction for R ISSTA, 232-241. https://doi.org/10.1145/3213846.3213863","Unit tests are labor-intensive to write and maintain. This paper looks into how well unit tests for a target software package can be extracted from the execution traces of client code. Our objective is to reduce the effort involved in creating test suites while minimizing the number and size of individual tests, and maximizing coverage. To evaluate the viability of our approach, we select a challenging target for automated test extraction, namely R, a programming language that is popular for data science applications. The challenges presented by R are its extreme dynamism, coerciveness, and lack of types. This combination decrease the efficacy of traditional test extraction techniques. We present Genthat, a tool developed over the last couple of years to non-invasively record execution traces of R programs and extract unit tests from those traces. We have carried out an evaluation on 1,545 packages comprising 1.7M lines of R code. The tests extracted by Genthat improved code coverage from the original rather low value of 267,496 lines to 700,918 lines. The running time of the generated tests is 1.9 times faster than the code they came from",1702
1617,Software Engineering,Jan Vitek,"October 1st, 2017",DejÃÅ√† Vu: A Map of Code Duplicates on GitHub,https://dl.acm.org/citation.cfm?id=3133908," Crista Lopes, Petr Maj, Pedro Martins, Di Yang, Jakub Zitny, Hitesh Sajnani, Jan Vitek","Previous studies have shown that there is a non-trivial amount of duplication in source code. This paper analyzes a corpus of 4.5 million non-fork projects hosted on GitHub representing over 428 million files written in Java, C++, Python, and JavaScript. We found that this corpus has a mere 85 million unique files. In other words, 70% of the code on GitHub consists of clones of previously created files. There is considerable variation between language ecosystems. JavaScript has the highest rate of file duplication, only 6% of the files are distinct. Java, on the other hand, has the least duplication, 60% of files are distinct. Lastly, a project-level analysis shows that between 9% and 31% of the projects contain at least 80% of files that can be found elsewhere. These rates of duplication have implications for systems built on open source software as well as for researchers interested in analyzing large code bases. As a concrete artifact of this study, we have created D√©j√†Vu, a publicly available map of code duplicates in GitHub repositories.",1703
1618,Software Engineering,Jan Vitek,"December 23rd, 2015",Is Sound Gradual Typing Dead?,https://doi.org/10.1145/2837614.2837630," Asumu Takikawa, Daniel Feltey, Ben Greenman, Max S. New, Jan Vitek, Matthias Felleisen. ""Is Sound Gradual Typing Dead?"". POPL ‚Äò16 Principles of Programming Languages (POPL). 456-468, 2016. DOI: 10.1145/2837614.2837630","Programmers have come to embrace dynamically-typed languages for prototyping and delivering large and complex systems. When it comes to maintaining and evolving these systems, the lack of explicit static typing becomes a bottleneck. In response, researchers have explored the idea of gradually-typed programming languages which allow the incremental addition of type annotations to software written in one of these untyped languages. Some of these new, hybrid languages insert run-time checks at the boundary between typed and untyped code to establish type soundness for the overall system. With sound gradual typing, programmers can rely on the language implementation to provide meaningful error messages when type invariants are violated. While most research on sound gradual typing remains theoretical, the few emerging implementations suffer from performance overheads due to these checks. None of the publications on this topic comes with a comprehensive performance evaluation. Worse, a few report disastrous numbers. In response, this paper proposes a method for evaluating the performance of gradually-typed programming languages. The method hinges on exploring the space of partial conversions from untyped to typed. For each benchmark, the performance of the different versions is reported in a synthetic metric that associates runtime overhead to conversion effort. The paper reports on the results of applying the method to Typed Racket, a mature implementation of sound gradual typing, using a suite of real-world programs of various sizes and complexities. Based on these results the paper concludes that, given the current state of implementation technologies, sound gradual typing faces significant challenges. Conversely, it raises the question of how implementations could reduce the overheads associated with soundness and how tools could be used to steer programmers clear from pathological cases.",1704
1619,Software Engineering,Dakuo Wang,"February 6th, 2025","More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",https://doi.org/10.48550/arXiv.2502.03732," Bingsheng Yao, Menglin Zhao, Yuling Sun, Weidan Cao, Changchang Yin, Stephen S. Intille, Xuhai Xu, Ping Zhang , Jingzhen Yang, Dakuo Wang. (2025). More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients CoRR, abs/2502.03732. https://doi.org/10.48550/arXiv.2502.03732","Anxiety, depression, and suicidality are common mental health sequelae following concussion in youth patients, often exacerbating concussion symptoms and prolonging recovery. Despite the critical need for early detection of these mental health symptoms, clinicians often face challenges in accurately collecting patients' mental health data and making clinical decision-making in a timely manner. Today's remote patient monitoring (RPM) technologies offer opportunities to objectively monitor patients' activities, but they were not specifically designed for youth concussion patients; moreover, the large amount of data collected by RPM technologies may also impose significant workloads on clinicians to keep up with and use the data. To address these gaps, we employed a three-stage study consisting of a formative study, interface design, and design evaluation. We first conducted a formative study through semi-structured interviews with six highly professional concussion clinicians and identified clinicians' key challenges in remotely collecting patient information and accessing patient treatment compliance. Subsequently, we proposed preliminary clinician-facing interface designs with the integration of AI-based RPM technologies (AI-RPM), followed by design evaluation sessions with highly professional concussion clinicians. Clinicians underscored the value of integrating multi-modal AI-RPM technologies to support clinicians' decision-making while emphasizing the importance of customizable interfaces with explainability and multiple responsible design considerations.",1705
1620,Software Engineering,Dakuo Wang,"November 1st, 2024",StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children‚Äôs Story-Based Learning,https://aclanthology.org/2024.emnlp-main.961," Jiaju Chen, Yuxuan Lu , Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li , Qianwen Wang, Dakuo Wang, Yuling Sun. (2024). StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning EMNLP, 17351-17370. https://aclanthology.org/2024.emnlp-main.961","Correct abstract if needed. Retain XML formatting tags such as <tex-math>. Abstract Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the conversation. This limitation can be attributed to the existing question-answering (QA) datasets used for children‚Äôs education, upon which the systems are built, failing to capture the nuances of how education experts think when conducting interactive story reading activities. To bridge this gap, we design an annotation framework, empowered by existing knowledge graph to capture experts‚Äô annotations and thinking process, and leverage this framework to construct StorySparkQA dataset, which comprises 5, 868 expert-annotated QA pairs with real-world knowledge. We conduct automated and human expert evaluations across various QA pair generation settings to demonstrate that our StorySparkQA can effectively support models in generating QA pairs that target real-world knowledge beyond story content. StorySparkQA is available at https://huggingface.co/datasets/NEU-HAI/StorySparkQA.",1706
1621,Software Engineering,Dakuo Wang,"October 18th, 2024",Vital Insight: Assisting Experts‚Äô Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM,https://doi.org/10.48550/arXiv.2410.14879," Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth D. Mynatt, Varun Mishra . (2024). Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM CoRR, abs/2410.14879. https://doi.org/10.48550/arXiv.2410.14879","Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",1707
1622,Software Engineering,Dakuo Wang,"August 24th, 2024",SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,https://doi.org/10.1145/3637528.3671586," Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang . (2024). SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing KDD, 6158-6168. https://doi.org/10.1145/3637528.3671586","Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis onset prediction and diagnosis could significantly improve the survival of sepsis patients. Existing predictive models are usually trained on high-quality data with few missing information, while missing values widely exist in real-world clinical scenarios (especially in the first hours of admissions to the hospital), which causes a significant decrease in accuracy and an increase in uncertainty for the predictive models. The common method to handle missing values is imputation, which replaces the unavailable variables with estimates from the observed data. The uncertainty of imputation results can be propagated to the sepsis prediction outputs, which have not been studied in existing works on either sepsis prediction or uncertainty quantification. In this study, we first define such propagated uncertainty as the variance of prediction output and then introduce uncertainty propagation methods to quantify the propagated uncertainty. Moreover, for the potential high-risk patients with low confidence due to limited observations, we propose a robust active sensing algorithm to increase confidence by actively recommending clinicians to observe the most informative variables. We validate the proposed models in both publicly available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The Ohio State University Wexner Medical Center (OSUWMC). The experimental results show that the propagated uncertainty is dominant at the beginning of admissions to hospitals and the proposed algorithm outperforms state-of-the-art active sensing methods. Finally, we implement a SepsisLab system for early sepsis prediction and active sensing based on our pre-trained models. Clinicians and potential sepsis patients can benefit from the system in early prediction and diagnosis of sepsis.",1708
1623,Software Engineering,Dakuo Wang,"August 7th, 2024",Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity,https://doi.org/10.48550/arXiv.2408.03586," Siyi Wu, Weidan Cao, Shihan Fu, Bingsheng Yao, Ziqi Yang, Changchang Yin, Varun Mishra , Daniel Addison, Ping Zhang , Dakuo Wang. (2024). Clinical Challenges and AI Opportunities in Decision-Making for Cancer Treatment-Induced Cardiotoxicity CoRR, abs/2408.03586. https://doi.org/10.48550/arXiv.2408.03586","Cardiotoxicity induced by cancer treatment has become a major clinical concern, affecting the long-term survival and quality of life of cancer patients. Effective clinical decision-making, including the detection of cancer treatment-induced cardiotoxicity and the monitoring of associated symptoms, remains a challenging task for clinicians. This study investigates the current practices and needs of clinicians in the clinical decision making of cancer treatment-induced cardiotoxicity and explores the potential of digital health technologies to support this process. Through semi-structured interviews with seven clinical experts, we identify a three-step decision-making paradigm: 1) symptom identification, 2) diagnostic testing and specialist collaboration, and 3) clinical decision-making and intervention. Our findings highlight the difficulties of diagnosing cardiotoxicity (absence of unified protocols and high variability in symptoms) and monitoring patient symptoms (lacking accurate and timely patient self-reported symptoms). The clinicians also expressed their need for effective early detection tools that can integrate remote patient monitoring capabilities. Based on these insights, we discuss the importance of understanding the dynamic nature of clinical workflows, and the design considerations for future digital tools to support cancer-treatment-induced cardiotoxicity decision-making.",1709
1624,Software Engineering,Dakuo Wang,"May 15th, 2024",Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults,https://doi.org/10.1145/3659625," Ziqi Yang, Xuhai Xu, Bingsheng Yao, Ethan Rogers, Shao Zhang, Stephen S. Intille, Nawar Shara, Guodong Gordon Gao, Dakuo Wang. (2024). Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 8, 73:1-73:35. https://doi.org/10.1145/3659625","Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered conversational interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.",1710
1625,Software Engineering,Dakuo Wang,"May 11th, 2024",Building LLM-based AI Agents in Social Virtual Reality,https://doi.org/10.1145/3613905.3651026," Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo Wang, Yvonne Coady, Mirjana Prpa. (2024). Building LLM-based AI Agents in Social Virtual Reality CHI Extended Abstracts, 65:1-65:7. https://doi.org/10.1145/3613905.3651026","In this paper, we introduce the design and evaluation of an LLM-based AI agent for human-agent interaction in Virtual Reality (VR). Our AI agent system leverages GPT-4, a Large Language Model (LLM) to simulate human behavior. Our LLM-based agent, deployed in VRChat as a Non-playable Character (NPC), exhibits the ability to respond to a player by providing context-relevant responses followed by appropriate facial expressions and body gestures. Our preliminary evaluation yielded the most optimal parameters for generating the most plausible responses. With our system, we lay the groundwork for future development of LLM-based NPCs in VR.",1711
1626,Software Engineering,Dakuo Wang,"May 11th, 2024",Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,https://doi.org/10.1145/3613904.3642343," Shao Zhang, Jianing Yu, Xuhai Xu, Changchang Yin, Yuxuan Lu , Bingsheng Yao, Melanie Tory, Lace M. K. Padilla, Jeffrey M. Caterino, Ping Zhang , Dakuo Wang. (2024). Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis CHI, 445:1-445:18. https://doi.org/10.1145/3613904.3642343","Today‚Äôs AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",1712
1627,Systems and Networking,David Choffnes,"November 4th, 2024",IoT Bricks Over v6: Understanding IPv6 Usage in Smart Homes,https://doi.org/10.1145/3646547.3688457," Tianrui Hu, Daniel J. Dubois, David R. Choffnes. (2024). IoT Bricks Over v6: Understanding IPv6 Usage in Smart Homes IMC, 595-611. https://doi.org/10.1145/3646547.3688457","Recent years have seen growing interest and support for IPv6 in residential networks. While nearly all modern networking devices and operating systems support IPv6, it remains unclear how this basic support translates into higher-layer functionality, privacy, and security in consumer IoT devices. In this paper, we present the first comprehensive study of IPv6 usage in smart homes in a testbed equipped with 93 distinct, popular consumer IoT devices. We investigate whether and how they support and use IPv6, focusing on factors such as IPv6 addressing, configuration, DNS and destinations, and privacy and security practices. We find that, despite most devices having some degree of IPv6 support, in an IPv6-only network just 20.4% transmit data to Internet IPv6 destinations, and only 8.6% remain functional, indicating that consumer IoT devices are not yet ready for IPv6 networks. Furthermore, 16.1% of devices use easily traceable IPv6 addresses, posing privacy risks. Our findings highlight the inadequate IPv6 support in consumer IoT devices compared to conventional devices such as laptops and mobile phones. This gap is concerning, as it may lead to not only usability issues but also privacy and security risks for smart home users.",1713
1628,Systems and Networking,David Choffnes,"October 24th, 2023","Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem",https://doi.org/10.1145/3618257.3624803," Umar Iqbal, Pouneh Nikkhah Bahrami, Rahmadi Trimananda, Hao Cui, Alexander Gamero-Garrido, Daniel J. Dubois, David R. Choffnes, Athina Markopoulou, Franziska Roesner, Zubair Shafiq. (2023). Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem IMC, 569-583. https://doi.org/10.1145/3618257.3624803","Smart speakers collect voice commands, which can be used to infer sensitive information about users. Given the potential for privacy harms, there is a need for greater transparency and control over the data collected, used, and shared by smart speaker platforms as well as third party skills supported on them. To bridge this gap, we build a framework to measure data collection, usage, and sharing by the smart speaker platforms. We apply our framework to the Amazon smart speaker ecosystem. Our results show that Amazon and third parties, including advertising and tracking services that are unique to the smart speaker ecosystem, collect smart speaker interaction data. We also find that Amazon processes smart speaker interaction data to infer user interests and uses those inferences to serve targeted ads to users. Smart speaker interaction also leads to ad targeting and as much as 30X higher bids in ad auctions, from third party advertisers. Finally, we find that Amazon's and third party skills' data practices are often not clearly disclosed in their policy documents.",1714
1629,Systems and Networking,David Choffnes,"October 24th, 2023",In the Room Where It Happens: Characterizing Local Communication and Threats in Smart Homes,https://doi.org/10.1145/3618257.3624830," Aniketh Girish, Tianrui Hu, Vijay Prakash, Daniel J. Dubois, Srdjan Matic, Danny Yuxing Huang, Serge Egelman, Joel Reardon, Juan Tapiador, David R. Choffnes, Narseo Vallina-Rodriguez. (2023). In the Room Where It Happens: Characterizing Local Communication and Threats in Smart Homes IMC, 437-456. https://doi.org/10.1145/3618257.3624830","The network communication between Internet of Things (IoT) devices on the same local network has significant implications for platform and device interoperability, security, privacy, and correctness. Yet, the analysis of local home Wi-Fi network traffic and its associated security and privacy threats have been largely ignored by prior literature, which typically focuses on studying the communication between IoT devices and cloud end-points, or detecting vulnerable IoT devices exposed to the Internet. In this paper, we present a comprehensive and empirical measurement study to shed light on the local communication within a smart home deployment and its threats. We use a unique combination of passive network traffic captures, protocol honeypots, dynamic mobile app analysis, and crowdsourced IoT data from participants to identify and analyze a wide range of device activities on the local network. We then analyze these datasets to characterize local network protocols, security and privacy threats associated with them. Our analysis reveals vulnerable devices, insecure use of network protocols, and sensitive data exposure by IoT devices. We provide evidence of how this information is exfiltrated to remote servers by mobile apps and third-party SDKs, potentially for household fingerprinting, surveillance and cross-device tracking. We make our datasets and analysis publicly available to support further research in this area.",1715
1630,Systems and Networking,David Choffnes,"October 24th, 2023",Behind the Scenes: Uncovering TLS and Server Certificate Practice of IoT Device Vendors in the Wild,https://doi.org/10.1145/3618257.3624815," Hongying Dong, Hao Shu, Vijay Prakash, Yizhe Zhang, Muhammad Talha Paracha, David R. Choffnes, Santiago Torres-Arias, Danny Yuxing Huang, Yixin Sun. (2023). Behind the Scenes: Uncovering TLS and Server Certificate Practice of IoT Device Vendors in the Wild IMC, 457-477. https://doi.org/10.1145/3618257.3624815","IoT devices are increasingly used in consumer homes. Despite recent works in characterizing IoT TLS usage for a limited number of in-lab devices, there exists a gap in quantitatively understanding TLS behaviors from devices in the wild and server-side certificate management. To bridge this knowledge gap, we conduct a new measurement study by focusing on the practice of device vendors, through a crowdsourced dataset of network traffic from 2,014 real-world IoT devices across 721 global users. By quantifying the sharing of TLS fingerprints across vendors and across devices, we uncover the prevalent use of customized TLS libraries (i.e., not matched to any known TLS libraries) and potential security concerns resulting from co-located TLS stacks of different services. Furthermore, we present the first known study on server-side certificate management for servers contacted by IoT devices. Our study highlights potential concerns in the TLS/PKI practice by IoT device vendors. We aim to raise visibility for these issues and motivate vendors to improve security practice.",1716
1631,Systems and Networking,David Choffnes,"October 24th, 2023",BehavIoT: Measuring Smart Home IoT Behavior Using Network-Inferred Behavior Models,https://doi.org/10.1145/3618257.3624829," Tianrui Hu, Daniel J. Dubois, David R. Choffnes. (2023). BehavIoT: Measuring Smart Home IoT Behavior Using Network-Inferred Behavior Models IMC, 421-436. https://doi.org/10.1145/3618257.3624829","Smart home IoT platforms are typically closed systems, meaning that there is poor visibility into device behavior. Understanding device behavior is important not only for determining whether devices are functioning as expected, but also can reveal implications for privacy (e.g., surreptitious audio/video recording), security (e.g., device compromise), and safety (e.g., denial of service on a baby monitor). While there has been some work on identifying devices and a handful of activities, an open question is what is the extent to which we can automatically model the entire behavior of an IoT deployment, and how it changes over time, without any privileged access to IoT devices or platform messages. In this work, we demonstrate that the vast majority of IoT behavior can indeed be modeled, using a novel multi-dimensional approach that relies only on the (often encrypted) network traffic exchanged by IoT devices. Our key insight is that IoT behavior (including cross-device interactions) can often be captured using relatively simple models such as timers (for periodic behavior) and probabilistic state-machines (for user-initiated behavior and devices interactions) during a limited observation phase. We then propose deviation metrics that can identify when the behavior of an IoT device or an IoT system changes over time. Our models and metrics successfully identify several notable changes in our IoT deployment, including a camera that changed locations, network outages that impact connectivity, and device malfunctions.",1717
1632,Systems and Networking,David Choffnes,"October 25th, 2022",Internet scale reverse traceroute,https://doi.org/10.1145/3517745.3561422," Kevin Vermeulen, Ege G√ºrmeri√ßliler, √çtalo Cunha, David R. Choffnes, Ethan Katz-Bassett. (2022). Internet scale reverse traceroute IMC, 694-715. https://doi.org/10.1145/3517745.3561422","Knowledge of Internet paths allows operators and researchers to better understand the Internet and troubleshoot problems. Paths are often asymmetric, so measuring just the forward path only gives partial visibility. Despite the existence of Reverse Traceroute, a technique that captures reverse paths (the sequence of routers traversed by traffic from an arbitrary, uncontrolled destination to a given source), this technique did not fulfill the needs of operators and the research community, as it had limited coverage, low throughput, and inconsistent accuracy. In this paper we design, implement and evaluate revtr 2.0, an Internet-scale Reverse Traceroute system that combines novel measurement approaches and studies with a large-scale deployment to improve throughput, accuracy, and coverage, enabling the first exploration of reverse paths at Internet scale. revtr 2.0 can run 15M reverse traceroutes in one day. This scale allows us to open the system to external sources and users, and supports tasks such as traffic engineering and troubleshooting.",1718
1633,Systems and Networking,David Choffnes,"October 25th, 2022",A comparative analysis of certificate pinning in Android & iOS,https://doi.org/10.1145/3517745.3561439," Amogh Pradeep, Muhammad Talha Paracha, Protick Bhowmick, Ali Davanian, Abbas Razaghpanah, Taejoong Chung, Martina Lindorfer, Narseo Vallina-Rodriguez, Dave Levin, David R. Choffnes. (2022). A comparative analysis of certificate pinning in Android & iOS IMC, 605-618. https://doi.org/10.1145/3517745.3561439","TLS certificate pinning is a security mechanism used by applications to protect their network traffic against malicious certificate authorities. Pinning can provide enhanced security to defend against malicious third-party access to sensitive data in transit. It can also hide an app's personal data collection from users and auditors. Prior studies found pinning was rarely used in the Android ecosystem, except in high-profile, security-sensitive apps.",1719
1634,Systems and Networking,David Choffnes,"November 2nd, 2021",IoTLS: understanding TLS usage in consumer IoT devices,https://doi.org/10.1145/3487552.3487830," Muhammad Talha Paracha, Daniel J. Dubois, Narseo Vallina-Rodriguez, David R. Choffnes. (2021). IoTLS: understanding TLS usage in consumer IoT devices Internet Measurement Conference, 165-178. https://doi.org/10.1145/3487552.3487830","Consumer IoT devices are becoming increasingly popular, with most leveraging TLS to provide connection security. In this work, we study a large number of TLS-enabled consumer IoT devices to shed light on how effectively they use TLS, in terms of establishing secure connections and correctly validating certificates, and how observed behavior changes over time. To this end, we gather more than two years of TLS network traffic from IoT devices, conduct active probing to test for vulnerabilities, and develop a novel blackbox technique for exploring the trusted root stores in IoT devices by exploiting a side-channel through TLS Alert Messages. We find a wide range of behaviors across devices, with some adopting best security practices but most being vulnerable in one or more of the following ways: use of old/insecure protocol versions and/or ciphersuites, lack of certificate validation, and poor maintenance of root stores. Specifically, we find that at least 8 IoT devices still include distrusted certificates in their root stores, 11/32 devices are vulnerable to TLS interception attacks, and that many devices fail to adopt modern protocol features over time. Our findings motivate the need for IoT manufacturers to audit, upgrade, and maintain their devices' TLS implementations in a consistent and uniform way that safeguards all of their network traffic.",1720
1635,Systems and Networking,David Choffnes,"October 1st, 2021",A Comparative Study of Dark Patterns Across Mobile and Web Modalities,https://doi.org/10.1145/3479521," Johanna Gunawan, Amogh Pradeep, David Choffnes, Woodrow Hartzog, and Christo Wilson. ""A Comparative Study of Dark Patterns Across Mobile and Web Modalities"". Proceedings of the ACM: Human-Computer Interaction, 5(CSCW2), October, 2021. DOI: 10.1145/3479521","Dark patterns are user interface elements that can influence a person's behavior against their intentions or best interests. Prior work identified these patterns in websites and mobile apps, but little is known about how the design of platforms might impact dark pattern manifestations and related human vulnerabilities. In this paper, we conduct a comparative study of mobile application, mobile browser, and web browser versions of 105 popular services to investigate variations in dark patterns across modalities. We perform manual tests, identify dark patterns in each service, and examine how they persist or differ by modality. Our findings show that while services can employ some dark patterns equally across modalities, many dark patterns vary between platforms, and that these differences saddle people with inconsistent experiences of autonomy, privacy, and control. We conclude by discussing broader implications for policymakers and practitioners, and provide suggestions for furthering dark patterns research.",1721
1636,Systems and Networking,Gene Cooperman,"August 5th, 2024",Enabling Practical Transparent Checkpointing for MPI: A Topological Sort Approach,https://doi.org/10.48550/arXiv.2408.02218," Yao Xu, Gene Cooperman. (2024). Enabling Practical Transparent Checkpointing for MPI: A Topological Sort Approach CoRR, abs/2408.02218. https://doi.org/10.48550/arXiv.2408.02218","MPI is the de facto standard for parallel computing on a cluster of computers. Checkpointing is an important component in any strategy for software resilience and for long-running jobs that must be executed by chaining together time-bounded resource allocations. This work solves an old problem: a practical and general algorithm for transparent checkpointing of MPI that is both efficient and compatible with most of the latest network software. Transparent checkpointing is attractive due to its generality and ease of use for most MPI application developers. Earlier efforts at transparent checkpointing for MPI, one decade ago, had two difficult problems: (i) by relying on a specific MPI implementation tied to a specific network technology; and (ii) by failing to demonstrate sufficiently low runtime overhead.Problem (i) (network dependence) was already solved in 2019 by MANA's introduction of split processes. Problem (ii) (efficient runtime overhead) is solved in this work. This paper introduces an approach that avoids these limitations, employing a novel topological sort to algorithmically determine a safe future synchronization point. The algorithm is valid for both blocking and non-blocking collective communication in MPI. We demonstrate the efficacy and scalability of our approach through both micro-benchmarks and a set of five real-world MPI applications, notably including the widely used VASP (Vienna Ab Initio Simulation Package), which is responsible for 11% of the workload on the Perlmutter supercomputer at Lawrence Berkley National Laboratory. VASP was previously cited as a special challenge for checkpointing, in part due to its multi-algorithm codes.",1722
1637,Systems and Networking,Gene Cooperman,"September 26th, 2023",Implementation-Oblivious Transparent Checkpoint-Restart for MPI,https://doi.org/10.48550/arXiv.2309.14996," Yao Xu, Leonid Belyaev, Twinkle Jain, Derek Schafer, Anthony Skjellum, Gene Cooperman. (2023). Implementation-Oblivious Transparent Checkpoint-Restart for MPI CoRR, abs/2309.14996. https://doi.org/10.48550/arXiv.2309.14996","This work presents experience with traditional use cases of checkpointing on a novel platform. A single codebase (MANA) transparently checkpoints production workloads for major available MPI implementations: ""develop once, run everywhere"". The new platform enables application developers to compile their application against any of the available standards-compliant MPI implementations, and test each MPI implementation according to performance or other features.",1723
1638,Systems and Networking,Gene Cooperman,"December 12th, 2022",Collective Vector Clocks: Low-Overhead Transparent Checkpointing for MPI,https://doi.org/10.48550/arXiv.2212.05701," Yao Xu, Gene Cooperman. (2022). Collective Vector Clocks: Low-Overhead Transparent Checkpointing for MPI CoRR, abs/2212.05701. https://doi.org/10.48550/arXiv.2212.05701","Taking snapshots of the state of a distributed computation is useful for off-line analysis of the computational state, for later restarting from the saved snapshot, for cloning a copy of the computation, and for migration to a new cluster. The problem is made more difficult when supporting collective operations across processes, such as barrier, reduce operations, scatter and gather, etc. Some processes may have reached the barrier or other collective operation, while other processes wait a long time to reach that same barrier or collective operation. At least two solutions are well-known in the literature: (I) draining in-flight network messages and then freezing the network at checkpoint time; and (ii) adding a barrier prior to the collective operation, and either completing the operation or aborting the barrier if not all processes are present. Both solutions suffer important drawbacks. The code in the first solution must be updated whenever one ports to a newer network. The second solution implies additional barrier-related network traffic prior to each collective operation. This work presents a third solution that avoids both drawbacks. There is no additional barrier-related traffic, and the solution is implemented entirely above the network layer. The work is demonstrated in the context of transparent checkpointing of MPI libraries for parallel computation, where each of the first two solutions have already been used in prior systems, and then abandoned due to the aforementioned drawbacks. Experiments demonstrate the low runtime overhead of this new, network-agnostic approach. The approach is also extended to non-blocking, collective operations in order to handle overlapping of computation and communication.",1724
1639,Systems and Networking,Gene Cooperman,"December 11th, 2022",McMini: A Programmable DPOR-based Model Checker for Multithreaded Programs,https://doi.org/10.48550/arXiv.2212.05468," Maxwell Pirtle, Luka Jovanovic, Gene Cooperman. (2022). McMini: A Programmable DPOR-based Model Checker for Multithreaded Programs CoRR, abs/2212.05468. https://doi.org/10.48550/arXiv.2212.05468",Model checking has become a key tool for gaining confidence in correctness of multi-threaded programs. A simple model checker is useful for detecting race conditions prior to production. Current model checkers hardwire the behavior of common thread operations. McMini is an **extensible** modelChecker based on DPOR (Dynamic Partial Order Reduction),1725
1640,Systems and Networking,Gene Cooperman,"November 9th, 2020",CRAC: Checkpoint-Restart Architecture for CUDA with Streams and UVM,https://dl.acm.org/doi/10.5555/3433701.3433803," Twinkle Jain and Gene Cooperman, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC'20), pp. 1083‚Äì1097, Nov., 2020, IEEE Computer Society","The share of the top 500 supercomputers with NVIDIA GPUs is now over 25% and continues to grow. While fault tolerance is a critical issue for supercomputing, there does not currently exist an efficient, scalable solution for CUDA applications on NVIDIA GPUs. CRAC (Checkpoint-Restart Architecture for CUDA) is a new checkpoint-restart solution for fault tolerance that supports the full range of CUDA applications. CRAC combines: low runtime overhead (approximately 1% or less); fast checkpoint-restart; support for scalable CUDA streams (for efficient usage of all of the thousands of GPU cores); and support for the full features of Unified Virtual Memory (eliminating the programmer's burden of migrating memory between device and host). CRAC achieves its flexible architecture by segregating application code (checkpointed) and its external GPU communication via non-reentrant CUDA libraries (not checkpointed) within a single process's memory. This eliminates the high overhead of inter-process communication in earlier approaches, and has fewer limitations.",1726
1641,Systems and Networking,Gene Cooperman,"June 27th, 2018",Functional Classification of Protein Structures by Local Structure Matching in Graph Representation,https://www.ncbi.nlm.nih.gov/pubmed/29604149," ""Functional Classification of Protein Structures by Local Structure Matching in Graph Representation"", Caitlyn L. Mills, Rohan Garg, Joslynn S. Lee, Liang Tian, Alexandru Suciu, Gene Cooperman, Penny J. Beuning, Mary Jo Ondrechen, Protein Science¬†27(6), pp. 1125--1135, 2018,","Abstract As a result of high-throughput protein structure initiatives, over 14,400 protein structures have been solved by Structural Genomics (SG) centers and participating research groups. While the totality of SG data represents a tremendous contribution to genomics and structural biology, reliable functional information for these proteins is generally lacking. Better functional predictions for SG proteins will add substantial value to the structural information already obtained. Our method described herein, Graph Representation of Active Sites for Prediction of Function (GRASP-Func), predicts quickly and accurately the biochemical function of proteins by representing residues at the predicted local active site as graphs rather than in Cartesian coordinates. We compare the GRASP-Func method to our previously reported method, Structurally Aligned Local Sites of Activity (SALSA), using the Ribulose Phosphate Binding Barrel (RPBB), 6-Hairpin Glycosidase (6-HG), and Concanavalin A-like Lectins/Glucanase (CAL/G) superfamilies as test cases. In each of the superfamilies, SALSA and the much faster method GRASP-Func yield similar correct classification of previously characterized proteins, providing a validated benchmark for the new method. In addition, we analyzed SG proteins using our SALSA and GRASP-Func methods to predict function. Forty-one SG proteins in the RPBB superfamily, nine SG proteins in the 6-HG superfamily, and one SG protein in the CAL/G superfamily were successfully classified into one of the functional families in their respective superfamily by both methods. This improved, faster, validated computational method can yield more reliable predictions of function that can be used for a wide variety of applications by the community. Keywords: 6-Hairpin Glycosidase (6-HG) superfamily; Concanavalin A-like Lectins/Glucanase (CAL/G) superfamily; Graph Representation of Active Sites for Prediction of Function (GRASP-Func); Ribulose Phosphate Binding Barrel (RPBB) superfamily; Structurally Aligned Local Sites of Activity (SALSA); protein function annotation.",1727
1642,Systems and Networking,Peter Desnoyers,"October 23rd, 2023",Persistent Memory Research in the Post-Optane Era,https://doi.org/10.1145/3609308.3625268," Peter Desnoyers, Ian F. Adams, Tyler Estro, Anshul Gandhi, Geoff Kuenning, Michael P. Mesnier, Carl A. Waldspurger, Avani Wildani, Erez Zadok. (2023). Persistent Memory Research in the Post-Optane Era DIMES@SOSP, 23-30. https://doi.org/10.1145/3609308.3625268","After over a decade of researcher anticipation for the arrival of persistent memory (PMem), the first shipments of 3D XPoint-based Intel Optane Memory in 2019 were quickly followed by its cancellation in 2022. Was this another case of an idea quickly fading from future to past tense, relegating work in this area to the graveyard of failed technologies? The recently introduced Compute Express Link (CXL) may offer a path forward, with its persistent memory profile offering a universal PMem attachment point. Yet new technologies for memory-speed persistence seem years off, and may never become competitive with evolving DRAM and flash speeds. Without persistent memory itself, is future PMem research doomed? We offer two arguments for why reports of the death of PMem research are greatly exaggerated. First, the bulk of persistent-memory research has not in fact addressed memory persistence, but rather in-memory crash consistency, which was never an issue in prior systems where CPUs could not observe post-crash memory states. CXL memory pooling allows multiple hosts to share a single memory, all in different failure domains, raising crash-consistency issues even with volatile memory. Second, we believe CXL necessitates a ""disaggregation"" of PMem research. Most work to date assumed a single technology and set of features, i.e. , speed, byte addressability, and CPU load/store access. With an open interface allowing new topologies and diverse PMem technologies, we argue for the need to examine these features individually and in combination. While one form of PMem may have been canceled, we argue that the research problems it raised not only remain relevant but have expanded in a CXL-based future.",1728
1643,Systems and Networking,Peter Desnoyers,"March 28th, 2022",Beating the I/O bottleneck: a case for log-structured virtual disks,https://doi.org/10.1145/3492321.3524271," Mohammad Hossein Hajkazemi, Vojtech Aschenbrenner, Mania Abdi, Emine Ugur Kaynar, Amin Mossayebzadeh, Orran Krieger, Peter Desnoyers. (2022). Beating the I/O bottleneck: a case for log-structured virtual disks EuroSys, 628-643. https://doi.org/10.1145/3492321.3524271","With the increasing dominance of SSDs for local storage, today's network mounted virtual disks can no longer offer competitive performance. We propose a Log-Structured Virtual Disk (LSVD) that couples log-structured approaches at both the cache and storage layer to provide a virtual disk on top of S3-like storage. Both cache and backend store are order-preserving, enabling LSVD to provide strong consistency guarantees in case of failure. Our prototype demonstrates that the approach preserves all the advantages of virtual disks, while offering dramatic performance improvements over not only commonly used virtual disks, but the same disks combined with inconsistent (i.e. unsafe) local caching.",1729
1644,Systems and Networking,Peter Desnoyers,"December 29th, 2021",The Open Cloud Testbed (OCT): A Platform for Research into new Cloud Technologies,https://doi.org/10.1109/CloudNet53349.2021.9657109," Michael Zink, David E. Irwin , Emmanuel Cecchet, Hakan Saplakoglu, Orran Krieger, Martin C. Herbordt, Michael Daitzman, Peter Desnoyers, Miriam Leeser, Suranga Handagala. (2021). The Open Cloud Testbed (OCT): A Platform for Research into new Cloud Technologies CloudNet, 140-147. https://doi.org/10.1109/CloudNet53349.2021.9657109","The Open Cloud Testbed (OCT) project is building and supporting a testbed for research and experimentation into new cloud platforms. Testbeds such as OCT are critical for enabling research into newCloud technologies. This paper gives an overview of the OpenCloud Testbed, including an overview on the existing components OCT is based on.",1730
1645,Systems and Networking,Engin Kirda,"November 13th, 2021",T-Reqs: HTTP Request Smuggling with Differential Fuzzing,https://doi.org/10.1145/3460120.3485384," Bahruz Jabiyev, Steven Sprecher, Kaan Onarlioglu, Engin Kirda. (2021). T-Reqs: HTTP Request Smuggling with Differential Fuzzing CCS, 1805-1820. https://doi.org/10.1145/3460120.3485384","HTTP Request Smuggling (HRS) is an attack that exploits the HTTP processing discrepancies between two servers deployed in a proxy-origin configuration, allowing attackers to smuggle hidden requests through the proxy. While this idea is not new, HRS is soaring in popularity due to recently revealed novel exploitation techniques and real-life abuse scenarios. In this work, we step back from the highly-specific exploits hogging the spotlight, and present the first work that systematically explores HRS within a scientific framework. We design an experiment infrastructure powered by a novel grammar-based differential fuzzer, test 10 popular server/proxy/CDN technologies in combinations, identify pairs that result in processing discrepancies, and discover exploits that lead to HRS. Our experiment reveals previously unknown ways to manipulate HTTP requests for exploitation, and for the first time documents the server pairs prone to HRS.",1731
1646,Systems and Networking,Engin Kirda,"February 9th, 2020",Discovering algorithmic denial-of-service vulnerabilities through guided micro-fuzzing,https://arxiv.org/abs/2002.03416," Blair, William, Andrea Mambretti, Sajjad Arshad, Michael Weissbacher, William K. Robertson, Engin Kirda and Manuel Egele. ‚ÄúHotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing.‚Äù ArXiv abs/2002.03416 (2020): n. pag.","Contemporary fuzz testing techniques focus on identifying memory corruption vulnerabilities that allow adversaries to achieve either remote code execution or information disclosure. Meanwhile, Algorithmic Complexity (AC)vulnerabilities, which are a common attack vector for denial-of-service attacks, remain an understudied threat. In this paper, we present HotFuzz, a framework for automatically discovering AC vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high CPU utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values.",1732
1647,Systems and Networking,Engin Kirda,"February 25th, 2016",TrueClick: automatically distinguishing trick banners from genuine download links,http://dl.acm.org/citation.cfm?id=2664279," ""TrueClick: automatically distinguishing trick banners from genuine download links"" S Duman, K Onarlioglu, AO Ulusoy, W Robertson, E Kirda- Proceedings of the 30th Annual Computer Security, 2014","The ubiquity of Internet advertising has made it a popular target for attackers. One well-known instance of these attacks is the widespread use of trick banners that use social engineering techniques to lure victims into clicking on deceptive fake links, potentially leading to a malicious domain or malware. A recent and pervasive trend by attackers is to imitate the ""download"" or ""play"" buttons in popular file sharing sites (e.g., one-click hosters, video-streaming sites, bittorrent sites) in an attempt to trick users into clicking on these fake banners instead of the genuine link. In this paper, we explore the problem of automatically assisting Internet users in detecting malicious trick banners and helping them identify the correct link. We present a set of features to characterize trick banners based on their visual properties such as image size, color, placement on the enclosing webpage, whether they contain animation effects, and whether they consistently appear with the same visual properties on consecutive loads of the same webpage. We have implemented a tool called TrueClick, which uses image processing and machine learning techniques to build a classifier based on these features to automatically detect the trick banners on a webpage. Our approach automatically classifies trick banners, and requires no manual effort to compile blacklists as current approaches do. Our experiments show that TrueClick results in a 3.55 factor improvement in correct link selection in the absence of other ad blocking software, and that it can detect trick banners missed by a popular ad detection tool, Adblock Plus.",1733
1648,Systems and Networking,Engin Kirda,"July 16th, 2015",BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications,http://link.springer.com/chapter/10.1007/978-3-662-47854-7_21," Ozcan, Ahmet Talha, et al. ""BabelCrypt: The Universal Encryption Layer for Mobile Messaging Applications."" Financial Cryptography and Data Security. Springer Berlin Heidelberg, 2015. 355-369.|","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1734
1649,Systems and Networking,Alan Mislove,"November 7th, 2022","Hammurabi: A Framework for Pluggable, Logic-based X.509 Certificate Validation Policies",https://doi.org/10.1145/3548606.3560594," James Larisch, Waqar Aqeel, Michael Lum, Yaelle Goldschlag, Kasra Torshizi, Leah Kannan, Yujie Wang, Taejoong Chung, Dave Levin, Bruce M. Maggs, Alan Mislove, Bryan Parno, and Christo Wilson. (2022). ""Hammurabi: A Framework for Pluggable, Logic-Based X.509 Certificate Validation Policies"". In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS ‚Äô22), November 7‚Äì11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA, 15 pages. DOI: 10.1145/3548606.3560594","This paper proposes using a logic programming language to disentangle X.509 certificate validation policy from mechanism. Expressing validation policies in a logic programming language provides multiple benefits. First, policy and mechanism can be more independently written, augmented, and analyzed compared to the current practice of interweaving them within a C or C++ implementation. Once written, these policies can be easily shared and modified for use in different TLS clients. Further, logic programming allows us to determine when clients differ in their policies and use the power of imputation to automatically generate interesting certificates, e.g., a certificate that will be accepted by one browser but not by another. We present a new framework called Hammurabi for expressing validation policies, and we demonstrate that we can express the complex policies of the Google Chrome and Mozilla Firefox web browsers in this framework. We confirm the fidelity of the Hammurabi policies by comparing the validation decisions they make with those made by the browsers themselves on over ten million certificate chains derived from Certificate Transparency logs, as well as 100K synthetic chains. We also use imputation to discover nine validation differences between the two browsers' policies. Finally, we demonstrate the feasibility of integrating Hammurabi into Firefox and the Go language in less than 100 lines of code each.",1735
1650,Systems and Networking,Alan Mislove,"October 25th, 2022",Measurement and analysis of implied identity in ad delivery optimization,https://doi.org/10.1145/3517745.3561450," Levi Kaplan, Nicole Gerzon, Alan Mislove, Piotr Sapiezynski. (2022). Measurement and analysis of implied identity in ad delivery optimization IMC, 195-209. https://doi.org/10.1145/3517745.3561450","The study was published in the open-source journal, The Open Knowledge Project. It is published by the Open Knowledge Foundation, a non-profit organization. We find dramatic skews in who ultimately sees ads solely based on the demographics of the person in the ads. These findings bring up novel technical, legal, and policy questions and underscore the need to better understand how platforms deliver ads.",1736
1651,Systems and Networking,Alan Mislove,"November 2nd, 2021",Selfish & opaque transaction ordering in the Bitcoin blockchain: the case for chain neutrality,https://doi.org/10.1145/3487552.3487823," Johnnatan Messias, Mohamed Alzayat, Balakrishnan Chandrasekaran , Krishna P. Gummadi, Patrick Loiseau, Alan Mislove. (2021). Selfish & opaque transaction ordering in the Bitcoin blockchain: the case for chain neutrality Internet Measurement Conference, 320-335. https://doi.org/10.1145/3487552.3487823","Most public blockchain protocols, including the popular Bitcoin and Ethereum blockchains, do not formally specify the order in which miners should select transactions from the pool of pending (or uncommitted) transactions for inclusion in the blockchain. Over the years, informal conventions or ""norms"" for transaction ordering have, however, emerged via the use of shared software by miners, e.g., the GetBlockTemplate (GBT) mining protocol in Bitcoin Core. Today, a widely held view is that Bitcoin miners prioritize transactions based on their offered ""transaction fee-per-byte."" Bitcoin users are, consequently, encouraged to increase the fees to accelerate the commitment of their transactions, particularly during periods of congestion. In this paper, we audit the Bitcoin blockchain and present statistically significant evidence of mining pools deviating from the norms to accelerate the commitment of transactions for which they have (i) a selfish or vested interest, or (ii) received dark-fee payments via opaque (non-public) side-channels. As blockchains are increasingly being used as a record-keeping substrate for a variety of decentralized (financial technology) systems, our findings call for an urgent discussion on defining neutrality norms that miners must adhere to when ordering transactions in the chains. Finally, we make our data sets and scripts publicly available.",1737
1652,Systems and Networking,Alan Mislove,"August 9th, 2021",The ties that un-bind: decoupling IP from web services and sockets for robust addressing agility at CDN-scale,https://doi.org/10.1145/3452296.3472922," Marwan Fayed, Lorenz Bauer, Vasileios Giotsas, Sami Kerola, Marek Majkowski, Pavel Odintsov, Jakub Sitnicki, Taejoong Chung, Dave Levin, Alan Mislove, Christopher A. Wood, Nick Sullivan. (2021). The ties that un-bind: decoupling IP from web services and sockets for robust addressing agility at CDN-scale SIGCOMM, 433-446. https://doi.org/10.1145/3452296.3472922","The couplings between IP addresses, names of content or services, and socket interfaces, are too tight. This impedes system manageability, growth, and overall provisioning. In turn, large-scale content providers are forced to use staggering numbers of addresses, ultimately leading to address exhaustion (IPv4) and inefficiency (IPv6). In this paper, we revisit IP bindings, entirely. We attempt to evolve addressing conventions by decoupling IP in DNS and from network sockets. Alongside technologies such as SNI and ECMP, a new architecture emerges that ``unbinds'' IP from services and servers, thereby returning IP's role to merely that of reachability. The architecture is under evaluation at a major CDN in multiple datacenters. We show that addresses can be generated randomly \emph{per-query}, for 20M+ domains and services, from as few as ~4K addresses, 256 addresses, and even \emph{one} IP address. We explain why this approach is transparent to routing, L4/L7 load-balancers, distributed caching, and all surrounding systems -- and is \emph{highly desirable}. Our experience suggests that many network-oriented systems and services (e.g., route leak mitigation, denial of service, measurement) could be improved, and new ones designed, if built with addressing agility.",1738
1653,Systems and Networking,Alan Mislove,"August 2nd, 2021",A Large-Scale Analysis of Deployed Traffic Differentiation Practices,https://doi.org/10.1145/3341302.3342092," Fangfan Li, Arian Akhavan Niaki, David Choffnes, Phillipa Gill, and Alan Mislove. 2019. A large-scale analysis of deployed traffic differentiation practices. In Proceedings of the ACM Special Interest Group on Data Communication (SIGCOMM '19). Association for Computing Machinery, New York, NY, USA, 130‚Äì144. DOI: 10.1145/3341302.3342092","Net neutrality has been the subject of considerable public debate over the past decade. Despite the potential impact on content providers and users, there is currently a lack of tools or data for stakeholders to independently audit the net neutrality policies of network providers. In this work, we address this issue by conducting a one-year study of content-based traffic differentiation policies deployed in operational networks, using results from 1,045,413 crowdsourced measurements conducted by 126,249 users across 2,735 ISPs in 183 countries/regions. We develop and evaluate a methodology that combines individual per-device measurements to form high-confidence, statistically significant inferences of differentiation practices, including fixed-rate bandwidth limits (i.e., throttling) and delayed throttling practices. Using this approach, we identify differentiation in both cellular and WiFi networks, comprising 30 ISPs in 7 countries. We also investigate the impact of throttling practices on video streaming resolution for several popular video streaming providers.",1739
1654,Systems and Networking,Alan Mislove,"March 1st, 2021",Building and Auditing Fair Algorithms: A Case Study in Candidate Screening,https://doi.org/10.1145/3442188.3445928," Christo Wilson, Avijit Ghosh, Shan Jiang, Alan Mislove, Lewis Baker, Janelle Szary, Kelly Trindel, and Frida Polli. ""Building and Auditing Fair Algorithms: A Case Study in Candidate Screening."" In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2021). Virtual Event, Canada, March, 2021. DOI: 10.1145/3442188.3445928","Academics, activists, and regulators are increasingly urging companies to develop and deploy sociotechnical systems that are fair and unbiased. Achieving this goal, however, is complex: the developer must (1) deeply engage with social and legal facets of ""fairness"" in a given context, (2) develop software that concretizes these values, and (3) undergo an independent algorithm audit to ensure technical correctness and social accountability of their algorithms. To date, there are few examples of companies that have transparently undertaken all three steps. In this paper we outline a framework for algorithmic auditing by way of a case-study of pymetrics, a startup that uses machine learning to recommend job candidates to their clients. We discuss how pymetrics approaches the question of fairness given the constraints of ethical, regulatory, and client demands, and how pymetrics' software implements adverse impact testing. We also present the results of an independent audit of pymetrics' candidate screening tool. We conclude with recommendations on how to structure audits to be practical, independent, and constructive, so that companies have better incentive to participate in third party audits, and that watchdog groups can be better prepared to investigate companies.",1740
1655,Systems and Networking,Alan Mislove,"February 11th, 2016",Peeking Beneath the Hood of Uber,http://dl.acm.org/citation.cfm?id=2815681," Chen, Le, Alan Mislove, and Christo Wilson. ""Peeking Beneath the Hood of Uber."" Proceedings of the 2015 ACM Conference on Internet Measurement Conference. ACM, 2015.","Recently, Uber has emerged as a leader in the ""sharing economy"". Uber is a ""ride sharing"" service that matches willing drivers with customers looking for rides. However, unlike other open marketplaces (e.g., AirBnB), Uber is a black-box: they do not provide data about supply or demand, and prices are set dynamically by an opaque ""surge pricing"" algorithm. The lack of transparency has led to concerns about whether Uber artificially manipulate prices, and whether dynamic prices are fair to customers and drivers. In order to understand the impact of surge pricing on passengers and drivers, we present the first in-depth investigation of Uber. We gathered four weeks of data from Uber by emulating 43 copies of the Uber smartphone app and distributing them throughout downtown San Francisco (SF) and midtown Manhattan. Using our dataset, we are able to characterize the dynamics of Uber in SF and Manhattan, as well as identify key implementation details of Uber's surge price algorithm. Our observations about Uber's surge price algorithm raise important questions about the fairness and transparency of this system.",1741
1656,Systems and Networking,Alan Mislove,"October 28th, 2015",Identifying Traffic Differentiation in Mobile Networks,https://doi.org/10.1145/2815675.2815691," Arash Molavi Kakhki, Abbas Razaghpanah, Hyungjoon Koo, Anke Li, Rajeshkumar Golani, David Choffnes, Phillipa Gill, and Alan Mislove. ‚ÄúIdentifying traffic differentiation in mobile networks.‚Äù Proceedings of the 2015 Internet Measurement Conference. 2015. DOI: 10.1145/2815675.2815691","Traffic differentiation---giving better (or worse) performance to certain classes of Internet traffic---is a well-known but poorly understood traffic management policy. There is active discussion on whether and how ISPs should be allowed to differentiate Internet traffic, but little data about current practices to inform this discussion. Previous work attempted to address this problem for fixed line networks; however, there is currently no solution that works in the more challenging mobile environment. In this paper, we present the design, implementation, and evaluation of the first system and mobile app for identifying traffic differentiation for arbitrary applications in the mobile environment (i.e., wireless networks such as cellular and WiFi, used by smartphones and tablets). The key idea is to use a VPN proxy to record and replay the network traffic generated by arbitrary applications, and compare it with the network behavior when replaying this traffic outside of an encrypted tunnel. We perform the first known testbed experiments with actual commercial shaping devices to validate our system design and demonstrate how it outperforms previous work for detecting differentiation. We released our app and collected differentiation results from 12 ISPs in 5 countries. We find that differentiation tends to affect TCP traffic (reducing rates by up to 60%) and that interference from middleboxes (including video-transcoding devices) is pervasive. By exposing such behavior, we hope to improve transparency for users and help inform future policies.",1742
1657,Systems and Networking,Cristina Nita-Rotaru,"December 9th, 2024",Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking,https://doi.org/10.1145/3658644.3670301," Ben Weintraub, Jiwon Kim, Ran Tao, Cristina Nita-Rotaru, Hamed Okhravi, Dave (Jing) Tian, Benjamin E. Ujcich. (2024). Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking CCS, 3630-3644. https://doi.org/10.1145/3658644.3670301","Intent-based networking (IBN) enables network administrators to express high-level goals and network policies without needing to specify low-level forwarding configurations, topologies, or protocols. Administrators can define intents that capture the overall behavior they want from the network, and an IBN controller compiles such intents into low-level configurations that get installed in the network and implement the desired behavior. We discovered that current IBN specifications and implementations do not specify that flow rule installation orderings should be enforced, which leads to temporal vulnerabilities where, for a limited time, attackers can exploit indeterminate connectivity behavior to gain unauthorized network access. In this paper, we analyze the causes of such temporal vulnerabilities and their security impacts with a representative case study via the ONOS IBN implementation. We devise the Phantom Link attack and demonstrate a working exploit to highlight the security impacts. To defend against such attacks, we propose Spotlight, a detection method that can alert a system administrator of risky intent updates prone to exploitable temporal vulnerabilities. Spotlight is effective in identifying risky updates using realistic network topologies and policies. We show that Spotlight can detect risky updates in a mean time of 0.65 seconds for topologies of over 1,300 nodes.",1743
1658,Systems and Networking,Cristina Nita-Rotaru,"December 9th, 2024",Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network,https://doi.org/10.1145/3658644.3670315," Ben Weintraub, Satwik Prabhu Kumble, Cristina Nita-Rotaru, Stefanie Roos. (2024). Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network CCS, 2562-2576. https://doi.org/10.1145/3658644.3670315","The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network. In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using them we re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment.",1744
1659,Systems and Networking,Cristina Nita-Rotaru,"December 9th, 2024",Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups,https://doi.org/10.1145/3658644.3690259," Christof Ferreira Torres, Albin Mamuti, Ben Weintraub, Cristina Nita-Rotaru, Shweta Shinde. (2024). Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups CCS, 2591-2605. https://doi.org/10.1145/3658644.3690259","The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging. In this paper, we investigate the prevalence and impact of MEV on Ethereum and prominent rollups such as Arbitrum, Optimism, and zkSync over a nearly three-year period. Our analysis encompasses various metrics including volume, profits, costs, competition, and response time to MEV opportunities. We discover that MEV is widespread on rollups, with trading volume comparable to Ethereum. We also find that, although MEV costs are lower on rollups, profits are also significantly lower compared to Ethereum. Additionally, we examine the prevalence of sandwich attacks on rollups. While our findings did not detect any sandwiching activity on popular rollups, we did identify the potential for cross-layer sandwich attacks facilitated by transactions that are sent across rollups and Ethereum. Consequently, we propose and evaluate the feasibility of three novel attacks that exploit cross-layer transactions, revealing that attackers could have already earned approximately 2 million USD through cross-layer sandwich attacks.",1745
1660,Systems and Networking,Cristina Nita-Rotaru,"July 17th, 2019",Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols,https://doi.org/10.1609/aaai.v33i01.33019478," Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser, Cristina Nita-Rotaru. (2019). Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols AAAI, 9478-9483. https://doi.org/10.1609/aaai.v33i01.33019478",Abstract Grammar-based fuzzing is a technique used to find software vulnerabilities by injecting well-formed inputs generated following rules that encode application semantics. Most grammar-based fuzzers for network protocols rely on human experts to manually specify these rules. In this work we study automated learning of protocol rules from textual specifications (i.e. RFCs). We evaluate the automatically extracted protocol rules by applying them to a state-of-the-art fuzzer for transport protocols and show that it leads to a smaller number of test cases while finding the same attacks as the system that uses manually specified rules.,1746
1661,Systems and Networking,Cristina Nita-Rotaru,"October 15th, 2018",Cross-App Poisoning in Software-Defined Networking,https://doi.org/10.1145/3243734.3243759," Benjamin E. Ujcich, Samuel Jero, Anne Edmundson, Qi Wang , Richard Skowyra, James Landry, Adam Bates , William H. Sanders, Cristina Nita-Rotaru, Hamed Okhravi. (2018). Cross-App Poisoning in Software-Defined Networking CCS, 648-663. https://doi.org/10.1145/3243734.3243759","Software-defined networking (SDN) continues to grow in popularity because of its programmable and extensible control plane realized through network applications (apps). However, apps introduce significant security challenges that can systemically disrupt network operations, since apps must access or modify data in a shared control plane state. If our understanding of how such data propagate within the control plane is inadequate, apps can co-opt other apps, causing them to poison the control plane's integrity. We present a class of SDN control plane integrity attacks that we call cross-app poisoning (CAP), in which an unprivileged app manipulates the shared control plane state to trick a privileged app into taking actions on its behalf. We demonstrate how role-based access control (RBAC) schemes are insufficient for preventing such attacks because they neither track information flow nor enforce information flow control (IFC). We also present a defense, ProvSDN, that uses data provenance to track information flow and serves as an online reference monitor to prevent CAP attacks. We implement ProvSDN on the ONOS SDN controller and demonstrate that information flow can be tracked with low-latency overheads.",1747
1662,Systems and Networking,Cristina Nita-Rotaru,"May 27th, 2018",Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,https://arxiv.org/abs/1804.00308," Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning  Matthew Jagielski, Alina Oprea, Chang Liu, Cristina Nita-Rotaru, and Bo Li  IEEE S&P (Oakland) 2018","As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",1748
1663,Systems and Networking,Cristina Nita-Rotaru,"October 23rd, 2017",Chizpurfle: A Gray-Box Android Fuzzer for Vendor Service Customizations,http://ieeexplore.ieee.org/document/8109068/," Antonio Ken Iannillo, Roberto Natella, Domenico Cotroneo, Cristina Nita-Rotaru. IEEE ISSRE 2017, September 2017","Chizpurfle is a novel ""gray-box"" fuzzing tool for vendor-specific Android services. Testing these services is challenging for existing tools, since vendors do not provide source code and the services cannot be run on a device emulator. Chiz Purfle has been designed to run on an unmodified Android OS on an actual device. The tool automatically discovers, fuzzes, and profiles proprietary services.",1749
1664,Systems and Networking,Cristina Nita-Rotaru,"September 1st, 2017",BEADS: Automated Attack Discovery in OpenFlow-based SDN Systems,https://link.springer.com/chapter/10.1007/978-3-319-66332-6_14," Samuel Jero, Xiangyu Bu, Hamed Okhravi, Cristina Nita-Rotaru, Richard Skowyra, Sonia Fahmy. RAID 2017, September 2017","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1750
1665,Systems and Networking,Cristina Nita-Rotaru,"June 29th, 2017",Analyzing Operational Behavior of Stateful Protocol Implementations for Detecting Semantic Bugs,http://ieeexplore.ieee.org/document/8023160/," Endadul Hoque, Omar Chowdhury, Sze Yiu Chau, Cristina Nita-Rotaru, Ninghui Li. IEEE DSN 2017, June 2017","Network protocol implementations must comply with their specifications that include properties describing the correct operational behavior of the protocol. Due to inconsistent interpretations of the specification, developers can unknowingly introduce semantic bugs, which cause the implementations to violate the respective properties. Detecting such bugs in stateful protocols becomes significantly difficult as their operations depend on their internal state machines and complex interactions between the protocol logic. We present an automated tool to help developers analyze their protocol implementations and detect semantic bugs violating the temporal properties of the protocols. The paper was published in the 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)",1751
1666,Systems and Networking,Guevara Noubir,"February 12th, 2025",Assumption-Free Fuzzy PSI via Predicate Encryption,https://eprint.iacr.org/2025/217," Erik-Oliver Blass, Guevara Noubir. (2025). Assumption-Free Fuzzy PSI via Predicate Encryption IACR Cryptol. ePrint Arch., 2025, 217. https://eprint.iacr.org/2025/217","We present the first protocol for efficient Fuzzy Private Set Intersection (PSI) that achieves linear communication complexity, does not depend on restrictive assumptions on the distribution of party inputs, and abstains from inefficient fully homomorphic encryption. Specifically, our protocol enables two parties to compute all pairs of elements from their respective sets that are within a given Hamming distance, without constraints on how these sets are structured. Our key insight is that securely computing the (threshold) Hamming distance between two inputs can be reduced to securely computing their inner product. Leveraging this reduction, we construct a Fuzzy PSI protocol using recent techniques for inner-product predicate encryption. To enable the use of predicate encryption in our setting, we establish that these predicate encryption schemes satisfy a weak notion of simulation security and demonstrate how their internal key derivation can be efficiently distributed without a trusted third party. As a result, our Fuzzy PSI on top of predicate encryption features not only asymptotically optimal linear communication complexity but is also concretely practical. BibTeX Copy to clipboard",1752
1667,Systems and Networking,Guevara Noubir,"May 20th, 2024",Establishing Trust in the Beyond-5G Core Network using Trusted Execution Environments,https://doi.org/10.48550/arXiv.2405.12177," Marinos Vomvas, Norbert Ludant, Guevara Noubir. (2024). Establishing Trust in the Beyond-5G Core Network using Trusted Execution Environments CoRR, abs/2405.12177. https://doi.org/10.48550/arXiv.2405.12177","The fifth generation (5G) of cellular networks starts a paradigm shift from the traditional monolithic system design to a Service Based Architecture, that fits modern performance requirements and scales efficiently to new services. This paradigm will be the foundation of future cellular core networks beyond 5G. The new architecture splits network functionalities into smaller logical entities that can be disaggregated logically, physically, and geographically. This affords interoperability between the mobile network operators and commercial software and hardware vendors or cloud providers. By making use of commodity services and products, this system construct inherits the vulnerabilities in those underlying technologies, thereby increasing its attack surface and requiring a rigorous security analysis. In this work, we review the security implications introduced in B5G networks, and the security mechanisms that are supported by the 5G standard. We emphasize on the support of Zero Trust Architecture in 5G and its relevance in decentralized deployments. We revisit the definition of trust in modern enterprise network operations and identify important Zero Trust properties that are weakened by the nature of cloud deployments. To that end, we propose a vertical extension of Zero Trust, namely, Zero Trust Execution, to model untrusted execution environments, and we provide an analysis on how to establish trust in Beyond-5G network architectures using Trusted Execution Environments. Our analysis shows how our model architecture handles the increased attack surface and reinforces the Zero Trust Architecture principles in the 5G Core, without any changes to the 5G standard. Finally, we provide experimental results over a 5G testbed using Open5GS and UERANSIM that demonstrate minimal performance overhead, and a monetary cost evaluation.",1753
1668,Systems and Networking,Guevara Noubir,"December 5th, 2022",On the Implications of Spoofing and Jamming Aviation Datalink Applications,https://doi.org/10.1145/3564625.3564651," Harshad Sathaye, Guevara Noubir, Aanjhan Ranganathan. (2022). On the Implications of Spoofing and Jamming Aviation Datalink Applications ACSAC, 548-560. https://doi.org/10.1145/3564625.3564651","Aviation datalink applications such as¬†controller-pilot datalink communications (CPDLC) and¬†automatic dependent surveillance-contract (ADS-C) were designed to supplement existing communication systems to accommodate increasing air traffic. These applications are typically used to provide departure clearance, en-route services such as altitude and flight plan changes, air traffic surveillance and reporting, and radio frequency assignments. Unlike most attacks proposed so far where the attacker influences decision-making through manipulated instruments, attacks on aviation datalink provide adversaries with a new attack vector to influence the flight crew‚Äôs decision-making through direct instructions. In this work, we perform a security analysis of these applications and outline the requirements for executing a successful attack. Specifically, we propose a coordinated multi-aircraft attack and show how an adversary capable of spoofing datalink messages and reactive jamming can influence the flight crew‚Äôs decision-making. Through geospatial analysis of historical flight data, we identify 48 vulnerable regions where an attacker has a 90% chance of encountering favorable conditions for coordinated multi-aircraft attacks. Next, we implement a reactive jammer that ensures stealthy attack execution by targeting messages from a specific aircraft with a reaction time of 1.48 ms and 98.85% jamming success. Even though by themselves these attacks have a lower probability of endangering the safety of the aircraft, the threat is magnified when combined with attacks on other avionics. Finally, we discuss the possibility of executing integrated attacks on aircraft system as a whole emphasizing the importance of securing individual components in the aviation ecosystem.",1754
1669,Systems and Networking,Guevara Noubir,"March 18th, 2022","DEFORM: A Practical, Universal Deep Beamforming System",https://doi.org/10.48550/arXiv.2203.09727," Hai N. Nguyen, Guevara Noubir. (2022). DEFORM: A Practical, Universal Deep Beamforming System CoRR, abs/2203.09727. https://doi.org/10.48550/arXiv.2203.09727","We introduce, design, and evaluate a set of universal receiver beamforming techniques. Our approach and system DEFORM, a Deep Learning (DL) based RX beamforming achieves significant gain for multi antenna RF receivers while being agnostic to the transmitted signal features (e.g., modulation or bandwidth). It is well known that combining coherent RF signals from multiple antennas results in a beamforming gain proportional to the number of receiving elements. However in practice, this approach heavily relies on explicit channel estimation techniques, which are link specific and require significant communication overhead to be transmitted to the receiver. DEFORM addresses this challenge by leveraging Convolutional Neural Network to estimate the channel characteristics in particular the relative phase to antenna elements. It is specifically designed to address the unique features of wireless signals complex samples, such as the ambiguous2œÄphase discontinuity and the high sensitivity of the link Bit Error Rate. The channel prediction is subsequently used in the Maximum Ratio Combining algorithm to achieve an optimal combination of the received signals. While being trained on a fixed, basic RF settings, we show that DEFORM DL model is universal, achieving up to 3 dB of SNR gain for a two antenna receiver in extensive experiments demonstrating various settings of modulations, bandwidths, and channels. The universality of DEFORM is demonstrated through joint beamforming relaying of LoRa (Chirp Spread Spectrum modulation) and ZigBee signals, achieving significant improvements to Packet Loss/Delivery Rates relatively to conventional Amplify and Forward (LoRa PLR reduced by 23 times and ZigBee PDR increased by 8 times).",1755
1670,Systems and Networking,Guevara Noubir,"March 18th, 2022",Towards an AI-Driven Universal Anti-Jamming Solution with Convolutional Interference Cancellation Network,https://doi.org/10.48550/arXiv.2203.09717," Hai N. Nguyen, Guevara Noubir. (2022). Towards an AI-Driven Universal Anti-Jamming Solution with Convolutional Interference Cancellation Network CoRR, abs/2203.09717. https://doi.org/10.48550/arXiv.2203.09717","Wireless links are increasingly used to deliver critical services, while intentional interference (jamming) remains a very serious threat to such services. In this paper, we are concerned with the design and evaluation of a universal anti-jamming building block, that is agnostic to the specifics of the communication link and can therefore be combined with existing technologies. We believe that such a block should not require explicit probes, sounding, training sequences, channel estimation, or even the cooperation of the transmitter. To meet these requirements, we propose an approach that relies on advances in Machine Learning, and the promises of neural accelerators and software defined radios. We identify and address multiple challenges, resulting in a convolutional neural network architecture and models for a multi-antenna system to infer the existence of interference, the number of interfering emissions and their respective phases. This information is continuously fed into an algorithm that cancels the interfering signal. We develop a two-antenna prototype system and evaluate our jamming cancellation approach in various environment settings and modulation schemes using Software Defined Radio platforms. We demonstrate that the receiving node equipped with our approach can detect a jammer with over 99% of accuracy and achieve a Bit Error Rate (BER) as low as10‚àí6even when the jammer power is nearly two orders of magnitude (18 dB) higher than the legitimate signal, and without requiring modifications to the link modulation. In non-adversarial settings, our approach can have other advantages such as detecting and mitigating collisions.",1756
1671,Systems and Networking,Guevara Noubir,"August 16th, 2019","A Billion Open Houses for Eve and Mallory: MitM, DoS, and Tracking Attacks on iOS and macOS Through Apple Wireless Direct Link",https://www.usenix.org/conference/usenixsecurity19/presentation/stute," M. Stute, S. Narain, A. Mariotto, A. Heinrich, G. Noubir, M. Hollick, ""A Billion Open Houses for Eve and Mallory: MitM, DoS, and Tracking Attacks on iOS and macOS Through Apple Wireless Direct Link"", in Usenix Security Symposium, 2019, [Full Paper PDF].","Apple Wireless Direct Link (AWDL) is a key protocol in Apple's ecosystem used by over one billion iOS and macOS devices. We conduct the first security and privacy analysis of AWDL and its integration with BLE. The flaws span across AirDrop's BLE discovery mechanism, AWDL synchronization, and Wi-Fi driver implementation.",1757
1672,Systems and Networking,Guevara Noubir,"May 15th, 2019",Wireless Attacks on Aircraft Instrument Landing Systems,https://doi.org/10.1145/3317549.3326298," Harshad Sathaye, Domien Schepers, Aanjhan Ranganathan, and Guevara Noubir. (2019). ""Wireless attacks on aircraft landing systems: demo"". In Proceedings of the 12th Conference on Security and Privacy in Wireless and Mobile Networks (WiSec '19). Association for Computing Machinery, New York, NY, USA, 295‚Äì297. DOI: 10.1145/3317549.3326298","Modern aircraft heavily rely on several wireless technologies for communications, control, and navigation. In this work, we demonstrate the vulnerability of aircraft instrument landing systems to wireless attacks. We show that it is possible to fully and in finegrain control the course deviation indicator, as displayed by the ILS receiver, in real-time, and demonstrate it on aviation-grade ILS receivers. We develop a tightly-controlled closed-loop ILS spoofer that autonomously adjusts the adversary's transmitted signals based on the aircraft's GPS location to cause an undetected off-runway landing. We demonstrate the integrated attack on an FAA certified flight-simulator (X-Plane)'s AI-based auto-land feature and show success rate with offset touchdowns of 18 meters to over 50 meters.",1758
1673,Systems and Networking,Guevara Noubir,"August 10th, 2018",Security of GPS/INS based On-road Location Tracking Systems,https://www.computer.org/csdl/proceedings-article/sp/2019/666000b092/19skgaJT6Bq," S. Narain, A. Ranganathan, G. Noubir, ""Security of GPS/INS based On-road Location Tracking Systems"", in IEEE Symposium on Security and Privacy, 2019, [Full Paper PDF].",Sign up for our newsletter. EMAIL ADDRESS IEEE COMPUTER SOCIETY DIGITAL LIBRARY,1759
1674,Systems and Networking,Guevara Noubir,"March 23rd, 2016",BaPu: Efficient and Practical Bunching of Access Point Uplinks,https://link.springer.com/chapter/10.1007/978-3-319-26850-7_23," T. Jin, T. D. Vo-Huu, E.-O. Blass, and G. Noubir, ""BaPu: Efficient and Practical Bunching of Access Point Uplinks"", in Proceedings of Networked Systems, NETYS'15, Lecture Notes in Computer Science, 2015","We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement",1760
1675,Systems and Networking,Guevara Noubir,"November 7th, 2014",Toward Robust Hidden Volumes using Write-Only Oblivious RAM,https://dl.acm.org/citation.cfm?id=2660313," E.-O Blass, 1.E.-O. Blass, T. Mayberry, G. Noubir, K. Onarlioglu (2014). ‚ÄúToward Robust Hidden Volumes using Write-Only Oblivious RAM‚Äù, in Proceedings of the ACM Conference on Computer and Communications Security (CCS‚Äô14)","With sensitive data being increasingly stored on mobile devices and laptops, hard disk encryption is more important than ever. In particular, being able to plausibly deny that a hard disk contains certain information is a very useful and interesting research goal. However, it has been known for some time that existing ``hidden volume'' solutions, like TrueCrypt, fail in the face of an adversary who is able to observe the contents of a disk on multiple, separate occasions. In this work, we explore more robust constructions for hidden volumes and present HiVE, which is resistant to more powerful adversaries with multiple-snapshot capabilities. In pursuit of this, we propose the first security definitions for hidden volumes, and prove HiVE secure under these definitions. At the core of HiVE, we design a new write-only Oblivious RAM. We show that, when only hiding writes, it is possible to achieve ORAM with optimal O(1) communication complexity and only poly-logarithmic user memory. This is a significant improvement over existing work and an independently interesting result. We go on to show that our write-only ORAM is specially equipped to provide hidden volume functionality with low overhead and significantly increased security. Finally, we implement HiVE as a Linux kernel block device to show both its practicality and usefulness on existing platforms.",1761
1676,Systems and Networking,Guevara Noubir,"April 2nd, 2014",On the Capacity of Adaptive Packetized Wireless Communication Links under Jamming,http://ieeexplore.ieee.org/document/6782359/," K. Firouzbakht, G. Noubir, M. Salehi (2014). ‚ÄúOn the Capacity of Adaptive Packetized Wireless Communication Links under Jamming‚Äù,  in IEEE Transactions on Wireless Communications","We define a constrained, two-player, zero-sum game between a transmitter/receiver pair with adaptive transmission parameters and an adversary with average and maximum power constraints. We investigate the maximum achievable transmission rate of a rate-adaptive, packetized, wireless AWGN communication link under different jamming scenarios. We show that randomization can significantly assist a smart jammer with limited average power. For more information on the IEEE Transactions on Wireless Communications, visit: http:www.IEEE.org/TWC.2014.",1762
1677,Systems and Networking,Ji-Yong Shin,"June 20th, 2024",LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs,https://doi.org/10.1145/3656423," Longfei Qiu, Yoonseung Kim, Ji-Yong Shin, Jieung Kim, Wolf Honor√©, Zhong Shao. (2024). LiDO: Linearizable Byzantine Distributed Objects with Refinement-Based Liveness Proofs Proc. ACM Program. Lang., 8, 1140-1164. https://doi.org/10.1145/3656423","Byzantine fault-tolerant state machine replication (SMR) protocols, such as PBFT, HotStuff, and Jolteon, are essential for modern blockchain technologies. However, they are challenging to implement correctly because they have to deal with any unexpected message from byzantine peers and ensure safety and liveness at all times. Many formal frameworks have been developed to verify the safety of SMR implementations, but there is still a gap in the verification of their liveness. Existing liveness proofs are either limited to the network level or do not cover popular partially synchronous protocols. We introduce LiDO, a consensus model that enables the verification of both safety and liveness of implementations through refinement. We observe that current consensus models cannot handle liveness because they do not include a pacemaker state. We show that by adding a pacemaker state to the LiDO model, we can express the liveness properties of SMR protocols as a few safety properties that can be easily verified by refinement proofs. Based on our LiDO model, we provide mechanized safety and liveness proofs for both unpipelined and pipelined Jolteon in Coq. This is the first mechanized liveness proof for a byzantine consensus protocol with non-trivial optimizations such as pipelining.",1763
1678,Systems and Networking,Ji-Yong Shin,"April 29th, 2024",AdoB: Bridging Benign and Byzantine Consensus with Atomic Distributed Objects,https://doi.org/10.1145/3649826," Wolf Honor√©, Longfei Qiu, Yoonseung Kim, Ji-Yong Shin, Jieung Kim, Zhong Shao. (2024). AdoB: Bridging Benign and Byzantine Consensus with Atomic Distributed Objects Proc. ACM Program. Lang., 8, 419-448. https://doi.org/10.1145/3649826","Achieving consensus is a challenging and ubiquitous problem in distributed systems that is only made harder by the introduction of malicious byzantine servers. While significant effort has been devoted to the benign and byzantine failure models individually, no prior work has considered the mechanized verification of both in a generic way. We claim this is due to the lack of an appropriate abstraction that is capable of representing both benign and byzantine consensus without either losing too much detail or becoming impractically complex. We build on recent work on the atomic distributed object model to fill this void with a novel abstraction called AdoB. In addition to revealing important insights into the essence of consensus, this abstraction has practical benefits for easing distributed system verification. As a case study, we proved safety and liveness properties for AdoB in Coq, which are the first such mechanized proofs to handle benign and byzantine consensus in a unified manner. We also demonstrate that AdoB faithfully models real consensus protocols by proving it is refined by standard network-level specifications of Fast Paxos and a variant of Jolteon.",1764
1679,Systems and Networking,Ji-Yong Shin,"June 9th, 2022",Adore: atomic distributed objects with certified reconfiguration,https://doi.org/10.1145/3519939.3523444," Wolf Honor√©, Ji-Yong Shin, Jieung Kim, Zhong Shao. (2022). Adore: atomic distributed objects with certified reconfiguration PLDI, 379-394. https://doi.org/10.1145/3519939.3523444","Finding the right abstraction is critical for reasoning about complex systems such as distributed protocols like Paxos and Raft. Despite a recent abundance of impressive verification work in this area, we claim the ways that past efforts model distributed state are not ideal for protocol-level reasoning: they either hide important details, or leak too much complexity from the network. As evidence we observe that nearly all of them avoid the complex, but important issue of reconfiguration. Reconfiguration's primary challenge lies in how it interacts with a protocol's core safety invariants. To handle this increased complexity, we introduce the Adore model, whose novel abstract state hides network-level communications while capturing dependencies between committed and uncommitted states, as well as metadata like election quorums. It includes first-class support for a generic reconfiguration command that can be instantiated with a variety of implementations. Under this model, the subtle interactions between reconfiguration and the core protocol become clear, and with this insight we completed the first mechanized proof of safety of a reconfigurable consensus protocol.",1765
1680,Systems and Networking,Ji-Yong Shin,"October 15th, 2021",Much ADO about failures: a fault-aware model for compositional verification of strongly consistent distributed systems,https://doi.org/10.1145/3485474," Wolf Honor√©, Jieung Kim, Ji-Yong Shin, and Zhong Shao. 2021. ""Much ADO about failures: a fault-aware model for compositional verification of strongly consistent distributed systems."" Proc. ACM Program. Lang. 5, OOPSLA, Article 97 (October 2021), 31 pages. DOI: 10.1145/3485474","Despite recent advances, guaranteeing the correctness of large-scale distributed applications without compromising performance remains a challenging problem. Network and node failures are inevitable and, for some applications, careful control over how they are handled is essential. Unfortunately, existing approaches either completely hide these failures behind an atomic state machine replication (SMR) interface, or expose all of the network-level details, sacrificing atomicity. We propose a novel, compositional, atomic distributed object (ADO) model for strongly consistent distributed systems that combines the best of both options. The object-oriented API abstracts over protocol-specific details and decouples high-level correctness reasoning from implementation choices. At the same time, it intentionally exposes an abstract view of certain key distributed failure cases, thus allowing for more fine-grained control over them than SMR-like models. We demonstrate that proving properties even of composite distributed systems can be straightforward with our Coq verification framework, Advert, thanks to the ADO model. We also show that a variety of common protocols including multi-Paxos and Chain Replication refine the ADO semantics, which allows one to freely choose among them for an application's implementation without modifying ADO-level correctness proofs.",1766
1681,Systems and Networking,Ji-Yong Shin,"October 1st, 2016",Towards Weakly Consistent Local Storage Systems,https://dl.acm.org/doi/10.1145/2987550.2987579," ""Towards Weakly Consistent Local Storage Systems,"" Ji-Yong Shin, Mahesh Balakrishnan, Tudor Marian, Jakub Szefer and Hakim Weatherspoon, In Proceedings of the ACM Symposium on Cloud Computing (SoCC), Santa Clara, CA, U.S.A., Oct 2016.","Heterogeneity is a fact of life for modern storage servers. For example, a server may spread terabytes of data across many different storage media, ranging from magnetic disks, DRAM, NAND-based solid state drives (SSDs), as well as hybrid drives that package various combinations of these technologies. It follows that access latencies to data can vary hugely depending on which media the data resides on. At the same time, modern storage systems naturally retain older versions of data due to the prevalence of log-structured designs and caches in software and hardware layers. In a sense, a contemporary storage system is very similar to a small-scale distributed system, opening the door to consistency/performance trade-offs. In this paper, we propose a class of local storage systems called StaleStores that support relaxed consistency, returning stale data for better performance. We describe several examples of StaleStores, and show via emulations that serving stale data can improve access latency by between 35% and 20X. We describe a particular StaleStore called Yogurt, a weakly consistent local block storage system. Depending on the application's consistency requirements (e.g. bounded staleness, mono-tonic reads, read-my-writes, etc.), Yogurt queries the access costs for different versions of data within tolerable staleness bounds and returns the fastest version. We show that a distributed key-value store running on top of Yogurt obtains a 6X speed-up for access latency by trading off consistency and performance within individual storage servers.",1767
1682,Systems and Networking,Ji-Yong Shin,"February 22nd, 2016",Isotope: Transactional Isolation for Block Storage,https://www.usenix.org/conference/fast16/technical-sessions/presentation/shin," ""Isotope: Transactional Isolation for Block Storage,"" Ji-Yong Shin, Mahesh Balakrishnan, Tudor Marian, and Hakim Weatherspoon, In Proceedings of the USENIX Conference on File and Storage Technologies (FAST), Santa Clara, CA, U.S.A., Feb 2016.","Ji-Yong Shin, Cornell University; Mahesh Balakrishnan, Yale University; Tudor Marian, Google; Hakim Weatherspoon, Cornell University Existing storage stacks are top-heavy and expect little from block storage. As a result, new high-level storage abstractions‚Äîand new designs for existing abstractions‚Äîare difficult to realize, requiring developers to implement from scratch complex functionality such as failure atomicity and fine-grained concurrency control. In this paper, we argue that pushing transactional isolation into the block store (in addition to atomicity and durability) is both viable and broadly useful, resulting in simpler high-level storage systems that provide strong semantics without sacrificing performance. We present Isotope, a new block store that supports ACID transactions over block reads and writes. Internally, Isotope uses a new multi-version concurrency control protocol that exploits fine-grained, sub-block parallelism in workloads and offers both strict serializability and snapshot isolation guarantees. We implemented several high-level storage systems over Isotope, including two key-value stores that implement the LevelDB API over a hashtable and B-tree, respectively, and a POSIX filesystem. We show that Isotope‚Äôs block-level transactions enable systems that are simple (100s of lines of code), robust (i.e., providing ACID guarantees), and fast (e.g., 415 MB/s for random file writes). We also show that these systems can be composed using Isotope, providing applications with transactions across different high-level constructs such as files, directories and key-value pairs. USENIX is committed to Open Access to the research presented at our events. Papers and proceedings are freely available to everyone once the event begins. Any video, audio, and/or slides that are posted after the event are also free and open to everyone. Support USENIX and our commitment to Open Access. Download Audio ¬© USENIX 2025 EIN 13-3055038",1768
1683,Systems and Networking,Cheng Tan,"December 27th, 2024",Instance-Optimized Mapping with Portfolio Methods,https://doi.org/10.1145/3704742.3704963," Yibo Zhao, Panagiotis Manolios, Cheng Tan . (2024). Instance-Optimized Mapping with Portfolio Methods PACMI@SOSP, 11-16. https://doi.org/10.1145/3704742.3704963","Mappings are ubiquitous in computer systems, such as translating virtual memory to physical memory, file paths to inode numbers, database keys to data locations. Traditional system mappings are often hand-crafted and data-agnostic. In this paper, we explore the use of neural networks as learned mappings that are automatically generated and data-dependent, optimizing performance for specific workloads and scenarios. Unlike prior learned structures, we employ a portfolio method consisting of a set of independent neural networks, each responsible for making sole decisions. Our preliminary results indicate that these portfolio mappings can generalize across multiple applications.",1769
1684,Systems and Networking,Cheng Tan,"September 16th, 2024",Scheduling Splittable Jobs on Configurable Machines,https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22," Matthew Casey, Rajmohan Rajaraman, David Stalfa, Cheng Tan . (2024). Scheduling Splittable Jobs on Configurable Machines APPROX/RANDOM, 22:1-22:20. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2024.22","Abstract Motivated by modern architectures allowing for the partitioning of a GPU into hardware separated instances, we initiate the study of scheduling splittable jobs on configurable machines. We consider machines that can be configured into smaller instances, which we call blocks, in multiple ways, each of which is referred to as a configuration. We introduce the Configurable Machine Scheduling (cms) problem, where we are given n jobs and a set C of configurations. A schedule consists of a set of machines, each assigned some configuration in C with each block in the configuration assigned to process one job. The amount of a job‚Äôs demand that is satisfied by a block is given by an arbitrary function of the job and block. The objective is to construct a schedule using as few machines as possible. We provide a tight logarithmic factor approximation algorithm for this problem in the general setting, a factor (3 + Œµ) approximation algorithm for arbitrary Œµ > 0 when there are O(1) input configurations, and a polynomial time approximation scheme when both the number and size of configurations are O(1). Finally, we utilize a technique for finding conic integer combinations in fixed dimension to develop an optimal polynomial time algorithm in the case with O(1) jobs, O(1) blocks, and every configuration up to a given size.",1770
1685,Systems and Networking,Cheng Tan,"July 10th, 2023",Encrypted Databases Made Secure Yet Maintainable,https://www.usenix.org/conference/osdi23/presentation/li-mingyu," Mingyu Li, Xuyang Zhao, Le Chen, Cheng Tan , Huorong Li, Sheng Wang , Zeyu Mi, Yubin Xia, Feifei Li , Haibo Chen . (2023). Encrypted Databases Made Secure Yet Maintainable OSDI, 117-133. https://www.usenix.org/conference/osdi23/presentation/li-mingyu",HEDB uses a dual-mode EDB design based on our analysis of DBA maintenance tasks. Execution Mode handles user queries by isolating DBAs from operators to prevent smuggle attacks. Maintenance Mode enables DBMS maintenance and operator troubleshooting through authenticated replay and anonymized replay.,1771
1686,Systems and Networking,Cheng Tan,"January 30th, 2023",NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers,https://doi.org/10.1145/3575693.3575707," Jiawei Liu , Jinkun Lin, Fabian Ruffy, Cheng Tan , Jinyang Li , Aurojit Panda, Lingming Zhang . (2023). NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers ASPLOS (2), 530-543. https://doi.org/10.1145/3575693.3575707","Deep-learning (DL) compilers such as TVM and TensorRT are increasingly being used to optimize deep neural network (DNN) models to meet performance, resource utilization and other requirements. Bugs in these compilers can result in models whose semantics differ from the original ones, producing incorrect results that corrupt the correctness of downstream applications. However, finding bugs in these compilers is challenging due to their complexity. In this work, we propose a new fuzz testing approach for finding bugs in deep-learning compilers. Our core approach consists of (i) generating diverse yet valid DNN test models that can exercise a large part of the compiler's transformation logic using light-weight operator specifications; (ii) performing gradient-based search to find model inputs that avoid any floating-point exceptional values during model execution, reducing the chance of missed bugs or false alarms; and (iii) using differential testing to identify bugs. We implemented this approach in NNSmith which has found 72 new bugs for TVM, TensorRT, ONNXRuntime, and PyTorch to date. Of these 58 have been confirmed and 51 have been fixed by their respective project maintainers.",1772
1687,Systems and Networking,Cheng Tan,"July 1st, 2021",Bringing Decentralized Search to Decentralized Services,https://www.usenix.org/conference/osdi21/presentation/li," Mingyu Li and Jinhao Zhu and Tianxu Zhang and Cheng Tan and Yubin Xia and Sebastian Angel and Haibo Chen, ""Bringing Decentralized Search to Decentralized Services"", 15th {USENIX} Symposium on Operating Systems Design and Implementation , 2021, i USENIX Association",DeSearch uses trusted hardware to build a network of workers that execute a pipeline of small search engine tasks. DeSearch then introduces a witness mechanism to make sure the completed tasks can be reused across different pipelines. We implement DeSearch for two existing decentralized services that handle over 80 million records and 240 GBs of data. We show that DeSearch can scale horizontally with the number of workers and can process 128 million search queries per day.,1773
1688,Systems and Networking,Cheng Tan,"December 19th, 2019",Detecting Incorrect Behavior of Cloud Databases as an Outsider,http://arxiv.org/abs/1912.09018," Cheng Tan , Changgeng Zhao, Shuai Mu , Michael Walfish. (2019). Detecting Incorrect Behavior of Cloud Databases as an Outsider CoRR, abs/1912.09018. http://arxiv.org/abs/1912.09018","Cloud DBs offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud DBs are complicated black boxes, running in a different administrative domain from their clients; thus, clients might like to know whether the DBs are meeting their contract. A core difficulty is that the underlying problem here, namely verifying serializability, is NP-complete. Nevertheless, we hypothesize that on real-world workloads, verifying serializability is tractable, and we treat the question as a systems problem, for the first time. We build Cobra, which tames the underlying search problem by blending a new encoding of the problem, hardware acceleration, and a careful choice of a suitable SMT solver. cobra also introduces a technique to address the challenge of garbage collection in this context. cobra improves over natural baselines by at least 10x in the problem size it can handle, while imposing modest overhead on clients.",1774
1689,Systems and Networking,Cheng Tan,"February 26th, 2019",Netbouncer: Active device and link failure localization in data center networks,https://dl.acm.org/doi/10.5555/3323234.3323283," Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng, Dongming Bi, and Dong Xiang. 2019. Netbouncer: active device and link failure localization in data center networks. In Proceedings of the 16th USENIX Conference on Networked Systems Design and Implementation (NSDI'19). USENIX Association, USA, 599‚Äì613.","The availability of data center services is jeopardized by various network incidents. One of the biggest challenges for network incident handling is to accurately localize the failures, among millions of servers and tens of thousands of network devices. In this paper, we propose NetBouncer, a failure localization system that leverages the IP-in-IP technique to actively probe paths in a data center network. NetBouncer provides a complete failure localization framework which is capable of detecting both device and link failures. It further introduces an algorithm for high accuracy link failure inference that is resilient to real-world data inconsistency by integrating both our troubleshooting domain knowledge and machine learning techniques. NetBouncer has been deployed in Microsoft Azure's data centers for three years. And in practice, it produced no false positives and only a few false negatives so far.",1775
1690,Systems and Networking,Cheng Tan,"January 1st, 2019",Taming Distrust in the Decentralized Internet with PIXIU,http://arxiv.org/abs/1901.06095," Yubin Xia, Qingyuan Liu, Cheng Tan , Jing Leng, Shangning Xu, Binyu Zang, Haibo Chen . (2019). Taming Distrust in the Decentralized Internet with PIXIU CoRR, abs/1901.06095. http://arxiv.org/abs/1901.06095","Decentralized Internet is booming. People are fascinated by its promise that users can truly own their data. However, in a decentralized Internet, completing a task usually involves multiple nodes with mutual distrust. Such distrust might eventually become a major obstacle for the growth of the decentralized Internet. In this paper, we analyze the distrust using a simple model and highlight the properties required to faithfully accomplish one task in a decentralized Internet. We also introduce our draft solution -- PIXIU, a framework to mitigate the distrust among different nodes. In PIXIU, we design and utilize trust-{\lambda} and decentralized executor to achieve the above-needed properties.",1776
1691,Systems and Networking,Cheng Tan,"October 14th, 2017","The efficient server audit problem, deduplicated re-execution, and the web",https://dl.acm.org/doi/10.1145/3132747.3132760," Cheng Tan, Lingfan Yu, Joshua B. Leners, and Michael Walfish. 2017. The Efficient Server Audit Problem, Deduplicated Re-execution, and the Web. In Proceedings of the 26th Symposium on Operating Systems Principles (SOSP '17). Association for Computing Machinery, New York, NY, USA, 546‚Äì564. DOI:https://doi.org/10.1145/3132747.3132760","You put a program on a concurrent server, but you don't trust the server; later, you get a trace of the actual requests that the server received from its clients and the responses that it delivered. You separately get logs from the server; these are untrusted. How can you use the logs to efficiently verify that the responses were derived from running the program on the requests? This is the Efficient Server Audit Problem, which abstracts real-world scenarios, including running a web application on an untrusted provider. We give a solution based on several new techniques, including simultaneous replay and efficient verification of concurrent executions. We implement the solution for PHP web applications. For several applications, our verifier achieves 5.6-10.9x speedup versus simply re-executing, with <10% overhead for the server.",1777
1692,Systems and Networking,Maryam Tanha,"September 12th, 2024",Revisiting Temporal Inconsistency and Feature Extraction for Android Malware Detection,https://doi.org/10.1109/CCECE59415.2024.10667123," Maryam Tanha, Arunab Singh, Gavin Knoke. (2024). Revisiting Temporal Inconsistency and Feature Extraction for Android Malware Detection CCECE, 301-306. https://doi.org/10.1109/CCECE59415.2024.10667123","Machine learning has become an essential instrument for conducting Android malware detection and analysis. We demonstrate the unreliability of the commonly used dex_date as the release time of an app. We propose a more accurate approach for creating temporally-consistent datasets based on an app‚Äôs upload year. We have open-sourced our data and feature extraction process for Android malware analysis, supporting both server-side and on-device extraction, to enhance research reproducibility and facilitate community access. The paper was published in the IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)",1778
1693,Systems and Networking,Maryam Tanha,"February 26th, 2024",Interpretable Android Malware Detection Based on Dynamic Analysis,https://doi.org/10.5220/0012415800003648," Arunab Singh, Maryam Tanha, Yashsvi Girdhar, Aaron Hunter . (2024). Interpretable Android Malware Detection Based on Dynamic Analysis ICISSP, 195-202. https://doi.org/10.5220/0012415800003648","The paper was published in the Journal of Applied Machine Learning and is available to download now. Android has emerged as the dominant operating system for smart devices, which has led to the proliferation of Android malware. Our approach provides explanations for the classification results by indicating the features that are contributing the most to the detection result. The quality of explanations are assessed using stability metrics.",1779
1694,Systems and Networking,Scott Valcourt,"November 30th, 2021",The Connect.Cyberinfrastructure Portal,https://doi.org/10.1145/3437359.3465606," Julie Ma, Sarah Akbar, Torey Battelle, Kevin L. Brandt, Eric Brown, Dana Brunson, Dhruva Chakravorty, Thomas E. Cheatham, Bhushan Chitre, Adrian Del Maestro, Andrea Elledge, Vikram Gazula, John Goodhue, James Griffioen, Abigail Hyde, Douglas M. Jennewein, Shelley Knuth, B. J. Lougee, Timothy Middelkoop, Sasmita Mohapatra, Sia Najafi, Kaylea Nelson, Lisa Perez, Bruce Segee, Julia Sheats, Andrew H. Sherman, Christopher Simmons, Ermal Toto, Scott Valcourt, Lucas Varella, Ralph Zottola. (2021). The Connect.Cyberinfrastructure Portal PEARC, 51:1-51:4. https://doi.org/10.1145/3437359.3465606","The Connect.Cyberinfrastructure.org Portal, originally known as the Cyberteam Portal, was developed to support the management of project workflows and to capture project results for the Northeast Cyberteam (NECT) [3,5,6]. Recently, the Portal has expanded to provide support for other programs in the Research Computing ecosystem, creating opportunities for collaboration, and leveraging a consistent, cohesive approach to common challenges. As reported at SC20 [6], a pilot was launched in July 2020 to enable six additional Cyberteam programs to explore the use of the Portal as a management tool for their related programs. In addition, in January of 2021, the Extreme Science and Engineering Discovery Environment (XSEDE) Campus Champions leadership decided to use the Portal to modernize participant management and onboarding functions. Portal details, preliminary results, and future plans are discussed.",1780
1695,Systems and Networking,Scott Valcourt,"December 22nd, 2020",Northeast Cyberteam ‚Äì Building an Environment for Sharing Best Practices and Solutions for Research Computing,https://doi.org/10.1109/HPEC43674.2020.9286254," John Goodhue, Julie Ma, Adrian Del Maestro, Sia Najafi, Bruce Segee, Scott Valcourt, Ralph Zottola. (2020). Northeast Cyberteam - Building an Environment for Sharing Best Practices and Solutions for Research Computing HPEC, 1-5. https://doi.org/10.1109/HPEC43674.2020.9286254","The Northeast Cyberteam Program is a collaborative effort across Maine, New Hampshire, Vermont, and Massachusetts. It seeks to assist researchers at small and medium-sized institutions in the region with making use of cyberinfrastructure. The Cyberteam Portal is used to access the self-service learning opportunities that otherwise would not be available. The conference will be held 22-24 September 2020 in Waltham, MA, USA. For more information, visit IEEE High Performance Extreme Computing Conference (HPEC) and the conference page here. Back to IEEE Xplore home.Back to the page you came from. ¬†http://www.ibtimes.com/news/features/top-stories/2020-iEI-High-Performance-Extreme-Computing-Conference-Waltham-MA.html.",1781
1696,Systems and Networking,Ziming Zhao,"December 1st, 2024",TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning,https://doi.org/10.1145/3658644.3690234," Cong Wu , Jing Chen , Ziming Zhao , Kun He , Guowen Xu, Yueming Wu , Haijun Wang, Hongwei Li , Yang Liu , Yang Xiang . (2024). TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning CCS, 956-970. https://doi.org/10.1145/3658644.3690234","Decentralized finance has experienced phenomenal growth, revolutionizing the landscape of financial transactions and asset management via blockchain. Yet, this swift growth brings with it substantial challenges, notably the surge in scam tokens, imposing significant security threats on cryptocurrency investments and trading. Existing detection methods of scam token, primarily relying on analyzing contract codes or transaction patterns, struggle to catch increasingly sophisticated tactics employed by scammers. For example, contract-based analysis are unable to identify scams lacking overt malicious code, e.g., most rugpulls, while transaction-based methods generally lack the foresight to early-detect potential risks. In this paper, we present TokenScout, the first temporal temporal graph neural network-based framework for scam token early detection. TokenScout formulates token transfer data as a dynamic temporal attributed multigraph and leverages the temporal graph learning model to learn graph representations. It also builds a graph representation refining model based on contrastive learning to learn a more discriminative representation space for risk identification. We evaluated TokenScout using a comprehensive dataset of 214,084 standard ERC20 tokens from 2015 to February 2023. TokenScout achieves a balanced accuracy of 98.41%. Additionally, from March to May 2023, deploying TokenScout on Ethereum effectively identified 706 rugpulls, 174 honeypots, and 90 Ponzi schemes, thereby alerting to potential risks exceeding 240 million.",1782
1697,Systems and Networking,Ziming Zhao,"June 26th, 2024",InsectACIDE: Debugger-Based Holistic Asynchronous CFI for Embedded System,https://doi.org/10.1109/RTAS61025.2024.00036," Yujie Wang, Cailani Lemieux Mack, Xi Tan , Ning Zhang , Ziming Zhao , Sanjoy K. Baruah, Bryan C. Ward. (2024). InsectACIDE: Debugger-Based Holistic Asynchronous CFI for Embedded System RTAS, 360-372. https://doi.org/10.1109/RTAS61025.2024.00036","Real-time and embedded systems are predominantly written in C, a language that is notoriously not memory safe. This has led to widespread memory-corruption vulnerabilities in real-time embedded cyber-physical systems (CPS) This is concerning, as such devices are becoming increasingly networked with the Internet of Things (IoT) and other communication technologies (e.g., 5G) This paper presents InsectACIDE, the first holistic CFI for embedded and real- time systems that does not require binary instrumentation. It checks that the sequence of control-flow transitions taken is valid, not just individual transitions, thereby detecting such attacks.",1783
1698,Systems and Networking,Ziming Zhao,"November 21st, 2023",SHERLOC: Secure and Holistic Control-Flow Violation Detection on Embedded Systems,https://doi.org/10.1145/3576915.3623077," Xi Tan , Ziming Zhao . (2023). SHERLOC: Secure and Holistic Control-Flow Violation Detection on Embedded Systems CCS, 1332-1346. https://doi.org/10.1145/3576915.3623077","Microcontroller-based embedded systems are often programmed in low-level languages and are vulnerable to control-flow hijacking attacks. One approach to prevent such attacks is to enforce control-flow integrity (CFI), but inlined CFI enforcement can pose challenges in embedded systems. For example, it increases binary size and changes memory layout. Trace-based control-flow violation detection (CFVD) offers an alternative that doesn't require instrumentation of the protected software or changes to its memory layout. However, existing CFVD methods used in desktop systems require kernel modifications to store and analyze the trace, which limits their use to monitoring unprivileged applications. But, embedded systems are interrupt-driven, with the majority of processing taking place in the privileged mode. Therefore, it is critical to provide a holistic and system-oriented CFVD solution that can monitor control-flow transfers both within and among privileged and unprivileged components. In this paper, we present SHERLOC, a Secure and Holistic Control-Flow Violation Detection mechanism designed for microcontroller-based embedded systems. SHERLOC ensures security by configuring the hardware tracing unit, storing trace records, and executing the violation detection algorithm in a trusted execution environment, which prevents privileged programs from bypassing monitoring or tampering with the trace. We address the challenges of achieving holistic and system-oriented CFVD by formalizing the problem and monitoring forward and backward edges of unprivileged and privileged programs, as well as control-flow transfers among unprivileged and privileged components. Specifically, SHERLOC overcomes the challenges of identifying legitimate asynchronous interrupts and context switches at run-time by using an interrupt- and scheduling-aware violation detection algorithm. Our evaluations on the ARMv8-M architecture demonstrate the effectiveness and efficiency of SHERLOC.",1784
1699,Systems and Networking,Ziming Zhao,"September 15th, 2023",Return-to-Non-Secure Vulnerabilities on ARM Cortex-M TrustZone: Attack and Defense,https://doi.org/10.1109/DAC56929.2023.10247972," Zheyuan Ma, Xi Tan , Lukasz Ziarek, Ning Zhang , Hongxin Hu, Ziming Zhao . (2023). Return-to-Non-Secure Vulnerabilities on ARM Cortex-M TrustZone: Attack and Defense DAC, 1-6. https://doi.org/10.1109/DAC56929.2023.10247972"," ARM Cortex-M is one of the most popular microcontroller architectures designed for embedded and Internet of Things (IoT) applications. To facilitate efficient execution, it has some unique hardware optimization. This fast state switch mechanism can be exploited for arbitrary code execution. The study was published in the 60th ACM/IEEE Design Automation Conference.",1785
1700,Computer Science Education,Albert Lionelle,"February 18th, 2025",An MS in CS for non-CS Majors: A Ten Year Retrospective,https://doi.org/10.1145/3641554.3701928," Logan W. Schmidt, Caitlin J. Kidder, Ildar Akhmetov, Megan Bebis, Alan C. Jamieson, Albert Lionelle, Sarah Maravetz, Sami Rollins, Ethan Selinger. (2025). An MS in CS for non-CS Majors: A Ten Year Retrospective SIGCSE (1), 1036-1042. https://doi.org/10.1145/3641554.3701928","For the last 10 years, our university has offered a two-semester bridge into a master's in computer science for people with undergraduate degrees in non-computing disciplines. Since its inception, the program has expanded to eight campuses across North America and has opened admission to students from all disciplines, including non-STEM disciplines. The bridge program has over 2000 currently enrolled students, with more than 50% women every year since 2020, and domestic enrollment has increased relative to direct entry master's students. Our data show that bridge students, including those with non-STEM backgrounds, perform comparably to direct entry students in terms of GPA. We attribute much of the program's success to institutional investment in resources specifically designed to meet the unique needs of bridge students. These resources include dedicated academic and career advising, co-curricular programming, and the hiring of full-time teaching faculty specifically recruited to teach these bridge students. This paper examines data pertaining to the bridge program and MSCS from 2013 to 2023; it includes analyses of the expansion of the bridge program to eight campuses in North America, the admission of students with non-STEM degrees to the bridge, the achievement of enrolling over 50% women and non-binary identifying students, the success of bridge students in the MSCS program and in obtaining job placements, and domestic student enrollment growth as compared to traditional direct entry master's students.",1786
1701,Computer Science Education,Ilmi Yoon,"March 7th, 2024",Socially Responsible Computing in an Introductory Course,https://doi.org/10.1145/3626252.3630926," Aakash Gautam, Anagha Kulkarni , Sarah Hug, Jane Lehr, Ilmi Yoon. (2024). Socially Responsible Computing in an Introductory Course SIGCSE (1), 373-379. https://doi.org/10.1145/3626252.3630926","Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum. Our students need to be able to examine the social complexities in which technology development and use are situated. Also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging. Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing. Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules. Rather than adding social on top of the technical content, our curricular approach seeks to weave them together. The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change. We share our approach to designing this new introductory socially responsible computing course and the students' reflections. We also highlight seven considerations for educators seeking to incorporate socially responsible computing.",1787
1702,Computer Science Education,Ilmi Yoon,"October 22nd, 2023",The Potential of a Visual Dialogue Agent In a Tandem Automated Audio Description System for Videos,https://doi.org/10.1145/3597638.3608402," Abigale Stangl, Shasta Ihorn, Yue-Ting Siu, Aditya Bodi, Mar Castanon, Lothar D. Narins, Ilmi Yoon. (2023). The Potential of a Visual Dialogue Agent In a Tandem Automated Audio Description System for Videos ASSETS, 32:1-32:17. https://doi.org/10.1145/3597638.3608402","The relentless pace of video production exacerbates the digital accessibility gap that individuals who are blind or low vision (BLV) face on a daily basis, resulting in disproportionate exclusion from community opportunities and risk management. Whereas previous automated audio description (AD) systems provide single-tool approaches for delivering minimum viable description (MVD) or delivering on-demand visual question answering (VQA), we present a tandem AI-based AD tool that combines MVD and on-demand VQA. A user study with 26 BLV individuals explored how the tandem system may be used under the conditions of delivering MVD and/or on-demand VQA with AI-only or human-in-the-loop support. When each tool was used in isolation, AI-only conditions scored significantly lower in both user enjoyment and comprehension. When used in tandem, AI-only conditions matched outcomes delivered with human-in-the-loop, which suggests that AI-only AD tools may be most effective when both types of tools are used in tandem. A multimodal analysis of interactions with the tandem system revealed areas for system improvement in terms of the timing of AD delivery and accurate content delivery. We discuss how the use of both types of tools in a tandem system can mitigate some of the digital frictions that have plagued efforts in machine learning and automated tools for accessibility.",1788
1703,Cybersecurity and Privacy,David Choffnes,"October 24th, 2023",Behind the Scenes: Uncovering TLS and Server Certificate Practice of IoT Device Vendors in the Wild,https://doi.org/10.1145/3618257.3624815," Hongying Dong, Hao Shu, Vijay Prakash, Yizhe Zhang, Muhammad Talha Paracha, David R. Choffnes, Santiago Torres-Arias, Danny Yuxing Huang, Yixin Sun. (2023). Behind the Scenes: Uncovering TLS and Server Certificate Practice of IoT Device Vendors in the Wild IMC, 457-477. https://doi.org/10.1145/3618257.3624815","IoT devices are increasingly used in consumer homes. Despite recent works in characterizing IoT TLS usage for a limited number of in-lab devices, there exists a gap in quantitatively understanding TLS behaviors from devices in the wild and server-side certificate management. To bridge this knowledge gap, we conduct a new measurement study by focusing on the practice of device vendors, through a crowdsourced dataset of network traffic from 2,014 real-world IoT devices across 721 global users. By quantifying the sharing of TLS fingerprints across vendors and across devices, we uncover the prevalent use of customized TLS libraries (i.e., not matched to any known TLS libraries) and potential security concerns resulting from co-located TLS stacks of different services. Furthermore, we present the first known study on server-side certificate management for servers contacted by IoT devices. Our study highlights potential concerns in the TLS/PKI practice by IoT device vendors. We aim to raise visibility for these issues and motivate vendors to improve security practice.",1789
1704,Cybersecurity and Privacy,David Choffnes,"October 24th, 2023",BehavIoT: Measuring Smart Home IoT Behavior Using Network-Inferred Behavior Models,https://doi.org/10.1145/3618257.3624829," Tianrui Hu, Daniel J. Dubois, David R. Choffnes. (2023). BehavIoT: Measuring Smart Home IoT Behavior Using Network-Inferred Behavior Models IMC, 421-436. https://doi.org/10.1145/3618257.3624829","Smart home IoT platforms are typically closed systems, meaning that there is poor visibility into device behavior. Understanding device behavior is important not only for determining whether devices are functioning as expected, but also can reveal implications for privacy (e.g., surreptitious audio/video recording), security (e.g., device compromise), and safety (e.g., denial of service on a baby monitor). While there has been some work on identifying devices and a handful of activities, an open question is what is the extent to which we can automatically model the entire behavior of an IoT deployment, and how it changes over time, without any privileged access to IoT devices or platform messages. In this work, we demonstrate that the vast majority of IoT behavior can indeed be modeled, using a novel multi-dimensional approach that relies only on the (often encrypted) network traffic exchanged by IoT devices. Our key insight is that IoT behavior (including cross-device interactions) can often be captured using relatively simple models such as timers (for periodic behavior) and probabilistic state-machines (for user-initiated behavior and devices interactions) during a limited observation phase. We then propose deviation metrics that can identify when the behavior of an IoT device or an IoT system changes over time. Our models and metrics successfully identify several notable changes in our IoT deployment, including a camera that changed locations, network outages that impact connectivity, and device malfunctions.",1790
1705,Cybersecurity and Privacy,David Choffnes,"October 25th, 2022",Internet scale reverse traceroute,https://doi.org/10.1145/3517745.3561422," Kevin Vermeulen, Ege G√ºrmeri√ßliler, √çtalo Cunha, David R. Choffnes, Ethan Katz-Bassett. (2022). Internet scale reverse traceroute IMC, 694-715. https://doi.org/10.1145/3517745.3561422","Knowledge of Internet paths allows operators and researchers to better understand the Internet and troubleshoot problems. Paths are often asymmetric, so measuring just the forward path only gives partial visibility. Despite the existence of Reverse Traceroute, a technique that captures reverse paths (the sequence of routers traversed by traffic from an arbitrary, uncontrolled destination to a given source), this technique did not fulfill the needs of operators and the research community, as it had limited coverage, low throughput, and inconsistent accuracy. In this paper we design, implement and evaluate revtr 2.0, an Internet-scale Reverse Traceroute system that combines novel measurement approaches and studies with a large-scale deployment to improve throughput, accuracy, and coverage, enabling the first exploration of reverse paths at Internet scale. revtr 2.0 can run 15M reverse traceroutes in one day. This scale allows us to open the system to external sources and users, and supports tasks such as traffic engineering and troubleshooting.",1791
1706,Cybersecurity and Privacy,Michael Ann DeVito,"March 23rd, 2024",Content Moderation Folk Theories and Perceptions of Platform Spirit among Marginalized Social Media Users,https://doi.org/10.1145/3632741," Samuel Mayworm, Michael Ann DeVito, Daniel Delmonaco, Hibby Thach, Oliver L. Haimson. (2024). Content Moderation Folk Theories and Perceptions of Platform Spirit among Marginalized Social Media Users ACM Trans. Soc. Comput., 7, 1-27. https://doi.org/10.1145/3632741","Social media users create folk theories to help explain how elements of social media operate. Marginalized social media users face disproportionate content moderation and removal on social media platforms. We conducted a qualitative interview study ( n = 24) to understand how marginalized social media users may create folk theories in response to content moderation and their perceptions of platforms‚Äô spirit, and how these theories may relate to their marginalized identities. We found that marginalized social media users develop folk theories informed by their perceptions of platforms‚Äô spirit to explain instances where their content was moderated in ways that violate their perceptions of how content moderation should work in practice. These folk theories typically address content being removed despite not violating community guidelines, along with bias against marginalized users embedded in guidelines. We provide implications for platforms, such as using marginalized users‚Äô folk theories as tools to identify elements of platform moderation systems that function incorrectly and disproportionately impact marginalized users.",1792
1707,Cybersecurity and Privacy,Joshua Gancher,"October 8th, 2024",FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions,https://doi.org/10.1145/3689729," Zhengyao Lin, Joshua Gancher, Bryan Parno. (2024). FlowCert: Translation Validation for Asynchronous Dataflow via Dynamic Fractional Permissions Proc. ACM Program. Lang., 8, 499-526. https://doi.org/10.1145/3689729","Coarse-grained reconfigurable arrays (CGRAs) have gained attention in recent years due to their promising power efficiency compared to traditional von Neumann architectures. To program these architectures using ordinary languages such as C, a dataflow compiler must transform the original sequential, imperative program into an equivalent dataflow graph, composed of dataflow operators running in parallel. This transformation is challenging since the asynchronous nature of dataflow graphs allows out-of-order execution of operators, leading to behaviors not present in the original imperative programs. We address this challenge by developing a translation validation technique for dataflow compilers to ensure that the dataflow program has the same behavior as the original imperative program on all possible inputs and schedules of execution. We apply this method to a state-of-the-art dataflow compiler targeting the RipTide CGRA architecture. Our tool uncovers 8 compiler bugs where the compiler outputs incorrect dataflow graphs, including a data race that is otherwise hard to discover via testing. After repairing these bugs, our tool verifies the correct compilation of all programs in the RipTide benchmark suite.",1793
1708,Cybersecurity and Privacy,Joshua Gancher,"January 11th, 2023",A Core Calculus for Equational Proofs of Cryptographic Protocols,https://doi.org/10.1145/3571223," Joshua Gancher, Kristina Sojakova, Xiong Fan, Elaine Shi, Greg Morrisett. (2023). A Core Calculus for Equational Proofs of Cryptographic Protocols Proc. ACM Program. Lang., 7, 866-892. https://doi.org/10.1145/3571223","Many proofs of interactive cryptographic protocols (e.g., as in Universal Composability) operate by proving the protocol at hand to be observationally equivalent to an idealized specification. While pervasive, formal tool support for observational equivalence of cryptographic protocols is still a nascent area of research. Current mechanization efforts tend to either focus on diff-equivalence, which establishes observational equivalence between protocols with identical control structures, or require an explicit witness for the observational equivalence in the form of a bisimulation relation. Our goal is to simplify proofs for cryptographic protocols by introducing a core calculus, IPDL, for cryptographic observational equivalences. Via IPDL, we aim to address a number of theoretical issues for cryptographic proofs in a simple manner, including probabilistic behaviors, distributed message-passing, and resource-bounded adversaries and simulators. We demonstrate IPDL on a number of case studies, including a distributed coin toss protocol, Oblivious Transfer, and the GMW multi-party computation protocol. All proofs of case studies are mechanized via an embedding of IPDL into the Coq proof assistant.",1794
1709,Cybersecurity and Privacy,Zhengzhong Jin,"June 11th, 2024",SNARGs under LWE via Propositional Proofs,https://doi.org/10.1145/3618260.3649770," Zhengzhong Jin, Yael Kalai, Alex Lombardi, Vinod Vaikuntanathan. (2024). SNARGs under LWE via Propositional Proofs STOC, 1750-1757. https://doi.org/10.1145/3618260.3649770",We construct a succinct non-interactive argument (SNARG) system for every NP language L that has a propositional proof of non-membership. The soundness of our SNARG system relies on the hardness of the learning with errors (LWE) problem. We additionally show that propositional proofs of unsatisfiability generically imply the existence of locally unsatisfiable extensions.,1795
1710,Cybersecurity and Privacy,Alan Mislove,"November 7th, 2022","Hammurabi: A Framework for Pluggable, Logic-based X.509 Certificate Validation Policies",https://doi.org/10.1145/3548606.3560594," James Larisch, Waqar Aqeel, Michael Lum, Yaelle Goldschlag, Kasra Torshizi, Leah Kannan, Yujie Wang, Taejoong Chung, Dave Levin, Bruce M. Maggs, Alan Mislove, Bryan Parno, and Christo Wilson. (2022). ""Hammurabi: A Framework for Pluggable, Logic-Based X.509 Certificate Validation Policies"". In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS ‚Äô22), November 7‚Äì11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA, 15 pages. DOI: 10.1145/3548606.3560594","This paper proposes using a logic programming language to disentangle X.509 certificate validation policy from mechanism. Expressing validation policies in a logic programming language provides multiple benefits. First, policy and mechanism can be more independently written, augmented, and analyzed compared to the current practice of interweaving them within a C or C++ implementation. Once written, these policies can be easily shared and modified for use in different TLS clients. Further, logic programming allows us to determine when clients differ in their policies and use the power of imputation to automatically generate interesting certificates, e.g., a certificate that will be accepted by one browser but not by another. We present a new framework called Hammurabi for expressing validation policies, and we demonstrate that we can express the complex policies of the Google Chrome and Mozilla Firefox web browsers in this framework. We confirm the fidelity of the Hammurabi policies by comparing the validation decisions they make with those made by the browsers themselves on over ten million certificate chains derived from Certificate Transparency logs, as well as 100K synthetic chains. We also use imputation to discover nine validation differences between the two browsers' policies. Finally, we demonstrate the feasibility of integrating Hammurabi into Firefox and the Go language in less than 100 lines of code each.",1796
1711,Data Management,Mirek Riedewald,"June 1st, 2020",QueryVis: Logic-based diagrams help users understand complicated SQL queries faster,https://doi.org/10.1145/3318464.3389767," Aristotelis Leventidis, Jiahui Zhang, Cody Dunne, Wolfgang Gatterbauer, H. V. Jagadish, and Mirek Ridewald. ‚ÄúQueryVis: Logic-based diagrams help users understand complicated SQL queries faster‚Äù. In: Proc. 2020 ACM SIGMOD International Conference on Management of  Data. SIGMOD. Preprint & supplemental material: osf.io/btszh. SIGMOD 2021 Most Reproducible Paper Award. 2020, pp. 2303‚Äì2318. doi: 10.1145/3318464.3389767.","Understanding the meaning of existing SQL queries is critical for code maintenance and reuse. Yet SQL can be hard to read, even for expert users or the original creator of a query. We conjecture that it is possible to capture the logical intent of queries in automatically-generated visual diagrams that can help users understand the meaning of queries faster and more accurately than SQL text alone. We present initial steps in that direction with visual diagrams that are based on the first-order logic foundation of SQL and can capture the meaning of deeply nested queries. Our diagrams build upon a rich history of diagrammatic reasoning systems in logic and were designed using a large body of human-computer interaction best practices: they are minimal in that no visual element is superfluous; they are unambiguous in that no two queries with different semantics map to the same visualization; and they extend previously existing visual representations of relational schemata and conjunctive queries in a natural way. An experimental evaluation involving 42 users on Amazon Mechanical Turk shows that with only a 2--3 minute static tutorial, participants could interpret queries meaningfully faster with our diagrams than when reading SQL alone. Moreover, we have evidence that our visual diagrams result in participants making fewer errors than with SQL. We believe that more regular exposure to diagrammatic representations of SQL can give rise to a pattern-based and thus more intuitive use and re-use of SQL. A full version of this paper with all appendices and supplemental material for the experimental study (stimuli, raw data, and analysis code) are available at https://osf.io/btszh.",1797
1712,Data Management,Cheng Tan,"December 27th, 2024",Instance-Optimized Mapping with Portfolio Methods,https://doi.org/10.1145/3704742.3704963," Yibo Zhao, Panagiotis Manolios, Cheng Tan . (2024). Instance-Optimized Mapping with Portfolio Methods PACMI@SOSP, 11-16. https://doi.org/10.1145/3704742.3704963","Mappings are ubiquitous in computer systems, such as translating virtual memory to physical memory, file paths to inode numbers, database keys to data locations. Traditional system mappings are often hand-crafted and data-agnostic. In this paper, we explore the use of neural networks as learned mappings that are automatically generated and data-dependent, optimizing performance for specific workloads and scenarios. Unlike prior learned structures, we employ a portfolio method consisting of a set of independent neural networks, each responsible for making sole decisions. Our preliminary results indicate that these portfolio mappings can generalize across multiple applications.",1798
1713,Data Science,Mario Nascimento,"November 7th, 2023","Conference Report: The 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022) Seattle, Washington, USA November 1-4, 2022",https://doi.org/10.1145/3632268.3632270," Matthias Renz, Mohamed Sarwat, Mario A. Nascimento, Shashi Shekar, Xing Xie . (2022). Conference Report: The 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022) Seattle, Washington, USA November 1-4, 2022 ACM SIGSPATIAL Special, 14, 2-6. https://doi.org/10.1145/3632268.3632270","This report presents the development and finalization of the 30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2022), which was held in Seattle, Washington, USA, November 1--4, 2022.",1799
1714,Data Science,Mirek Riedewald,"May 1st, 2020",Optimal Algorithms for Ranked Enumeration of Answers to Full Conjunctive Queries,https://doi.org/10.14778/3397230.3397250," Nikolaos Tziavelis, Deepak Ajwani, Wolfgang Gatterbauer, Mirek Riedewald, Xiaofeng Yang. PVLDB 13(9):1582-1597, 2020","We study ranked enumeration of join-query results according to very general orders defined by selective dioids. Our main contribution is a framework for ranked enumeration over a class of dynamic programming problems that generalizes seemingly different problems that had been studied in isolation. To this end, we extend classic algorithms that find the k -shortest paths in a weighted graph. For full conjunctive queries, including cyclic ones, our approach is optimal in terms of the time to return the top result and the delay between results. These optimality properties are derived for the widely used notion of data complexity, which treats query size as a constant. By performing a careful cost analysis, we are able to uncover a previously unknown tradeoff between two incomparable enumeration approaches: one has lower complexity when the number of returned results is small, the other when the number is very large. We theoretically and empirically demonstrate the superiority of our techniques over batch algorithms, which produce the full result and then sort it. Our technique is not only faster for returning the first few results, but on some inputs beats the batch algorithm even when all results are produced.",1800
1715,Data Science,Cheng Tan,"December 27th, 2024",Instance-Optimized Mapping with Portfolio Methods,https://doi.org/10.1145/3704742.3704963," Yibo Zhao, Panagiotis Manolios, Cheng Tan . (2024). Instance-Optimized Mapping with Portfolio Methods PACMI@SOSP, 11-16. https://doi.org/10.1145/3704742.3704963","Mappings are ubiquitous in computer systems, such as translating virtual memory to physical memory, file paths to inode numbers, database keys to data locations. Traditional system mappings are often hand-crafted and data-agnostic. In this paper, we explore the use of neural networks as learned mappings that are automatically generated and data-dependent, optimizing performance for specific workloads and scenarios. Unlike prior learned structures, we employ a portfolio method consisting of a set of independent neural networks, each responsible for making sole decisions. Our preliminary results indicate that these portfolio mappings can generalize across multiple applications.",1801
1716,Data Science,Cheng Tan,"January 30th, 2023",NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers,https://doi.org/10.1145/3575693.3575707," Jiawei Liu , Jinkun Lin, Fabian Ruffy, Cheng Tan , Jinyang Li , Aurojit Panda, Lingming Zhang . (2023). NNSmith: Generating Diverse and Valid Test Cases for Deep Learning Compilers ASPLOS (2), 530-543. https://doi.org/10.1145/3575693.3575707","Deep-learning (DL) compilers such as TVM and TensorRT are increasingly being used to optimize deep neural network (DNN) models to meet performance, resource utilization and other requirements. Bugs in these compilers can result in models whose semantics differ from the original ones, producing incorrect results that corrupt the correctness of downstream applications. However, finding bugs in these compilers is challenging due to their complexity. In this work, we propose a new fuzz testing approach for finding bugs in deep-learning compilers. Our core approach consists of (i) generating diverse yet valid DNN test models that can exercise a large part of the compiler's transformation logic using light-weight operator specifications; (ii) performing gradient-based search to find model inputs that avoid any floating-point exceptional values during model execution, reducing the chance of missed bugs or false alarms; and (iii) using differential testing to identify bugs. We implemented this approach in NNSmith which has found 72 new bugs for TVM, TensorRT, ONNXRuntime, and PyTorch to date. Of these 58 have been confirmed and 51 have been fixed by their respective project maintainers.",1802
1717,Data Visualization,Cody Dunne,"May 7th, 2021",Remote and Collaborative Virtual Reality Experiments via Social VR Platforms,https://doi.org/10.1145/3411764.3445426," David Saffo, Sara Di Bartolomeo, Caglar Yildirim, and Cody Dunne. 2021. Remote and Collaborative Virtual Reality Experiments via Social VR Platforms. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 523, 1‚Äì15. DOI:https://doi.org/10.1145/3411764.3445426","Virtual reality (VR) researchers struggle to conduct remote studies. Previous work has focused on working around limitations imposed by traditional crowdsourcing methods. However, the potential for leveraging social VR platforms for HCI evaluations is largely unexplored. These platforms have large VR-ready user populations, distributed synchronous virtual environments, and support for user-generated content. We demonstrate how social VR platforms can be used to practically and ethically produce valid research results by replicating two studies using one such platform (VRChat): a quantitative study on Fitts‚Äô Law and a qualitative study on tabletop collaboration. Our replication studies exhibited analogous results to the originals, indicating the research validity of this approach. Moreover, we easily recruited experienced VR users with their own hardware for synchronous, remote, and collaborative participation. We further provide lessons learned for future researchers experimenting using social VR platforms. This paper and all supplemental materials are available at osf.io/c2amz.",1803
1718,Games,Alexandra To,"April 1st, 2020",Critical Race Theory for HCI,https://dl.acm.org/doi/abs/10.1145/3313831.3376392?casa_token=bFFinok3wQUAAAAA:pIhe3UMXrdodkEObdgnJcVrJ91iHRaDQj3hzi9YtI7dYpIxsSbLgPNrIFz6HrG-Zqbxif1e-CzE," Ogbonnaya-Ogburu, I. F., Smith, A. D., To, A., & Toyama, K. (2020, April). Critical race theory for HCI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1-16).","The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to ""interest convergence"", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: all HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.",1804
1719,Human-Centered Computing,Timothy W. Bickmore,"September 14th, 2021",A Friendly Face in the Crowd: Reducing Public Speaking Anxiety with an Emotional Support Agent in the Audience,https://dl.acm.org/doi/abs/10.1145/3472306.3478364," Murali, P., Trinh, A. and Bickmore, T. A Friendly Face in the Crowd: Reducing Public Speaking Anxiety with an Emotional Support Agent in the Audience. In Proceedings of the ACM International Conference on Intelligent Virtual Agents (IVA) (2021).","We present Friendly Face - a virtual agent designed to reduce public speaking anxiety by standing within an audience. The agent senses the speaker's behavior during an oral presentation and provides emotional and instrumental support. The system unobtrusively tracks the motion, speech, and prosody of the presenter and provides an intuitive interface to give supportive feedback whenever the presenter looks at the agent, attentive listening behavior through agent gaze and backchannel listening behavior, and time and topic cueing based on real-time analysis of speech content compared to presentation slide contents. An evaluation of Friendly Face agent with a functionally equivalent control system demonstrated that the agent system led to significant reductions in public speaking anxiety compared to a control condition, assessed both objectively with physiological measures and validated self-report instruments.",1805
1720,Human-Centered Computing,Varun Mishra,"June 24th, 2021",Detecting Receptivity for mHealth Interventions in the Natural Environment,https://dl.acm.org/doi/10.1145/3463492," Varun Mishra, Florian K√ºnzler, Jan-Niklas Kramer, Elgar Fleisch, Tobias Kowatsch, and David Kotz. 2021. Detecting Receptivity for mHealth Interventions in the Natural Environment. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2, Article 74 (June 2021), 24 pages. DOI: https://doi.org/10.1145/3463492","Just-In-Time Adaptive Intervention (JITAI) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. A crucial aspect of JITAIs is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. Some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. For effective intervention delivery, however, a JITAI system needs to make in-the-moment decisions about a user's receptivity. To this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions. We leveraged prior work regarding receptivity to JITAIs and deployed a chatbot-based digital coach - Ally - that provided physical-activity interventions and motivated participants to achieve their step goals. We extended the original Ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. For comparison, we included a control model that sent intervention messages at random times. The app randomly selected a delivery model for each intervention message. We observed that the machine-learning models led up to a 40% improvement in receptivity as compared to the control model. Further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study.",1806
1721,Systems and Networking,Ji-Yong Shin,"November 1st, 2019","WormSpace: A Modular Foundation for Simple, Verifiable Distributed Systems",https://dl.acm.org/doi/10.1145/3357223.3362739," ""WormSpace: A Modular Foundation for Simple, Verifiable Distributed Systems,‚Äù Ji-Yong Shin, Jieung Kim, Wolf Honor√©, Hern√°n Vanzetto, Srihari Radhakrishnan, Mahesh Balakrishnan, and Zhong Shao, In Proceedings of the ACM Symposium on Cloud Computing (SoCC), Santa Cruz, CA, U.S.A., Nov 2019.","We propose the Write-Once Register (WOR) as an abstraction for building and verifying distributed systems. A WOR exposes a simple, data-centric API: clients can capture, write, and read it. Applications can use a sequence or a set of WORs to obtain properties such as durability, concurrency control, and failure atomicity. By hiding the logic for distributed coordination underneath a data-centric API, the WOR abstraction enables easy, incremental, and extensible implementation and verification of applications built above it. We present the design, implementation, and verification of a system called WormSpace that provides developers with an address space of WORs, implementing each WOR via a Paxos instance. We describe three applications built over WormSpace: a flexible, efficient Multi-Paxos implementation; a shared log implementation with lower append latency than the state-of-the-art; and a fault-tolerant transaction coordinator that uses an optimal number of round-trips. We show that these applications are simple, easy to verify, and match the performance of unverified monolithic implementations. We use a modular layered verification approach to link the proofs for WormSpace, its applications, and a verified operating system to produce the first verified distributed system stack from the application to the operating system.",1807
1722,Systems and Networking,Cheng Tan,"August 24th, 2021",Building verified neural networks with specifications for systems,https://dl.acm.org/doi/10.1145/3476886.3477508," Cheng Tan, Yibo Zhu, and Chuanxiong Guo. 2021. Building verified neural networks with specifications for systems. Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on Systems. Association for Computing Machinery, New York, NY, USA, 42‚Äì47. DOI:https://doi.org/10.1145/3476886.3477508","Neural networks (NNs) are beneficial to many services, and we believe systems‚Äîsuch as OSes, databases, networked systems‚Äîare not an exception. But applying NNs in these critical systems is challenging: people have to risk getting unexpected outcomes from NNs because NN behaviors are not well-defined. To tame these undefined behaviors, we introduce a framework ouroboros, which builds verified NNs that follow user-defined specifications. These specifications comprise input and output constraints which characterize the behaviors of a NN. We do a case study on database learned indexes to demonstrate that training verified NN models is possible. Though many challenges remain, ouroboros enables us, for the first time, to apply NNs in critical systems with _confidence_.",1808
1723,Systems and Networking,Cheng Tan,"November 4th, 2020",Cobra: Making transactional key-value stores verifiably serializable,https://dl.acm.org/doi/abs/10.5555/3488766.3488770," Cheng Tan, Changgeng Zhao, Shuai Mu, and Michael Walfish. 2020. COBRA: making transactional key-value stores verifiably serializable. Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation. Article 4, 63‚Äì80.","Today's cloud databases offer strong properties, including serializability, sometimes called the gold standard database correctness property. But cloud databases are complicated black boxes, running in a different administrative domain from their clients. Thus, clients might like to know whether the databases are meeting their contract. To that end, we introduce cobra; cobra applies to transactional key-value stores. It is the first system that combines (a) black-box checking, of (b) serializability, while (c) scaling to real-world online transactional processing workloads. The core technical challenge is that the underlying search problem is computationally expensive. COBRA tames that problem by starting with a suitable SMT solver. COBRA then introduces several new techniques, including a new encoding of the validity condition; hardware acceleration to prune inputs to the solver; and a transaction segmentation mechanism that enables scaling and garbage collection. Cobra imposes modest overhead on clients, improves over baselines by 10√ó in verification cost, and (unlike the baselines) supports continuous verification. Our artifact can handle 2000 transactions/sec, equivalent to 170M/day.",1809
1724,Cybersecurity and Privacy,Kevin Fu,"February 26th, 2024",EM Eye: Characterizing Electromagnetic Side-channel Eavesdropping on Embedded Cameras,https://www.ndss-symposium.org/ndss-paper/em-eye-characterizing-electromagnetic-side-channel-eavesdropping-on-embedded-cameras/," Yan Long , Qinhong Jiang, Chen Yan , Tobias Alam, Xiaoyu Ji , Wenyuan Xu , Kevin Fu. (2024). EM Eye: Characterizing Electromagnetic Side-channel Eavesdropping on Embedded Cameras NDSS. https://www.ndss-symposium.org/ndss-paper/em-eye-characterizing-electromagnetic-side-channel-eavesdropping-on-embedded-cameras/","Yan Long (University of Michigan), Qinhong Jiang (Zhejiang University), Chen Yan (Zhejiang University), Tobias Alam (University of Michigan), Xiaoyu Ji (Zhejiang University), Wenyuan Xu (Zhejiang University), Kevin Fu (Northeastern University) IoT devices and other embedded systems are increasingly equipped with cameras that can sense critical information in private spaces. The data security of these cameras, however, has hardly been scrutinized from the hardware design perspective. Our paper presents the first attempt to analyze the attack surface of physical-channel eavesdropping on embedded cameras. We characterize EM Eye--a vulnerability in the digital image data transmission interface that allows adversaries to reconstruct high-quality image streams from the cameras' unintentional electromagnetic emissions, even from over 2 meters away in many cases. Our evaluations of 4 popular IoT camera development platforms and 12 commercial off-the-shelf devices with cameras show that EM Eye poses threats to a wide range of devices, from smartphones to dash cams and home security cameras. By exploiting this vulnerability, adversaries may be able to visually spy on private activities in an enclosed room from the other side of a wall. We provide root cause analysis and modeling that enable system defenders to identify and simulate mitigation against this vulnerability, such as improving embedded cameras' data transmission protocols with minimum costs. We further discuss EM Eye's relationship with known computer display eavesdropping attacks to reveal the gaps that need to be addressed to protect the data confidentiality of sensing systems.",1810
1725,Cybersecurity and Privacy,Kevin Fu,"February 26th, 2024",GhostType: The Limits of Using Contactless Electromagnetic Interference to Inject Phantom Keys into Analog Circuits of Keyboards,https://www.ndss-symposium.org/ndss-paper/ghosttype-the-limits-of-using-contactless-electromagnetic-interference-to-inject-phantom-keys-into-analog-circuits-of-keyboards/," Qinhong Jiang, Yanze Ren, Yan Long , Chen Yan , Yumai Sun, Xiaoyu Ji , Kevin Fu, Wenyuan Xu . (2024). GhostType: The Limits of Using Contactless Electromagnetic Interference to Inject Phantom Keys into Analog Circuits of Keyboards NDSS. https://www.ndss-symposium.org/ndss-paper/ghosttype-the-limits-of-using-contactless-electromagnetic-interference-to-inject-phantom-keys-into-analog-circuits-of-keyboards/","Qinhong Jiang (Zhejiang University), Yanze Ren (Zhejiang University), Yan Long (University of Michigan), Chen Yan (Zhejiang University), Yumai Sun (University of Michigan), Xiaoyu Ji (Zhejiang University), Kevin Fu (Northeastern University), Wenyuan Xu (Zhejiang University) Keyboards are the primary peripheral input devices for various critical computer application scenarios. This paper performs a security analysis of the keyboard sensing mechanisms and uncovers a new class of vulnerabilities that can be exploited to induce phantom keys---fake keystrokes injected into keyboards' analog circuits in a contactless way using electromagnetic interference (EMI). Besides normal keystrokes, such phantom keys also include keystrokes that cannot be achieved by human operators, such as rapidly injecting over 10,000 keys per minute and injecting hidden keys that do not exist on the physical keyboard. The underlying principles of phantom key injection consist in inducing false voltages on keyboard sensing GPIO pins through EMI coupled onto matrix circuits. We investigate the voltage and timing requirements of injection signals both theoretically and empirically to establish the theory of phantom key injection. To validate the threat of keyboard sensing vulnerabilities, we design GhostType that can cause denial-of-service of the keyboard and inject random keystrokes as well as certain targeted keystrokes of the adversary's choice. We have validated GhostType on 48 of 50 off-the-shelf keyboards/keypads from 20 brands including both membrane/mechanical structures and USB/Bluetooth protocols. Some example consequences of GhostType include completely blocking keyboard operations, crashing and turning off downstream computers, and deleting files on computers. Finally, we glean lessons from our investigations and propose countermeasures including EMI shielding, phantom key detection, and keystroke scanning signal improvement.",1811
1726,Cybersecurity and Privacy,Engin Kirda,"February 24th, 2025",Secure IP Address Allocation at Cloud Scale,https://www.ndss-symposium.org/ndss-paper/secure-ip-address-allocation-at-cloud-scale/," Eric Pauley, Kyle Domico, Blaine Hoak, Ryan Sheatsley, Quinn Burke , Yohan Beugin, Engin Kirda, Patrick D. McDaniel. (2025). Secure IP Address Allocation at Cloud Scale NDSS. https://www.ndss-symposium.org/ndss-paper/secure-ip-address-allocation-at-cloud-scale/","Eric Pauley (University of Wisconsin‚ÄìMadison), Kyle Domico (University of Wisconsin‚ÄìMadison), Blaine Hoak (University of Wisconsin‚ÄìMadison), Ryan Sheatsley (University of Wisconsin‚ÄìMadison), Quinn Burke (University of Wisconsin‚ÄìMadison), Yohan Beugin (University of Wisconsin‚ÄìMadison), Engin Kirda (Northeastern University), Patrick McDaniel (University of Wisconsin‚ÄìMadison) Public clouds necessitate dynamic resource allocation and sharing. However, the dynamic allocation of IP addresses can be abused by adversaries to source malicious traffic, bypass rate limiting systems, and even capture traffic intended for other cloud tenants. As a result, both the cloud provider and their customers are put at risk, and defending against these threats requires a rigorous analysis of tenant behavior, adversarial strategies, and cloud provider policies. In this paper, we develop a practical defense for IP address allocation through such an analysis. We first develop a statistical model of cloud tenant deployment behavior based on literature and measurement of deployed systems. Through this, we analyze IP allocation policies under existing and novel threat models. In response to our stronger proposed threat model, we design IP scan segmentation, an IP allocation policy that protects the address pool against adversarial scanning even when an adversary is not limited by number of cloud tenants. Through empirical evaluation on both synthetic and real-world allocation traces, we show that IP scan segmentation reduces adversaries' ability to rapidly allocate addresses, protecting both address space reputation and cloud tenant data. In this way, we show that principled analysis and implementation of cloud IP address allocation can lead to substantial security gains for tenants and their users.",1812
1727,Cybersecurity and Privacy,Engin Kirda,"February 26th, 2024",Untangle: Multi-Layer Web Server Fingerprinting,https://www.ndss-symposium.org/ndss-paper/untangle-multi-layer-web-server-fingerprinting/," Cem Topcuoglu, Kaan Onarlioglu, Bahruz Jabiyev, Engin Kirda. (2024). Untangle: Multi-Layer Web Server Fingerprinting NDSS. https://www.ndss-symposium.org/ndss-paper/untangle-multi-layer-web-server-fingerprinting/","Cem Topcuoglu (Northeastern University), Kaan Onarlioglu (Akamai Technologies), Bahruz Jabiyev (Northeastern University), Engin Kirda (Northeastern University) Web server fingerprinting is a common activity in vulnerability management and security testing, with network scanners offering the capability for over two decades. All known fingerprinting techniques are designed for probing a single, isolated web server. However, the modern Internet is made up of complex layered architectures, where chains of CDNs, reverse proxies, and cloud services front origin servers. That renders existing fingerprinting tools and techniques utterly ineffective. We present the first methodology that can fingerprint servers in a multi-layer architecture, by leveraging the HTTP processing discrepancies between layers. This technique is capable of detecting both the server technologies involved and their correct ordering. It is theoretically extendable to any number of layers, any server technology, deployed in any order, but of course within practical constraints. We then address those practical considerations and present a concrete implementation of the scheme in a tool called Untangle, empirically demonstrating its ability to fingerprint 3-layer architectures with high accuracy.",1813
1728,Cybersecurity and Privacy,Cristina Nita-Rotaru,"February 25th, 2021",More than a Fair Share: Network Data Remanence Attacks against Secret Sharing-based Schemes,https://www.ndss-symposium.org/ndss-paper/more-than-a-fair-share-network-data-remanence-attacks-against-secret-sharing-based-schemes/," Leila Rashidi, Daniel Kostecki, Alexander James, Anthony Peterson, Majid Ghaderi, Samuel Jero, Cristina Nita-Rotaru, Hamed Okhravi, Reihaneh Safavi-Naini. (2021). More than a Fair Share: Network Data Remanence Attacks against Secret Sharing-based Schemes NDSS. https://www.ndss-symposium.org/ndss-paper/more-than-a-fair-share-network-data-remanence-attacks-against-secret-sharing-based-schemes/","Leila Rashidi (University of Calgary), Daniel Kostecki (Northeastern University), Alexander James (University of Calgary), Anthony Peterson (Northeastern University), Majid Ghaderi (University of Calgary), Samuel Jero (MIT Lincoln Laboratory), Cristina Nita-Rotaru (Northeastern University), Hamed Okhravi (MIT Lincoln Laboratory), Reihaneh Safavi-Naini (University of Calgary) With progress toward a practical quantum computer has come an increasingly rapid search for quantum-safe, secure communication schemes that do not rely on discrete logarithm or factorization problems. One such encryption scheme, Multi-path Switching with Secret Sharing (MSSS), combines secret sharing with multi-path switching to achieve security as long as the adversary does not have global observability of all paths and thus cannot capture enough shares to reconstruct messages. MSSS assumes that sending a share on a path is an atomic operation and all paths have the same delay. We identify a side-channel vulnerability for MSSS, created by the fact that in real networks, sending a share is not an atomic operation as paths have multiple hops and different delays. This channel, referred to as Network Data Remanence (NDR), is present in all schemes like MSSS whose security relies on path atomicity and all paths having same delay. We demonstrate the presence of NDR in a physical testbed. We then identify two new attacks that exploit the side- channel, referred to as NDR Blind and NDR Planned, propose an analytical model to analyze the attacks, and demonstrate them using an implementation of MSSS based on the ONOS SDN controller. Finally, we present a countermeasure for the attacks and show its effectiveness in simulations and Mininet experiments.",1814
1729,Cybersecurity and Privacy,Ziming Zhao,"February 24th, 2025",Defending Against Membership Inference Attacks on Iteratively Pruned Deep Neural Networks,https://www.ndss-symposium.org/ndss-paper/defending-against-membership-inference-attacks-on-iteratively-pruned-deep-neural-networks/," Jing Shang, Jian Wang, Kailun Wang, Jiqiang Liu, Nan Jiang, Md. Armanuzzaman, Ziming Zhao . (2025). Defending Against Membership Inference Attacks on Iteratively Pruned Deep Neural Networks NDSS. https://www.ndss-symposium.org/ndss-paper/defending-against-membership-inference-attacks-on-iteratively-pruned-deep-neural-networks/","Jing Shang (Beijing Jiaotong University), Jian Wang (Beijing Jiaotong University), Kailun Wang (Beijing Jiaotong University), Jiqiang Liu (Beijing Jiaotong University), Nan Jiang (Beijing University of Technology), Md Armanuzzaman (Northeastern University), Ziming Zhao (Northeastern University) Model pruning is a technique for compressing deep learning models, and using an iterative way to prune the model can achieve better compression effects with lower utility loss. However, our analysis reveals that iterative pruning significantly increases model memorization, making the pruned models more vulnerable to membership inference attacks (MIAs). Unfortunately, the vast majority of existing defenses against MIAs are designed for original and unpruned models. In this paper, we propose a new framework WeMem to weaken memorization in the iterative pruning process. Specifically, our analysis identifies two important factors that increase memorization in iterative pruning, namely data reuse and inherent memorability. We consider the individual and combined impacts of both factors, forming three scenarios that lead to increased memorization in iteratively pruned models. We design three defense primitives based on these factors' characteristics. By combining these primitives, we propose methods tailored to each scenario to weaken memorization effectively. Comprehensive experiments under ten adaptive MIAs demonstrate the effectiveness of the proposed defenses. Moreover, our defenses outperform five existing defenses in terms of privacy-utility tradeoff and efficiency. Additionally, we enhance the proposed defenses to automatically adjust settings for optimal defense, improving their practicability.",1815
1730,Personal Health Informatics,Kevin Fu,"February 26th, 2024",EM Eye: Characterizing Electromagnetic Side-channel Eavesdropping on Embedded Cameras,https://www.ndss-symposium.org/ndss-paper/em-eye-characterizing-electromagnetic-side-channel-eavesdropping-on-embedded-cameras/," Yan Long , Qinhong Jiang, Chen Yan , Tobias Alam, Xiaoyu Ji , Wenyuan Xu , Kevin Fu. (2024). EM Eye: Characterizing Electromagnetic Side-channel Eavesdropping on Embedded Cameras NDSS. https://www.ndss-symposium.org/ndss-paper/em-eye-characterizing-electromagnetic-side-channel-eavesdropping-on-embedded-cameras/","Yan Long (University of Michigan), Qinhong Jiang (Zhejiang University), Chen Yan (Zhejiang University), Tobias Alam (University of Michigan), Xiaoyu Ji (Zhejiang University), Wenyuan Xu (Zhejiang University), Kevin Fu (Northeastern University) IoT devices and other embedded systems are increasingly equipped with cameras that can sense critical information in private spaces. The data security of these cameras, however, has hardly been scrutinized from the hardware design perspective. Our paper presents the first attempt to analyze the attack surface of physical-channel eavesdropping on embedded cameras. We characterize EM Eye--a vulnerability in the digital image data transmission interface that allows adversaries to reconstruct high-quality image streams from the cameras' unintentional electromagnetic emissions, even from over 2 meters away in many cases. Our evaluations of 4 popular IoT camera development platforms and 12 commercial off-the-shelf devices with cameras show that EM Eye poses threats to a wide range of devices, from smartphones to dash cams and home security cameras. By exploiting this vulnerability, adversaries may be able to visually spy on private activities in an enclosed room from the other side of a wall. We provide root cause analysis and modeling that enable system defenders to identify and simulate mitigation against this vulnerability, such as improving embedded cameras' data transmission protocols with minimum costs. We further discuss EM Eye's relationship with known computer display eavesdropping attacks to reveal the gaps that need to be addressed to protect the data confidentiality of sensing systems.",1816
1731,Personal Health Informatics,Kevin Fu,"February 26th, 2024",GhostType: The Limits of Using Contactless Electromagnetic Interference to Inject Phantom Keys into Analog Circuits of Keyboards,https://www.ndss-symposium.org/ndss-paper/ghosttype-the-limits-of-using-contactless-electromagnetic-interference-to-inject-phantom-keys-into-analog-circuits-of-keyboards/," Qinhong Jiang, Yanze Ren, Yan Long , Chen Yan , Yumai Sun, Xiaoyu Ji , Kevin Fu, Wenyuan Xu . (2024). GhostType: The Limits of Using Contactless Electromagnetic Interference to Inject Phantom Keys into Analog Circuits of Keyboards NDSS. https://www.ndss-symposium.org/ndss-paper/ghosttype-the-limits-of-using-contactless-electromagnetic-interference-to-inject-phantom-keys-into-analog-circuits-of-keyboards/","Qinhong Jiang (Zhejiang University), Yanze Ren (Zhejiang University), Yan Long (University of Michigan), Chen Yan (Zhejiang University), Yumai Sun (University of Michigan), Xiaoyu Ji (Zhejiang University), Kevin Fu (Northeastern University), Wenyuan Xu (Zhejiang University) Keyboards are the primary peripheral input devices for various critical computer application scenarios. This paper performs a security analysis of the keyboard sensing mechanisms and uncovers a new class of vulnerabilities that can be exploited to induce phantom keys---fake keystrokes injected into keyboards' analog circuits in a contactless way using electromagnetic interference (EMI). Besides normal keystrokes, such phantom keys also include keystrokes that cannot be achieved by human operators, such as rapidly injecting over 10,000 keys per minute and injecting hidden keys that do not exist on the physical keyboard. The underlying principles of phantom key injection consist in inducing false voltages on keyboard sensing GPIO pins through EMI coupled onto matrix circuits. We investigate the voltage and timing requirements of injection signals both theoretically and empirically to establish the theory of phantom key injection. To validate the threat of keyboard sensing vulnerabilities, we design GhostType that can cause denial-of-service of the keyboard and inject random keystrokes as well as certain targeted keystrokes of the adversary's choice. We have validated GhostType on 48 of 50 off-the-shelf keyboards/keypads from 20 brands including both membrane/mechanical structures and USB/Bluetooth protocols. Some example consequences of GhostType include completely blocking keyboard operations, crashing and turning off downstream computers, and deleting files on computers. Finally, we glean lessons from our investigations and propose countermeasures including EMI shielding, phantom key detection, and keystroke scanning signal improvement.",1817
1732,Systems and Networking,Engin Kirda,"February 24th, 2025",Secure IP Address Allocation at Cloud Scale,https://www.ndss-symposium.org/ndss-paper/secure-ip-address-allocation-at-cloud-scale/," Eric Pauley, Kyle Domico, Blaine Hoak, Ryan Sheatsley, Quinn Burke , Yohan Beugin, Engin Kirda, Patrick D. McDaniel. (2025). Secure IP Address Allocation at Cloud Scale NDSS. https://www.ndss-symposium.org/ndss-paper/secure-ip-address-allocation-at-cloud-scale/","Eric Pauley (University of Wisconsin‚ÄìMadison), Kyle Domico (University of Wisconsin‚ÄìMadison), Blaine Hoak (University of Wisconsin‚ÄìMadison), Ryan Sheatsley (University of Wisconsin‚ÄìMadison), Quinn Burke (University of Wisconsin‚ÄìMadison), Yohan Beugin (University of Wisconsin‚ÄìMadison), Engin Kirda (Northeastern University), Patrick McDaniel (University of Wisconsin‚ÄìMadison) Public clouds necessitate dynamic resource allocation and sharing. However, the dynamic allocation of IP addresses can be abused by adversaries to source malicious traffic, bypass rate limiting systems, and even capture traffic intended for other cloud tenants. As a result, both the cloud provider and their customers are put at risk, and defending against these threats requires a rigorous analysis of tenant behavior, adversarial strategies, and cloud provider policies. In this paper, we develop a practical defense for IP address allocation through such an analysis. We first develop a statistical model of cloud tenant deployment behavior based on literature and measurement of deployed systems. Through this, we analyze IP allocation policies under existing and novel threat models. In response to our stronger proposed threat model, we design IP scan segmentation, an IP allocation policy that protects the address pool against adversarial scanning even when an adversary is not limited by number of cloud tenants. Through empirical evaluation on both synthetic and real-world allocation traces, we show that IP scan segmentation reduces adversaries' ability to rapidly allocate addresses, protecting both address space reputation and cloud tenant data. In this way, we show that principled analysis and implementation of cloud IP address allocation can lead to substantial security gains for tenants and their users.",1818
1733,Systems and Networking,Engin Kirda,"February 26th, 2024",Untangle: Multi-Layer Web Server Fingerprinting,https://www.ndss-symposium.org/ndss-paper/untangle-multi-layer-web-server-fingerprinting/," Cem Topcuoglu, Kaan Onarlioglu, Bahruz Jabiyev, Engin Kirda. (2024). Untangle: Multi-Layer Web Server Fingerprinting NDSS. https://www.ndss-symposium.org/ndss-paper/untangle-multi-layer-web-server-fingerprinting/","Cem Topcuoglu (Northeastern University), Kaan Onarlioglu (Akamai Technologies), Bahruz Jabiyev (Northeastern University), Engin Kirda (Northeastern University) Web server fingerprinting is a common activity in vulnerability management and security testing, with network scanners offering the capability for over two decades. All known fingerprinting techniques are designed for probing a single, isolated web server. However, the modern Internet is made up of complex layered architectures, where chains of CDNs, reverse proxies, and cloud services front origin servers. That renders existing fingerprinting tools and techniques utterly ineffective. We present the first methodology that can fingerprint servers in a multi-layer architecture, by leveraging the HTTP processing discrepancies between layers. This technique is capable of detecting both the server technologies involved and their correct ordering. It is theoretically extendable to any number of layers, any server technology, deployed in any order, but of course within practical constraints. We then address those practical considerations and present a concrete implementation of the scheme in a tool called Untangle, empirically demonstrating its ability to fingerprint 3-layer architectures with high accuracy.",1819
1734,Systems and Networking,Cristina Nita-Rotaru,"February 25th, 2021",More than a Fair Share: Network Data Remanence Attacks against Secret Sharing-based Schemes,https://www.ndss-symposium.org/ndss-paper/more-than-a-fair-share-network-data-remanence-attacks-against-secret-sharing-based-schemes/," Leila Rashidi, Daniel Kostecki, Alexander James, Anthony Peterson, Majid Ghaderi, Samuel Jero, Cristina Nita-Rotaru, Hamed Okhravi, Reihaneh Safavi-Naini. (2021). More than a Fair Share: Network Data Remanence Attacks against Secret Sharing-based Schemes NDSS. https://www.ndss-symposium.org/ndss-paper/more-than-a-fair-share-network-data-remanence-attacks-against-secret-sharing-based-schemes/","Leila Rashidi (University of Calgary), Daniel Kostecki (Northeastern University), Alexander James (University of Calgary), Anthony Peterson (Northeastern University), Majid Ghaderi (University of Calgary), Samuel Jero (MIT Lincoln Laboratory), Cristina Nita-Rotaru (Northeastern University), Hamed Okhravi (MIT Lincoln Laboratory), Reihaneh Safavi-Naini (University of Calgary) With progress toward a practical quantum computer has come an increasingly rapid search for quantum-safe, secure communication schemes that do not rely on discrete logarithm or factorization problems. One such encryption scheme, Multi-path Switching with Secret Sharing (MSSS), combines secret sharing with multi-path switching to achieve security as long as the adversary does not have global observability of all paths and thus cannot capture enough shares to reconstruct messages. MSSS assumes that sending a share on a path is an atomic operation and all paths have the same delay. We identify a side-channel vulnerability for MSSS, created by the fact that in real networks, sending a share is not an atomic operation as paths have multiple hops and different delays. This channel, referred to as Network Data Remanence (NDR), is present in all schemes like MSSS whose security relies on path atomicity and all paths having same delay. We demonstrate the presence of NDR in a physical testbed. We then identify two new attacks that exploit the side- channel, referred to as NDR Blind and NDR Planned, propose an analytical model to analyze the attacks, and demonstrate them using an implementation of MSSS based on the ONOS SDN controller. Finally, we present a countermeasure for the attacks and show its effectiveness in simulations and Mininet experiments.",1820
1735,Systems and Networking,Ziming Zhao,"February 24th, 2025",Defending Against Membership Inference Attacks on Iteratively Pruned Deep Neural Networks,https://www.ndss-symposium.org/ndss-paper/defending-against-membership-inference-attacks-on-iteratively-pruned-deep-neural-networks/," Jing Shang, Jian Wang, Kailun Wang, Jiqiang Liu, Nan Jiang, Md. Armanuzzaman, Ziming Zhao . (2025). Defending Against Membership Inference Attacks on Iteratively Pruned Deep Neural Networks NDSS. https://www.ndss-symposium.org/ndss-paper/defending-against-membership-inference-attacks-on-iteratively-pruned-deep-neural-networks/","Jing Shang (Beijing Jiaotong University), Jian Wang (Beijing Jiaotong University), Kailun Wang (Beijing Jiaotong University), Jiqiang Liu (Beijing Jiaotong University), Nan Jiang (Beijing University of Technology), Md Armanuzzaman (Northeastern University), Ziming Zhao (Northeastern University) Model pruning is a technique for compressing deep learning models, and using an iterative way to prune the model can achieve better compression effects with lower utility loss. However, our analysis reveals that iterative pruning significantly increases model memorization, making the pruned models more vulnerable to membership inference attacks (MIAs). Unfortunately, the vast majority of existing defenses against MIAs are designed for original and unpruned models. In this paper, we propose a new framework WeMem to weaken memorization in the iterative pruning process. Specifically, our analysis identifies two important factors that increase memorization in iterative pruning, namely data reuse and inherent memorability. We consider the individual and combined impacts of both factors, forming three scenarios that lead to increased memorization in iteratively pruned models. We design three defense primitives based on these factors' characteristics. By combining these primitives, we propose methods tailored to each scenario to weaken memorization effectively. Comprehensive experiments under ten adaptive MIAs demonstrate the effectiveness of the proposed defenses. Moreover, our defenses outperform five existing defenses in terms of privacy-utility tradeoff and efficiency. Additionally, we enhance the proposed defenses to automatically adjust settings for optimal defense, improving their practicability.",1821
1736,Artificial Intelligence,Sina Fazelpour,"June 1st, 2022",Diversity and homophily in social networks,https://escholarship.org/uc/item/7646n2mc," Sina Fazelpour, Hannah Rubin. (2022). Diversity and homophily in social networks CogSci. https://escholarship.org/uc/item/7646n2mc","Diversity of social identities can improve the performance of groups through varied cognitive and communicative pathways. Recently, research efforts have focused on identifying when we should expect to see these potential benefits in real-world settings. While most research to date has studied this topic at individual and interpersonal levels, in this paper, we develop an agent-based model to explore how various aspects of homophily, the tendency of individuals to associate with similar others, affects performance at a larger scale. Study 1 examines how two types of homophily---identity-driven and opinion-driven---impact collective performance on a sequential decision-making task via modulating network formation and trust relations. Study 2 considers how the presence of identity-based conformity pressure can affect the findings from the first study. Overall, we find that the effect of homophily on performance is complex, depending on the operative dimensions of similarity, mediating pathways, and the specific outcome of interest. Finally, we discuss the implications of our results for policy interventions aiming to improve group performance.",1822
1737,Computer Science Education,Carla E. Brodley,"December 31st, 2015",Cortical feature analysis and machine learning improves detection of ‚ÄúMRI-negative‚Äù focal cortical dysplasia,https://doi.org/10.1016/j.yebeh.2015.04.055," Bilal Ahmed, Carla E. Brodley, Karen E. Blackmon, Ruben Kuzniecky, Gilad Barash, Chad Carlson, Brian T. Quinn, Werner Doyle, Jacqueline French, Orrin Devinsky, Thomas Thesen. ""Cortical feature analysis and machine learning improves detection of ‚ÄúMRI-negative‚Äù focal cortical dysplasia"". Science Direct, Epilepsy & Behavior, 2015. DOI: 10.1016/j.yebeh.2015.04.055","Focal cortical dysplasia (FCD) is the most common cause of pediatric epilepsy and the third most common lesion in adults with treatment-resistant epilepsy. Advances in MRI have revolutionized the diagnosis of FCD, resulting in higher success rates for resective epilepsy surgery. However, many patients with histologically confirmed FCD have normal presurgical MRI studies (‚ÄòMRI-negative‚Äô), making presurgical diagnosis difficult. The purpose of this study was to test whether a novel MRI postprocessing method successfully detects histopathologically verified FCD in a sample of patients without visually appreciable lesions. We applied an automated quantitative morphometry approach which computed five surface-based MRI features and combined them in a machine learning model to classify lesional and nonlesional vertices. Accuracy was defined by classifying contiguous vertices as ‚Äúlesional‚Äù when they fell within the surgical resection region. Our multivariate method correctly detected the lesion in 6 of 7 MRI-positive patients, which is comparable with the detection rates that have been reported in univariate vertex-based morphometry studies. More significantly, in patients that were MRI-negative, machine learning correctly identified 14 out of 24 FCD lesions (58%). This was achieved after separating abnormal thickness and thinness into distinct classifiers, as well as separating sulcal and gyral regions. Results demonstrate that MRI-negative images contain sufficient information to aid in the in vivo detection of visually elusive FCD lesions.",1823
1738,Algorithms and Theory,Rajmohan Rajaraman,"July 11th, 2016",Robust and Probabilistic Failure-Aware Placement,http://www.ccs.neu.edu/home/rraj/Pubs/FailureAwarePlacementSPAA2016.pdf," Rajmohan Rajaraman , M. Korupolu ACM Symposium on Parallelism in Algorithms and Architectures, July 2016","Motivated by the growing complexity and heterogeneity of modern data centers, and the prevalence of commodity com- ponent failures, this paper studies the failure-aware place- ment problem of placing tasks of a parallel job on machines in the data center with the goal of increasing availability. We consider two models of failures: adversarial and prob- abilistic. In the adversarial model, each node has a weight (higher weight implying higher reliability) and the adver- sary can remove any subset of nodes of total weight at most a given bound W and our goal is to Ô¨Ånd a placement that incurs the least disruption against such an adversary. In the probabilistic model, each node has a probability of failure and we need to Ô¨Ånd a placement that maximizes the proba- bility that at least K out of N tasks survive at any time. For adversarial failures, we Ô¨Årst show that (i) the prob- lems are in Œ£2, the second level of the polynomial hierarchy, (ii) a basic variant, that we call RobustFAP, is co-NP- hard, and (iii) an all-or-nothing version of RobustFAP is Œ£2-complete. We then give a PTAS for RobustFAP, a key ingredient of which is a solution that we design for a frac- tional version of RobustFAP. We then study fractional Ro- bustFAP over hierarchies, denoted HierRobustFAP, and introduce a notion of hierarchical max-min fairness and a novel Generalized Spreading algorithm which is simultane- ously optimal for all W. These generalize the classical notion of max-min fairness to work with nodes of diÔ¨Äering capaci- ties, diÔ¨Äering reliability weights and hierarchical structures. Using randomized rounding, we extend this to give an algo- rithm for integral HierRobustFAP. For the probabilistic version, we Ô¨Årst give an algorithm that achieves an additive Œµ approximation in the failure probability for the single level version, called ProbFAP, while giving up a (1+Œµ) multiplicative factor in the number of failures. We then extend the result to the hierarchical ver- sion, HierProbFAP, achieving an Œµ additive approximation ‚àóSupported in part by NSF grants CNS-1217981, CCF- 1422715, and CCF-1535929, and a Google Research Award. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation on the Ô¨Årst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a fee. Request permissions from permissions@acm.org. SPAA ‚Äô16, July 11 - 13, 2016, PaciÔ¨Åc Grove, CA, USA c‚Éù2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4210-0/16/07...$15.00 DOI: http://dx.dos and open problems In this paper, we formulate and initiate the study of failure- aware placement for hierarchical data centers under adver- sarial and probabilistic failures. For both classes, we give hardness results and approximation algorithms for multiple variants: based on generalized spreading for HierRobust- FAP and Poisson approximation for HierProbFAP. One natural question is to improve the approximation guarantees and design more practical implementations for some of the variants. In particular, the approximation fac- tor in the bicriteria PTAS for HierProbFAP grows linearly in the number of levels. While this is reasonable for current datacenters (which typically have three to four levels of hi- erarchy), it would be interesting to see if the approximation factor can be made sublinear or even independent of number of levels. Similarly, our PTASes incur high running times (e.g., for RobustFAP, a standard implementation would take time O(n(3+ln(1/Œµ))/Œµ) time), and it is important to de- sign practical implementations of PTASes that trade oÔ¨Äap- proximation guarantees for simplicity. On a related note, our study here has focused on identical tasks of the same size. It will be interesting to extend this to an on-line sequence of jobs of possibly diÔ¨Äerent sizes. A further extension would be to consider dynamic task migra- tions to improve availability as jobs Ô¨Ånish and leave.",1824
1739,Artificial Intelligence,Christopher Amato,"February 20th, 2023",Improving Deep Policy Gradients with Value Function Search,https://openreview.net/pdf?id=6qZC7pfenQm," Enrico Marchesini, Christopher Amato. (2023). Improving Deep Policy Gradients with Value Function Search ICLR. https://openreview.net/pdf?id=6qZC7pfenQm","Deep Policy Gradient (PG) algorithms employ value networks to drive the learn- ing of parameterized policies and reduce the variance of the gradient estimates. However, value function approximation gets stuck in local optima and struggles to fit the actual return, limiting the variance reduction efficacy and leading policies to sub-optimal performance. This paper focuses on improving value approxima- tion and analyzing the effects on Deep PG primitives such as value prediction, variance reduction, and correlation of gradient estimates with the true gradient. To this end, we introduce a Value Function Search that employs a population of perturbed value networks to search for a better approximation. Our framework does not require additional environment interactions, gradient computations, or ensembles, providing a computationally inexpensive approach to enhance the su- pervised learning task on which value networks train. Crucially, we show that improving Deep PG primitives results in improved sample efficiency and policies with higher returns using common continuous control benchmark domains. 1VFS introduces a two-scale perturbation operator voted to diversify a population of value networks to (i) explore local variations of current critics‚Äô predictions and (ii) allow to explore diversified value functions to escape from local optima. The practical results of such components have been investigated with additional experiments that also motivate the improvement in sample efficiency and performance of VFS-based algorithms in a range of standard continuous control benchmarks. Our findings suggest that improving fundamental Deep PG primitives translates into higher-performing policies and better sample efficiency. 9 Published as a conference paper at ICLR 2023 7",1825
1740,Artificial Intelligence,Christopher Amato,"May 5th, 2018",Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems,http://www.ccs.neu.edu/home/camato/publications/ICRA2018.pdf," Nghia Hoang, Yuchen Xiao, Kavinayan Sivakumar, Christopher Amato and Jonathan P. How. In the Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA-18), May 2018.","‚Äî A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self- interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with Ô¨Åxed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach Ô¨Årst optimizes a set of stratagems that represent these best responses. These optimized stratagems are then inte- grated into a uniÔ¨Åed policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.This paper introduces a novel near-optimal adversarial pol- icy switching algorithm for decentralized, non-cooperative multi-agent systems. Unlike the existing works in literature which are mostly limited to simple decision-making sce- narios where a single agent plans its best response against an adversary whose strategy is speciÔ¨Åed a priori under reasonable assumptions, we investigate instead a class of multi-agent scenarios where multiple robots need to operate independently in collaboration with their teammates to act effectively against adversaries with changing strategies. To achieve this, we Ô¨Årst optimize a set of basic stratagems that each is tuned to respond optimally to a pre-identiÔ¨Åed basic tactic of the adversaries. The stratagems are then integrated into a uniÔ¨Åed policy which performs near-optimally against B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (a) (b) (c) B3 B2 B1 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (d) (e) (f) Fig. 6: Image excerpts from a video demo showing (1) a team of 3 allied (blue) robots (B1,B2 and B3) that implement the optimized stratagem produced by our framework (Section III) to compete against (2) an opposing team of 2 opponent (red) robots (R1 and R2) which implement the hand-coded tactics DL and DR (see Section VI-A), respectively: (a) B1,B2 and B3 decide to invade the opposition territory; (b) B1 and B3 decide to attack the center while B2 decides to take the left Ô¨Çank of the opposition; (c) B2 passes through R1‚Äôs defense while B1 takes an interesting position to block R2 so that B3 can pass through its defense; (d) B1 and B2 detect the Ô¨Çag and mount a pincer attack; (e) R2 arrives to defend the Ô¨Çag and B2 retreats to avoid getting tagged; and (f) without noticing B1 from behind, R2 continues its DR patrol, thus losing the Ô¨Çag to B1. any high-level strategies of the adversaries that switches between their basic tactics. The near-optimality of our pro- posed framework can be established in both theoretical and empirical settings with interesting and consistent results. We believe this is a signiÔ¨Åcant step towards bridging the gap between theory and practice in multi-agent research.",1826
1741,Artificial Intelligence,Christopher Amato,"August 4th, 2017",COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs,http://www.ccs.neu.edu/home/camato/publications/cogdice_ijcai.pdf," COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs. Madison Clark-Turner and Christopher Amato. In the Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), August 2017","The decentralized partially observable Markov de- cision process (Dec-POMDP) is a powerful model for representing multi-agent problems with de- centralized behavior. Unfortunately, current Dec- POMDP solution methods cannot solve problems with continuous observations, which are common in many real-world domains. To that end, we present a framework for representing and gener- ating Dec-POMDP policies that explicitly include continuous observations. We apply our algorithm to a novel tagging problem and an extended version of a common benchmark, where it generates poli- cies that meet or exceed the values of equivalent discretized domains without the need for Ô¨Ånding an adequate discretization. 1This paper presented, for the Ô¨Årst time, an algorithm that gen- erates joint policies for Dec-POMDPs with continuous ob- servations. We presented both a discrete-observation ver- sion of the algorithm, which is applicable in domains with a large number of discrete observations, and a continuous- observation version. This method is broadly applicable as many real-world domains have large or continuous observa- tion spaces. COG-DICE has been successful in generating joint policies for both a novel and a preexisting problem and has highlighted the negative impacts that inappropriate dis- cretization can have on joint policy structure and value. For future work, we are interested in extending this work to high- dimensional observation spaces by exploring other (nonlin- ear) divisions and optimizing the algorithm parameters by ei- ther integrating these optimizations into the algorithm or pos- sibly building on previous work on Bayesian non-parametrics [Liu et al., 2015].",1827
1742,Artificial Intelligence,David Bau,"October 24th, 2022",Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,https://openreview.net/pdf?id=DeG07_TcZvT," Kenneth Li , Aspen K. Hopkins, David Bau, Fernanda B. Vi√©gas, Hanspeter Pfister, Martin Wattenberg. (2023). Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task ICLR. https://openreview.net/pdf?id=DeG07_TcZvT","Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce ‚Äúlatent saliency maps‚Äù that help explain predictions. 1 1Our experiments provide evidence that Othello-GPT maintains a representation of game board states‚Äî that is, the Othello ‚Äúworld‚Äù‚Äîto produce sequences it was trained on. This representation appears to be nonlinear in an essential way. Further, we find that these representations can be causally linked to how the model makes its predictions. Understanding of the internal representations of a sequence model is interesting in its own right, but may also be helpful in deeper interpretations of the network. We have also described how interventional experiments may be used to create a ‚Äúlatent saliency map‚Äù, which gives a picture, in terms of the Othello board, of how the network has made a prediction. Applied to two versions of Othello-GPT that were trained on different data sets, the latent saliency maps highlight the dramatic differences between underlying representations of the Othello-GPT trained on synthetic dataset and its counterpart trained on championship dataset. There are several potential lines of future work. One natural extension would be to perform the same type of investigations with other, more complex games. It would also be interesting to compare the strategies learned by a sequence model trained on game transcripts with those of a model trained with a priori knowledge of Othello. One option is to compare latent saliency maps of Othello‚ÄìGPT with standard saliency maps of an Othello-playing program which has the actual board state as input. More broadly, it would be interesting to study how our results generalize to models trained on natural language. One stepping stone might be to look at language models whose training data has included game transcripts. Will we see similar representation of board state? Grammar engineering tools (Weston et al., 2015; Hermann et al., 2017; CÀÜot¬¥e et al., 2018) could help define a synthetic data generation process that maps world representations onto natural language sentences, providing a similarly controllable setting like Othello while closing the distance to natural languages. For more complex natural language tasks, can we find meaningful world representations? Our hope is that the tools described in this paper‚Äînonlinear probes, layerwise interventions, and latent saliency maps‚Äîmay prove useful in natural language settings. 9 Published as a conference paper at ICLR 2023",1828
1743,Artificial Intelligence,Ehsan Elhamifar,"December 8th, 2019",Deep Supervised Summarization: Algorithm and Application to Learning Instructions,https://khoury.northeastern.edu/home/eelhami/publications/SupFL_NeurIPS19.pdf," Deep Supervised Summarization: Algorithm and Application to Learning Instructions C. Xu and E. Elhamifar, Neural Information Processing Systems (NeurIPS), 2019.","We address the problem of Ô¨Ånding representative points of datasets by learning from multiple datasets and their ground-truth summaries. We develop a supervised subset selection framework, based on the facility location utility function, which learns to map datasets to their ground-truth representatives. To do so, we propose to learn representations of data so that the input of transformed data to the facility location recovers their ground-truth representatives. Given the NP-hardness of the utility function, we consider its convex relaxation based on sparse representation and investigate conditions under which the solution of the convex optimization recovers ground-truth representatives of each dataset. We design a loss function whose minimization over the parameters of the data representation network leads to satisfying the theoretical conditions, hence guaranteeing recovering ground- truth summaries. Given the non-convexity of the loss function, we develop an efÔ¨Åcient learning scheme that alternates between representation learning by mini- mizing our proposed loss given the current assignments of points to ground-truth representatives and updating assignments given the current data representation. By experiments on the problem of learning key-steps (subactivities) of instruc- tional videos, we show that our proposed framework improves the state-of-the-art supervised subset selection algorithms. 1s We addressed the problem of supervised subset selection by generalizing the facility location to learn from ground-truth summaries. We considered an efÔ¨Åcient sparse optimization of the uncapacitated facility location and investigated conditions under which it recovers ground-truth representatives and also becomes equivalent to the original NP-hard problem. We designed a loss function and an efÔ¨Åcient framework to learn representations of data so that the input of transformed data to the facility location satisÔ¨Åes the theoretical conditions, hence, recovers ground-truth summaries. We showed the effectiveness of our method for recovering key-steps of instructional videos. To the best of our knowledge, this is the Ô¨Årst work on supervised subset selection that derives conditions under which subset selection recovers ground-truth representatives and employs them to design a loss function for deep representation learning. We believe that this work took a major step towards a theoretically motivated supervised subset selection framework.",1829
1744,Artificial Intelligence,Ehsan Elhamifar,"October 27th, 2019",Unsupervised Procedure Learning via Joint Dynamic Summarization,http://www.ccs.neu.edu/home/eelhami/publications/ICCV19-ProceL-Ehsan.pdf," Unsupervised Procedure Learning via Joint Dynamic Summarization. E. Elhamifar and Z. Naing, International Conference on Computer Vision (ICCV), 2019.","We address the problem of unsupervised procedure learning from unconstrained instructional videos. Our goal is to produce a summary of the procedure key-steps and their ordering needed to perform a given task, as well as localization of the key-steps in videos. We develop a col- laborative sequential subset selection framework, where we build a dynamic model on videos by learning states and transitions between them, where states correspond to dif- ferent subactivities, including background and procedure steps. To extract procedure key-steps, we develop an opti- mization framework that Ô¨Ånds a sequence of a small number of states that well represents all videos and is compatible with the state transition model. Given that our proposed optimization is non-convex and NP-hard, we develop a fast greedy algorithm whose complexity is linear in the length of the videos and the number of states of the dynamic model, hence, scales to large datasets. Under appropriate condi- tions on the transition model, our proposed formulation is approximately submodular, hence, comes with performance guarantees. We also present ProceL, a new multimodal dataset of 47.3 hours of videos and their transcripts from diverse tasks, for procedure learning evaluation. By exten- sive experiments, we show that our framework signiÔ¨Åcantly improves the state of the art performance.We developed a joint dynamic summarization method and a fast greedy algorithm for unsupervised procedure learning. Our method handles repeated key-steps, back- ground and missing or additional key-steps in videos. We presented ProceL, a new multimodal dataset for procedure learning. We showed our method signiÔ¨Åcantly improves the state of the art performance and showed the effectiveness of summarization tools, in general, for procedure learning.",1830
1745,Artificial Intelligence,Ehsan Elhamifar,"June 16th, 2019",Facility Location: Approximate Submodularity and Greedy Algorithm,http://www.ccs.neu.edu/home/eelhami/publications/SeqFL_ICML19.pdf," Facility Location: Approximate Submodularity and Greedy Algorithm, E. Elhamifar, International Conference on Machine Learning (ICML), 2019.","We develop and analyze a novel utility function and a fast optimization algorithm for subset se- lection in sequential data that incorporates the dynamic model of data. We propose a cardinality- constrained sequential facility location function that Ô¨Ånds a Ô¨Åxed number of representatives, where the sequence of representatives is compatible with the dynamic model and well encodes the data. As maximizing this new objective function is NP- hard, we develop a fast greedy algorithm based on submodular maximization. Unlike the con- ventional facility location, the computation of the marginal gain in our case cannot be done by oper- ations on each item independently. We exploit the sequential structure of the problem and develop an efÔ¨Åcient dynamic programming-based algorithm that computes the marginal gain exactly. We in- vestigate conditions on the dynamic model, under which our utility function is (Œµ-approximately) submodualr, hence, the greedy algorithm comes with performance guarantees. By experiments on synthetic data and the problem of procedure learning from instructional videos, we show that our framework signiÔ¨Åcantly improves the compu- tational time, achieves better objective function values and obtains more coherent summaries.s We proposed a utility function and a fast greedy algorithm for subset selection in sequential datasets, taking advantage of the dynamic model of data. We proved that under appro- priate conditions on transition dynamics, our utility function is Œµ-approximately submodular, hence, enjoys approximate guarantees via the greedy method. By experiments on syn- thetic and real data, we showed the effectiveness of our method in terms of running time and attained objective val- ues as well as addressing the procedure learning task. Greedy Sequential Facility Location",1831
1746,Artificial Intelligence,Ehsan Elhamifar,"December 4th, 2017",Subset Selection and Summarization in Sequential Data,http://www.ccs.neu.edu/home/eelhami/publications/SeqSS-NIPS17-Ehsan.pdf," E. Elhamifar and M. C. De Paolis Kaluza; Neural Information Processing Systems (NIPS), 2017.","Subset selection, which is the task of Ô¨Ånding a small subset of representative items from a large ground set, Ô¨Ånds numerous applications in different areas. Sequential data, including time-series and ordered data, contain important structural relation- ships among items, imposed by underlying dynamic models of data, that should play a vital role in the selection of representatives. However, nearly all existing subset selection techniques ignore underlying dynamics of data and treat items independently, leading to incompatible sets of representatives. In this paper, we develop a new framework for sequential subset selection that Ô¨Ånds a set of represen- tatives compatible with the dynamic models of data. To do so, we equip items with transition dynamic models and pose the problem as an integer binary optimization over assignments of sequential items to representatives, that leads to high encoding, diversity and transition potentials. Our formulation generalizes the well-known facility location objective to deal with sequential data, incorporating transition dynamics among facilities. As the proposed formulation is non-convex, we derive a max-sum message passing algorithm to solve the problem efÔ¨Åciently. Experiments on synthetic and real data, including instructional video summarization, show that our sequential subset selection framework not only achieves better encoding and diversity than the state of the art, but also successfully incorporates dynamics of data, leading to compatible representatives. 1s and Future Work We developed a new framework for sequential subset selection that takes advantage of the underlying dynamic models of data, promoting to select a set of representatives that are compatible according to the dynamic models of data. By experiments on synthetic and real data, we showed the effectiveness of our method for summarization of sequential data. Our ongoing research include development of fast greedy algorithms for our sequential subset selection formulation, investigation of the theoretical guarantees of our method, as well as development of more effective summarization-based feature extraction techniques and working with larger datasets for the task of instructional data summarization. 9",1832
1747,Artificial Intelligence,Ehsan Elhamifar,"July 21st, 2017",Online Summarization via Submodular and Convex Optimization,http://www.ccs.neu.edu/home/eelhami/publications/onlineSS_CVPR17-Ehsan.pdf," E. Elhamifar and M. C. De Paolis Kaluza  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.","We consider the problem of subset selection in the online setting, where data arrive incrementally. Instead of stor- ing and running subset selection on the entire dataset, we propose an incremental subset selection framework that, at each time instant, uses the previously selected set of repre- sentatives and the new batch of data in order to update the set of representatives. We cast the problem as an integer bi- nary optimization minimizing the encoding cost of the data via representatives regularized by the number of selected items. As the proposed optimization is, in general, NP-hard and non-convex, we study a greedy approach based on un- constrained submodular optimization and also propose an efÔ¨Åcient convex relaxation. We show that, under appropri- ate conditions, the solution of our proposed convex algo- rithm achieves the global optimal solution of the non-convex problem. Our results also address the conventional problem of subset selection in the ofÔ¨Çine setting, as a special case. By extensive experiments on the problem of video summa- rization, we demonstrate that our proposed online subset selection algorithms perform well on real data, capturing diverse representative events in videos, while they obtain objective function values close to the ofÔ¨Çine setting.s We studied the problem of subset selection in the online setting, where data arrive incrementally. We proposed an incremental subset selection framework that, at each time instant, uses the previously selected set of representatives and the new batch of data in order to update the set of representatives. We cast the problem as an integer binary optimization minimizing the encoding cost of the data via representatives regularized by the number of selected items. We studied a randomized greedy approach based on uncon- strained submodular optimization and proposed a convex algorithm with theoretical performance guarantees. By ex- periments on real videos, we demonstrated the effectiveness of our methods for online video summarization.",1833
1748,Artificial Intelligence,Byron Wallace,"April 25th, 2017",Exploiting Domain Knowledge via Grouped Weight Sharing with Application to Text Categorization,https://arxiv.org/pdf/1702.02535v3.pdf," Ye Zhang, Matthew Lease, Byron C. Wallace","A fundamental advantage of neural mod- els for NLP is their ability to learn rep- resentations from scratch. However, in practice this often means ignoring existing external linguistic resources, e.g., Word- Net or domain speciÔ¨Åc ontologies such as the UniÔ¨Åed Medical Language System (UMLS). We propose a general, novel method for exploiting such resources via weight sharing. Prior work on weight sharing in neural networks has considered it largely as a means of model compres- sion. In contrast, we treat weight shar- ing as a Ô¨Çexible mechanism for incorpo- rating prior knowledge into neural models. We show that this approach consistently yields improved performance on classiÔ¨Å- cation tasks compared to baseline strate- gies that do not exploit weight sharing. 1We have proposed a novel method for incorporat- ing prior semantic knowledge into neural models via stochastic weight sharing. We have showed it generally improves text classiÔ¨Åcation performance vs. model variants which do not exploit external resources and vs. an approach based on retroÔ¨Åtting prior to training. In future work, we will inves- tigate generalizing our approach beyond classiÔ¨Å- cation, and to inform weight sharing using other varieties and sources of linguistic knowledge.",1834
1749,Artificial Intelligence,Robin Walters,"February 27th, 2023",Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction,https://openreview.net/pdf?id=_2bDpAtr7PI," David Klee, Ondrej Biza, Robert Platt, Robin Walters. (2023). Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction ICLR. https://openreview.net/pdf?id=_2bDpAtr7PI","Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in SO(3). How- ever, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages SO(3) equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at https://dmklee.github.io/image2sphere. 1In this work, we present the first method to leverage SO(3)-equivariance for predicting distributions over 3D rotations from single images. Our method is better suited than regression methods at handling unknown object symmetries, generates more expressive distributions than methods using parametric families of multi-modal distributions while requiring fewer samples than an implicit modeling approach. We demonstrate state-of-the-art performance on the challenging PASCAL3D+ dataset composed of real images. One limitation of our work is that we use a high maximum frequency, L, in the spherical convolution operations to have higher resolution predictions. Because the number of operations in a spherical convolution is quadratic in L, it may be impractical for applications where more spherical convolutions are required. 9 Published as a conference paper at ICLR 2023",1835
1750,Artificial Intelligence,Robin Walters,"June 8th, 2022",Integrating Symmetry into Differentiable Planning with Steerable Convolutions,https://openreview.net/pdf?id=n7CPzMPKQl," Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2023). Integrating Symmetry into Differentiable Planning with Steerable Convolutions ICLR. https://openreview.net/pdf?id=n7CPzMPKQl","In this paper, we study a principled approach on incorporating group symme- try into end-to-end differentiable planning algorithms and explore the benefits of symmetry in planning. To achieve this, we draw inspiration from equivariant con- volution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant op- erator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navi- gation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2- DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN. 1, SymVIN and SymGPPN generalize better to different map sizes, com- pared to all non-equivariant baselines. Remark. In summary, our results show that the Sym- Plan models demonstrate end-to-end planning and learn- ing ability, potentially enabling further applications to other tasks as a differentiable component for planning. Additional results and ablation studies are in Appendix H. 7 DISCUSSION In this work, we study the symmetry in the 2D path-planning problem, and build a framework using the theory of steerable CNNs to prove that value iteration in path planning is actually a form of steer- able CNN (on 2D grids). Motivated by our theory, we proposed two symmetric planning algorithms that provided significant empirical improvements in several path-planning domains. Although our focus in this paper has been on Z2, our framework can potentially generalize to path planning on higher-dimensional or even continuous Euclidean spaces (Weiler et al., 2018; Brandstetter et al., 2021), by using equivariant operations on steerable feature fields (such as steerable convolutions, pooling, and point-wise non-linearities) from steerable CNNs. We hope that our SymPlan frame- work, along with the design of practical symmetric planning algorithms, can provide a new pathway for integrating symmetry into differentiable planning. 9 Published as a conference paper at ICLR 2023 8 ACKNOWLEDGEMENT This work was supported by NSF Grants #2107256 and #2134178. R. Walters is supported by The Roux Institute and the Harold Alfond Foundation. We also thank the audience from previous poster and talk presentations for helpful discussions and anonymous reviewers for useful feedback. 9 REPRODUCIBILITY STATEMENT We provide additional details in the appendix. We also plan to open source the codebase. We briefly outline the appendix below. 1. Additional Discussion 2. Background: Technical background and concepts on steerable CNNs and group CNNs 3. Method: we provide full details on how to reproduce it 4. Theory/Framework: we provide the complete version of the theory statements 5. Proofs: this includes all proofs 6. Experiment / Environment / Implementation details: useful details for reproducibility 7. Additional results 10 Published as a conference paper at ICLR 2023",1836
1751,Artificial Intelligence,Lawson Wong,"June 8th, 2022",Integrating Symmetry into Differentiable Planning with Steerable Convolutions,https://openreview.net/pdf?id=n7CPzMPKQl," Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2023). Integrating Symmetry into Differentiable Planning with Steerable Convolutions ICLR. https://openreview.net/pdf?id=n7CPzMPKQl","In this paper, we study a principled approach on incorporating group symme- try into end-to-end differentiable planning algorithms and explore the benefits of symmetry in planning. To achieve this, we draw inspiration from equivariant con- volution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant op- erator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navi- gation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2- DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN. 1, SymVIN and SymGPPN generalize better to different map sizes, com- pared to all non-equivariant baselines. Remark. In summary, our results show that the Sym- Plan models demonstrate end-to-end planning and learn- ing ability, potentially enabling further applications to other tasks as a differentiable component for planning. Additional results and ablation studies are in Appendix H. 7 DISCUSSION In this work, we study the symmetry in the 2D path-planning problem, and build a framework using the theory of steerable CNNs to prove that value iteration in path planning is actually a form of steer- able CNN (on 2D grids). Motivated by our theory, we proposed two symmetric planning algorithms that provided significant empirical improvements in several path-planning domains. Although our focus in this paper has been on Z2, our framework can potentially generalize to path planning on higher-dimensional or even continuous Euclidean spaces (Weiler et al., 2018; Brandstetter et al., 2021), by using equivariant operations on steerable feature fields (such as steerable convolutions, pooling, and point-wise non-linearities) from steerable CNNs. We hope that our SymPlan frame- work, along with the design of practical symmetric planning algorithms, can provide a new pathway for integrating symmetry into differentiable planning. 9 Published as a conference paper at ICLR 2023 8 ACKNOWLEDGEMENT This work was supported by NSF Grants #2107256 and #2134178. R. Walters is supported by The Roux Institute and the Harold Alfond Foundation. We also thank the audience from previous poster and talk presentations for helpful discussions and anonymous reviewers for useful feedback. 9 REPRODUCIBILITY STATEMENT We provide additional details in the appendix. We also plan to open source the codebase. We briefly outline the appendix below. 1. Additional Discussion 2. Background: Technical background and concepts on steerable CNNs and group CNNs 3. Method: we provide full details on how to reproduce it 4. Theory/Framework: we provide the complete version of the theory statements 5. Proofs: this includes all proofs 6. Experiment / Environment / Implementation details: useful details for reproducibility 7. Additional results 10 Published as a conference paper at ICLR 2023",1837
1752,Computational Biology,Benjamin Gyori,"November 7th, 2023","A simple standard for ontological mappings 2023: updates on data model, collaborations and tooling",https://ceur-ws.org/Vol-3591/om2023_STpaper3.pdf," Nicolas Matentzoglu, Ian Braun, Anita R. Caron, Damien Goutte-Gattat, Benjamin M. Gyori, Nomi L. Harris, Emily Hartley, Harshad B. Hegde, Sven Hertling, Charles Tapley Hoyt, Hyeongsik Kim , Huanyu Li , James A. McLaughlin, C√°ssia Trojahn, Nicole A. Vasilevsky, Christopher J. Mungall. (2023). A simple standard for ontological mappings 2023: updates on data model, collaborations and tooling OM@ISWC, 73-78. https://ceur-ws.org/Vol-3591/om2023_STpaper3.pdf","The Simple Standard for Ontological Mappings (SSSOM) was first published in December 2021 (v. 0.9). After a number of revisions prompted by community feedback, we have published version 0.15.0 in July 2023. Here we report on the progress made since August 2022, in particular changes to tooling, data model and summary of ongoing standardisation efforts. Keywords standards, mappings, ontologies, ontology mapping, FAIR data1s Compared to the last update a year ago, changes to the SSSOM standard are getting fewer, which means that the metadata model is finally stabilising. Our intention is to launch version 1.0 by the year‚Äôs end. Efforts have shifted notably to community engagement and collaboration, and expansion of SSSOM related tooling. The main aspiration of the data and terminology mapping community should be to share well defined semantic mappings in completely open Mapping Commons, and support domain experts to curate better, semantically meaningful mappings.",1838
1753,Computer Science Education,Felix Muzny,"February 1st, 2021",Integrating Ethics into Introductory Programming Classes,https://cmci.colorado.edu/~cafi5706/SIGCSE2021_IntegratingEthics.pdf," Casey Fiesler, Mikhaila Friske, Natalie Garrett, Felix Muzny, Jessie J. Smith, Jason Zietz. 2021. Integrating Ethics into Introductory Programming Classes. In Proceedings of the ACM SIGCSE Technical Symposium on Computer Science Education, Toronto, Canada.","Increasing attention to the role of ethical consideration in com- puting has led to calls for greater integration of this critical topic into technical classes rather than siloed in standalone computing ethics classes. The motivation for such integration is not only to support in-situ learning, but also to emphasize to students that ethical consideration is inherently part of the technical practice of computing. We propose that the logical place to begin emphasiz- ing ethics is on day one of computing education: in introductory programming classes. This paper presents one approach to ethics integration into such classes: assignments that teach basic program- ming concepts (e.g., conditionals or iteration) but are contextualized with real-world ethical dilemmas or concepts. We report on experi- ences with this approach in multiple introductory programming courses, including details about select assignments, insights from instructors and teaching assistants, and results from surveys of a subset of students who took these courses. Based on these experi- ences we provide preliminary plans for future work, along with a roadmap for instructors to emulate our approach and suggestions for overcoming challenges they might face. CCS CONCEPTS ‚Ä¢ Social and professional topics ‚ÜíModel curricula. KEYWORDS ethics, introductory programming, CS1, social impact, assignments, university, undergraduate, content ACM Reference Format: Casey Fiesler, Mikhaila Friske, Natalie Garrett, Felix Muzny, Jessie J. Smith, and Jason Zietz. 202Nearly 25 years ago an NSF working group suggested integration of an ethics and social impact ‚Äútenth strand‚Äù throughout computer science core courses [19]. In recent years, large-scale projects like EmbeddedEthiCS [11] and the Responsible Computer Science Chal- lenge [23], as well as individual models such as ethics integration into HCI classes [30] or machine learning [24], have shown more movement towards this goal. As universities grapple with how best to handle the increasing demand for computer scientists with expertise in ethically wrought fields such as artificial intelligence [10], our hope is that touching on ethics early and often, starting with introductory programming, can have a profound impact on the perception of ethics as part of ‚Äúdoing computer science.‚Äù 9",1839
1754,Cybersecurity and Privacy,Engin Kirda,"August 11th, 2016","UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware",https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_kharraz.pdf," A. Kharraz, S. Arshad, C. Mulliner, W. Robertson, E. Kirda. ""UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware"". In USENIX Security Symposium Austin, TX US, Aug 2016.","Although the concept of ransomware is not new (s In this paper we presented UNVEIL, a novel approach to detecting and analyzing ransomware. Our system is the first in the literature to specifically identify typical behavior of ransomware such as malicious encryption of files and locking of user desktops. These are behaviors that are difficult for ransomware to hide or change. The evaluation of UNVEIL shows that our approach was able to correctly detect 13,637 ransomware samples from multiple families in a real-world data feed with zero false positives. In fact, UNVEIL outperformed all ex- isting AV scanners and a modern industrial sandboxing technology in detecting both superficial and technically sophisticated ransomware attacks. Among our findings was also a new ransomware family that no security com- pany had previously detected before we submitted it to VirusTotal. 9",1840
1755,Cybersecurity and Privacy,Alan Mislove,"May 24th, 2018",Privacy Risks with Facebook‚Äôs PII-based Targeting: Auditing a Data Broker‚Äôs Advertising Interface,https://mislove.org/publications/PII-Oakland.pdf," G. Venkatadri et al., ""Privacy Risks with Facebook's PII-Based Targeting: Auditing a Data Broker's Advertising Interface,"" 2018 IEEE Symposium on Security and Privacy (SP), San Francisco, CA, 2018, pp. 89-107.","‚ÄîSites like Facebook and Google now serve as de facto data brokers, aggregating data on users for the purpose of implementing powerful advertising platforms. Historically, these services allowed advertisers to select which users see their ads via targeting attributes. Recently, most advertising platforms have begun allowing advertisers to target users directly by uploading the personal information of the users who they wish to advertise to (e.g., their names, email addresses, phone numbers, etc.); these services are often known as custom audiences. Custom audiences effectively represent powerful linking mechanisms, allowing advertisers to leverage any PII (e.g., from customer data, public records, etc.) to target users. In this paper, we focus on Facebook‚Äôs custom audience implementation and demonstrate attacks that allow an adversary to exploit the interface to infer users‚Äô PII as well as to infer their activity. SpeciÔ¨Åcally, we show how the adversary can infer users‚Äô full phone numbers knowing just their email address, determine whether a particular user visited a website, and de-anonymize all the visitors to a website by inferring their phone numbers en masse. These attacks can be conducted without any interaction with the victim(s), cannot be detected by the victim(s), and do not require the adversary to spend money or actually place an ad. We propose a simple and effective Ô¨Åx to the attacks based on reworking the way Facebook de-duplicates uploaded information. Facebook‚Äôs security team acknowledged the vulnerability and has put into place a Ô¨Åx that is a variant of the Ô¨Åx we propose. Overall, our results indicate that advertising platforms need to carefully consider the privacy implications of their interfaces.The vast amounts of user data that social networking services have collected is now utilized by their advertising platforms to allow advertisers to target users via their PII. In this paper, we have shown how the inclusion of PII-based targeting opens up new privacy leaks in advertising platforms. By giving advertisers Ô¨Åne-grained control over the set of users targeted, and by providing them with coarse-grained statistics of audience sizes, the platforms open themselves to powerful attacks that can let an adversary learn private information about users. While we have proposed a solution to the attacks we uncovered, our work shows that platforms need to carefully audit their interfaces when introducing PII-based targeting.",1841
1756,Cybersecurity and Privacy,William Robertson,"August 16th, 2016",Tracing Information Flows Between Ad Exchanges Using Retargeted Ads,https://cbw.sh/static/pdf/bashir-usenix16.pdf," Muhammad Ahmad Bashir, Sajjad Arshad, William Robertson, Christo Wilson. ""Tracing Information Flows Between Ad Exchanges Using Retargeted Ads"". In Proceedings of Usenix Security. Austin, TX, August, 2016.","Numerous surveys have shown that Web users are con- cerned about the loss of privacy associated with online tracking. Alarmingly, these surveys also reveal that peo- ple are also unaware of the amount of data sharing that occurs between ad exchanges, and thus underestimate the privacy risks associated with online tracking. In reality, the modern ad ecosystem is fueled by a Ô¨Çow of user data between trackers and ad exchanges. Al- though recent work has shown that ad exchanges rou- tinely perform cookie matching with other exchanges, these studies are based on brittle heuristics that cannot detect all forms of information sharing, especially under adversarial conditions. In this study, we develop a methodology that is able to detect client- and server-side Ô¨Çows of information be- tween arbitrary ad exchanges. Our key insight is to lever- age retargeted ads as a tool for identifying information Ô¨Çows. Intuitively, our methodology works because it re- lies on the semantics of how exchanges serve ads, rather than focusing on speciÔ¨Åc cookie matching mechanisms. Using crawled data on 35,448 ad impressions, we show that our methodology can successfully categorize four different kinds of information sharing behavior between ad exchanges, including cases where existing heuristic methods fail. We conclude with a discussion of how our Ô¨Åndings and methodologies can be leveraged to give users more control over what kind of ads they see and how their in- formation is shared between ad exchanges. 1s or recommendations expressed in this mate- rial are those of the authors and do not necessarily reÔ¨Çect the views of the NSF.",1842
1757,Cybersecurity and Privacy,William Robertson,"August 11th, 2016","UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware",https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_kharraz.pdf," A. Kharraz, S. Arshad, C. Mulliner, W. Robertson, E. Kirda. ""UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware"". In USENIX Security Symposium Austin, TX US, Aug 2016.","Although the concept of ransomware is not new (s In this paper we presented UNVEIL, a novel approach to detecting and analyzing ransomware. Our system is the first in the literature to specifically identify typical behavior of ransomware such as malicious encryption of files and locking of user desktops. These are behaviors that are difficult for ransomware to hide or change. The evaluation of UNVEIL shows that our approach was able to correctly detect 13,637 ransomware samples from multiple families in a real-world data feed with zero false positives. In fact, UNVEIL outperformed all ex- isting AV scanners and a modern industrial sandboxing technology in detecting both superficial and technically sophisticated ransomware attacks. Among our findings was also a new ransomware family that no security com- pany had previously detected before we submitted it to VirusTotal. 9",1843
1758,Data Management,Mirek Riedewald,"May 1st, 2023",Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals,https://www.vldb.org/pvldb/vol16/p2377-chen.pdf," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2023). Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals Proc. VLDB Endow., 16, 2377-2390. https://www.vldb.org/pvldb/vol16/p2377-chen.pdf","This work considers why-not questions in the context of top-k queries and score-based ranking functions. Following the popular linear scalarization approach for multi-objective optimization, we study rankings based on the weighted sum of multiple scores. A given weight choice may be controversial or perceived as unfair to certain individuals or organizations, triggering the question why some entity of interest has not yet shown up in the top-k. We introduce various notions of such why-not-yet queries and for- mally define them as satisfiability or optimization problems, whose goal is to propose alternative ranking functions that address the placement of the entities of interest. While some why-not-yet prob- lems have linear constraints, others require quantifiers, disjunction, and negation. We propose several optimizations, ranging from a monotonic-core construction that approximates the complex con- straints with a conjunction of linear ones, to various techniques that let the user control the tradeoff between running time and approximation quality. Experiments with real and synthetic data demonstrate the practicality and scalability of our technique, show- ing its superiority compared to the state of the art (SOA). PVLDB Reference Format: Zixuan Chen, Panagiotis Manolios, and Mirek Riedewald. Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals. PVLDB, 16(9): 2377 - 2390, 2023. doi:10.14778/359858We propose the first general exact solution for problems SAT, BEST, and POINT. Adopting sampling approaches from related work can only provide approximate answers or results in infeasible running time for BEST. In general, sampling becomes ineffective when only a small fraction of the space of possible weight vectors ranks the expected tuples among the top-ùëò. For BOX, we propose the first known solution. To make it practical and scalable, we propose the notion of a monotonic core. Our clustering approach enables the user to improve running time for all problems as desired by controlling the number of clusters, with moderate loss in result quality even for large data. Interesting avenues for future work are computing a compact description of the entire set of weight vectors that rank the expected tuples among the top-ùëòand generalizing the approach to noisy and unreliable data.",1844
1759,Data Management,Mirek Riedewald,"January 1st, 2021","Beyond Equi-joins: Ranking, Enumeration and Factorization",http://www.vldb.org/pvldb/vol14/p2599-tziavelis.pdf," Nikolaos Tziavelis, Wolfgang Gatterbauer, Mirek Riedewald. (2021). Beyond Equi-joins: Ranking, Enumeration and Factorization Proc. VLDB Endow., 14, 2599-2612. http://www.vldb.org/pvldb/vol14/p2599-tziavelis.pdf","We study theta-joins in general and join predicates with conjunc- tions and disjunctions of inequalities in particular, focusing on ranked enumeration where the answers are returned incrementally in an order dictated by a given ranking function. Our approach achieves strong time and space complexity properties: with ùëõdenot- ing the number of tuples in the database, we guarantee for acyclic full join queries with inequality conditions that for every value of ùëò, the ùëòtop-ranked answers are returned in O(ùëõpolylogùëõ+ ùëòlogùëò) time. This is within a polylogarithmic factor of O(ùëõ+ ùëòlogùëò),S AND FUTURE WORK Theta- and inequality-joins of multiple relations are generally con- sidered ‚Äúhard‚Äù and even state-of-the-art commercial DBMSs strug- gle with their efficient computation. We developed the first ranked- enumeration techniques that achieve non-trivial worst-case guar- antees for a large class of these joins: For small ùëò, returning the ùëò top-ranked join answers for full acyclic queries takes only slightly- more-than-linear time and space (O(ùëõpolylogùëõ)) for any DNF of inequality predicates. For general theta-joins, time and space com- plexity are quadratic in input size. These are strong worst-case guar- antees, close to the lower time bound of O(ùëõ) and much lower than the O(ùëõ‚Ñì) size of intermediate or final results traditional join algo- rithms may have to deal with. Our results apply to many cyclic joins (modulo higher pre-processing cost depending on query width) and all acyclic joins, even those with selections and many types of pro- jections. In the future, we will study parallel computation and more general cyclic joins and projections.",1845
1760,Data Science,Albert-L√°szl√≥ Barab√°si,"September 8th, 2020",3D Topology Transformation with Generative Adversarial Networks,http://computationalcreativity.net/iccc20/papers/052-iccc20.pdf," Luca Stornaiuolo, Nima Dehmamy, Albert-L√°szl√≥ Barab√°si, Mauro Martino. (2020). 3D Topology Transformation with Generative Adversarial Networks ICCC, 461-468. http://computationalcreativity.net/iccc20/papers/052-iccc20.pdf","Generation and transformation of images and videos using artiÔ¨Åcial intelligence have Ô¨Çourished over the past few years. Yet, there are only a few works aim- ing to produce creative 3D shapes, such as sculptures. Here we show a novel 3D-to-3D topology transfor- mation method using Generative Adversarial Networks (GAN). We use a modiÔ¨Åed pix2pix GAN, which we call Vox2Vox, to transform the volumetric style of a 3D ob- ject while retaining the original object shape. In par- ticular, we show how to transform 3D models into two new volumetric topologies - the 3D Network and the Ghirigoro. We describe how to use our approach to con- struct customized 3D representations. We believe that the generated 3D shapes are novel and inspirational. Fi- nally, we compare the results between our approach and a baseline algorithm that directly convert the 3D shapes, without using our GAN.and Future Direction In this paper, we presented a novel 3D-to-3D topology trans- fer paradigm based on transformations in 3D space. In particular, we built a 3D conditional GAN, Vox2Vox, that performs volumetric transformations to modify the internal structure of any 3D object, while maintaining its overall shape. We described our complete pipeline to apply our ap- proach to two different topologies: the 3D Network and the Ghirigoro. The results obtained by employing our method- ology are novel and inspirational. We compared the out- puts of the pipeline while using or not the 3D-cGAN and found that using the Vox2Vox output as a prior distribution results in much nicer outcomes where features are placed in strategic positions in the 3D shape preserving its struc- tural features. As a future direction, we plan to improve the 3D-to-3D topology transfer by given also the topology as a conditional input of the generative network. To do that, the machine learning algorithm has to learn itself the abstraction of the topology from a given 3D object.",1846
1761,Data Science,Mirek Riedewald,"May 1st, 2023",Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals,https://www.vldb.org/pvldb/vol16/p2377-chen.pdf," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2023). Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals Proc. VLDB Endow., 16, 2377-2390. https://www.vldb.org/pvldb/vol16/p2377-chen.pdf","This work considers why-not questions in the context of top-k queries and score-based ranking functions. Following the popular linear scalarization approach for multi-objective optimization, we study rankings based on the weighted sum of multiple scores. A given weight choice may be controversial or perceived as unfair to certain individuals or organizations, triggering the question why some entity of interest has not yet shown up in the top-k. We introduce various notions of such why-not-yet queries and for- mally define them as satisfiability or optimization problems, whose goal is to propose alternative ranking functions that address the placement of the entities of interest. While some why-not-yet prob- lems have linear constraints, others require quantifiers, disjunction, and negation. We propose several optimizations, ranging from a monotonic-core construction that approximates the complex con- straints with a conjunction of linear ones, to various techniques that let the user control the tradeoff between running time and approximation quality. Experiments with real and synthetic data demonstrate the practicality and scalability of our technique, show- ing its superiority compared to the state of the art (SOA). PVLDB Reference Format: Zixuan Chen, Panagiotis Manolios, and Mirek Riedewald. Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals. PVLDB, 16(9): 2377 - 2390, 2023. doi:10.14778/359858We propose the first general exact solution for problems SAT, BEST, and POINT. Adopting sampling approaches from related work can only provide approximate answers or results in infeasible running time for BEST. In general, sampling becomes ineffective when only a small fraction of the space of possible weight vectors ranks the expected tuples among the top-ùëò. For BOX, we propose the first known solution. To make it practical and scalable, we propose the notion of a monotonic core. Our clustering approach enables the user to improve running time for all problems as desired by controlling the number of clusters, with moderate loss in result quality even for large data. Interesting avenues for future work are computing a compact description of the entire set of weight vectors that rank the expected tuples among the top-ùëòand generalizing the approach to noisy and unreliable data.",1847
1762,Data Science,Mirek Riedewald,"January 1st, 2021","Beyond Equi-joins: Ranking, Enumeration and Factorization",http://www.vldb.org/pvldb/vol14/p2599-tziavelis.pdf," Nikolaos Tziavelis, Wolfgang Gatterbauer, Mirek Riedewald. (2021). Beyond Equi-joins: Ranking, Enumeration and Factorization Proc. VLDB Endow., 14, 2599-2612. http://www.vldb.org/pvldb/vol14/p2599-tziavelis.pdf","We study theta-joins in general and join predicates with conjunc- tions and disjunctions of inequalities in particular, focusing on ranked enumeration where the answers are returned incrementally in an order dictated by a given ranking function. Our approach achieves strong time and space complexity properties: with ùëõdenot- ing the number of tuples in the database, we guarantee for acyclic full join queries with inequality conditions that for every value of ùëò, the ùëòtop-ranked answers are returned in O(ùëõpolylogùëõ+ ùëòlogùëò) time. This is within a polylogarithmic factor of O(ùëõ+ ùëòlogùëò),S AND FUTURE WORK Theta- and inequality-joins of multiple relations are generally con- sidered ‚Äúhard‚Äù and even state-of-the-art commercial DBMSs strug- gle with their efficient computation. We developed the first ranked- enumeration techniques that achieve non-trivial worst-case guar- antees for a large class of these joins: For small ùëò, returning the ùëò top-ranked join answers for full acyclic queries takes only slightly- more-than-linear time and space (O(ùëõpolylogùëõ)) for any DNF of inequality predicates. For general theta-joins, time and space com- plexity are quadratic in input size. These are strong worst-case guar- antees, close to the lower time bound of O(ùëõ) and much lower than the O(ùëõ‚Ñì) size of intermediate or final results traditional join algo- rithms may have to deal with. Our results apply to many cyclic joins (modulo higher pre-processing cost depending on query width) and all acyclic joins, even those with selections and many types of pro- jections. In the future, we will study parallel computation and more general cyclic joins and projections.",1848
1763,Formal Methods,Gene Cooperman,"June 1st, 2019",MANA for MPI: MPI-Agnostic Network-Agnostic Transparent Checkpointing,http://www.ccs.neu.edu/home/gene/papers/hpdc19.pdf," ""MANA for MPI: MPI-Agnostic Network-Agnostic Transparent Checkpointing"", Rohan Garg, Gregory Price, and Gene Cooperman, Proc. of 28th Int. Symp. on High Performance Parallel and Distributed Computing, Phoenix, AZ, USA, ACM, pp.¬†49--60, June, 2019","Transparently checkpointing MPI for fault tolerance and load bal- ancing is a long-standing problem in HPC. The problem has been complicated by the need to provide checkpoint-restart services for all combinations of an MPI implementation over all network interconnects. This work presents MANA (MPI-Agnostic Network- Agnostic transparent checkpointing), a single code base which sup- ports all MPI implementation and interconnect combinations. The agnostic properties imply that one can checkpoint an MPI appli- cation under one MPI implementation and perhaps over TCP, and then restart under a second MPI implementation over InfiniBand on a cluster with a different number of CPU cores per node. This tech- nique is based on a novel split-process approach, which enables two separate programs to co-exist within a single process with a single address space. This work overcomes the limitations of the two most widely adopted transparent checkpointing solutions, BLCR and DMTCP/InfiniBand, which require separate modifications to each MPI implementation and/or underlying network AP2 MANA: DESIGN AND IMPLEMENTATION Multiple aspects of the design of MANA are covered in this sec- tion. Section 2.1 discusses the design for supporting a split-process. Section 2.2 discusses the need to save and restore persistent MPI opaque objects, such as communicators, groups and topologies. Section 2.3 briefly discusses the commonly used algorithm to drain point-to-point MPI messages in transit prior to intiaiting a check- point. Sections 2.4 and 2.5 present a new two-phase algorithm (Algorithm 2), which enables checkpointing in-progress MPI collec- tive communication calls in a fully agnostic environment. Finally, Sections 2.6 and 2.7 present details of the overall implementation of MANA. 2.1 Upper and Lower Half: Checkpointing with an Ephemeral MPI Library In this section, we define the lower half of a split-process as the memory associated with the MPI library and dependencies, includ- ing network libraries. The upper half is the remaining Linux process memory associated with the MPI application‚Äôs code, data, stack, and other regions (e.g., environment variables). The terms lower half and upper half are in analogy with the upper and lower half of a device driver in an operating system kernel. This separation into lower and upper half does not involve additional threads or processes. Instead, it serves primarily to tag memory so that only upper half memory will be saved or restored during checkpoint and restart. Section 2.6 describes an additional ‚Äúhelper thread‚Äù, but that thread is active only during checkpoint and restart. Libc and other system libraries may appear in both the lower half as a dependency of the MPI libraries, and the upper half as an independent dependency of the MPI application. This split-process approach allows MANA to balance two con- flicting objectives: a shared address space; and isolation of upper and lower halves. The isolation allows MANA to omit the lower half memory (an ‚Äúephemeral‚Äù MPI library) when it creates a checkpoint image file. The shared address space allows the flow of control to pass efficiently from the upper-half MPI application to the lower- half MPI library through standard C/Fortran calling conventions, including call by reference. As previously noted, Remote Produce Calls (RPC) are not employed. Isolation is needed so that at checkpoint time, the lower half can be omitted from the checkpoint image, and at the time of restart, replaced with a small ‚Äúbootstrap‚Äù MPI program with new MPI li- braries. The bootstrap program calls MPI_Init() and each MPI process discovers its MPI rank via a call to MPI_Rank(). The mem- ory present at this time becomes the lower half. The MPI process then restores the upper-half memory from a checkpoint image file corresponding to the MPI rank id. Control is then transferred back to the upper-half MPI application, and the stack in the lower half is never used again. Shared address space is needed for efficiency. A dual-process proxy approach was explored in [16, Section IV.B] and in [35, Sec- tion IV.A]. The former work reported a 6% runtime overhead for real-world CUDA applications, and the latter work reported run- time overheads in excess of 20% for some OpenCL examples from the NVIDIA SDK 3.0. In contrast, Section 3 reports runtime over- heads less than 2% for MANA under older Linux kernels, and less than 1% runtime overhead for recent Linux kernels. Discarding the lower half greatly simplifies the task of check- pointing. By discarding the lower half, the MPI application in the upper half appears as an isolated process with no inter-process communication. Therefore, a single-process checkpointing package can create a checkpoint image. A minor inconvenience of this split-process approach is that calls to sbrk() will cause the kernel to extend the process heap in the data segment. Calls to sbrk() can be caused by invocations of malloc(). Since the kernel has no concept of a split-process, the kernel may choose, for example, to extend the lower half data segment after restart since that corresponds to the original program seen by the kernel before the upper-half memory is restored. MANA resolves this by interposing on calls to sbrk() in the upper-half libc, and then inserts calls to mmap() to extend the heap of the upper-half. Finally, MANA employs coordinated checkpointing, and a check- point coordinator sends messages to each MPI rank at the time of checkpoint (see Sections 2.3, 2.4 and 2.5). MPI opaque objects (communicators, groups, topologies) are detected on creation and restored on restart (see Section 2.2). This is part of a broader strat- egy by which MPI calls with persistent effects (such as creation of these opaque objects) are recorded during runtime and replayed on restart. 2.2 Checkpointing MPI Communicators, Groups, and Topologies An MPI application can create communication subgroups and topolo- gies to group processes for ease of programmability and efficient communication. MPI implementations provide opaque handles to the application as a reference to a communicator object or group. MANA interposes on all calls that refer to these opaque identi- fiers, and virtualizes the identifiers. At runtime, MANA records any MPI calls that can modify the MPI communication state, such as MPI_Comm_create, MPI_Group_incl, etc. On restart, MANA recre- ates the MPI communicator state by replaying the MPI calls using a new MPI library. The runtime virtualization of identifiers allows the application to continue running with consistent handles across checkpoint-restart. A similar checkpointing strategy also works for other opaque identifiers, such as, MPI derived datatypes, etc. 2.3 Checkpointing MPI Point-to-Point Communication Capturing the state of MPI processes requires quiescing the process threads, and preserving the process memory to a file on the disk. However, this alone is not sufficient to capture a consistent state of the computation. Any MPI messages sent but not yet received at the time of quiescing processes must also be saved as part of the checkpoint image. MANA employs a variation of an all-to-all bookmark exchange algorithm to reach this consistent state. LAM/MPI [31] demon- strated the efficacy of a such a Chandy/Lamport [11] algorithm for checkpointing MPI applications. Hursey et al. [22] lifted this mechanism out of interconnect drivers and into the MPI library. MANA further lifts this mechanism outside the MPI library, and into a virtualized MPI API. An early prototype of MANA demonstrated a na√Øve application of this bookmark exchange algorithm was sufficient for handling pre-checkpoint draining for point-to-point communication; how- ever, collective-communication calls may have MPI implementation effects that can determine when it is ‚Äúsafe‚Äù to begin a checkpoint. For this reason, a na√Øve application to the entire API was insufficient to ensure correctness. This is discussed in Section 2.4. 2.4 Checkpointing MPI Collectives: Overview The MPI collective communications primitive involves communi- cation amongst all or a program-defined subset of MPI ranks (as specified by the MPI communicator argument to the function). The internal behavior of collectives are specific to each MPI implemen- tation, and so it is not possible to make guarantees about their behavior, such as when and how messages are exchanged when ranks are waiting for one or more ranks to enter the collective. In prior work [22, 31], internal knowledge of the MPI library state was required to ensure that checkpointing would occur at a ‚Äúsafe‚Äù state. In particular, Hursey et al. [22] required interconnect drivers be classified as ‚Äúcheckpoint-friendly‚Äù or ‚Äúcheckpoint-unfriendly‚Äù, changing behavior based on this classification. As MANA lives outside the MPI library, a naive application of the Hursey et al. algorithm can have effects that cross the upper and lower half boundaries of an MPI rank (for example, when shared memory is being used for MPI communication). This problem occurs because of the truly network-agnostic trait of MANA. As MANA has no concept of transport level constructs, it cannot determine what ‚Äúsafe‚Äù means in context of collectives. To correct this, MANA‚Äôs support for collective communication requires it to maintain the following invariant: No checkpoint must take place while a rank is inside a collective communication call. There exists one exception to this rule: a trivial barrier. A trivial barrier is a simple call to MPI_Barrier(). This call produces no side effects on an MPI rank, and so it can be safely interrupted during checkpoint, and then re-issued when restarting the MPI application. This is possible due to the split-process architecture of MANA, as trivial barrier calls occur exclusively in the lower half, which is discarded and replaced across checkpoint and restart. MANA leverages this exception to build a solution for all other collective calls. As we discuss MANA‚Äôs algorithm for checkpointing collective calls, we take into consideration three subtle, but important, con- cerns. Challenge I (consistency): In the case of a single MPI collec- tive communication call, there is a danger that rank A will see a request to checkpoint before entering the collective call, while rank B will see the same request after entering the collective call, in violation of MANA‚Äôs invariant. Both ranks might report that they are ready to checkpoint, and the resulting inconsistent snapshot will create problems during restart. This situation could arise, for example, if the mes- sage from the checkpoint coordinator to rank B is excessively delayed in the network. To resolve this, MANA introduces a two-pass protocol in which the coordinator makes a re- quest (sends an intend-to-checkpoint message), each MPI rank acknowledges with its current state, and finally the coordinator posts a checkpoint request (possibly preceded by extra iterations). Challenge II (progress and latency): Given the aforementioned solution for consistency, long delays may occur before a checkpoint request can be serviced. It may be that rank A has entered the barrier, and rank B will require several hours to finish a task before entering the barrier. Hence, the two-pass protocol may create unacceptable delays before a checkpoint can be taken. Algorithm 2 addresses this by introducing a trivial barrier prior to the collective communication call. We refer to this as a two-phase algorithm since each collective call is now replaced by a wrapper function that invokes a trivial barrier call (phase 1) followed by the original collective call (phase 2). Challenge III (multiple collective calls): Until now, it was assumed that at most one MPI collective communication call was in progress at the time of checkpoint. It may happen that there are multiple ongoing collective calls. During the time that some MPI ranks exit from a collective call, it may happen that MPI ranks associated with an independent col- lective call have left the MPI trivial barrier (phase 1) and have now entered the real collective call (phase 2). As a result, servicing a checkpoint may be excessive delayed. To solve this, we introduce an intend-to-checkpoint message, such that no ranks will be allowed to enter phase 2, and extra itera- tions will be inserted into the request-acknowledge protocol between coordinator and MPI rank. 2.5 Checkpointing MPI Collectives: Detailed Algorithm Here we present a single algorithm (Algorithm 2) for checkpointing MPI collectives which contains the elements described in Section 2.4: a multi-iteration protocol; and a two-phase algorithm incorporating a trivial barrier before any collective communication call. From the viewpoint of an MPI application, any call to an MPI collective communication function is interposed on by a wrapper function, as shown in Algorithm 1. Algorithm 1 Two-Phase collective communication wrapper. (This wrapper function interposes on all MPI collective com- munication functions invoked by an MPI application) 1: function Collective Communication Wrapper 2: # Begin Phase 1 3: Call MPI_Barrier() # trivial barrier 4: # Begin Phase 2 5: Call original MPI collective communication function 6: end function Recall that a trivial barrier is an extra call to MPI_Barrier() prior to a collective call. A collective MPI call can intuitively be divided into two parts: the participating MPI ranks ‚Äúregister‚Äù themselves as ready for the collective communication; and then the ‚Äúwork‚Äù of communication is carried out. Where the time for the collective communication calls of an MPI program is significant, it is typically due to significant ‚Äúwork‚Äù in the second part of the calls. Adding a trivial barrier requires the MPI ranks to register themselves once for the trvial barrier (but no work is involved), and then register themselves again for the actual MPI collective communication. The overhead due to registering twice is tiny in practice. Evidence for this can be seen in the experiments in Section 3.2.3, which show small overhead. The purpose of Algorithm 1 is to enforce the following extension of the invariant presented in Section 2.4: No checkpoint must take place while a rank is inside the collective communication call (Phase 2) of a wrapper function for collective communication (Algorithm 1). We formalize this with the following theorem, which guarantees Algorithm 2 satisfies this invariant. Theorem 1. Under Algorithm 2, an MPI rank is never inside a collective communication call when a checkpoint message is received from the checkpoint coordinator. The proof of this theorem is deferred until the end of this sub- section. We begin the path to this proof by stating an axiom that serves to define the concept of a barrier. Axiom 1. For a given invocation of an MPI barrier, it never happens that a rank A exits from the barrier before another rank B enters the barrier under the ‚Äúhappens-before‚Äù relation. Next, we present the following two lemmas. Checkpoint Coordinator Rank A Rank B Barrier (1) (3) (2) (4) Figure 1: Fundamental ‚Äúhappens-before‚Äù relation in commu- nication between the checkpoint coordinator and the MPI ranks involved in an MPI barrier. Lemma 1. For a given MPI barrier, if the checkpoint coordinator sends a message to each MPI rank participating in the barrier, and if at least one of the reply messages from the participating ranks reports that its rank has exited the barrier, then the MPI coordinator can send a second message to each participating rank, and each MPI rank will reply that it has entered the barrier (and perhaps also exited the barrier). Proof. We prove the lemma by contradiction. Suppose that the lemma does not hold. Figure 1 shows the general case in which this happens. At event 4, the checkpoint coordinator will conclude that event 1 (rank A has exited the MPI barrier) happened before event 2 (the first reply by each rank), which happened before event 3 (in which rank B has not yet entered the barrier). But this contradicts Axiom 1. Therefore, our assumption is false, and the lemma does indeed hold. ‚ñ° Lemma 2. Recall that an MPI collective communication wrapper makes a call to a trivial barrier and then makes an MPI collective communication call. For a given invocation of an MPI collective com- munication wrapper, we know that one of four cases must hold: (a) an MPI rank is in the collective communication call, and all other ranks are either in the call, or have exited; (b) an MPI rank is in the collective communication call, and no rank has exited, and every other rank has at least entered the trivial barrier (and possibly proceeded further); (c) an MPI rank is in the trivial barrier and no other rank has exited (but some may not yet have entered the trivial barrier); (d) either no MPI rank has entered the trivial barrier, or all MPI ranks have exited the MPI collective communication call. Proof. The proof is by repeated application of Lemma 1. For case a, if an MPI rank is in the collective communication call and another rank has exited the collective call, then Lemma 1 says that there cannot be any rank that has not yet entered the collective call. For case b, note that if an MPI rank is in the collective communi- cation call, then that rank has exited the trivial barrier. Therefore, by Lemma 1, all other ranks have at least entered the trivial barrier. Further, we can assume that no ranks that have exited the collec- tive call, since we would otherwise be in case a, which is already accounted for. For case c, note that if an MPI rank is in the trivial barrier and no rank has exited the trivial barrier, then Lemma 1 says that there cannot be any rank that has not yet entered the trivial barrier. Finally, if we are not in case a, b, or c, then the only remaining possibility is case d: all ranks have not yet entered the trivial barrier or all ranks have exited the collective call. ‚ñ° Algorithm 2 Two-Phase algorithm for deadlock-free check- pointing of MPI collectives 1: Messages: {intend-to-checkpoint, extra-iteration, do-ckpt} 2: MPI states: {ready, in-phase-1, exit-phase-2} 3: Process Checkpoint Coordinator do 4: function Begin Checkpoint 5: send intend-to-ckpt msg to all ranks 6: receive responses from each rank 7: while some rank in state exit-phase-2 do 8: send extra-iteration msg to all ranks 9: receive responses from each rank 10: end while 11: send do-ckpt msg to all ranks 12: end function 13: Process MPI Rank do 14: upon event intend-to-ckpt msg or extra-iteration msg do 15: if not inCollectiveWrapper then 16: reply to ckpt coord: state ‚Üêready 17: end if 18: if inCollectiveWrapper and in Phase 1 then 19: reply to ckpt coord: state ‚Üêin-phase-1 20: end if 21: if inCollectiveWrapper and in Phase 2 then 22: # guaranteed ckpt coord won‚Äôt request ckpt here 23: finish executing coll. comm. call 24: reply to ckpt coord: state ‚Üêexit-phase-2 25: # ckpt coord can request ckpt after this 26: set state ‚Üêready 27: end if 28: continue, but wait before next coll. comm. call 29: upon event do-ckpt msg do 30: # guaranteed now that no rank is in phase 2 during ckpt 31: do local checkpoint for this rank 32: # all ranks may now continue executing 33: if this rank is waiting before coll. comm. call then 34: unblock this rank and continue executing 35: end if We now continue with the proof of the main theorem (Theo- rem 1), which was deferred earlier. Proof. (Proof of Theorem 1 for Algorithm 2.) Lemma 2 states that one of four cases must hold in a call by MANA to an MPI collective communication wrapper. We wish to exclude the possibility that an MPI rank is in the collective communication call (case a or b of the lemma) when the checkpoint coordinator invokes a checkpoint. In Algorithm 2, assume that the checkpoint coordinator has sent an intend-to-ckpt message, and has not yet sent a do-ckpt message. An MPI rank will either reply with state ready or in-phase-1 (show- ing that it is not in the collective communication call and that it will stop before entering the collective communication call), or else it must be in Phase 2 of the wrapper (potentially within the collective communication call), and it will not reply to the coordinator until exiting the collective call. ‚ñ° Theorem 2. Under Algorithm 2, deadlock will never occur. Further, the delay between the time when all ranks have received the intend- to-checkpoint message and the time when the do-ckpt message has been sent is bounded by the maximum time for any individual MPI rank to enter and exit the collective communication call, plus network message latency. Proof. The algorithm will never deadlock, since each rank must either make progress based on the normal MPI operation or else it stops before the collective communication call. If any rank replies with the state exit-phase-2, then the checkpoint coordinator will send an additional extra-iteration message. So, at the time of check- point, all ranks will have state ready or in-phase-1. Next, the delay between the time when all ranks have received the intend-to-checkpoint message and the time when the do-ckpt message has been sent is clearly bounded by the maximum time for an individual MPI rank to enter and exit the collective commu- nication call, plus the usual network message latency. This is the case since once the intend-to-checkpoint message is received, no MPI rank may enter the collective communication call. So, upon re- ceiving the intend-to-checkpoint message, either the rank is already in Phase 2 or else it will remain in Phase 1. ‚ñ° Implementation of Algorithm 2: At the time of process launch for an MPI rank, a separate checkpoint helper thread is also in- jected into each rank. This thread is responsible for listening to checkpoint-related messages from a separate coordinator process and then responding. This allows the MPI rank to asynchronously process events based on messages received from the checkpoint coordinator. Furthermore at the time of checkpoint, the existing threads of the MPI rank process are quiesced (paused) by the helper thread, and the helper thread carries out the checkpointing require- ments, such as copying the upper-half memory regions to stable storage. The coordinator process does not participate in the check- pointing directly. In the implementation, a DMTCP coordinator and DMTCP checkpoint thread [1] are modified to serve as checkpoint coordinator and helper thread, respectively. 2.6 Verification with TLA+/PlusCal To gain further confidence in our implementation for handling collective communication (Section 2.5), we developed a model for the protocol in TLA+ [25] and then used the PlusCal model checker of TLA+ based on TLC [38] to verify Algorithm 2. Specifically, PlusCal was used to verify the algorithm invariants of deadlock- free execution and consistent state when multiple concurrent MPI processes are executing. The PlusCal model checker did not report any deadlocks or broken invariants for our implementation. 2.7 Checkpoint/Restart Package Any single-process checkpointing package could be utilized for the basis of implementing MANA. This work presents a prototype implemented by extending DMTCP [1] and by developing a DMTCP plugin [2]. Cao et al. [9] demonstrated that DMTCP can checkpoint MPI-based HPCG over 32,752 CPU cores (38 TB) in 11 minutes, and MPI-based NAMD over 16,368 cores (10 TB) in 2.6 minutes. DMTCP uses a helper thread inside each application process, and a coordinated checkpointing protocol by using a centralized coor- dinator daemon. Since this was close to the design requirements of MANA, we leveraged this infrastructure and extended the DMTCP coordinator to implement the two-phase algorithm. The same approach could be extended to base MANA on top of a different underlying transparent checkpointing package. For example, one could equally well have modified an existing MPI co- ordinator process to communicate with a custom helper thread in each MPI rank that then invokes the BLCR checkpointing package when it is required to execute the checkpoint. In particular, all sock- ets and other network communication objects are inside the lower half, and so even a single-process or single-host checkpointing package such as BLCR would suffice for this work. 3 EXPERIMENTAL EVALUATION This section seeks to answer the following questions: Q1: What is the runtime overhead of running MPI applications under MANA? Q2: What are the checkpoint and restart overheads of transparent checkpointing of MPI applications under MANA? Q3: Can MANA allow transparent switching of MPI implementa- tions across checkpoint-restart for the purpose of load balancing? 3.1 Setup We first describe the hardware and software setup for MANA‚Äôs evaluation. 3.1.1 Hardware. The experiments were run on the Cori supercom- puter [13] at the National Energy Research Scientific Computing Center (NERSC). As of this writing, Cori is the #12 supercomputer in the Top-500 list [36]. All experiments used the Intel Haswell nodes (dual socket with a 16-core Xeon E5-2698 v3 each) connected via Cray‚Äôs Aries interconnect network. Checkpoints were saved to the backend Lustre filesystem. 3.1.2 Software. Cori provides modules for two implementations of MPI: Intel MPI and Cray MPICH. The Cray compiler (based on an Intel compiler) and Cray MPICH are the recommended way to use MPI, presumably for reasons of performance. Cray MPICH version 3.0 was used for the experiments. 3.1.3 Application Benchmarks. MANA was tested with five real- world HPC applications from different computational science do- mains: (1) GROMACS [4]: Versatile package for molecular dynamics, often used for biochemical molecules. (2) CLAMR [12, 29]: Mini-application for CelL-based Adaptive Mesh Refinement. 90 95 100 Normalized Performance (%) GROMACS miniFE HPCG CLAMR LULESH 1 2 4 8 16 32 0 1 2 4 8 16 32 1 2 4 8 16 32 # MPI Rank(s) (Single node) 1 2 4 8 16 32 1 9 27 Figure 2: Single Node: Runtime overhead under MANA for different real-world HPC benchmarks with an unpatched Linux kernel. (Higher is better.) 90 95 100 Normalized Performance (%) GROMACS miniFE HPCG CLAMR LULESH 2 4 8 16 32 64 0 2 4 8 16 32 64 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) 2 4 8 16 32 64 2 4 8 16 32 64 Figure 3: Multiple Nodes: Runtime overhead under MANA for different real-world HPC benchmarks with an un- patched Linux kernel. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. (Higher is bet- ter.) (3) miniFE [20]: Proxy application for unstructured implicit fi- nite element codes. (4) LULESH [24]: Unstructured Lagrangian Explicit Shock Hy- drodynamics (5) HPCG [14] (High Performance Conjugate Gradient): Uses a variety of linear algebra operations to match a broad set of important HPC applications, and used for ranking HPC systems. 3.2 Runtime Overhead 3.2.1 Real-world HPC Applications. Next, we evaluate the perfor- mance of MANA for real-world HPC applications. It will be shown that the runtime overhead is close to 0 % for miniFE and HPCG, and as much as 2 % for the other three applications. The higher overhead has been tracked down to an inefficiency in the Linux ker- nel [27] in the case of many point-to-point MPI calls (send/receive) with messages of small size. This worst case is analyzed further in Section 3.3, where tests with an optimized Linux kernel show a worst case runtime overhead of 0.6 %. The optimized Linux kernel is based on a patch under review for a future Linux version. Single Node: Since the tests were performed within a larger clus- ter where the network use of other jobs could create congestion, we first eliminate any network-related overhead by running the benchmarks on a single node with multiple MPI ranks, both under 0 1000000 2000000 3000000 4000000 Size (Bytes) 0 5000 10000 15000 20000 Bandwidth (MB/s) Without MANA With MANA (native kernel) With MANA (patched kernel) Figure 4: Point-to-Point Bandwidth under MANA with patched and unpatched Linux kernel. (Higher is better.) MANA and natively (without MANA). This experiment isolates the single-node runtime overhead of MANA by ensuring that all communication among ranks is intra-node. Figure 2 shows the results for the five different real-world HPC applications running on a single node under MANA. Each run was repeated 5 times (including the native runs), and the figure shows the mean of the 5 runs. The absolute runtimes varied from 4.5 min to 15 min, depending on the configuration. The worst case overhead incurred by MANA is 2.1 % in the case of GROMACS (with 16 MPI ranks). In most cases, the mean overhead is less than 2 %. Multiple Nodes: Next, the scaling of MANA across the network is examined for up to 64 compute nodes and with 32 ranks per node (except for LULESH, whose configuration restricts the number of ranks/node based on the number of nodes). Hence, the number of MPI ranks ranges from 64 to 2048. Figure 3 shows the results of five different real-world HPC ap- plications running on multiple nodes under MANA. Each run was repeated 5 times, and the mean of 5 runs is reported. We observe a trend similar to the single node case. MANA imposes an overhead of typically less than 2 %. The highest overhead observed is 4.5 % in the case of GROMACS (512 ranks running over 16 nodes). However, see Section 3.3 where we demonstrate a reduced overhead of 0.6 % with GROMACS. 3.2.2 Memory Overhead. The upper-half libraries were built with mpicc, and hence include additional copies of the MPI library that are not used. However, the upper-half MPI library is never ini- tialized, and so no network library is ever loaded into the upper half. Since a significant portion of the lower half is comprised only of the MPI library and its dependencies, the additional copy of the libraries (with one copy residing in the upper half) imposes a constant memory overhead. This text segment (code region) was 26 MB in all of our experiments on Cori with the Cray MPI library. In addition to the code, the libraries (for example, the networking driver library) in the lower half also allocate additional memory regions (shared memory regions, pinned memory regions, memory- mapped driver regions). We observed that the shared memory re- gions mapped by the network driver library grow in proportion with the number of nodes (up to 64 nodes): from 2 MB (for 2 nodes) to 40 MB for (64 nodes). We expect MANA to have a reduced check- point time compared to DMTCP/InfiniBand [10], as MANA discards these regions during checkpointing, reducing the amount of data that‚Äôs written out to the disk. 0 1000000 2000000 3000000 4000000 Size (Bytes) 0 50 100 150 200 250 300 Latency (¬µs) Without MANA With MANA (a) Point-to-Point Latency 0 200000 400000 600000 800000 1000000 Size (Bytes) 0 50 100 150 200 250 300 Latency (¬µs) Without MANA With MANA (b) Collective MPI_Gather 0 200000 400000 600000 800000 1000000 Size (Bytes) 0 100 200 300 400 500 Latency (¬µs) Without MANA With MANA (c) Collective MPI_Allreduce Figure 5: OSU Micro-benchmarks under MANA. (Results are for two MPI ranks on a single node.) 3.2.3 Microbenchmarks. To dig deeper into the sources for the run- time overhead, we tested MANA with the OSU micro-benchmarks. The benchmarks stress and evaluate the bandwidth and latency of different specific MPI subsystems. Our choice of the specific micro-benchmarks was motivated by the MPI calls commonly used by our real-world MPI applications. Figure 5 shows the results with three benchmarks from the OSU micro-benchmark suite. These benchmarks correspond with the most frequently used MPI subsystems in the set of real-world HPC applications. The benchmarks were run with 2 MPI ranks running on a single compute node. The results show that latency does not suffer under MANA, for both point-to-point and collective communication. (The latency curves for application running under MANA closely follow the curves when the application is run natively.) 3.3 Source of Overhead and Improved Overhead for Patched Linux Kernel All experiments in this section were performed on a single node of our local cluster, where it was possible to directly install a patched Linux kernel in the bare machine. Further investigation revealed two sources of runtime overhead. The larger source of overhead is due to the use of the ‚ÄúFS‚Äù register during transfer of flow of control between the upper and lower half and back during a call to the MPI library in the lower half. The ‚ÄúFS‚Äù register of the x86-64 CPU is used by most compilers to refer to the thread-local variables declared in the source code. The upper and lower half programs each have their own thread-local storage region. Hence, when switching between the upper and lower half programs, the value of the ‚ÄúFS‚Äù register must be changed to point to the correct thread-local region. Most Linux kernels today require a kernel call to invoke a privileged assembly instruction to get or set the ‚ÄúFS‚Äù register. In 2011, Intel Ivy Bridge CPUs introduced a new, unprivileged FSGSBASE assembly instruction for modifying the ‚ÄúFS‚Äù register, and a patch to the Linux kernel [27] is under review to allow other Linux programs to use this more efficient mechanism for managing the ‚ÄúFS‚Äù register. (Other architectures, such as ARM, use unprivileged addressing modes for thread-local variables that do not depend on special constructs, such as the x86 segments.) A second (albeit smaller) source of overhead is the virtualization of MPI communicators and datatypes, and recording of metadata for MPI sends and receives. Virtualization requires a hash table lookup and locks for thread safety. The first and larger source of overhead is then eliminated by using the patched Linux kernel, as discussed above. Point-to-point bandwidth benchmarks were run both with and without the patched Linux kernel (Figure 4). A degradation in runtime performance is seen for MANA for small message sizes (less than 1 MB) in the case of a native kernel. However, the figure shows that the patched kernel yields much reduced runtime overhead for MANA. Note that the Linux kernel community is actively reviewing this patch (currently in its third version), and it is likely to be incorporated in future Linux releases. Finally, we return to GROMACS, since it exhibited a higher runtime overhead (e.g., 2.1 % in the case of 16 ranks) in many cases. We did a similar experiment, running GROMACS with 16 MPI ranks on a single node with the patched kernel. With the patched kernel, the performance degradation was reduced to 0.6 %. 3.4 Checkpoint-restart Overhead In this section, we evaluate MANA‚Äôs performance when checkpoint- ing and restarting HPC applications. Figure 6 shows the checkpoint- ing overhead for five different real-world HPC applications running on multiple nodes under MANA. Each run was repeated 5 times, and the mean of five runs is reported. For each run, we use the fsync system call to ensure the data is flushed to the Lustre backend storage. The total checkpointing data written at each checkpoint varies from 5.9 GB (in the case of 64 ranks of GROMACS running over 2 nodes) to 4 TB (in the case of 2048 ranks of HPCG running over 64 nodes). Note that the checkpointing overhead is proportional to the total amount of memory used by the benchmark. This is also reflected in the size of the checkpoint image per MPI rank. While Figure 6 reports the overall checkpoint time, note that there is significant variation in the write times for each MPI rank during a given run. (The time for one rank to write its checkpoint data can be up to 4 times more than that for 90 % of the other ranks.) This phenomenon of stragglers during a parallel write has also been noted by other researchers [2, 37]. Thus, the overall checkpoint time is bottlenecked by the checkpoint time of the slowest rank. Next, we ask what are the sources of the checkpointing overhead? Does the draining of MPI messages and the two-phase algorithm impose a significant overhead at checkpoint time? 2 4 8 16 32 64 1 5 10 15 20 25 30 35 40 Checkpoint Time (s) (93 MB) (93 MB) (92 MB) (92 MB) (94 MB) (92 MB) GROMACS 2 4 8 16 32 64 (2.0 GB) (1.3 GB) (806 MB) (1.3 GB) (902 MB) (1.3 GB) miniFE 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) HPCG 2 4 8 16 32 64 (656 MB) (594 MB) (552 MB) (501 MB) (594 MB) (552 MB) CLAMR 2 4 8 16 32 64 (276 MB) (164 MB) (114 MB) (91 MB) (85 MB) (88 MB) LULESH Figure 6: Checkpointing overhead and checkpoint image sizes under MANA for different real-world HPC bench- marks running on multiple nodes. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. For LULESH, the total number of ranks was either 64 (for 2, 4, and 8 nodes), or 512 (for 16, 32, and 64 nodes). Hence, the maximum number of ranks (for 64 nodes) was 2048. The numbers above the bars (in parentheses) indicate the check- point image size for each MPI rank. 2 4 8 16 32 64 1 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Restart Time (s) GROMACS 2 4 8 16 32 64 miniFE 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) HPCG 2 4 8 16 32 64 CLAMR 2 4 8 16 32 64 LULESH Figure 7: Restart overhead under MANA for different real- world HPC benchmarks running on multiple nodes. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. Ranks/node is as in Figure 6. Figure 8 shows the contribution of different components to the checkpointing overhead for the case of 64 nodes for the five different benchmarks. In all cases, the communication overhead for handling MPI collectives in the two-phase algorithm of Section 2.5 is found to be less than 1.6 s. In all cases, the time to drain in-flight MPI messages was less than 0.7 s. The total checkpoint time was dominated by the time to write to the storage system. The next big source of checkpointing GROMACS miniFE HPCG CLAMR LULESH Benchmark (64 nodes; 32 ranks/node, except LULESH) 0 20 40 60 80 100 Contribution to Checkpoint Time (%s) Write Time Drain Time Comm. overhead Figure 8: Contribution of different factors to the checkpoint- ing overhead under MANA for different real-world HPC benchmarks running on 64 nodes. Ranks/node is as in Fig- ure 6. The ‚Äúdrain time‚Äù is the delay in starting a checkpoint while MPI message in transit are completed. The communi- cation overhead is the time required in the protocol for net- work communication between the checkpoint coordinator and each rank. overhead was the communication overhead. The current imple- mentation of the checkpointing protocol in DMTCP uses TCP/IP sockets for communication between the MPI ranks and the central- ized DMTCP coordinator. The communication overhead associated with the TCP layer is found to increase with the number of ranks, especially due to metadata in the case of small messages that are exchanged between MPI ranks and the coordinator. Finally, Figure 7 shows the restart overhead under MANA for the different MPI benchmarks. The restart time varies from less than 10 s to 68 s (for 2048 ranks of HPCG running over 64 nodes). The restart times increase in proportion to the total amount of checkpointing data that is read from the storage. In all the cases, the restart overhead is dominated by the time to read the data from the disk. The time to recreate the MPI opaque identifiers (see Section 2.2) is less than 10 % of the total restart time. 3.5 Transparent Switching of MPI libraries across Checkpoint-restart This section demonstrates that MANA can transparently switch between different MPI implementations across checkpoint-restart. This is useful for debugging programs (even the MPI library) as it allows a program to switch from a production version of an MPI library to a debug version of the MPI library. The GROMACS application is launched using the production version of CRAY MPI, and a checkpoint is taken 55 s into the run. The computation is then restarted on top of a custom-compiled debug version of MPICH (for MPICH version 3.3). MPICH was chosen because it is a reference implementation whose simplicity makes it easy to instrument for debugging. 3.6 Transparent Migration across Clusters Next, we consider cross-cluster migration for purposes of wide- area load balancing either among clusters at a single HPC site or even among multiple HPC sites. This is rarely done, since the two common vehicles for transparent checkpoint (BLCR as the base of 190 200 210 220 Runtime (s) Native Restarted (migrated from Cori) Open MPI/IB (2x4) MPICH/TCP (2x4) MPICH (8x1) Restart Configuration 0 Figure 9: Performance degradation of GROMACS after cross- cluster migration under three different restart configura- tions. The application was restarted after being check- pointed at the half-way mark on Cori. (Lower is better.) an MPI-specific checkpoint-restart service; or DMTCP/InfiniBand) both save the MPI library within the checkpoint image and continue to use that same MPI library on the remote cluster after migration. At each site and for each cluster, administrators typically configure and tune a locally recommended MPI implementation for perfor- mance. Migrating an MPI application along with its underlying MPI library destroys the benefit of this local performance tuning. This experiment showcases the benefits of MPI-agnostic, network- agnostic support for transparent checkpointing. GROMACS is run under MANA, initially running on Cori with a statically linked Cray MPI library running over the Cray Aries network. GROMACS on Cori is configured to run with 8 ranks over 4 nodes (2 ranks per node). Each GROMACS rank is single-threaded. A checkpoint was then taken exactly half way into the run. The checkpoints were then migrated to a local cluster that uses Open MPI over the InfiniBand network. The restarted GROMACS under MANA was compared with three other configurations: GROMACS using the local Open MPI, con- figured to use the local InfiniBand network (8 ranks over 2 nodes); GROMACS/MPICH, configured to use TCP (8 ranks over 2 nodes); and GROMACS/MPICH, running on a single node (8 ranks over 1 node). The network-agnostic nature of MANA allowed the Cori version of GROMACS to be restarted on the local cluster with any of three network options. We wished to isolate the effects due to MANA from the effects due to different compilers on Cori and the local cluster. In order to accomplish this, the native GROMACS on the local cluster was com- piled specially. The Cray compiler of Cori (using Intel‚Äôs C compiler) was used to generate object files (.o files) on Cori. Those object files were copied to the local cluster. The native GROMACS was then built using the local mpicc, but with the (.o files) as input instead of the (.c files). The local mpicc linked these files with the local MPI implementation, and the native application was then launched in the traditional way. Figure 9 shows that GROMACS‚Äôs performance degrades by less than 1.8% post restart on the local cluster for the three different restart configurations (compared to the corresponding native runs). Also, note that the performance of GROMACS under MANA post restart closely tracks the performance of the native configuration. 4 DISCUSSION AND FUTURE WORK Next, we discuss both the limitations and some future implications of this work concerning dynamic load balancing. 4.1 Limitations While the split-process approach for checkpointing and process migration is quite flexible, it does include some limitations inherited by any approach based on transparent checkpointing. Naturally, when restarting on a different architecture, the CPU instruction set must be compatible. In particular, on the x86 architecture, the MPI application code must be compiled to the oldest x86 sub-architecture among those remote clusters where one might consider restarting a checkpoint image. (However, the MPI libraries themselves may be fully optimized for the local architecture, since restarting on a remote cluster implies using a new lower half.) Similarly, while MPI implies a standard API, any local extensions to MPI must be avoided. The application binary interface (ABI) used by the compiled MPI application must either be compatible or else a ‚Äúshim‚Äù layer of code must be inserted in the wrapper functions for calling from the upper half to the lower half. And of course, the use of a checkpoint coordinator implies coor- dinated checkpointing. If a single MPI rank crashes, MANA must restore the entire MPI computation from an earlier checkpoint. 4.2 Future Work MPI version 3 has added nonblocking collective communication calls (e.g., MPI_Igather). In future work, we propose to extend the two-phase algorithm for collective communication of Section 2.5 to the nonblocking case. The approach to be explored would be to employ a first phase that uses a nonblocking trivial barrier (MPI_Ibarrier), and to then convert the actual asynchronous col- lective call to a synchronous collective call (e.g., MPI_Gather to MPI_Igather) for the second phase. Nonblocking variations of col- lective communication calls are typically used as performance op- timizations in an MPI application. If an MPI rank reaches the col- lective communication early, then instead of blocking, it can con- tinue with an alternate compute task while occasionally testing (via MPI_Test/MPI_Wait) to see if the other ranks have all reached the barrier. In the two-phase analog, a wrapper around the nonblocking collective communication causes MPI_Ibarrier to be invoked. When the ranks have all reached the nonblocking trivial barrier and the MPI_Test/MPI_Wait calls of the original MPI application reports completion of the MPI_Ibarrier call of phase 1, then this implies that the ranks are all ready to enter the actual collective call of phase 2. A wrapper around MPI_Test/MPI_Wait can then invoke the actual collective call of phase 2. The split-process approach of MANA opens up some impor- tant new features in managing long-running MPI applications. An immediately obvious feature is the possibility of switching in the middle of a long run to a customized MPI implementation. Hence, one can dynamically substitute a customized MPI for performance analysis (e.g., using PMPI for profiling or tracing); or using a spe- cially compiled ‚Äúdebug‚Äù version of MPI to analyze a particular but occurring in the MPI library in the middle of a long run. This work also helps support many tools and proposals for opti- mizing MPI applications. For example, a trace analyzer is sometimes used to discover communication hotspots and opportunities for bet- ter load balancing. Such results are then fed back by re-configuring the binding of MPI ranks to specific hosts in order to better fit the underlying interconnect topology. MANA can enable new approaches to dynamically load balance across clusters and also to re-bind MPI ranks in the middle of a long run to create new configurations of rank-to-host bindings (new topology mappings). Currently, such bindings are chosen statically and used for the entire lifetime of the MPI application run. This added flexibility allows system managers to burst current long- running applications into the Cloud during periods of heavy usage or when the the MPI application enters a new phase for which a different rank-to-host binding is optimal. Finally, MANA can enable a new class of very long-running MPI applications ‚Äî ones which may outlive the lifespan of the original MPI Implementation, cluster, or even the network interconnect. Such temporally complex computations might be discarded as in- feasible today without the ability to migrate MPI implementations or clusters. 5 RELATED WORK Hursey et al. [22] developed a semi-network-agnostic checkpoint service for Open-MPI. It applied an ‚ÄúMPI Message‚Äù abstraction to a Chandy/Lamport algorithm [11], greatly reducing the complexity to support checkpoint/restart for many multiple network intercon- nects. However, it also highlighted the weakness of implementing transparent checkpointing within the MPI library, since porting to an additional MPI implementation would likely require as much software development as for the first MPI implementation. Addi- tionally, its dependence on BLCR imposed a large overhead cost, as it lacks support for SysV shared memory. Separate proxy processes for high- and low-level operations have been proposed both by CRUM (for CUDA) and McKernel (for the Linux kernel). CRUM [16] showed that by running a non-reentrant library in a separate process, one can work around the problem of a library ‚Äúpolluting‚Äù the address space of the application process ‚Äî i.e., creating and leaving side-effects in the application process‚Äôs address space. This decomposition of a single application process into two processes, however, forces the transfer of data between two processes via RPC, which can cause a large overhead. McKernel [17] runs a ‚Äúlightweight‚Äù kernel along with a full- fledged Linux kernel. The HPC application runs on the lightweight kernel, which implements time-critical system calls. The rest of the functionality is offloaded to a proxy process running on the Linux kernel. The proxy process is mapped in the address space of the main application, similar to MANA‚Äôs concept of a lower half, to min- imize the overhead of ‚Äúcall forwarding‚Äù (argument marshalling/un- marshalling). In general, a proxy process approach is problematic for MPI, since it can lead to additional jitter as the operating system tries to schedule the extra proxy process alongside the application pro- cess. The jitter harms performance since the MPI computation is constrained to complete no faster than its slowest MPI rank. Process-in-process [21] has in common with MANA that both approaches load multiple programs into a single address space. However, the goal of process-in-process was intra-node communi- cation optimization, and not checkpoint-restart. Process-in-process loads all MPI ranks co-located on the same node as separate threads within a single process, but in different logical ‚Äúnamespaces‚Äù, in the sense of the dlmopen namespaces in Linux. It would be diffi- cult to adapt process-in-process for use in checkpoint-restart since that approach implies a single ‚Äúld.so‚Äù run-time linker library that managed all of the MPI ranks. In particular, difficulties occur when restarting with fresh MPI libraries while ‚Äúld.so‚Äù retains pointers to destructor functions in the pre-checkpoint MPI libraries. In the special regime of application-specific checkpointing for bulk synchronous MPI applications, Sultana et al. [33] supported checkpointing by separately saving and restoring MPI state (MPI identifiers such as communicators, and so on). This is combined with application-specific code to save the application state. Thus, when a live process fails, it is restored using these two components, without the need restart the overall MPI job. SCR [32], and FTI [3] are other application-specific checkpoint- ing techniques. An application developer declares memory regions they‚Äôd like to checkpoint and checkpointing can only be done at specific points in the program determined by the application devel- oper. Combining these techniques with transparent checkpointing is outside the scope of this work, though it is an interesting avenue for further inquiry. In general, application-specific and transparent checkpointing each have their merits. Both application-specific and transparent checkpointing are used in practice. At the high end of HPC, application-specific checkpointing is preferred since the labor for supporting this is small compared to the labor already invested in supporting an extreme HPC application. At the low and medium end of HPC, developers prefer trans- parent checkpointing because the development effort for the soft- ware is more moderate, and the labor overhead of a specialized application-specific checkpointing solution would then be signif- icant. System architectures based on burst buffers (e.g., Cray‚Äôs DataWarp [19]) can be used to reduce the checkpointing overhead for both application-specific and transparent checkpointing. 6 CONCLUSION This work presents an MPI-Agnostic, Network-Agnostic transpar- ent checkpointing methodology for MPI (MANA), based on a split- process mechanism. The runtime overhead is typically less than 2%, even in spite of the overhead incurred by the current Linux ker- nel when the ‚ÄúFS‚Äù register is modified each time control passes between upper and lower half. Further, Section 3.3 shows that a commit (patch) to fix this by the Linux kernel developers is un- der review and that this commit reduces the runtime overhead of GROMACS from 2.1% to 0.6% using the patched kernel. Similar reductions to about 0.6% runtime overhead are expected in the general case. An additional major novelty is the demonstration of practical, efficient migration between clusters at different sites using differ- ent networks and different configurations of CPU cores per node. This was considered impractical in the past because a checkpoint image from one cluster will not be tuned for optimal performance on the second cluster. Section 3.6 demonstrates that this is now feasible, and that the migration of a GROMACS job with 8 MPI ranks experiences an average runtime overhead of less than 1.8% as compared to the native GROMACS application (without MANA) on the remote cluster. As before, even this overhead of 1.8% is likely to be reduced to about 0.6% in the future, based on the results of Section 3.3 with a patched Linux kernel.",1849
1764,Formal Methods,Gene Cooperman,"March 15th, 2018",Transparently Checkpointing Software Test Benches to Improve Productivity of SoC Verification in an Emulation Environment,http://www.ccs.neu.edu/home/gene/papers/dvcon-us-18.pdf," ""Transparently Checkpointing Software Test Benches to Improve Productivity of SoC Verification in an Emulation Environment"", Ankit Garg, Suresh Krishnamurthy, Gene Cooperman, Rohan Garg, and Jeff Evans, <em>2018 Design and Verification Conference and Exhibition</em> (DVCON-US 2018)","Traditionally hardware emulation has been used in in-circuit emulation (ICE) mode where the design under test (DUT) executes inside the emulator and connected to the real target, which acts as a testbench. Over time, the software testbench-based emulation environments have become very popular, since the users can control its operation remotely from their desktops. This makes emulators an enterprise resource, accessible to a multitude of users spread across continents and multiple time zones. And since emulators are expensive resources, it is important to utilize them efficiently. Full checkpoint save/restore capability of emulation jobs helps the utilization by enabling flexible job scheduling, shortening of jobs by jumping ahead to interesting points for debug, carrying out what-if analysis, etc. Emulators have native save/restore capabilities for the model on the emulator. The software testbenches can be complex in multiple dimensions. For example, they may be using C/C++, SystemC, SystemVerilog, etc. They may be multi- threaded and based on multiple processes, they may be using IPC, and so on. It then becomes a challenge to save the states of such sophisticated software testbenches both transparently and through a uniform, reliable, mechanism. Since the objective is to solve the problem at an enterprise level, it is critical to find a uniform solution for a diverse set of software testbenches throughout the enterprise. The DMTCP (Distributed MultiThreaded Checkpointing) package supports such a uniform solution. This paper describes the integration of DMTCP with a virtual testbench-based emulation. This brings large benefits to a real life environment that includes multiple emulators within the larger set of enterprise resources. There are other, additional applications of full checkpoint save/restore for emulation jobs that become apparent only after having gained experience with its use in job management. For example, after having observed the behavior of an application prior to checkpoint, additional triggers can be inserted at the time of restore, to enhance debugging of an exception or other unusual behavior.s. II. BACKGROUND: CO-MODELING AND DMTCP A. Review of Co-Modeling Architecture Co-emulation, or (transaction-level) Co-Modeling, is the process of modeling cycle-accurate synthesizable hardware models (DUTs) running on an emulator, communicating with testbenches at transaction level via a high- speed link between the emulator and the host system. The reusable testbenches are interfaced to synthesizable transactors co-located with the DUT in the emulator. These ‚Äúaccelerated‚Äù transactors convert high-level transactions to signal-level stimuli to drive the DUT. During an emulation run, the hardware communicates with the software testbench using a high-speed link. For every DUT clock or for each time point in the model execution, communication may be required by one or more synthesizable transactors. In the general case, the DUT clocks will be suspended at times to complete all the communication requests for a given point in the model execution. So at any point of time, there could be inflight data in the link. Figure 1. Co-Modeling Architecture B. Review of DMTCP flow DMTCP is an open-source package that provides a capability for Checkpoint/Restart in applications involving multiple processes/threads distributed across multiple hosts and connected by socket connections. The package can be downloaded from: http://dmtcp.sourceforge.net It operates under Linux, with no modifications to the Linux kernel or to the user code, and it can be used by unprivileged users (no root privilege needed). One can later restart from a checkpoint, or even migrate the processes by moving the checkpoint files to another host prior to restarting. Figure 2 shows the typical flow of a user job under DMTCP. Figure 2. Typical flow of a user job under DMTCP A detailed description on DMTCP (Distributed MultiThreaded Checkpointing) internals can be found in [1]. DMTCP also provides a flexible plugin model that supports the ability to write an add-on library that can: support DMTCP event hooks; add custom wrappers around system calls; and add a custom distributed name service facility [2, 3]. III. MOTIVATING USE CASES Checkpoint-restore of emulation jobs opens a wide of range of applications, which will help users build a fault- tolerant emulation system, powerful debug mechanisms, and increase usage efficiency of critical resources like hardware emulators. This section describes different use cases for such capability in emulation. The following section, Section IV, then presents the Checkpoint/Restore Framework in detail. A. Skipping repeated initial sequences Designs may have an initialization phase that is always executed for each test. This may be a hardware reset phase or boot-up, which takes a great deal of time before an actual test can start. We can save much of the emulation runtime by taking a checkpoint right after this repeated initial sequence. New tests can then just restart immediately after this initial sequence, thus saving a great deal of regression time. Another application of this is to do what-if analysis after reaching an interesting point in the execution. In Figure 3, each test Test0, Test1, Test2 executes the same initial sequence, which takes C1 time. Figure 3. Job Progress with fixed initialization sequence The tests then follow their own unique paths, completing the test in different time intervals (T0, T1, and T2). This C1 time is saved if we checkpoint just after completion of the initial sequence and then restore from the checkpoint at the original state in each test. B. Better Job Management Policies One of the advantages of virtualization of test environments is the ability to use emulators remotely. This allows emulation to be moved to the data center, with jobs being managed by a workload management platform such as LSF. However, the non-pre-emptive nature of emulation jobs forbids pre-emptive scheduling policies. This prevents a high-priority job from acquiring the resources occupied by a currently executing low-priority job. For example, a currently running long job cannot be removed even though a short job has just arrived. The short job has to wait until the long job exits and frees up the resources. Hence, the non-pre-emptive nature of emulation jobs can easily lead to inefficient use of emulators. Consider the scenario depicted in Figure 4: Figure 4. Job Management Job1 occupies 4 slots on Emulator1 and Job2 occupies 2 slots on Emulator2. Further a high-priority request from Job3 arrives for 6 resources. As resources are fragmented, irrespective of its priority, Job3 has to wait for either of Job1 or Job2 to finish. The Checkpoint/Restore capability can remove this shortcoming and enable a pre-emptive scheduling policy. We could have checkpointed either of Job1 or Job2 and freed up the resources for Job3. Whenever resources become available, the checkpointed job can then be restarted using the DMTCP restart scripts. Further, this situation also leads to inefficient use of emulators due to resource fragmentation within each emulator. Using Checkpoint/Restore we could have migrated an interfering job to a different emulator, thereby making contiguous resources available for the new job. In Figure 5, the checkpoint of Job2 is taken first, and then Job2 is restarted on Emulator1. This frees up all 6 slots on Emulator2 for Job3. Job3 can now be allocated using contiguous resources on Emulator2. Figure 5. Resource free with Job Migration Another interesting example concerns the issue of ‚Äúfairness‚Äù for large-capacity jobs. In a distribution system dominated by high-priority, small-capacity jobs, a low-priority large-capacity job may never actually get a chance to run if the policy is to wait for required slots to become available. Further, a high-priority long job can lead to underutilization of emulation resources as freed slots cannot be allocated for other small jobs if they have to be pooled for a high-priority long job waiting in the queue. With checkpoint-restart, one can save all the small jobs at once, run the large job and then restart the small jobs. A long low-priority job might otherwise never get an opportunity to complete, if not for the use of checkpoint-restart. There are several such instances where checkpoint- restart can offer this kind of flexibility in an emulation job scheduling system. C. Debugging from past simulation time Debugging is an important requirement for verification engineers. Much time is spent in debugging functional issues in design as well as integration issues with software during validation of a full SoC. The ability to take a checkpoint of the full system can provide capabilities to start debugging just before an issue occurs, by restarting from the point of a previous checkpoint state. For example, one can take periodic checkpoints and when a problem is seen: start from the last checkpoint, run again and capture more debug information. This is a tremendous advantage when a debugging issue occurs only after a run of long duration. A large amount of time is saved, since one no longer needs to wait for the test to arrive at the point of interest. IV. CHECKPOINT/RESTORE FRAMEWORK In this section we describe the implementation of checkpoint-restore for emulation jobs. We address checkpoint and restore separately. Figure 6 shows the typical flow of an emulation job under DMTCP. Note that in Figure 2, the checkpoint was invoked by the user at an arbitrary point in time. However, in the emulation flow (Figure 6), the user invokes the checkpoint programmatically from within the user code, when the simulation reaches certain number of cycles. Figure 6. Typical flow of an emulation job under DMTCP. A. Checkpoint Checkpointing of emulation jobs involves both the emulator and the testbench on the workstation. One must save the simulation state for the design running on an emulator, while also employing binary-level checkpointing using DMTCP for the processes representing the testbench side and running on the workstation. As always, we have to make sure that the hardware side stops generating further transactions when a checkpoint is in progress. In addition, checkpointing requires that we make sure that there is no in-flight data inside the high-speed interface between the emulator and the testbench at the time of checkpointing. In the case that a checkpoint is taken without flushing the in-flight data, those transactions will be lost at the time of restoring from the checkpoint, thus resulting both in incorrect hardware state and incorrect state on the testbench side. Figure 7. Flowchart for Checkpoint Algorithm The following is the integrated algorithm for checkpointing of an emulation job. These steps are also depicted graphically in Figure 7. 1) A Checkpoint Request is received by the testbench either through an external utility such as dmtcp_command or through a user-exposed API, ScheduleCheckpoint, made by testbench itself. The request is sent to the emulator in order to freeze the running design. This will stop both the user design clocks and the simulation time itself. 2) Once a design is frozen, additional transactions from the hardware side will no longer be generated. At this point the data in flight inside the link is flushed until all of them have been processed and the emulator reaches a quiescent state. 3) When the emulator has reached a quiescent state, the system initiates the checkpoint of the emulator model by using the checkpoint technology native to the emulator. This will store the current design state to disk. 4) The system then disconnects from the emulator and makes sure that all emulator-related processes are terminated. This step will ensure that any external connections not running under DMTCP are removed from consideration. For example, there may be connections to a licensing server, to some waveform dump servers, and so on. This also reduces the overall checkpoint time by freeing up memory used by these external connections that the binary checkpointing procedure would otherwise have to save, as described in the next step. Further, checkpoints taken this way are independent of which specific emulator the session was running on, and this makes it easy to relocate saved emulation jobs to other emulators. 5) Next, the system initiates DMTCP-based checkpointing on the testbench side. This involves calling dmtcp_checkpoint, a part of the DMTCP API. Here, one writes an emulation-specific external plugin for DMTCP, which will specify which files must be checkpointed. The DMTCP plugin is specific to the emulator and testbench infrastructure, and must also specify the path to the checkpoint database, where DMTCP checkpoint image files are saved alongside the hardware database, as a consolidated database within the user specified path. . DMTCP also allows a user to have certain processes be explicitly excluded from checkpointing. This might be required for the case where processes have been spawned from an external library linked into the user testbench. Those processes are not required as part of a correct checkpoint state. And further, attempting to save such superfluous processes leads to other issues when restoring from a checkpoint if those processes were communicating with external processes that were not running under DMTCP. The details of DMTCP external plugins can be found in [2, 3]. 6) After the invocation of dmtcp_checkpoint returns, we can choose either to exit the current emulation or to resume the current run. 7) After resuming from a checkpoint, the following steps are taken: ‚óè Re-connect to same emulator and configure the same design again. ‚óè Restart the tool-specific processes and re-connect to servers from which they exited in step (4). This step is isolated to the emulation tool‚Äôs internal workings, and does not require the collaboration of DMTCP. ‚óè Perform a hardware design restore from the same checkpoint database and start the design clocks. ‚óè Note that after being restored from a checkpoint, the testbench side resumes in a correct state at the end of this procedure, and so nothing more is required on the testbench side. B. Restore/Restart The DMTCP package dumps a restart script at the time of checkpoint. This script takes care of restarting the entire testbench tree of processes. This script also takes care of restarting processes that were on remote machines. After restart, the system will ‚Äúwake up‚Äù in step (6) in the checkpoint sequence above, as if we have just returned from the call to dmtcp_checkpoint. So the remaining steps to restart are the same as those described in step (7) above. Figure 8. Flowchart for Restore The following is the algorithm for the restart/resume. These steps are also depicted graphically in Figure 8. 1) Use the restart script generated by DMTCP that relies on the checkpoint database (the checkpoint image files) in order to bring the whole testbench tree of processes up and running. 2) After DMTCP‚Äôs restore/restart, we return from the call to dmtcp_checkpoint. The next steps bring the HDL side up and fork any tool-specific processes. 3) The system then re-connects the emulator resource and downloads the design. 4) The system then restarts the tool-specific processes and re-connects to external servers such as license servers, waveform collection servers, etc. This step is completely isolated from the internal workings of the emulator tool. 5) The system then performs the hardware design restore using the same checkpoint database, and it starts the design clocks. This is the last step in successfully restoring the emulation. V. CASE STUDY: SKIPPING THE OS BOOT IN AN OEM COMPANY‚ÄôS SOC VALIDATION ENVIRONMENT For this case study, the SoC validation environment instantiates a SoC containing a CPU, Memory Subsystem, Switching Fabric, and peripherals. The SoC is modeled in a hybrid environment whereby part of the SoC is modeled on the workstation and part of the SoC is modeled in the emulator, and the Switching Fabric is the bridge between the models. Many of the SoC validation use cases require firstly booting an operating system (OS) in order to run the applications that are being validated. The boot of the OS takes on the order of hours to days. Often the applications that are being validated execute in a fraction of the time that it takes to boot the OS. This means that only a fraction of the emulation time was used to validate the application and the larger portion of the time is spent booting the OS in order to be able to run the application. Thus the overall boot time has an important impact not only on how many applications can be run per user per day, but also, from an emulation efficiency standpoint, how much emulation time is spent just getting the OS booted versus running the applications that are used to validate the SoC and/or the application. The ideal scenario would be to eliminate the time it takes to boot the OS. A solution close to the ideal scenario is to checkpoint the SoC validation environment after the boot of the OS. This OS boot can then be delivered as part of a checkpoint image that is bundled with the rest of the SoC validation environment. The checkpoint of the hardware can be taken by technology native to the emulator. The complexity is in the checkpointing of the part of the SoC validation environment that is executing on the workstation. There were two early attempts to checkpoint, before settling on DMTCP as the preferred solution. A first attempt at checkpointing, prior to the use of DMTCP, was to capture all of the stimulus from the hardware during the OS boot along with a checkpoint of the hardware, and then to restore the OS boot using the stimulus. This stimulus was replayed into the software test bench to re-establish the state of the software, and then finally restore the state of the emulator using the hardware checkpoint. This method worked, except it had two notable drawbacks: (1) Depending on how much stimulus needed to be captured, the size of the replay database could become quite large. (2) The time it took the software testbench to execute, controlled the time it took to perform the restoration of the software testbench. A second attempt at checkpointing prior to employing DMTCP was to leverage the Boost C++ libraries to make each of the software components of the SoC validation environment checkpoint-able. This method worked except that it had a major drawback in that each SoC validation software component had to be developed with checkpointing in mind and if there was just one component that didn¬πt support checkpointing or did the checkpointing incorrectly, the SoC validation environment was not checkpoint-able. Hence, the ideal solution would be to transparently checkpoint the software in the same way as we checkpoint the hardware. The DMTCP-based approach was able to overcome the limitations of these first two attempts by transparently checkpointing the software on the workstation, which includes the part of the SoC modeled on the workstation, the software testbench, and the emulation software. The checkpoint is taken without concern for how the software has been modeled and also without concern for the speed at which the software testbench executes. This resulted in making an ‚ÄúOS boot‚Äù checkpoint available to the users along with the SoC verification environment. This allows those users to restore the checkpoint in less than 5 minutes, and to then to run their applications for SoC validation in an environment after the OS boot. Now, users requiring this use case can focus their emulation time on running their application, and skipping the lengthy OS boot time. The DMTCP-based approach has accelerated the time to run an application by close to a factor of two. Additionally, it has freed up the emulation time that would have been spent in ‚ÄúOS boot‚Äù, thus saving many hours of emulation time. In addition, the DMTCP approach also saves the state of the emulation runtime software itself. This feature provides added value, as compared to the two earlier checkpointing approaches. The checkpoint-restore flow can now set up to address additional aspects of the emulation runtime environment, such as triggers, which are important for debugging in the case of an exception. This enables the designer to create an environment closer to a ‚Äúturnkey solution‚Äù, in which the end user no longer has to remember to load the trigger prior to starting the run of their application. First use case of DMTCP at an OEM company was on a regression suite consisting of 40 jobs. The 40 jobs had a similar profile in that they required around 1 hour to boot the OS and then 1 hour of execution of test content. DMTCP was used to create a checkpoint just after the boot of the OS. This checkpoint then becomes part of the collateral of that database. Any future user of that database and software configuration can restore the checkpoint rather than re-running the boot of the OS. The restoration of database using the checkpoint takes around 5 minutes. That is a time savings of 55 minutes per job for this regression. As a reminder, this environment is a hybrid environment and pending the configuration of whether the CPU is in software or RTL and also the type of OS can greatly impact the ""OS boot"" time from an hour to days. For this regression the 40 jobs were able to run in around 22 hours versus previously they would have taken 40 hour. Job throughput was increased close to 2x. This results not only in a substantial time savings but also a substantial cost savings. Figure 9. Regression Suite Emulation Time Comparison Figure 9 is highlighting the changes introduced by adding DMTCP into this use case; the following points are related to the numbers in the figure 9. 1) Checkpoint is created for OS boot as part of preparing the database for users. 2) Restoring OS boot from checkpoint saves 55 minutes for each job. 3) First job is completed after 1.1 hours with DMTCP versus 2 hours without DMTCP. 4) Full regression is completed after 22.9 hours with DMTCP versus 40 hours without DMTCP. During the integration of DMTCP with the emulation and SoC validation environment, we faced several challenges: (1) Very large read-only files were being saved as part of the checkpoint. This had an impact on both checkpoint/restore time as well as the memory footprint on disk. This was solved by having the DMTCP Emulation plugin detect and decide not to checkpoint such read-only files. The tool-specific file list was written into the DMTCP plugin to identify just those files that needed to be checkpointed. (2) Checkpoints were not portable to another site, due to some file paths that were preserved as part of the checkpoint. This was solved by using the existing file path virtualization plugin of DMTCP, allowing these paths to be changed at restore time. Limitations found when deploying DMTCP 1) Some use cases have a remote process connected via TCP on Windows machine. Additional work would be required to support this kind of use case both within the DMTCP community as well as in the testbench infrastructure. 2) Some use cases require changing the initial state of the environment which is part of the DMTCP checkpoint. For instance, if you had a SoC that had a programmable number of DIMMs and the number of DIMMs was changing per test you wouldn't be able to re-use a single checkpoint. DMTCP was found to be easy to integrate, and it required minimal changes to emulation environment. This has demonstrated the success of this approach toward OS-based use case validation during emulation. VI. FUTURE WORK We intend to work on developing preemptive capabilities for emulation jobs in a workload management system such as LSF. A case study in this environment is needed in order to discover the practical challenges thereof, and to help deploy this technology for more flexible job scheduling management. Finally, verification of a network switch presents an additional interesting case study for the future. In this scenario, a virtual machine is often required, so that simulated Ethernet traffic can be injected by the virtual machine into the environment for verification test coverage. This makes transparent checkpointing on the testbench side more difficult, since even though the virtual machine can be modified to inject Ethernet traffic, the virtual machine snapshot facility is difficult to modify, and so the state of the Ethernet traffic generator will not be checkpointed. On restore, some steps in the state diagram for Ethernet packets may be lost. As part of future work, it is proposed to use the ability of DMTCP to checkpoint a virtual machine from the outside. DMTCP has the ability to carry out a snapshot from the outside for the case of a QEMU virtual machine over KVM [4]. That same work [4] also presents DMTCP's ability to checkpoint a network of virtual machines. This latter case makes possible verification for end-to-end Ethernet test coverage between two virtual machines. VII. CONCLUSION This paper describes the approach to transparently checkpoint/restore emulation jobs and various key benefits it brings along with it. This integration was successfully tried in an OEM company‚Äôs SOC validation environment, which not only reduced total regression time but also increased Emulator efficiency. Emulation time is precious and any saving of this time directly affects one‚Äôs total verification cost. Experimental results have shown that this approach, when integrated with job management system, has increased the emulator utilization and has also increased the productivity of the verification engineers by providing them with a window to look back in time. The integration has also been successfully tried for a variety of software testbenches including C/C++/SystemC, and a SystemVerilog testbench running on a simulator. These testbenches can have multiple threads or multiple processes spread across different machines.",1850
1765,Formal Methods,Gene Cooperman,"May 7th, 2014",Transparent Checkpoint-Restart over InfiniBand,http://www.ccs.neu.edu/home/gene/papers/hpdc14.pdf," ""Transparent Checkpoint-Restart over InfiniBand"", Jiajun Cao, Gregory Kerr, Kapil Arya and Gene Cooperman, ACM Symposium on High Performance Parallel and Distributed Computing (HPDC'14), pp. 13--24, ACM Press, 2014.","Transparently saving the state of the InÔ¨ÅniBand network as part of distributed checkpointing has been a long-standing challenge for researchers. The lack of a solution has forced typical MPI implementations to include custom checkpoint- restart services that ‚Äútear down‚Äù the network, checkpoint each node in isolation, and then re-connect the network again. This work presents the Ô¨Årst example of transpar- ent, system-initiated checkpoint-restart that directly sup- ports InÔ¨ÅniBand. The new approach simpliÔ¨Åes current prac- tice by avoiding the need for a privileged kernel module. The generality of this approach is demonstrated by applying it both to MPI and to Berkeley UPC (UniÔ¨Åed Parallel C), in its native mode (without MPI). Scalability is shown by check- pointing 2,048 MPI processes across 128 nodes (with 16 cores per node). The run-time overhead varies between 0.8% ands (Section 7) are presented. 2. BACKGROUND Section 2.1 reviews some concepts of InÔ¨ÅniBand, necessary for understanding the checkpointing approach described in Section 3. Section 2.2 describes the use of plugins in DMTCP. 2.1 InÔ¨ÅniBand Verbs API In order to understand the algorithm, we review some concepts from the Verbs API of InÔ¨ÅniBand. While there are several",1851
1766,Formal Methods,Panagiotis (Pete) Manolios,"May 1st, 2023",Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals,https://www.vldb.org/pvldb/vol16/p2377-chen.pdf," Zixuan Chen, Panagiotis Manolios, Mirek Riedewald. (2023). Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals Proc. VLDB Endow., 16, 2377-2390. https://www.vldb.org/pvldb/vol16/p2377-chen.pdf","This work considers why-not questions in the context of top-k queries and score-based ranking functions. Following the popular linear scalarization approach for multi-objective optimization, we study rankings based on the weighted sum of multiple scores. A given weight choice may be controversial or perceived as unfair to certain individuals or organizations, triggering the question why some entity of interest has not yet shown up in the top-k. We introduce various notions of such why-not-yet queries and for- mally define them as satisfiability or optimization problems, whose goal is to propose alternative ranking functions that address the placement of the entities of interest. While some why-not-yet prob- lems have linear constraints, others require quantifiers, disjunction, and negation. We propose several optimizations, ranging from a monotonic-core construction that approximates the complex con- straints with a conjunction of linear ones, to various techniques that let the user control the tradeoff between running time and approximation quality. Experiments with real and synthetic data demonstrate the practicality and scalability of our technique, show- ing its superiority compared to the state of the art (SOA). PVLDB Reference Format: Zixuan Chen, Panagiotis Manolios, and Mirek Riedewald. Why Not Yet: Fixing a Top-k Ranking that Is Not Fair to Individuals. PVLDB, 16(9): 2377 - 2390, 2023. doi:10.14778/359858We propose the first general exact solution for problems SAT, BEST, and POINT. Adopting sampling approaches from related work can only provide approximate answers or results in infeasible running time for BEST. In general, sampling becomes ineffective when only a small fraction of the space of possible weight vectors ranks the expected tuples among the top-ùëò. For BOX, we propose the first known solution. To make it practical and scalable, we propose the notion of a monotonic core. Our clustering approach enables the user to improve running time for all problems as desired by controlling the number of clusters, with moderate loss in result quality even for large data. Interesting avenues for future work are computing a compact description of the entire set of weight vectors that rank the expected tuples among the top-ùëòand generalizing the approach to noisy and unreliable data.",1852
1767,Formal Methods,Ji-Yong Shin,"March 5th, 2024",FusionFlow: Accelerating Data Preparation for Machine Learning with Hybrid CPU-GPU Processing,https://www.vldb.org/pvldb/vol17/p863-kim.pdf," Taeyoon Kim, Chanho Park, Mansur Mukimbekov, Heelim Hong, Minseok Kim, Ze Jin, Changdae Kim, Ji-Yong Shin, Myeongjae Jeon. (2023). FusionFlow: Accelerating Data Preparation for Machine Learning with Hybrid CPU-GPU Processing Proc. VLDB Endow., 17, 863-876. https://www.vldb.org/pvldb/vol17/p863-kim.pdf","Data augmentation enhances the accuracy of DL models by diversi- fying training samples through a sequence of data transformations. While recent advancements in data augmentation have demonstrated remarkable efficacy, they often rely on computationally expensive and dynamic algorithms. Unfortunately, current system optimiza- tions, primarily designed to leverage CPUs, cannot effectively sup- port these methods due to costs and limited resource availability. To address these issues, we introduce FusionFlow, a system that cooperatively utilizes both CPUs and GPUs to accelerate the data preprocessing stage of DL training that runs the data augmentation algorithm. FusionFlow orchestrates data preprocessing tasks across CPUs and GPUs while minimizing interference with GPU-based model training. In doing so, it effectively mitigates the risk of GPU memory overflow by managing memory allocations of the tasks within the GPU-wide free space. Furthermore, FusionFlow provides a dynamic scheduling strategy for tasks with varying computational demands and reallocates compute resources on the fly to enhance training throughput for both single and multi-GPU DL jobs. Our evaluations show that FusionFlow outperforms existing CPU-based methods by 16‚Äì285% in single-machine scenarios and, to achieve similar training speeds, requires 50‚Äì60% fewer CPUs compared to utilizing scalable compute resources from external servers. PVLDB Reference Format: Taeyoon Kim, ChanHo Park, Mansur Mukimbekov, Heelim Hong, Minseok Kim, Ze Jin, Changdae Kim, Ji-Yong Shin, and Myeongjae Jeon. FusionFlow: Accelerating Data Preprocessing for Machine Learning with CPU-GPU Cooperation. PVLDB, 17(4): 863 - 876, 2023. doi:10.14778/3636218.3636238 PVLDB Artifact Availability: The source code, data, and/or other artifacts have been made available at https://github.com/omnia-unist/FusionFlow. This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 17, No. 4 ISSN 2150-8097. doi:10.14778/3636218.3636238 1We propose FusionFlow that speeds up the dynamic data augmen- tation algorithms on CPUs and GPUs. The key idea is exploiting intra-batch parallelism, which splits an input mini-batch into mul- tiple tiny-batches and augments the mini-batch in parallel on those compute resources. FusionFlow applies several optimizations to make GPU-offloading of tiny-batch tasks highly effective and per- forms CPU worker scaling to make CPU resource usage in data- parallel training more balanced. Experimental results confirm the effectiveness of FusionFlow.",1853
1768,Games,Seth Cooper,"October 20th, 2020",Grammar Based Modular Level Generator for a Programming Puzzle Game,https://ceur-ws.org/Vol-2862/paper12.pdf," Chaima Jemmali, Carter Ithier, Seth Cooper, Magy Seif El-Nasr. (2020). Grammar Based Modular Level Generator for a Programming Puzzle Game AIIDE Workshops. https://ceur-ws.org/Vol-2862/paper12.pdf","Procedural Content Generation is widely used in games, how- ever, its use in educational puzzle games has been limited. These types of games present common challenges such as solvability and non triviality, but also the extra challenge of preserving intended learning goals. In this paper, we present a modular constructive approach to generate levels in a puzzle programming game. The approach uses a grammar to gen- erate game elements from code and works backwards from the solution to ensure solvability, controllability over the so- lution, and variation, allowing for alternative solutions that preserve the learning goals.In this paper, we presented a grammar based modular ap- proach to generate levels in a programming puzzle game. The approach works backwards from a solution code and uses both the solution map and the initial map to ensure that levels are solvable using the input code. The levels gener- ated allow variation in the solution space through alterna- tive codes while minimizing shorter, more trivial solutions. However, some of them still allow shorter codes. In the fu- ture, we want to improve on the approach, build a user- friendly interface and conduct a user-study with designers. Further, we would like to work on integrating procedurally generated levels within the game according to some player model that will inform us about the coding constructs that the player needs practice with.",1854
1769,Machine Learning,Christopher Amato,"February 20th, 2023",Improving Deep Policy Gradients with Value Function Search,https://openreview.net/pdf?id=6qZC7pfenQm," Enrico Marchesini, Christopher Amato. (2023). Improving Deep Policy Gradients with Value Function Search ICLR. https://openreview.net/pdf?id=6qZC7pfenQm","Deep Policy Gradient (PG) algorithms employ value networks to drive the learn- ing of parameterized policies and reduce the variance of the gradient estimates. However, value function approximation gets stuck in local optima and struggles to fit the actual return, limiting the variance reduction efficacy and leading policies to sub-optimal performance. This paper focuses on improving value approxima- tion and analyzing the effects on Deep PG primitives such as value prediction, variance reduction, and correlation of gradient estimates with the true gradient. To this end, we introduce a Value Function Search that employs a population of perturbed value networks to search for a better approximation. Our framework does not require additional environment interactions, gradient computations, or ensembles, providing a computationally inexpensive approach to enhance the su- pervised learning task on which value networks train. Crucially, we show that improving Deep PG primitives results in improved sample efficiency and policies with higher returns using common continuous control benchmark domains. 1VFS introduces a two-scale perturbation operator voted to diversify a population of value networks to (i) explore local variations of current critics‚Äô predictions and (ii) allow to explore diversified value functions to escape from local optima. The practical results of such components have been investigated with additional experiments that also motivate the improvement in sample efficiency and performance of VFS-based algorithms in a range of standard continuous control benchmarks. Our findings suggest that improving fundamental Deep PG primitives translates into higher-performing policies and better sample efficiency. 9 Published as a conference paper at ICLR 2023 7",1855
1770,Machine Learning,Christopher Amato,"May 5th, 2018",Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems,http://www.ccs.neu.edu/home/camato/publications/ICRA2018.pdf," Nghia Hoang, Yuchen Xiao, Kavinayan Sivakumar, Christopher Amato and Jonathan P. How. In the Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA-18), May 2018.","‚Äî A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self- interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with Ô¨Åxed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach Ô¨Årst optimizes a set of stratagems that represent these best responses. These optimized stratagems are then inte- grated into a uniÔ¨Åed policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.This paper introduces a novel near-optimal adversarial pol- icy switching algorithm for decentralized, non-cooperative multi-agent systems. Unlike the existing works in literature which are mostly limited to simple decision-making sce- narios where a single agent plans its best response against an adversary whose strategy is speciÔ¨Åed a priori under reasonable assumptions, we investigate instead a class of multi-agent scenarios where multiple robots need to operate independently in collaboration with their teammates to act effectively against adversaries with changing strategies. To achieve this, we Ô¨Årst optimize a set of basic stratagems that each is tuned to respond optimally to a pre-identiÔ¨Åed basic tactic of the adversaries. The stratagems are then integrated into a uniÔ¨Åed policy which performs near-optimally against B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (a) (b) (c) B3 B2 B1 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (d) (e) (f) Fig. 6: Image excerpts from a video demo showing (1) a team of 3 allied (blue) robots (B1,B2 and B3) that implement the optimized stratagem produced by our framework (Section III) to compete against (2) an opposing team of 2 opponent (red) robots (R1 and R2) which implement the hand-coded tactics DL and DR (see Section VI-A), respectively: (a) B1,B2 and B3 decide to invade the opposition territory; (b) B1 and B3 decide to attack the center while B2 decides to take the left Ô¨Çank of the opposition; (c) B2 passes through R1‚Äôs defense while B1 takes an interesting position to block R2 so that B3 can pass through its defense; (d) B1 and B2 detect the Ô¨Çag and mount a pincer attack; (e) R2 arrives to defend the Ô¨Çag and B2 retreats to avoid getting tagged; and (f) without noticing B1 from behind, R2 continues its DR patrol, thus losing the Ô¨Çag to B1. any high-level strategies of the adversaries that switches between their basic tactics. The near-optimality of our pro- posed framework can be established in both theoretical and empirical settings with interesting and consistent results. We believe this is a signiÔ¨Åcant step towards bridging the gap between theory and practice in multi-agent research.",1856
1771,Machine Learning,Christopher Amato,"August 4th, 2017",COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs,http://www.ccs.neu.edu/home/camato/publications/cogdice_ijcai.pdf," COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs. Madison Clark-Turner and Christopher Amato. In the Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), August 2017","The decentralized partially observable Markov de- cision process (Dec-POMDP) is a powerful model for representing multi-agent problems with de- centralized behavior. Unfortunately, current Dec- POMDP solution methods cannot solve problems with continuous observations, which are common in many real-world domains. To that end, we present a framework for representing and gener- ating Dec-POMDP policies that explicitly include continuous observations. We apply our algorithm to a novel tagging problem and an extended version of a common benchmark, where it generates poli- cies that meet or exceed the values of equivalent discretized domains without the need for Ô¨Ånding an adequate discretization. 1This paper presented, for the Ô¨Årst time, an algorithm that gen- erates joint policies for Dec-POMDPs with continuous ob- servations. We presented both a discrete-observation ver- sion of the algorithm, which is applicable in domains with a large number of discrete observations, and a continuous- observation version. This method is broadly applicable as many real-world domains have large or continuous observa- tion spaces. COG-DICE has been successful in generating joint policies for both a novel and a preexisting problem and has highlighted the negative impacts that inappropriate dis- cretization can have on joint policy structure and value. For future work, we are interested in extending this work to high- dimensional observation spaces by exploring other (nonlin- ear) divisions and optimizing the algorithm parameters by ei- ther integrating these optimizations into the algorithm or pos- sibly building on previous work on Bayesian non-parametrics [Liu et al., 2015].",1857
1772,Machine Learning,David Bau,"October 24th, 2022",Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,https://openreview.net/pdf?id=DeG07_TcZvT," Kenneth Li , Aspen K. Hopkins, David Bau, Fernanda B. Vi√©gas, Hanspeter Pfister, Martin Wattenberg. (2023). Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task ICLR. https://openreview.net/pdf?id=DeG07_TcZvT","Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce ‚Äúlatent saliency maps‚Äù that help explain predictions. 1 1Our experiments provide evidence that Othello-GPT maintains a representation of game board states‚Äî that is, the Othello ‚Äúworld‚Äù‚Äîto produce sequences it was trained on. This representation appears to be nonlinear in an essential way. Further, we find that these representations can be causally linked to how the model makes its predictions. Understanding of the internal representations of a sequence model is interesting in its own right, but may also be helpful in deeper interpretations of the network. We have also described how interventional experiments may be used to create a ‚Äúlatent saliency map‚Äù, which gives a picture, in terms of the Othello board, of how the network has made a prediction. Applied to two versions of Othello-GPT that were trained on different data sets, the latent saliency maps highlight the dramatic differences between underlying representations of the Othello-GPT trained on synthetic dataset and its counterpart trained on championship dataset. There are several potential lines of future work. One natural extension would be to perform the same type of investigations with other, more complex games. It would also be interesting to compare the strategies learned by a sequence model trained on game transcripts with those of a model trained with a priori knowledge of Othello. One option is to compare latent saliency maps of Othello‚ÄìGPT with standard saliency maps of an Othello-playing program which has the actual board state as input. More broadly, it would be interesting to study how our results generalize to models trained on natural language. One stepping stone might be to look at language models whose training data has included game transcripts. Will we see similar representation of board state? Grammar engineering tools (Weston et al., 2015; Hermann et al., 2017; CÀÜot¬¥e et al., 2018) could help define a synthetic data generation process that maps world representations onto natural language sentences, providing a similarly controllable setting like Othello while closing the distance to natural languages. For more complex natural language tasks, can we find meaningful world representations? Our hope is that the tools described in this paper‚Äînonlinear probes, layerwise interventions, and latent saliency maps‚Äîmay prove useful in natural language settings. 9 Published as a conference paper at ICLR 2023",1858
1773,Machine Learning,Divya Chaudhary,"October 22nd, 2023",Exploring the Indian Political YouTube Landscape: A Multimodal Multi-Task Approach,https://ceur-ws.org/Vol-3566/paper1.pdf," Adwita Arora, Naman Dhingra, Divya Chaudhary, Ian Gorton, Bijendra Kumar. (2023). Exploring the Indian Political YouTube Landscape: A Multimodal Multi-Task Approach MUWS@CIKM, 3-17. https://ceur-ws.org/Vol-3566/paper1.pdf","Social media profoundly influences all facets of our lives, including politics. Political parties, politicians, and media outlets have strategically cultivated their social media presence to engage with the public. However, with the advent of freely available Internet services in India, there has been a rising proliferation in the community of independent content creators on YouTube, with many getting millions of views per video. In this study, we present a novel multimodal dataset of videos, taken from 20 independent and influential content creators, annotated for five socially and politically relevant labels with a high inter-annotator score (0.820 - 0.956 Cohen‚Äôs Kappa Score) falling under the categories - Humour/Satire, Opposition/Criticism, Support/Advocacy, and Informational/Analysis. We consider three modalities in our dataset - textual (title and description of the video), visual (thumbnail) and audio (MFCC coefficients and additional spectral and temporal features) modalities. We also perform preliminary classification on our dataset using an early fusion multimodal model, combining audio, visual and textual modalities, which performs better than other unimodal and bimodal approaches, yielding a Macro-F1 score of 0.8742 and ROC-AUC score of 0.769. By introducing this novel dataset, we aim to stimulate further investigation within the domains of opinion dissemination across social networks and the analysis of multimodal content, especially within the Indian context. Keywords Multimodal Analysis, Political Analysis, Social Media Analysiss The consumption of content on social media sites, like YouTube, has grown manifold over the last decade. This has led to an exponential rise in the creation of short-form and long-form content on various topics, ranging from comedic videos to documentaries. In this study, we analyzed one such content creation topic, political videos uploaded by independent Indian content creators. We annotated around 400 videos collected from YouTube for different socially and politically relevant labels. We performed a content analysis on our annotated dataset using BERTopic for topic modelling and YAKE! for keyword extraction. We also applied an early fusion multimodal model on the features extracted using state-of-the-art backbone representations, namely MuRIL for text, ConvNeXT for images, and MCFF, ZCR, Spectral Bandwidth, Chroma STFT and Spectral Rolloff for audio. Our classification model yielded a Macro-F1 score of 0.8742. Compared to other unimodal and bimodal models, the early fusion model yielded significantly better results. 6. Future Work Future work that focuses on a number of important areas of development will raise the calibre and scope of this research. Here are some directions we want to go in: 1. Experimentation with other fusion models In this paper, we used an early fusion model, combining modalities before classification. However, there are alternative fusion techniques that warrant exploration, such as late fusion models, where each modality is processed independently before being integrated with other modalities, and attention- based fusion models where the importance of different modalities is assessed with respect to the task at hand, or ensemble models, which combines the strengths of multiple prediction models to improve results. 2. Audio feature extraction The features extracted for audio in this study are numerical metrics that regrettably fail to capture the nuances of speech, especially code-mixed Hindi-English speech, which is a predominant mode of communication in India. Experi- menting with other audio feature extraction methods, for example, using transcripts to capture semantic meaning, Mel-frequency spectrograms to capture phonetic variation or transformer-based models that are distinguished for their contextual understanding can offer more sophisticated results. 3. Extending the dataset We chose to annotate data collected for five tasks for the purposes of this study. However, the methods of classification and analysis can be extended to include even more relevant labels that cover more NLP and discourse analysis tasks. This includes the detection of hate speech towards marginalised communities veiled as opinions, misinformation and fake news detection or the spread and polarization of public opinions over time. 4. Multilingual and cross-regional support While our selection procedure primarily focused on YouTube channels that offered content in Hindi or English, it‚Äôs important to recognise that a more inclusive approach is necessary for a thorough representation of India‚Äôs political environment. To adequately capture the complex and varied political narratives that arise across the nation‚Äôs various linguistic and cultural realms, region- specific content must be included.",1859
1774,Machine Learning,Divya Chaudhary,"September 18th, 2023",Detection of Sexism on Social Media with Multiple Simple Transformers,https://ceur-ws.org/Vol-3497/paper-082.pdf," Chirayu Jhakal, Khushi Singal, Manan Suri, Divya Chaudhary, Bijendra Kumar, Ian Gorton. (2023). Detection of Sexism on Social Media with Multiple Simple Transformers CLEF (Working Notes), 959-966. https://ceur-ws.org/Vol-3497/paper-082.pdf","Social media platforms have become virtual communication channels, allowing users to voice their thoughts and opinions. However, this openness and features of anonymity have also given rise to the proliferation of harmful and offensive content, including sexism. This research aims at proposing a methodology and explores the use of different simple transformers. Monolingual Simple Transformers such as BERT, RoBERTa[1], BERTweet, DistilBERT, XLNet were evaluated on the EXIST2023 shared task challenge at the IberLEF2023 dataset. It was observed that RoBERTa has given the best results among all other transformers. The proposed approach has great scope for the efficient detection of sexist content on social media, aiding in the development of effective content moderation systems. Keywords Sexism Detection, Simple Transformer Models, Natural Language Processing,, our study highlights the effectiveness of pre-trained transformer models in detecting sexism in tweets, both in English and Spanish. The results demonstrate the importance of using language-specific models and models designed for social media data to achieve higher accuracy. This research contributes to the development of automated systems for identifying and addressing sexism in online communication, ultimately fostering a more inclusive and respectful digital environment. 6. Conclusion In this research, we investigated the detection of sexism in tweets using pre-trained transformer models for both English and Spanish languages. Our results demonstrate that these models can be effective in identifying instances of sexism in social media content. The BERTweet model performed well in capturing the nuances of English tweets, while the CamemBERT model showed promise for Spanish tweets. Additionally, the XLNet model exhibited superior performance among the English models, highlighting the effectiveness of permutation-based approaches. However, it is important to note that the accuracies achieved, especially for Spanish models, can still be improved. The findings of this study have implications for developing automated systems that can detect and mitigate sexism in online communication. By leveraging pre-trained transformer models, we can gain insights into the prevalence of sexism and take steps toward fostering a more inclusive and respectful digital environment. 7. Future Work While this research provides valuable insights into the detection of sexism in tweets, there are several avenues for future work that can enhance the accuracy and robustness of the models. Firstly, data augmentation techniques can be employed to improve model performance [3] [4] [5] [6]. By increasing the diversity and quantity of training data through techniques such as back-translation, word replacement, or text synthesis, we can potentially reduce the model‚Äôs bias and enhance its ability to detect subtle forms of sexism. Secondly, ensemble modeling can be explored to leverage the strengths of multiple models and improve overall performance. By combining predictions from different models, either by majority voting or weighted averaging, we can potentially achieve higher accuracy and mitigate the limitations of individual models. Furthermore, it is important to expand the evaluation of sexism detection models to different languages and cultural contexts. The linguistic characteristics and contextual nuances can significantly vary across languages, necessitating the development of language-specific models and datasets. Additionally, further research should focus on addressing the issue of bias in the models. It is crucial to identify and mitigate any biases encoded in the pre-trained models to ensure fair and equitable detection of sexism. Finally, it would be beneficial to conduct user studies and assess the real-world impact of automated systems in addressing sexism in online spaces. Understanding user perceptions, reactions, and potential ethical concerns will guide the development of more effective and responsible solutions. By pursuing these avenues, we can advance the field of sexism detection in social media and contribute to the development of robust and inclusive technologies.",1860
1775,Machine Learning,Ehsan Elhamifar,"December 8th, 2019",Deep Supervised Summarization: Algorithm and Application to Learning Instructions,https://khoury.northeastern.edu/home/eelhami/publications/SupFL_NeurIPS19.pdf," Deep Supervised Summarization: Algorithm and Application to Learning Instructions C. Xu and E. Elhamifar, Neural Information Processing Systems (NeurIPS), 2019.","We address the problem of Ô¨Ånding representative points of datasets by learning from multiple datasets and their ground-truth summaries. We develop a supervised subset selection framework, based on the facility location utility function, which learns to map datasets to their ground-truth representatives. To do so, we propose to learn representations of data so that the input of transformed data to the facility location recovers their ground-truth representatives. Given the NP-hardness of the utility function, we consider its convex relaxation based on sparse representation and investigate conditions under which the solution of the convex optimization recovers ground-truth representatives of each dataset. We design a loss function whose minimization over the parameters of the data representation network leads to satisfying the theoretical conditions, hence guaranteeing recovering ground- truth summaries. Given the non-convexity of the loss function, we develop an efÔ¨Åcient learning scheme that alternates between representation learning by mini- mizing our proposed loss given the current assignments of points to ground-truth representatives and updating assignments given the current data representation. By experiments on the problem of learning key-steps (subactivities) of instruc- tional videos, we show that our proposed framework improves the state-of-the-art supervised subset selection algorithms. 1s We addressed the problem of supervised subset selection by generalizing the facility location to learn from ground-truth summaries. We considered an efÔ¨Åcient sparse optimization of the uncapacitated facility location and investigated conditions under which it recovers ground-truth representatives and also becomes equivalent to the original NP-hard problem. We designed a loss function and an efÔ¨Åcient framework to learn representations of data so that the input of transformed data to the facility location satisÔ¨Åes the theoretical conditions, hence, recovers ground-truth summaries. We showed the effectiveness of our method for recovering key-steps of instructional videos. To the best of our knowledge, this is the Ô¨Årst work on supervised subset selection that derives conditions under which subset selection recovers ground-truth representatives and employs them to design a loss function for deep representation learning. We believe that this work took a major step towards a theoretically motivated supervised subset selection framework.",1861
1776,Machine Learning,Ehsan Elhamifar,"October 27th, 2019",Unsupervised Procedure Learning via Joint Dynamic Summarization,http://www.ccs.neu.edu/home/eelhami/publications/ICCV19-ProceL-Ehsan.pdf," Unsupervised Procedure Learning via Joint Dynamic Summarization. E. Elhamifar and Z. Naing, International Conference on Computer Vision (ICCV), 2019.","We address the problem of unsupervised procedure learning from unconstrained instructional videos. Our goal is to produce a summary of the procedure key-steps and their ordering needed to perform a given task, as well as localization of the key-steps in videos. We develop a col- laborative sequential subset selection framework, where we build a dynamic model on videos by learning states and transitions between them, where states correspond to dif- ferent subactivities, including background and procedure steps. To extract procedure key-steps, we develop an opti- mization framework that Ô¨Ånds a sequence of a small number of states that well represents all videos and is compatible with the state transition model. Given that our proposed optimization is non-convex and NP-hard, we develop a fast greedy algorithm whose complexity is linear in the length of the videos and the number of states of the dynamic model, hence, scales to large datasets. Under appropriate condi- tions on the transition model, our proposed formulation is approximately submodular, hence, comes with performance guarantees. We also present ProceL, a new multimodal dataset of 47.3 hours of videos and their transcripts from diverse tasks, for procedure learning evaluation. By exten- sive experiments, we show that our framework signiÔ¨Åcantly improves the state of the art performance.We developed a joint dynamic summarization method and a fast greedy algorithm for unsupervised procedure learning. Our method handles repeated key-steps, back- ground and missing or additional key-steps in videos. We presented ProceL, a new multimodal dataset for procedure learning. We showed our method signiÔ¨Åcantly improves the state of the art performance and showed the effectiveness of summarization tools, in general, for procedure learning.",1862
1777,Machine Learning,Ehsan Elhamifar,"June 16th, 2019",Facility Location: Approximate Submodularity and Greedy Algorithm,http://www.ccs.neu.edu/home/eelhami/publications/SeqFL_ICML19.pdf," Facility Location: Approximate Submodularity and Greedy Algorithm, E. Elhamifar, International Conference on Machine Learning (ICML), 2019.","We develop and analyze a novel utility function and a fast optimization algorithm for subset se- lection in sequential data that incorporates the dynamic model of data. We propose a cardinality- constrained sequential facility location function that Ô¨Ånds a Ô¨Åxed number of representatives, where the sequence of representatives is compatible with the dynamic model and well encodes the data. As maximizing this new objective function is NP- hard, we develop a fast greedy algorithm based on submodular maximization. Unlike the con- ventional facility location, the computation of the marginal gain in our case cannot be done by oper- ations on each item independently. We exploit the sequential structure of the problem and develop an efÔ¨Åcient dynamic programming-based algorithm that computes the marginal gain exactly. We in- vestigate conditions on the dynamic model, under which our utility function is (Œµ-approximately) submodualr, hence, the greedy algorithm comes with performance guarantees. By experiments on synthetic data and the problem of procedure learning from instructional videos, we show that our framework signiÔ¨Åcantly improves the compu- tational time, achieves better objective function values and obtains more coherent summaries.s We proposed a utility function and a fast greedy algorithm for subset selection in sequential datasets, taking advantage of the dynamic model of data. We proved that under appro- priate conditions on transition dynamics, our utility function is Œµ-approximately submodular, hence, enjoys approximate guarantees via the greedy method. By experiments on syn- thetic and real data, we showed the effectiveness of our method in terms of running time and attained objective val- ues as well as addressing the procedure learning task. Greedy Sequential Facility Location",1863
1778,Machine Learning,Ehsan Elhamifar,"December 4th, 2017",Subset Selection and Summarization in Sequential Data,http://www.ccs.neu.edu/home/eelhami/publications/SeqSS-NIPS17-Ehsan.pdf," E. Elhamifar and M. C. De Paolis Kaluza; Neural Information Processing Systems (NIPS), 2017.","Subset selection, which is the task of Ô¨Ånding a small subset of representative items from a large ground set, Ô¨Ånds numerous applications in different areas. Sequential data, including time-series and ordered data, contain important structural relation- ships among items, imposed by underlying dynamic models of data, that should play a vital role in the selection of representatives. However, nearly all existing subset selection techniques ignore underlying dynamics of data and treat items independently, leading to incompatible sets of representatives. In this paper, we develop a new framework for sequential subset selection that Ô¨Ånds a set of represen- tatives compatible with the dynamic models of data. To do so, we equip items with transition dynamic models and pose the problem as an integer binary optimization over assignments of sequential items to representatives, that leads to high encoding, diversity and transition potentials. Our formulation generalizes the well-known facility location objective to deal with sequential data, incorporating transition dynamics among facilities. As the proposed formulation is non-convex, we derive a max-sum message passing algorithm to solve the problem efÔ¨Åciently. Experiments on synthetic and real data, including instructional video summarization, show that our sequential subset selection framework not only achieves better encoding and diversity than the state of the art, but also successfully incorporates dynamics of data, leading to compatible representatives. 1s and Future Work We developed a new framework for sequential subset selection that takes advantage of the underlying dynamic models of data, promoting to select a set of representatives that are compatible according to the dynamic models of data. By experiments on synthetic and real data, we showed the effectiveness of our method for summarization of sequential data. Our ongoing research include development of fast greedy algorithms for our sequential subset selection formulation, investigation of the theoretical guarantees of our method, as well as development of more effective summarization-based feature extraction techniques and working with larger datasets for the task of instructional data summarization. 9",1864
1779,Machine Learning,Ehsan Elhamifar,"July 21st, 2017",Online Summarization via Submodular and Convex Optimization,http://www.ccs.neu.edu/home/eelhami/publications/onlineSS_CVPR17-Ehsan.pdf," E. Elhamifar and M. C. De Paolis Kaluza  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.","We consider the problem of subset selection in the online setting, where data arrive incrementally. Instead of stor- ing and running subset selection on the entire dataset, we propose an incremental subset selection framework that, at each time instant, uses the previously selected set of repre- sentatives and the new batch of data in order to update the set of representatives. We cast the problem as an integer bi- nary optimization minimizing the encoding cost of the data via representatives regularized by the number of selected items. As the proposed optimization is, in general, NP-hard and non-convex, we study a greedy approach based on un- constrained submodular optimization and also propose an efÔ¨Åcient convex relaxation. We show that, under appropri- ate conditions, the solution of our proposed convex algo- rithm achieves the global optimal solution of the non-convex problem. Our results also address the conventional problem of subset selection in the ofÔ¨Çine setting, as a special case. By extensive experiments on the problem of video summa- rization, we demonstrate that our proposed online subset selection algorithms perform well on real data, capturing diverse representative events in videos, while they obtain objective function values close to the ofÔ¨Çine setting.s We studied the problem of subset selection in the online setting, where data arrive incrementally. We proposed an incremental subset selection framework that, at each time instant, uses the previously selected set of representatives and the new batch of data in order to update the set of representatives. We cast the problem as an integer binary optimization minimizing the encoding cost of the data via representatives regularized by the number of selected items. We studied a randomized greedy approach based on uncon- strained submodular optimization and proposed a convex algorithm with theoretical performance guarantees. By ex- periments on real videos, we demonstrated the effectiveness of our methods for online video summarization.",1865
1780,Machine Learning,David Smith,"December 6th, 2023",Automatic Collation for Diversifying Corpora: Commonly Copied Texts as Distant Supervision for Handwritten Text Recognition,https://ceur-ws.org/Vol-3558/paper1708.pdf," David A. Smith, Jacob Murel, Jonathan Parkes Allen, Matthew Thomas Miller. (2023). Automatic Collation for Diversifying Corpora: Commonly Copied Texts as Distant Supervision for Handwritten Text Recognition CHR, 206-221. https://ceur-ws.org/Vol-3558/paper1708.pdf","Handwritten text recognition (HTR) has enabled many researchers to gather textual evidence from the human record. One common training paradigm for HTR is to identify an individual manuscript or coherent collection and to transcribe enough data to achieve acceptable performance on that collection. To build generalized models for Arabic-script manuscripts, perhaps one of the largest textual traditions in the pre-modern world, we need an approach that can improve its accuracy on unseen manuscripts and hands without linear growth in the amount of manually annotated data. We propose Automatic Collation for Diversifying Corpora (ACDC), taking advantage of the existence of multiple manuscripts of popular texts. Starting from an initial HTR model, ACDC automatically detects matching passages of popular texts in noisy HTR output and selects high-quality lines for retraining HTR without any manually annotated data. We demonstrate the eÊòÄÊòÄectiveness of this approach to distant supervision by annotating a test set drawn from a diverse collection of 59 Arabic-script manuscripts and a training set of 81 manuscripts of popular texts embedded within a larger corpus. AÊòÄÁêÄer a few rounds of ACDC retraining, character accuracy rates on the test set increased by 19.6% absolute percentage, while a supervised model trained on manually annotated data from the same collection increased accuracy by 15.9%. We analyze the variation in ACDC‚Äôs performance across books and languages and discuss further applications to collating manuscript families. Keywords handwritten text recognition, collation, manuscriptss, or recommendations expressed do not necessarily reÊòÄÊ∞Äect those of the NEH or Mellon.",1866
1781,Machine Learning,David Smith,"June 27th, 2014",Detecting and Evaluating Local Text Reuse in Social Networks,https://aclanthology.org/W14-2707.pdf," Shaobin Xu, David Smith, Abigail Mullen, and Ryan Cordell. Detecting and evaluating local text reuse in social networks. In ACL Joint Workshop on Social Dynamics and Personal Attributes in Social Media, 2014.","Texts propagate among participants in many social networks and provide evi- dence for network structure. We describe intrinsic and extrinsic evaluations for algo- rithms that detect clusters of reused pas- sages embedded within longer documents in large collections. We explore applica- tions of these approaches to two case stud- ies: the culture of free reprinting in the nineteenth-century United States and the use of similar language in the public state- ments of U.S. members of Congress. 1s We have presented techniques for detecting reused passages embedded within the larger discourses Figure 4: Reprints of John Brown‚Äôs 1859 speech at his sentencing. Counties are shaded with histor- ical population data, where available. Even taking population differences into account, few newspa- pers in the South printed the abolitionist‚Äôs state- ment. produced by actors in social networks. Some of this shared content is as brief as partisan talking points or lines of poetry; other reprints can en- compass extensive legislative boilerplate or chap- ters of novels. The longer passages are easier to detect, with prefect pseudo-recall without exhaus- tive scanning of the corpus. Precision-recall trade- offs will vary with the density of text reuse and the noise introduced by optical character recog- nition and other features of data collection. We then showed the feasibility of using network re- gression to measure the correlations between con- nections inferred from text reuse and networks de- rived from outside information.",1867
1782,Machine Learning,Robin Walters,"February 27th, 2023",Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction,https://openreview.net/pdf?id=_2bDpAtr7PI," David Klee, Ondrej Biza, Robert Platt, Robin Walters. (2023). Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction ICLR. https://openreview.net/pdf?id=_2bDpAtr7PI","Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in SO(3). How- ever, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages SO(3) equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at https://dmklee.github.io/image2sphere. 1In this work, we present the first method to leverage SO(3)-equivariance for predicting distributions over 3D rotations from single images. Our method is better suited than regression methods at handling unknown object symmetries, generates more expressive distributions than methods using parametric families of multi-modal distributions while requiring fewer samples than an implicit modeling approach. We demonstrate state-of-the-art performance on the challenging PASCAL3D+ dataset composed of real images. One limitation of our work is that we use a high maximum frequency, L, in the spherical convolution operations to have higher resolution predictions. Because the number of operations in a spherical convolution is quadratic in L, it may be impractical for applications where more spherical convolutions are required. 9 Published as a conference paper at ICLR 2023",1868
1783,Machine Learning,Robin Walters,"June 8th, 2022",Integrating Symmetry into Differentiable Planning with Steerable Convolutions,https://openreview.net/pdf?id=n7CPzMPKQl," Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2023). Integrating Symmetry into Differentiable Planning with Steerable Convolutions ICLR. https://openreview.net/pdf?id=n7CPzMPKQl","In this paper, we study a principled approach on incorporating group symme- try into end-to-end differentiable planning algorithms and explore the benefits of symmetry in planning. To achieve this, we draw inspiration from equivariant con- volution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant op- erator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navi- gation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2- DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN. 1, SymVIN and SymGPPN generalize better to different map sizes, com- pared to all non-equivariant baselines. Remark. In summary, our results show that the Sym- Plan models demonstrate end-to-end planning and learn- ing ability, potentially enabling further applications to other tasks as a differentiable component for planning. Additional results and ablation studies are in Appendix H. 7 DISCUSSION In this work, we study the symmetry in the 2D path-planning problem, and build a framework using the theory of steerable CNNs to prove that value iteration in path planning is actually a form of steer- able CNN (on 2D grids). Motivated by our theory, we proposed two symmetric planning algorithms that provided significant empirical improvements in several path-planning domains. Although our focus in this paper has been on Z2, our framework can potentially generalize to path planning on higher-dimensional or even continuous Euclidean spaces (Weiler et al., 2018; Brandstetter et al., 2021), by using equivariant operations on steerable feature fields (such as steerable convolutions, pooling, and point-wise non-linearities) from steerable CNNs. We hope that our SymPlan frame- work, along with the design of practical symmetric planning algorithms, can provide a new pathway for integrating symmetry into differentiable planning. 9 Published as a conference paper at ICLR 2023 8 ACKNOWLEDGEMENT This work was supported by NSF Grants #2107256 and #2134178. R. Walters is supported by The Roux Institute and the Harold Alfond Foundation. We also thank the audience from previous poster and talk presentations for helpful discussions and anonymous reviewers for useful feedback. 9 REPRODUCIBILITY STATEMENT We provide additional details in the appendix. We also plan to open source the codebase. We briefly outline the appendix below. 1. Additional Discussion 2. Background: Technical background and concepts on steerable CNNs and group CNNs 3. Method: we provide full details on how to reproduce it 4. Theory/Framework: we provide the complete version of the theory statements 5. Proofs: this includes all proofs 6. Experiment / Environment / Implementation details: useful details for reproducibility 7. Additional results 10 Published as a conference paper at ICLR 2023",1869
1784,Natural Language Processing,David Bau,"October 24th, 2022",Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,https://openreview.net/pdf?id=DeG07_TcZvT," Kenneth Li , Aspen K. Hopkins, David Bau, Fernanda B. Vi√©gas, Hanspeter Pfister, Martin Wattenberg. (2023). Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task ICLR. https://openreview.net/pdf?id=DeG07_TcZvT","Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce ‚Äúlatent saliency maps‚Äù that help explain predictions. 1 1Our experiments provide evidence that Othello-GPT maintains a representation of game board states‚Äî that is, the Othello ‚Äúworld‚Äù‚Äîto produce sequences it was trained on. This representation appears to be nonlinear in an essential way. Further, we find that these representations can be causally linked to how the model makes its predictions. Understanding of the internal representations of a sequence model is interesting in its own right, but may also be helpful in deeper interpretations of the network. We have also described how interventional experiments may be used to create a ‚Äúlatent saliency map‚Äù, which gives a picture, in terms of the Othello board, of how the network has made a prediction. Applied to two versions of Othello-GPT that were trained on different data sets, the latent saliency maps highlight the dramatic differences between underlying representations of the Othello-GPT trained on synthetic dataset and its counterpart trained on championship dataset. There are several potential lines of future work. One natural extension would be to perform the same type of investigations with other, more complex games. It would also be interesting to compare the strategies learned by a sequence model trained on game transcripts with those of a model trained with a priori knowledge of Othello. One option is to compare latent saliency maps of Othello‚ÄìGPT with standard saliency maps of an Othello-playing program which has the actual board state as input. More broadly, it would be interesting to study how our results generalize to models trained on natural language. One stepping stone might be to look at language models whose training data has included game transcripts. Will we see similar representation of board state? Grammar engineering tools (Weston et al., 2015; Hermann et al., 2017; CÀÜot¬¥e et al., 2018) could help define a synthetic data generation process that maps world representations onto natural language sentences, providing a similarly controllable setting like Othello while closing the distance to natural languages. For more complex natural language tasks, can we find meaningful world representations? Our hope is that the tools described in this paper‚Äînonlinear probes, layerwise interventions, and latent saliency maps‚Äîmay prove useful in natural language settings. 9 Published as a conference paper at ICLR 2023",1870
1785,Natural Language Processing,David Smith,"December 6th, 2023",Automatic Collation for Diversifying Corpora: Commonly Copied Texts as Distant Supervision for Handwritten Text Recognition,https://ceur-ws.org/Vol-3558/paper1708.pdf," David A. Smith, Jacob Murel, Jonathan Parkes Allen, Matthew Thomas Miller. (2023). Automatic Collation for Diversifying Corpora: Commonly Copied Texts as Distant Supervision for Handwritten Text Recognition CHR, 206-221. https://ceur-ws.org/Vol-3558/paper1708.pdf","Handwritten text recognition (HTR) has enabled many researchers to gather textual evidence from the human record. One common training paradigm for HTR is to identify an individual manuscript or coherent collection and to transcribe enough data to achieve acceptable performance on that collection. To build generalized models for Arabic-script manuscripts, perhaps one of the largest textual traditions in the pre-modern world, we need an approach that can improve its accuracy on unseen manuscripts and hands without linear growth in the amount of manually annotated data. We propose Automatic Collation for Diversifying Corpora (ACDC), taking advantage of the existence of multiple manuscripts of popular texts. Starting from an initial HTR model, ACDC automatically detects matching passages of popular texts in noisy HTR output and selects high-quality lines for retraining HTR without any manually annotated data. We demonstrate the eÊòÄÊòÄectiveness of this approach to distant supervision by annotating a test set drawn from a diverse collection of 59 Arabic-script manuscripts and a training set of 81 manuscripts of popular texts embedded within a larger corpus. AÊòÄÁêÄer a few rounds of ACDC retraining, character accuracy rates on the test set increased by 19.6% absolute percentage, while a supervised model trained on manually annotated data from the same collection increased accuracy by 15.9%. We analyze the variation in ACDC‚Äôs performance across books and languages and discuss further applications to collating manuscript families. Keywords handwritten text recognition, collation, manuscriptss, or recommendations expressed do not necessarily reÊòÄÊ∞Äect those of the NEH or Mellon.",1871
1786,Natural Language Processing,David Smith,"June 27th, 2014",Detecting and Evaluating Local Text Reuse in Social Networks,https://aclanthology.org/W14-2707.pdf," Shaobin Xu, David Smith, Abigail Mullen, and Ryan Cordell. Detecting and evaluating local text reuse in social networks. In ACL Joint Workshop on Social Dynamics and Personal Attributes in Social Media, 2014.","Texts propagate among participants in many social networks and provide evi- dence for network structure. We describe intrinsic and extrinsic evaluations for algo- rithms that detect clusters of reused pas- sages embedded within longer documents in large collections. We explore applica- tions of these approaches to two case stud- ies: the culture of free reprinting in the nineteenth-century United States and the use of similar language in the public state- ments of U.S. members of Congress. 1s We have presented techniques for detecting reused passages embedded within the larger discourses Figure 4: Reprints of John Brown‚Äôs 1859 speech at his sentencing. Counties are shaded with histor- ical population data, where available. Even taking population differences into account, few newspa- pers in the South printed the abolitionist‚Äôs state- ment. produced by actors in social networks. Some of this shared content is as brief as partisan talking points or lines of poetry; other reprints can en- compass extensive legislative boilerplate or chap- ters of novels. The longer passages are easier to detect, with prefect pseudo-recall without exhaus- tive scanning of the corpus. Precision-recall trade- offs will vary with the density of text reuse and the noise introduced by optical character recog- nition and other features of data collection. We then showed the feasibility of using network re- gression to measure the correlations between con- nections inferred from text reuse and networks de- rived from outside information.",1872
1787,Natural Language Processing,Byron Wallace,"April 25th, 2017",Exploiting Domain Knowledge via Grouped Weight Sharing with Application to Text Categorization,https://arxiv.org/pdf/1702.02535v3.pdf," Ye Zhang, Matthew Lease, Byron C. Wallace","A fundamental advantage of neural mod- els for NLP is their ability to learn rep- resentations from scratch. However, in practice this often means ignoring existing external linguistic resources, e.g., Word- Net or domain speciÔ¨Åc ontologies such as the UniÔ¨Åed Medical Language System (UMLS). We propose a general, novel method for exploiting such resources via weight sharing. Prior work on weight sharing in neural networks has considered it largely as a means of model compres- sion. In contrast, we treat weight shar- ing as a Ô¨Çexible mechanism for incorpo- rating prior knowledge into neural models. We show that this approach consistently yields improved performance on classiÔ¨Å- cation tasks compared to baseline strate- gies that do not exploit weight sharing. 1We have proposed a novel method for incorporat- ing prior semantic knowledge into neural models via stochastic weight sharing. We have showed it generally improves text classiÔ¨Åcation performance vs. model variants which do not exploit external resources and vs. an approach based on retroÔ¨Åtting prior to training. In future work, we will inves- tigate generalizing our approach beyond classiÔ¨Å- cation, and to inform weight sharing using other varieties and sources of linguistic knowledge.",1873
1788,Network Science,Albert-L√°szl√≥ Barab√°si,"September 8th, 2020",3D Topology Transformation with Generative Adversarial Networks,http://computationalcreativity.net/iccc20/papers/052-iccc20.pdf," Luca Stornaiuolo, Nima Dehmamy, Albert-L√°szl√≥ Barab√°si, Mauro Martino. (2020). 3D Topology Transformation with Generative Adversarial Networks ICCC, 461-468. http://computationalcreativity.net/iccc20/papers/052-iccc20.pdf","Generation and transformation of images and videos using artiÔ¨Åcial intelligence have Ô¨Çourished over the past few years. Yet, there are only a few works aim- ing to produce creative 3D shapes, such as sculptures. Here we show a novel 3D-to-3D topology transfor- mation method using Generative Adversarial Networks (GAN). We use a modiÔ¨Åed pix2pix GAN, which we call Vox2Vox, to transform the volumetric style of a 3D ob- ject while retaining the original object shape. In par- ticular, we show how to transform 3D models into two new volumetric topologies - the 3D Network and the Ghirigoro. We describe how to use our approach to con- struct customized 3D representations. We believe that the generated 3D shapes are novel and inspirational. Fi- nally, we compare the results between our approach and a baseline algorithm that directly convert the 3D shapes, without using our GAN.and Future Direction In this paper, we presented a novel 3D-to-3D topology trans- fer paradigm based on transformations in 3D space. In particular, we built a 3D conditional GAN, Vox2Vox, that performs volumetric transformations to modify the internal structure of any 3D object, while maintaining its overall shape. We described our complete pipeline to apply our ap- proach to two different topologies: the 3D Network and the Ghirigoro. The results obtained by employing our method- ology are novel and inspirational. We compared the out- puts of the pipeline while using or not the 3D-cGAN and found that using the Vox2Vox output as a prior distribution results in much nicer outcomes where features are placed in strategic positions in the 3D shape preserving its struc- tural features. As a future direction, we plan to improve the 3D-to-3D topology transfer by given also the topology as a conditional input of the generative network. To do that, the machine learning algorithm has to learn itself the abstraction of the topology from a given 3D object.",1874
1789,Robotics,Robert Platt,"February 27th, 2023",Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction,https://openreview.net/pdf?id=_2bDpAtr7PI," David Klee, Ondrej Biza, Robert Platt, Robin Walters. (2023). Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction ICLR. https://openreview.net/pdf?id=_2bDpAtr7PI","Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in SO(3). How- ever, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages SO(3) equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at https://dmklee.github.io/image2sphere. 1In this work, we present the first method to leverage SO(3)-equivariance for predicting distributions over 3D rotations from single images. Our method is better suited than regression methods at handling unknown object symmetries, generates more expressive distributions than methods using parametric families of multi-modal distributions while requiring fewer samples than an implicit modeling approach. We demonstrate state-of-the-art performance on the challenging PASCAL3D+ dataset composed of real images. One limitation of our work is that we use a high maximum frequency, L, in the spherical convolution operations to have higher resolution predictions. Because the number of operations in a spherical convolution is quadratic in L, it may be impractical for applications where more spherical convolutions are required. 9 Published as a conference paper at ICLR 2023",1875
1790,Robotics,Christopher Amato,"February 20th, 2023",Improving Deep Policy Gradients with Value Function Search,https://openreview.net/pdf?id=6qZC7pfenQm," Enrico Marchesini, Christopher Amato. (2023). Improving Deep Policy Gradients with Value Function Search ICLR. https://openreview.net/pdf?id=6qZC7pfenQm","Deep Policy Gradient (PG) algorithms employ value networks to drive the learn- ing of parameterized policies and reduce the variance of the gradient estimates. However, value function approximation gets stuck in local optima and struggles to fit the actual return, limiting the variance reduction efficacy and leading policies to sub-optimal performance. This paper focuses on improving value approxima- tion and analyzing the effects on Deep PG primitives such as value prediction, variance reduction, and correlation of gradient estimates with the true gradient. To this end, we introduce a Value Function Search that employs a population of perturbed value networks to search for a better approximation. Our framework does not require additional environment interactions, gradient computations, or ensembles, providing a computationally inexpensive approach to enhance the su- pervised learning task on which value networks train. Crucially, we show that improving Deep PG primitives results in improved sample efficiency and policies with higher returns using common continuous control benchmark domains. 1VFS introduces a two-scale perturbation operator voted to diversify a population of value networks to (i) explore local variations of current critics‚Äô predictions and (ii) allow to explore diversified value functions to escape from local optima. The practical results of such components have been investigated with additional experiments that also motivate the improvement in sample efficiency and performance of VFS-based algorithms in a range of standard continuous control benchmarks. Our findings suggest that improving fundamental Deep PG primitives translates into higher-performing policies and better sample efficiency. 9 Published as a conference paper at ICLR 2023 7",1876
1791,Robotics,Christopher Amato,"May 5th, 2018",Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems,http://www.ccs.neu.edu/home/camato/publications/ICRA2018.pdf," Nghia Hoang, Yuchen Xiao, Kavinayan Sivakumar, Christopher Amato and Jonathan P. How. In the Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA-18), May 2018.","‚Äî A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self- interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with Ô¨Åxed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach Ô¨Årst optimizes a set of stratagems that represent these best responses. These optimized stratagems are then inte- grated into a uniÔ¨Åed policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.This paper introduces a novel near-optimal adversarial pol- icy switching algorithm for decentralized, non-cooperative multi-agent systems. Unlike the existing works in literature which are mostly limited to simple decision-making sce- narios where a single agent plans its best response against an adversary whose strategy is speciÔ¨Åed a priori under reasonable assumptions, we investigate instead a class of multi-agent scenarios where multiple robots need to operate independently in collaboration with their teammates to act effectively against adversaries with changing strategies. To achieve this, we Ô¨Årst optimize a set of basic stratagems that each is tuned to respond optimally to a pre-identiÔ¨Åed basic tactic of the adversaries. The stratagems are then integrated into a uniÔ¨Åed policy which performs near-optimally against B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (a) (b) (c) B3 B2 B1 R1 R2 B1 B3 B2 R1 R2 B1 B3 B2 R1 R2 (d) (e) (f) Fig. 6: Image excerpts from a video demo showing (1) a team of 3 allied (blue) robots (B1,B2 and B3) that implement the optimized stratagem produced by our framework (Section III) to compete against (2) an opposing team of 2 opponent (red) robots (R1 and R2) which implement the hand-coded tactics DL and DR (see Section VI-A), respectively: (a) B1,B2 and B3 decide to invade the opposition territory; (b) B1 and B3 decide to attack the center while B2 decides to take the left Ô¨Çank of the opposition; (c) B2 passes through R1‚Äôs defense while B1 takes an interesting position to block R2 so that B3 can pass through its defense; (d) B1 and B2 detect the Ô¨Çag and mount a pincer attack; (e) R2 arrives to defend the Ô¨Çag and B2 retreats to avoid getting tagged; and (f) without noticing B1 from behind, R2 continues its DR patrol, thus losing the Ô¨Çag to B1. any high-level strategies of the adversaries that switches between their basic tactics. The near-optimality of our pro- posed framework can be established in both theoretical and empirical settings with interesting and consistent results. We believe this is a signiÔ¨Åcant step towards bridging the gap between theory and practice in multi-agent research.",1877
1792,Robotics,Christopher Amato,"August 4th, 2017",COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs,http://www.ccs.neu.edu/home/camato/publications/cogdice_ijcai.pdf," COG-DICE: An Algorithm for Solving Continuous-Observation Dec-POMDPs. Madison Clark-Turner and Christopher Amato. In the Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), August 2017","The decentralized partially observable Markov de- cision process (Dec-POMDP) is a powerful model for representing multi-agent problems with de- centralized behavior. Unfortunately, current Dec- POMDP solution methods cannot solve problems with continuous observations, which are common in many real-world domains. To that end, we present a framework for representing and gener- ating Dec-POMDP policies that explicitly include continuous observations. We apply our algorithm to a novel tagging problem and an extended version of a common benchmark, where it generates poli- cies that meet or exceed the values of equivalent discretized domains without the need for Ô¨Ånding an adequate discretization. 1This paper presented, for the Ô¨Årst time, an algorithm that gen- erates joint policies for Dec-POMDPs with continuous ob- servations. We presented both a discrete-observation ver- sion of the algorithm, which is applicable in domains with a large number of discrete observations, and a continuous- observation version. This method is broadly applicable as many real-world domains have large or continuous observa- tion spaces. COG-DICE has been successful in generating joint policies for both a novel and a preexisting problem and has highlighted the negative impacts that inappropriate dis- cretization can have on joint policy structure and value. For future work, we are interested in extending this work to high- dimensional observation spaces by exploring other (nonlin- ear) divisions and optimizing the algorithm parameters by ei- ther integrating these optimizations into the algorithm or pos- sibly building on previous work on Bayesian non-parametrics [Liu et al., 2015].",1878
1793,Robotics,Robin Walters,"February 27th, 2023",Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction,https://openreview.net/pdf?id=_2bDpAtr7PI," David Klee, Ondrej Biza, Robert Platt, Robin Walters. (2023). Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction ICLR. https://openreview.net/pdf?id=_2bDpAtr7PI","Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in SO(3). How- ever, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages SO(3) equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at https://dmklee.github.io/image2sphere. 1In this work, we present the first method to leverage SO(3)-equivariance for predicting distributions over 3D rotations from single images. Our method is better suited than regression methods at handling unknown object symmetries, generates more expressive distributions than methods using parametric families of multi-modal distributions while requiring fewer samples than an implicit modeling approach. We demonstrate state-of-the-art performance on the challenging PASCAL3D+ dataset composed of real images. One limitation of our work is that we use a high maximum frequency, L, in the spherical convolution operations to have higher resolution predictions. Because the number of operations in a spherical convolution is quadratic in L, it may be impractical for applications where more spherical convolutions are required. 9 Published as a conference paper at ICLR 2023",1879
1794,Robotics,Robin Walters,"June 8th, 2022",Integrating Symmetry into Differentiable Planning with Steerable Convolutions,https://openreview.net/pdf?id=n7CPzMPKQl," Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2023). Integrating Symmetry into Differentiable Planning with Steerable Convolutions ICLR. https://openreview.net/pdf?id=n7CPzMPKQl","In this paper, we study a principled approach on incorporating group symme- try into end-to-end differentiable planning algorithms and explore the benefits of symmetry in planning. To achieve this, we draw inspiration from equivariant con- volution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant op- erator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navi- gation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2- DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN. 1, SymVIN and SymGPPN generalize better to different map sizes, com- pared to all non-equivariant baselines. Remark. In summary, our results show that the Sym- Plan models demonstrate end-to-end planning and learn- ing ability, potentially enabling further applications to other tasks as a differentiable component for planning. Additional results and ablation studies are in Appendix H. 7 DISCUSSION In this work, we study the symmetry in the 2D path-planning problem, and build a framework using the theory of steerable CNNs to prove that value iteration in path planning is actually a form of steer- able CNN (on 2D grids). Motivated by our theory, we proposed two symmetric planning algorithms that provided significant empirical improvements in several path-planning domains. Although our focus in this paper has been on Z2, our framework can potentially generalize to path planning on higher-dimensional or even continuous Euclidean spaces (Weiler et al., 2018; Brandstetter et al., 2021), by using equivariant operations on steerable feature fields (such as steerable convolutions, pooling, and point-wise non-linearities) from steerable CNNs. We hope that our SymPlan frame- work, along with the design of practical symmetric planning algorithms, can provide a new pathway for integrating symmetry into differentiable planning. 9 Published as a conference paper at ICLR 2023 8 ACKNOWLEDGEMENT This work was supported by NSF Grants #2107256 and #2134178. R. Walters is supported by The Roux Institute and the Harold Alfond Foundation. We also thank the audience from previous poster and talk presentations for helpful discussions and anonymous reviewers for useful feedback. 9 REPRODUCIBILITY STATEMENT We provide additional details in the appendix. We also plan to open source the codebase. We briefly outline the appendix below. 1. Additional Discussion 2. Background: Technical background and concepts on steerable CNNs and group CNNs 3. Method: we provide full details on how to reproduce it 4. Theory/Framework: we provide the complete version of the theory statements 5. Proofs: this includes all proofs 6. Experiment / Environment / Implementation details: useful details for reproducibility 7. Additional results 10 Published as a conference paper at ICLR 2023",1880
1795,Robotics,Lawson Wong,"June 8th, 2022",Integrating Symmetry into Differentiable Planning with Steerable Convolutions,https://openreview.net/pdf?id=n7CPzMPKQl," Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong. (2023). Integrating Symmetry into Differentiable Planning with Steerable Convolutions ICLR. https://openreview.net/pdf?id=n7CPzMPKQl","In this paper, we study a principled approach on incorporating group symme- try into end-to-end differentiable planning algorithms and explore the benefits of symmetry in planning. To achieve this, we draw inspiration from equivariant con- volution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant op- erator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navi- gation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2- DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN. 1, SymVIN and SymGPPN generalize better to different map sizes, com- pared to all non-equivariant baselines. Remark. In summary, our results show that the Sym- Plan models demonstrate end-to-end planning and learn- ing ability, potentially enabling further applications to other tasks as a differentiable component for planning. Additional results and ablation studies are in Appendix H. 7 DISCUSSION In this work, we study the symmetry in the 2D path-planning problem, and build a framework using the theory of steerable CNNs to prove that value iteration in path planning is actually a form of steer- able CNN (on 2D grids). Motivated by our theory, we proposed two symmetric planning algorithms that provided significant empirical improvements in several path-planning domains. Although our focus in this paper has been on Z2, our framework can potentially generalize to path planning on higher-dimensional or even continuous Euclidean spaces (Weiler et al., 2018; Brandstetter et al., 2021), by using equivariant operations on steerable feature fields (such as steerable convolutions, pooling, and point-wise non-linearities) from steerable CNNs. We hope that our SymPlan frame- work, along with the design of practical symmetric planning algorithms, can provide a new pathway for integrating symmetry into differentiable planning. 9 Published as a conference paper at ICLR 2023 8 ACKNOWLEDGEMENT This work was supported by NSF Grants #2107256 and #2134178. R. Walters is supported by The Roux Institute and the Harold Alfond Foundation. We also thank the audience from previous poster and talk presentations for helpful discussions and anonymous reviewers for useful feedback. 9 REPRODUCIBILITY STATEMENT We provide additional details in the appendix. We also plan to open source the codebase. We briefly outline the appendix below. 1. Additional Discussion 2. Background: Technical background and concepts on steerable CNNs and group CNNs 3. Method: we provide full details on how to reproduce it 4. Theory/Framework: we provide the complete version of the theory statements 5. Proofs: this includes all proofs 6. Experiment / Environment / Implementation details: useful details for reproducibility 7. Additional results 10 Published as a conference paper at ICLR 2023",1881
1796,Software Engineering,Jan Vitek,"November 15th, 2017",Correctness of Speculative Optimizations with Dynamic Deoptimization,https://arxiv.org/pdf/1711.03050.pdf," Olivier Fluckiger, Gabriel Scherer, Ming-Ho Yee, Aviral Goel, Amal Ahmed and Jan Vitek","machine state. The relation C AœÑ ‚àí‚ÜíC‚Ä≤ specifies that executing the next instruction may result in the configuration C‚Ä≤. The action AœÑ indicates whether this reduction is observable: it is either the silent action, written œÑ, an I/O action read lit or print lit, or stop. We write C T ‚àí‚Üí‚àóC‚Ä≤ when there are zero or more steps from C to C‚Ä≤. The trace T is a list of non-silent actions in the order in which they appeared. Actions are defined in Figure 16, and the full reduction relation is given in Figure 17. Most rules get the current instruction, I(L), perform an operation, and advance to the next label, referred to by the shorthand (L +1). The read lit and print lit actions represent observable I/O operations. They are emitted by Read and Print in Figure 17. The action read lit on the read x transition may be any literal value. This is the only reduction rule that is non-deterministic. Note that the relation C ‚àí‚Üí‚àóC‚Ä≤, containing only sequences of silent reductions, is deterministic. The Proceedings of the ACM on Programming Languages, Vol. 2, No. POPL, Article 49. Publication date: January 2018. Correctness of Speculative Optimizations 49:15 A ::= I/O action | print lit | read lit | stop AœÑ ::= | A | œÑ silent label T ::= action trace | (empty trace) | A | AœÑ | T A | T AœÑ [Refl] C ‚àí‚Üí‚àóC [SilentCons] C T ‚àí‚Üí‚àóC‚Ä≤ C‚Ä≤ œÑ ‚àí‚ÜíC‚Ä≤‚Ä≤ C T ‚àí‚Üí‚àóC‚Ä≤‚Ä≤ [ActionCons] C T ‚àí‚Üí‚àóC‚Ä≤ C‚Ä≤ A ‚àí‚ÜíC‚Ä≤‚Ä≤ C T A ‚àí‚Üí‚àóC‚Ä≤‚Ä≤ Fig. 16. Actions and traces. stop reduction emits the stop transition, and also produces a configuration with no instructions, ‚àÖ. This is a technical device to ensure that the resulting configuration is stuck. A program with a silent loop has a different trace from a program that halts. Given a program P, let start(P) be its starting configuration, and reachable(P) be the set of configurations reachable from it; they are all the states that may be encountered during a valid run of P. [StartConf] I def= P(main, active) L def= start(I) start(P) def= ‚ü®P I L ‚àÖ‚àÖ‚àÖ‚ü© reachable(P) def= {C | ‚àÉT, start(P) T ‚àí‚Üí‚àóC} 5.3 Equivalence of Configurations: Bisimulation We use weak bisimulation to prove equivalence between configurations. The idea is to define, for each program transformation, a correspondence relation R between configurations over the source and transformed programs. We show that related configurations have the same observable behavior, and reducing them results in configurations that are themselves related. Two programs are equivalent if their starting configurations are related. Definition 5.1 (Weak Bisimulation). Given programs P1 and P2 and relation R between the config- urations of P1 and P2, R is a weak simulation if for any related states (C1, C2) ‚ààR and any reduction C1 AœÑ ‚àí‚ÜíC‚Ä≤ 1 over P1, there exists a reduction C2 AœÑ ‚àí‚Üí‚àóC‚Ä≤ 2 over P2 such that (C‚Ä≤ 1, C‚Ä≤ 2) are themselves related by R. Reduction over P2 is allowed to take zero or more steps, but not to change the trace. In other words, the diagram on the left below can always be completed into the diagram on the right. C1 C‚Ä≤ 1 C2 R AœÑ C1 C‚Ä≤ 1 C2 C‚Ä≤ 2 R AœÑ R ‚àó AœÑ R is a weak bisimulation if it is a weak simulation and the symmetric relation R‚àí1 also is‚Äîa reduction from C2 can be matched by CS Speculative optimizations are key to just-in-time optimization of dynamic languages. As these optimizations depend on predicates about the program state, the language implementation must monitor the validity of predicates and be ready to deoptimize the program if a predicate is invalidated. While, many modern compiler rely on this approach, the interplay between optimization and deoptimization often remains opaque. Our contribution is to show that when the predicates and the deoptimization metadata are reified in the program representation, it becomes quite easy to define correct program transformations that are deoptimization aware. In this work we extend the intermediate representation with one new instruction, assume, which plays the double role of checking for the validity of predicates and specifying the actions required to deoptimize the program. Program transformations can inspect both the predicates that are being monitored and the deoptimization metadata and transform them when needed. The formalization presented here is for one particular intermediate language that we hope to be representative of a typical dynamic language. We present a bisimulation proof between multiple versions of the same function, optimized under different assumptions. We formalize deoptimization invariants between versions and show that they enable very simple proofs for standard compiler optimizations, constant folding, unreachable code elimination, and function inlining. We also prove correct three optimizations that are specifically dealing with deoptimizations, namely unrestricted deoptimization, predicate hoisting, and assume composition. There are multiple avenues of future investigation. The optimizations presented here rely on intraprocedural analysis and the granularity of deoptimization is a whole function. If we were to extend this work to interprocedural analysis, it would become much trickier to determine what functions are to be invalidated as a speculation in one function may allow optimizations in many other functions. The current representation forces to check predicates before each use, but some predicates are cheaper to check by monitoring operations that could invalidate them. To do this would require changes to our model as the assume instruction would need to be split between a monitor and a deoptimization point. Lastly, the expressive power of predicates is an interesting question as there is a clear trade-off ‚Äî richer predicates may allow more optimizations but are likely to be costlier to monitor.",1882
1797,Systems and Networking,Gene Cooperman,"June 1st, 2019",MANA for MPI: MPI-Agnostic Network-Agnostic Transparent Checkpointing,http://www.ccs.neu.edu/home/gene/papers/hpdc19.pdf," ""MANA for MPI: MPI-Agnostic Network-Agnostic Transparent Checkpointing"", Rohan Garg, Gregory Price, and Gene Cooperman, Proc. of 28th Int. Symp. on High Performance Parallel and Distributed Computing, Phoenix, AZ, USA, ACM, pp.¬†49--60, June, 2019","Transparently checkpointing MPI for fault tolerance and load bal- ancing is a long-standing problem in HPC. The problem has been complicated by the need to provide checkpoint-restart services for all combinations of an MPI implementation over all network interconnects. This work presents MANA (MPI-Agnostic Network- Agnostic transparent checkpointing), a single code base which sup- ports all MPI implementation and interconnect combinations. The agnostic properties imply that one can checkpoint an MPI appli- cation under one MPI implementation and perhaps over TCP, and then restart under a second MPI implementation over InfiniBand on a cluster with a different number of CPU cores per node. This tech- nique is based on a novel split-process approach, which enables two separate programs to co-exist within a single process with a single address space. This work overcomes the limitations of the two most widely adopted transparent checkpointing solutions, BLCR and DMTCP/InfiniBand, which require separate modifications to each MPI implementation and/or underlying network AP2 MANA: DESIGN AND IMPLEMENTATION Multiple aspects of the design of MANA are covered in this sec- tion. Section 2.1 discusses the design for supporting a split-process. Section 2.2 discusses the need to save and restore persistent MPI opaque objects, such as communicators, groups and topologies. Section 2.3 briefly discusses the commonly used algorithm to drain point-to-point MPI messages in transit prior to intiaiting a check- point. Sections 2.4 and 2.5 present a new two-phase algorithm (Algorithm 2), which enables checkpointing in-progress MPI collec- tive communication calls in a fully agnostic environment. Finally, Sections 2.6 and 2.7 present details of the overall implementation of MANA. 2.1 Upper and Lower Half: Checkpointing with an Ephemeral MPI Library In this section, we define the lower half of a split-process as the memory associated with the MPI library and dependencies, includ- ing network libraries. The upper half is the remaining Linux process memory associated with the MPI application‚Äôs code, data, stack, and other regions (e.g., environment variables). The terms lower half and upper half are in analogy with the upper and lower half of a device driver in an operating system kernel. This separation into lower and upper half does not involve additional threads or processes. Instead, it serves primarily to tag memory so that only upper half memory will be saved or restored during checkpoint and restart. Section 2.6 describes an additional ‚Äúhelper thread‚Äù, but that thread is active only during checkpoint and restart. Libc and other system libraries may appear in both the lower half as a dependency of the MPI libraries, and the upper half as an independent dependency of the MPI application. This split-process approach allows MANA to balance two con- flicting objectives: a shared address space; and isolation of upper and lower halves. The isolation allows MANA to omit the lower half memory (an ‚Äúephemeral‚Äù MPI library) when it creates a checkpoint image file. The shared address space allows the flow of control to pass efficiently from the upper-half MPI application to the lower- half MPI library through standard C/Fortran calling conventions, including call by reference. As previously noted, Remote Produce Calls (RPC) are not employed. Isolation is needed so that at checkpoint time, the lower half can be omitted from the checkpoint image, and at the time of restart, replaced with a small ‚Äúbootstrap‚Äù MPI program with new MPI li- braries. The bootstrap program calls MPI_Init() and each MPI process discovers its MPI rank via a call to MPI_Rank(). The mem- ory present at this time becomes the lower half. The MPI process then restores the upper-half memory from a checkpoint image file corresponding to the MPI rank id. Control is then transferred back to the upper-half MPI application, and the stack in the lower half is never used again. Shared address space is needed for efficiency. A dual-process proxy approach was explored in [16, Section IV.B] and in [35, Sec- tion IV.A]. The former work reported a 6% runtime overhead for real-world CUDA applications, and the latter work reported run- time overheads in excess of 20% for some OpenCL examples from the NVIDIA SDK 3.0. In contrast, Section 3 reports runtime over- heads less than 2% for MANA under older Linux kernels, and less than 1% runtime overhead for recent Linux kernels. Discarding the lower half greatly simplifies the task of check- pointing. By discarding the lower half, the MPI application in the upper half appears as an isolated process with no inter-process communication. Therefore, a single-process checkpointing package can create a checkpoint image. A minor inconvenience of this split-process approach is that calls to sbrk() will cause the kernel to extend the process heap in the data segment. Calls to sbrk() can be caused by invocations of malloc(). Since the kernel has no concept of a split-process, the kernel may choose, for example, to extend the lower half data segment after restart since that corresponds to the original program seen by the kernel before the upper-half memory is restored. MANA resolves this by interposing on calls to sbrk() in the upper-half libc, and then inserts calls to mmap() to extend the heap of the upper-half. Finally, MANA employs coordinated checkpointing, and a check- point coordinator sends messages to each MPI rank at the time of checkpoint (see Sections 2.3, 2.4 and 2.5). MPI opaque objects (communicators, groups, topologies) are detected on creation and restored on restart (see Section 2.2). This is part of a broader strat- egy by which MPI calls with persistent effects (such as creation of these opaque objects) are recorded during runtime and replayed on restart. 2.2 Checkpointing MPI Communicators, Groups, and Topologies An MPI application can create communication subgroups and topolo- gies to group processes for ease of programmability and efficient communication. MPI implementations provide opaque handles to the application as a reference to a communicator object or group. MANA interposes on all calls that refer to these opaque identi- fiers, and virtualizes the identifiers. At runtime, MANA records any MPI calls that can modify the MPI communication state, such as MPI_Comm_create, MPI_Group_incl, etc. On restart, MANA recre- ates the MPI communicator state by replaying the MPI calls using a new MPI library. The runtime virtualization of identifiers allows the application to continue running with consistent handles across checkpoint-restart. A similar checkpointing strategy also works for other opaque identifiers, such as, MPI derived datatypes, etc. 2.3 Checkpointing MPI Point-to-Point Communication Capturing the state of MPI processes requires quiescing the process threads, and preserving the process memory to a file on the disk. However, this alone is not sufficient to capture a consistent state of the computation. Any MPI messages sent but not yet received at the time of quiescing processes must also be saved as part of the checkpoint image. MANA employs a variation of an all-to-all bookmark exchange algorithm to reach this consistent state. LAM/MPI [31] demon- strated the efficacy of a such a Chandy/Lamport [11] algorithm for checkpointing MPI applications. Hursey et al. [22] lifted this mechanism out of interconnect drivers and into the MPI library. MANA further lifts this mechanism outside the MPI library, and into a virtualized MPI API. An early prototype of MANA demonstrated a na√Øve application of this bookmark exchange algorithm was sufficient for handling pre-checkpoint draining for point-to-point communication; how- ever, collective-communication calls may have MPI implementation effects that can determine when it is ‚Äúsafe‚Äù to begin a checkpoint. For this reason, a na√Øve application to the entire API was insufficient to ensure correctness. This is discussed in Section 2.4. 2.4 Checkpointing MPI Collectives: Overview The MPI collective communications primitive involves communi- cation amongst all or a program-defined subset of MPI ranks (as specified by the MPI communicator argument to the function). The internal behavior of collectives are specific to each MPI implemen- tation, and so it is not possible to make guarantees about their behavior, such as when and how messages are exchanged when ranks are waiting for one or more ranks to enter the collective. In prior work [22, 31], internal knowledge of the MPI library state was required to ensure that checkpointing would occur at a ‚Äúsafe‚Äù state. In particular, Hursey et al. [22] required interconnect drivers be classified as ‚Äúcheckpoint-friendly‚Äù or ‚Äúcheckpoint-unfriendly‚Äù, changing behavior based on this classification. As MANA lives outside the MPI library, a naive application of the Hursey et al. algorithm can have effects that cross the upper and lower half boundaries of an MPI rank (for example, when shared memory is being used for MPI communication). This problem occurs because of the truly network-agnostic trait of MANA. As MANA has no concept of transport level constructs, it cannot determine what ‚Äúsafe‚Äù means in context of collectives. To correct this, MANA‚Äôs support for collective communication requires it to maintain the following invariant: No checkpoint must take place while a rank is inside a collective communication call. There exists one exception to this rule: a trivial barrier. A trivial barrier is a simple call to MPI_Barrier(). This call produces no side effects on an MPI rank, and so it can be safely interrupted during checkpoint, and then re-issued when restarting the MPI application. This is possible due to the split-process architecture of MANA, as trivial barrier calls occur exclusively in the lower half, which is discarded and replaced across checkpoint and restart. MANA leverages this exception to build a solution for all other collective calls. As we discuss MANA‚Äôs algorithm for checkpointing collective calls, we take into consideration three subtle, but important, con- cerns. Challenge I (consistency): In the case of a single MPI collec- tive communication call, there is a danger that rank A will see a request to checkpoint before entering the collective call, while rank B will see the same request after entering the collective call, in violation of MANA‚Äôs invariant. Both ranks might report that they are ready to checkpoint, and the resulting inconsistent snapshot will create problems during restart. This situation could arise, for example, if the mes- sage from the checkpoint coordinator to rank B is excessively delayed in the network. To resolve this, MANA introduces a two-pass protocol in which the coordinator makes a re- quest (sends an intend-to-checkpoint message), each MPI rank acknowledges with its current state, and finally the coordinator posts a checkpoint request (possibly preceded by extra iterations). Challenge II (progress and latency): Given the aforementioned solution for consistency, long delays may occur before a checkpoint request can be serviced. It may be that rank A has entered the barrier, and rank B will require several hours to finish a task before entering the barrier. Hence, the two-pass protocol may create unacceptable delays before a checkpoint can be taken. Algorithm 2 addresses this by introducing a trivial barrier prior to the collective communication call. We refer to this as a two-phase algorithm since each collective call is now replaced by a wrapper function that invokes a trivial barrier call (phase 1) followed by the original collective call (phase 2). Challenge III (multiple collective calls): Until now, it was assumed that at most one MPI collective communication call was in progress at the time of checkpoint. It may happen that there are multiple ongoing collective calls. During the time that some MPI ranks exit from a collective call, it may happen that MPI ranks associated with an independent col- lective call have left the MPI trivial barrier (phase 1) and have now entered the real collective call (phase 2). As a result, servicing a checkpoint may be excessive delayed. To solve this, we introduce an intend-to-checkpoint message, such that no ranks will be allowed to enter phase 2, and extra itera- tions will be inserted into the request-acknowledge protocol between coordinator and MPI rank. 2.5 Checkpointing MPI Collectives: Detailed Algorithm Here we present a single algorithm (Algorithm 2) for checkpointing MPI collectives which contains the elements described in Section 2.4: a multi-iteration protocol; and a two-phase algorithm incorporating a trivial barrier before any collective communication call. From the viewpoint of an MPI application, any call to an MPI collective communication function is interposed on by a wrapper function, as shown in Algorithm 1. Algorithm 1 Two-Phase collective communication wrapper. (This wrapper function interposes on all MPI collective com- munication functions invoked by an MPI application) 1: function Collective Communication Wrapper 2: # Begin Phase 1 3: Call MPI_Barrier() # trivial barrier 4: # Begin Phase 2 5: Call original MPI collective communication function 6: end function Recall that a trivial barrier is an extra call to MPI_Barrier() prior to a collective call. A collective MPI call can intuitively be divided into two parts: the participating MPI ranks ‚Äúregister‚Äù themselves as ready for the collective communication; and then the ‚Äúwork‚Äù of communication is carried out. Where the time for the collective communication calls of an MPI program is significant, it is typically due to significant ‚Äúwork‚Äù in the second part of the calls. Adding a trivial barrier requires the MPI ranks to register themselves once for the trvial barrier (but no work is involved), and then register themselves again for the actual MPI collective communication. The overhead due to registering twice is tiny in practice. Evidence for this can be seen in the experiments in Section 3.2.3, which show small overhead. The purpose of Algorithm 1 is to enforce the following extension of the invariant presented in Section 2.4: No checkpoint must take place while a rank is inside the collective communication call (Phase 2) of a wrapper function for collective communication (Algorithm 1). We formalize this with the following theorem, which guarantees Algorithm 2 satisfies this invariant. Theorem 1. Under Algorithm 2, an MPI rank is never inside a collective communication call when a checkpoint message is received from the checkpoint coordinator. The proof of this theorem is deferred until the end of this sub- section. We begin the path to this proof by stating an axiom that serves to define the concept of a barrier. Axiom 1. For a given invocation of an MPI barrier, it never happens that a rank A exits from the barrier before another rank B enters the barrier under the ‚Äúhappens-before‚Äù relation. Next, we present the following two lemmas. Checkpoint Coordinator Rank A Rank B Barrier (1) (3) (2) (4) Figure 1: Fundamental ‚Äúhappens-before‚Äù relation in commu- nication between the checkpoint coordinator and the MPI ranks involved in an MPI barrier. Lemma 1. For a given MPI barrier, if the checkpoint coordinator sends a message to each MPI rank participating in the barrier, and if at least one of the reply messages from the participating ranks reports that its rank has exited the barrier, then the MPI coordinator can send a second message to each participating rank, and each MPI rank will reply that it has entered the barrier (and perhaps also exited the barrier). Proof. We prove the lemma by contradiction. Suppose that the lemma does not hold. Figure 1 shows the general case in which this happens. At event 4, the checkpoint coordinator will conclude that event 1 (rank A has exited the MPI barrier) happened before event 2 (the first reply by each rank), which happened before event 3 (in which rank B has not yet entered the barrier). But this contradicts Axiom 1. Therefore, our assumption is false, and the lemma does indeed hold. ‚ñ° Lemma 2. Recall that an MPI collective communication wrapper makes a call to a trivial barrier and then makes an MPI collective communication call. For a given invocation of an MPI collective com- munication wrapper, we know that one of four cases must hold: (a) an MPI rank is in the collective communication call, and all other ranks are either in the call, or have exited; (b) an MPI rank is in the collective communication call, and no rank has exited, and every other rank has at least entered the trivial barrier (and possibly proceeded further); (c) an MPI rank is in the trivial barrier and no other rank has exited (but some may not yet have entered the trivial barrier); (d) either no MPI rank has entered the trivial barrier, or all MPI ranks have exited the MPI collective communication call. Proof. The proof is by repeated application of Lemma 1. For case a, if an MPI rank is in the collective communication call and another rank has exited the collective call, then Lemma 1 says that there cannot be any rank that has not yet entered the collective call. For case b, note that if an MPI rank is in the collective communi- cation call, then that rank has exited the trivial barrier. Therefore, by Lemma 1, all other ranks have at least entered the trivial barrier. Further, we can assume that no ranks that have exited the collec- tive call, since we would otherwise be in case a, which is already accounted for. For case c, note that if an MPI rank is in the trivial barrier and no rank has exited the trivial barrier, then Lemma 1 says that there cannot be any rank that has not yet entered the trivial barrier. Finally, if we are not in case a, b, or c, then the only remaining possibility is case d: all ranks have not yet entered the trivial barrier or all ranks have exited the collective call. ‚ñ° Algorithm 2 Two-Phase algorithm for deadlock-free check- pointing of MPI collectives 1: Messages: {intend-to-checkpoint, extra-iteration, do-ckpt} 2: MPI states: {ready, in-phase-1, exit-phase-2} 3: Process Checkpoint Coordinator do 4: function Begin Checkpoint 5: send intend-to-ckpt msg to all ranks 6: receive responses from each rank 7: while some rank in state exit-phase-2 do 8: send extra-iteration msg to all ranks 9: receive responses from each rank 10: end while 11: send do-ckpt msg to all ranks 12: end function 13: Process MPI Rank do 14: upon event intend-to-ckpt msg or extra-iteration msg do 15: if not inCollectiveWrapper then 16: reply to ckpt coord: state ‚Üêready 17: end if 18: if inCollectiveWrapper and in Phase 1 then 19: reply to ckpt coord: state ‚Üêin-phase-1 20: end if 21: if inCollectiveWrapper and in Phase 2 then 22: # guaranteed ckpt coord won‚Äôt request ckpt here 23: finish executing coll. comm. call 24: reply to ckpt coord: state ‚Üêexit-phase-2 25: # ckpt coord can request ckpt after this 26: set state ‚Üêready 27: end if 28: continue, but wait before next coll. comm. call 29: upon event do-ckpt msg do 30: # guaranteed now that no rank is in phase 2 during ckpt 31: do local checkpoint for this rank 32: # all ranks may now continue executing 33: if this rank is waiting before coll. comm. call then 34: unblock this rank and continue executing 35: end if We now continue with the proof of the main theorem (Theo- rem 1), which was deferred earlier. Proof. (Proof of Theorem 1 for Algorithm 2.) Lemma 2 states that one of four cases must hold in a call by MANA to an MPI collective communication wrapper. We wish to exclude the possibility that an MPI rank is in the collective communication call (case a or b of the lemma) when the checkpoint coordinator invokes a checkpoint. In Algorithm 2, assume that the checkpoint coordinator has sent an intend-to-ckpt message, and has not yet sent a do-ckpt message. An MPI rank will either reply with state ready or in-phase-1 (show- ing that it is not in the collective communication call and that it will stop before entering the collective communication call), or else it must be in Phase 2 of the wrapper (potentially within the collective communication call), and it will not reply to the coordinator until exiting the collective call. ‚ñ° Theorem 2. Under Algorithm 2, deadlock will never occur. Further, the delay between the time when all ranks have received the intend- to-checkpoint message and the time when the do-ckpt message has been sent is bounded by the maximum time for any individual MPI rank to enter and exit the collective communication call, plus network message latency. Proof. The algorithm will never deadlock, since each rank must either make progress based on the normal MPI operation or else it stops before the collective communication call. If any rank replies with the state exit-phase-2, then the checkpoint coordinator will send an additional extra-iteration message. So, at the time of check- point, all ranks will have state ready or in-phase-1. Next, the delay between the time when all ranks have received the intend-to-checkpoint message and the time when the do-ckpt message has been sent is clearly bounded by the maximum time for an individual MPI rank to enter and exit the collective commu- nication call, plus the usual network message latency. This is the case since once the intend-to-checkpoint message is received, no MPI rank may enter the collective communication call. So, upon re- ceiving the intend-to-checkpoint message, either the rank is already in Phase 2 or else it will remain in Phase 1. ‚ñ° Implementation of Algorithm 2: At the time of process launch for an MPI rank, a separate checkpoint helper thread is also in- jected into each rank. This thread is responsible for listening to checkpoint-related messages from a separate coordinator process and then responding. This allows the MPI rank to asynchronously process events based on messages received from the checkpoint coordinator. Furthermore at the time of checkpoint, the existing threads of the MPI rank process are quiesced (paused) by the helper thread, and the helper thread carries out the checkpointing require- ments, such as copying the upper-half memory regions to stable storage. The coordinator process does not participate in the check- pointing directly. In the implementation, a DMTCP coordinator and DMTCP checkpoint thread [1] are modified to serve as checkpoint coordinator and helper thread, respectively. 2.6 Verification with TLA+/PlusCal To gain further confidence in our implementation for handling collective communication (Section 2.5), we developed a model for the protocol in TLA+ [25] and then used the PlusCal model checker of TLA+ based on TLC [38] to verify Algorithm 2. Specifically, PlusCal was used to verify the algorithm invariants of deadlock- free execution and consistent state when multiple concurrent MPI processes are executing. The PlusCal model checker did not report any deadlocks or broken invariants for our implementation. 2.7 Checkpoint/Restart Package Any single-process checkpointing package could be utilized for the basis of implementing MANA. This work presents a prototype implemented by extending DMTCP [1] and by developing a DMTCP plugin [2]. Cao et al. [9] demonstrated that DMTCP can checkpoint MPI-based HPCG over 32,752 CPU cores (38 TB) in 11 minutes, and MPI-based NAMD over 16,368 cores (10 TB) in 2.6 minutes. DMTCP uses a helper thread inside each application process, and a coordinated checkpointing protocol by using a centralized coor- dinator daemon. Since this was close to the design requirements of MANA, we leveraged this infrastructure and extended the DMTCP coordinator to implement the two-phase algorithm. The same approach could be extended to base MANA on top of a different underlying transparent checkpointing package. For example, one could equally well have modified an existing MPI co- ordinator process to communicate with a custom helper thread in each MPI rank that then invokes the BLCR checkpointing package when it is required to execute the checkpoint. In particular, all sock- ets and other network communication objects are inside the lower half, and so even a single-process or single-host checkpointing package such as BLCR would suffice for this work. 3 EXPERIMENTAL EVALUATION This section seeks to answer the following questions: Q1: What is the runtime overhead of running MPI applications under MANA? Q2: What are the checkpoint and restart overheads of transparent checkpointing of MPI applications under MANA? Q3: Can MANA allow transparent switching of MPI implementa- tions across checkpoint-restart for the purpose of load balancing? 3.1 Setup We first describe the hardware and software setup for MANA‚Äôs evaluation. 3.1.1 Hardware. The experiments were run on the Cori supercom- puter [13] at the National Energy Research Scientific Computing Center (NERSC). As of this writing, Cori is the #12 supercomputer in the Top-500 list [36]. All experiments used the Intel Haswell nodes (dual socket with a 16-core Xeon E5-2698 v3 each) connected via Cray‚Äôs Aries interconnect network. Checkpoints were saved to the backend Lustre filesystem. 3.1.2 Software. Cori provides modules for two implementations of MPI: Intel MPI and Cray MPICH. The Cray compiler (based on an Intel compiler) and Cray MPICH are the recommended way to use MPI, presumably for reasons of performance. Cray MPICH version 3.0 was used for the experiments. 3.1.3 Application Benchmarks. MANA was tested with five real- world HPC applications from different computational science do- mains: (1) GROMACS [4]: Versatile package for molecular dynamics, often used for biochemical molecules. (2) CLAMR [12, 29]: Mini-application for CelL-based Adaptive Mesh Refinement. 90 95 100 Normalized Performance (%) GROMACS miniFE HPCG CLAMR LULESH 1 2 4 8 16 32 0 1 2 4 8 16 32 1 2 4 8 16 32 # MPI Rank(s) (Single node) 1 2 4 8 16 32 1 9 27 Figure 2: Single Node: Runtime overhead under MANA for different real-world HPC benchmarks with an unpatched Linux kernel. (Higher is better.) 90 95 100 Normalized Performance (%) GROMACS miniFE HPCG CLAMR LULESH 2 4 8 16 32 64 0 2 4 8 16 32 64 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) 2 4 8 16 32 64 2 4 8 16 32 64 Figure 3: Multiple Nodes: Runtime overhead under MANA for different real-world HPC benchmarks with an un- patched Linux kernel. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. (Higher is bet- ter.) (3) miniFE [20]: Proxy application for unstructured implicit fi- nite element codes. (4) LULESH [24]: Unstructured Lagrangian Explicit Shock Hy- drodynamics (5) HPCG [14] (High Performance Conjugate Gradient): Uses a variety of linear algebra operations to match a broad set of important HPC applications, and used for ranking HPC systems. 3.2 Runtime Overhead 3.2.1 Real-world HPC Applications. Next, we evaluate the perfor- mance of MANA for real-world HPC applications. It will be shown that the runtime overhead is close to 0 % for miniFE and HPCG, and as much as 2 % for the other three applications. The higher overhead has been tracked down to an inefficiency in the Linux ker- nel [27] in the case of many point-to-point MPI calls (send/receive) with messages of small size. This worst case is analyzed further in Section 3.3, where tests with an optimized Linux kernel show a worst case runtime overhead of 0.6 %. The optimized Linux kernel is based on a patch under review for a future Linux version. Single Node: Since the tests were performed within a larger clus- ter where the network use of other jobs could create congestion, we first eliminate any network-related overhead by running the benchmarks on a single node with multiple MPI ranks, both under 0 1000000 2000000 3000000 4000000 Size (Bytes) 0 5000 10000 15000 20000 Bandwidth (MB/s) Without MANA With MANA (native kernel) With MANA (patched kernel) Figure 4: Point-to-Point Bandwidth under MANA with patched and unpatched Linux kernel. (Higher is better.) MANA and natively (without MANA). This experiment isolates the single-node runtime overhead of MANA by ensuring that all communication among ranks is intra-node. Figure 2 shows the results for the five different real-world HPC applications running on a single node under MANA. Each run was repeated 5 times (including the native runs), and the figure shows the mean of the 5 runs. The absolute runtimes varied from 4.5 min to 15 min, depending on the configuration. The worst case overhead incurred by MANA is 2.1 % in the case of GROMACS (with 16 MPI ranks). In most cases, the mean overhead is less than 2 %. Multiple Nodes: Next, the scaling of MANA across the network is examined for up to 64 compute nodes and with 32 ranks per node (except for LULESH, whose configuration restricts the number of ranks/node based on the number of nodes). Hence, the number of MPI ranks ranges from 64 to 2048. Figure 3 shows the results of five different real-world HPC ap- plications running on multiple nodes under MANA. Each run was repeated 5 times, and the mean of 5 runs is reported. We observe a trend similar to the single node case. MANA imposes an overhead of typically less than 2 %. The highest overhead observed is 4.5 % in the case of GROMACS (512 ranks running over 16 nodes). However, see Section 3.3 where we demonstrate a reduced overhead of 0.6 % with GROMACS. 3.2.2 Memory Overhead. The upper-half libraries were built with mpicc, and hence include additional copies of the MPI library that are not used. However, the upper-half MPI library is never ini- tialized, and so no network library is ever loaded into the upper half. Since a significant portion of the lower half is comprised only of the MPI library and its dependencies, the additional copy of the libraries (with one copy residing in the upper half) imposes a constant memory overhead. This text segment (code region) was 26 MB in all of our experiments on Cori with the Cray MPI library. In addition to the code, the libraries (for example, the networking driver library) in the lower half also allocate additional memory regions (shared memory regions, pinned memory regions, memory- mapped driver regions). We observed that the shared memory re- gions mapped by the network driver library grow in proportion with the number of nodes (up to 64 nodes): from 2 MB (for 2 nodes) to 40 MB for (64 nodes). We expect MANA to have a reduced check- point time compared to DMTCP/InfiniBand [10], as MANA discards these regions during checkpointing, reducing the amount of data that‚Äôs written out to the disk. 0 1000000 2000000 3000000 4000000 Size (Bytes) 0 50 100 150 200 250 300 Latency (¬µs) Without MANA With MANA (a) Point-to-Point Latency 0 200000 400000 600000 800000 1000000 Size (Bytes) 0 50 100 150 200 250 300 Latency (¬µs) Without MANA With MANA (b) Collective MPI_Gather 0 200000 400000 600000 800000 1000000 Size (Bytes) 0 100 200 300 400 500 Latency (¬µs) Without MANA With MANA (c) Collective MPI_Allreduce Figure 5: OSU Micro-benchmarks under MANA. (Results are for two MPI ranks on a single node.) 3.2.3 Microbenchmarks. To dig deeper into the sources for the run- time overhead, we tested MANA with the OSU micro-benchmarks. The benchmarks stress and evaluate the bandwidth and latency of different specific MPI subsystems. Our choice of the specific micro-benchmarks was motivated by the MPI calls commonly used by our real-world MPI applications. Figure 5 shows the results with three benchmarks from the OSU micro-benchmark suite. These benchmarks correspond with the most frequently used MPI subsystems in the set of real-world HPC applications. The benchmarks were run with 2 MPI ranks running on a single compute node. The results show that latency does not suffer under MANA, for both point-to-point and collective communication. (The latency curves for application running under MANA closely follow the curves when the application is run natively.) 3.3 Source of Overhead and Improved Overhead for Patched Linux Kernel All experiments in this section were performed on a single node of our local cluster, where it was possible to directly install a patched Linux kernel in the bare machine. Further investigation revealed two sources of runtime overhead. The larger source of overhead is due to the use of the ‚ÄúFS‚Äù register during transfer of flow of control between the upper and lower half and back during a call to the MPI library in the lower half. The ‚ÄúFS‚Äù register of the x86-64 CPU is used by most compilers to refer to the thread-local variables declared in the source code. The upper and lower half programs each have their own thread-local storage region. Hence, when switching between the upper and lower half programs, the value of the ‚ÄúFS‚Äù register must be changed to point to the correct thread-local region. Most Linux kernels today require a kernel call to invoke a privileged assembly instruction to get or set the ‚ÄúFS‚Äù register. In 2011, Intel Ivy Bridge CPUs introduced a new, unprivileged FSGSBASE assembly instruction for modifying the ‚ÄúFS‚Äù register, and a patch to the Linux kernel [27] is under review to allow other Linux programs to use this more efficient mechanism for managing the ‚ÄúFS‚Äù register. (Other architectures, such as ARM, use unprivileged addressing modes for thread-local variables that do not depend on special constructs, such as the x86 segments.) A second (albeit smaller) source of overhead is the virtualization of MPI communicators and datatypes, and recording of metadata for MPI sends and receives. Virtualization requires a hash table lookup and locks for thread safety. The first and larger source of overhead is then eliminated by using the patched Linux kernel, as discussed above. Point-to-point bandwidth benchmarks were run both with and without the patched Linux kernel (Figure 4). A degradation in runtime performance is seen for MANA for small message sizes (less than 1 MB) in the case of a native kernel. However, the figure shows that the patched kernel yields much reduced runtime overhead for MANA. Note that the Linux kernel community is actively reviewing this patch (currently in its third version), and it is likely to be incorporated in future Linux releases. Finally, we return to GROMACS, since it exhibited a higher runtime overhead (e.g., 2.1 % in the case of 16 ranks) in many cases. We did a similar experiment, running GROMACS with 16 MPI ranks on a single node with the patched kernel. With the patched kernel, the performance degradation was reduced to 0.6 %. 3.4 Checkpoint-restart Overhead In this section, we evaluate MANA‚Äôs performance when checkpoint- ing and restarting HPC applications. Figure 6 shows the checkpoint- ing overhead for five different real-world HPC applications running on multiple nodes under MANA. Each run was repeated 5 times, and the mean of five runs is reported. For each run, we use the fsync system call to ensure the data is flushed to the Lustre backend storage. The total checkpointing data written at each checkpoint varies from 5.9 GB (in the case of 64 ranks of GROMACS running over 2 nodes) to 4 TB (in the case of 2048 ranks of HPCG running over 64 nodes). Note that the checkpointing overhead is proportional to the total amount of memory used by the benchmark. This is also reflected in the size of the checkpoint image per MPI rank. While Figure 6 reports the overall checkpoint time, note that there is significant variation in the write times for each MPI rank during a given run. (The time for one rank to write its checkpoint data can be up to 4 times more than that for 90 % of the other ranks.) This phenomenon of stragglers during a parallel write has also been noted by other researchers [2, 37]. Thus, the overall checkpoint time is bottlenecked by the checkpoint time of the slowest rank. Next, we ask what are the sources of the checkpointing overhead? Does the draining of MPI messages and the two-phase algorithm impose a significant overhead at checkpoint time? 2 4 8 16 32 64 1 5 10 15 20 25 30 35 40 Checkpoint Time (s) (93 MB) (93 MB) (92 MB) (92 MB) (94 MB) (92 MB) GROMACS 2 4 8 16 32 64 (2.0 GB) (1.3 GB) (806 MB) (1.3 GB) (902 MB) (1.3 GB) miniFE 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) (2.0 GB) HPCG 2 4 8 16 32 64 (656 MB) (594 MB) (552 MB) (501 MB) (594 MB) (552 MB) CLAMR 2 4 8 16 32 64 (276 MB) (164 MB) (114 MB) (91 MB) (85 MB) (88 MB) LULESH Figure 6: Checkpointing overhead and checkpoint image sizes under MANA for different real-world HPC bench- marks running on multiple nodes. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. For LULESH, the total number of ranks was either 64 (for 2, 4, and 8 nodes), or 512 (for 16, 32, and 64 nodes). Hence, the maximum number of ranks (for 64 nodes) was 2048. The numbers above the bars (in parentheses) indicate the check- point image size for each MPI rank. 2 4 8 16 32 64 1 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Restart Time (s) GROMACS 2 4 8 16 32 64 miniFE 2 4 8 16 32 64 # Compute Nodes (32 ranks/node, except LULESH) HPCG 2 4 8 16 32 64 CLAMR 2 4 8 16 32 64 LULESH Figure 7: Restart overhead under MANA for different real- world HPC benchmarks running on multiple nodes. In all cases, except LULESH, 32 MPI ranks were executed on each compute node. Ranks/node is as in Figure 6. Figure 8 shows the contribution of different components to the checkpointing overhead for the case of 64 nodes for the five different benchmarks. In all cases, the communication overhead for handling MPI collectives in the two-phase algorithm of Section 2.5 is found to be less than 1.6 s. In all cases, the time to drain in-flight MPI messages was less than 0.7 s. The total checkpoint time was dominated by the time to write to the storage system. The next big source of checkpointing GROMACS miniFE HPCG CLAMR LULESH Benchmark (64 nodes; 32 ranks/node, except LULESH) 0 20 40 60 80 100 Contribution to Checkpoint Time (%s) Write Time Drain Time Comm. overhead Figure 8: Contribution of different factors to the checkpoint- ing overhead under MANA for different real-world HPC benchmarks running on 64 nodes. Ranks/node is as in Fig- ure 6. The ‚Äúdrain time‚Äù is the delay in starting a checkpoint while MPI message in transit are completed. The communi- cation overhead is the time required in the protocol for net- work communication between the checkpoint coordinator and each rank. overhead was the communication overhead. The current imple- mentation of the checkpointing protocol in DMTCP uses TCP/IP sockets for communication between the MPI ranks and the central- ized DMTCP coordinator. The communication overhead associated with the TCP layer is found to increase with the number of ranks, especially due to metadata in the case of small messages that are exchanged between MPI ranks and the coordinator. Finally, Figure 7 shows the restart overhead under MANA for the different MPI benchmarks. The restart time varies from less than 10 s to 68 s (for 2048 ranks of HPCG running over 64 nodes). The restart times increase in proportion to the total amount of checkpointing data that is read from the storage. In all the cases, the restart overhead is dominated by the time to read the data from the disk. The time to recreate the MPI opaque identifiers (see Section 2.2) is less than 10 % of the total restart time. 3.5 Transparent Switching of MPI libraries across Checkpoint-restart This section demonstrates that MANA can transparently switch between different MPI implementations across checkpoint-restart. This is useful for debugging programs (even the MPI library) as it allows a program to switch from a production version of an MPI library to a debug version of the MPI library. The GROMACS application is launched using the production version of CRAY MPI, and a checkpoint is taken 55 s into the run. The computation is then restarted on top of a custom-compiled debug version of MPICH (for MPICH version 3.3). MPICH was chosen because it is a reference implementation whose simplicity makes it easy to instrument for debugging. 3.6 Transparent Migration across Clusters Next, we consider cross-cluster migration for purposes of wide- area load balancing either among clusters at a single HPC site or even among multiple HPC sites. This is rarely done, since the two common vehicles for transparent checkpoint (BLCR as the base of 190 200 210 220 Runtime (s) Native Restarted (migrated from Cori) Open MPI/IB (2x4) MPICH/TCP (2x4) MPICH (8x1) Restart Configuration 0 Figure 9: Performance degradation of GROMACS after cross- cluster migration under three different restart configura- tions. The application was restarted after being check- pointed at the half-way mark on Cori. (Lower is better.) an MPI-specific checkpoint-restart service; or DMTCP/InfiniBand) both save the MPI library within the checkpoint image and continue to use that same MPI library on the remote cluster after migration. At each site and for each cluster, administrators typically configure and tune a locally recommended MPI implementation for perfor- mance. Migrating an MPI application along with its underlying MPI library destroys the benefit of this local performance tuning. This experiment showcases the benefits of MPI-agnostic, network- agnostic support for transparent checkpointing. GROMACS is run under MANA, initially running on Cori with a statically linked Cray MPI library running over the Cray Aries network. GROMACS on Cori is configured to run with 8 ranks over 4 nodes (2 ranks per node). Each GROMACS rank is single-threaded. A checkpoint was then taken exactly half way into the run. The checkpoints were then migrated to a local cluster that uses Open MPI over the InfiniBand network. The restarted GROMACS under MANA was compared with three other configurations: GROMACS using the local Open MPI, con- figured to use the local InfiniBand network (8 ranks over 2 nodes); GROMACS/MPICH, configured to use TCP (8 ranks over 2 nodes); and GROMACS/MPICH, running on a single node (8 ranks over 1 node). The network-agnostic nature of MANA allowed the Cori version of GROMACS to be restarted on the local cluster with any of three network options. We wished to isolate the effects due to MANA from the effects due to different compilers on Cori and the local cluster. In order to accomplish this, the native GROMACS on the local cluster was com- piled specially. The Cray compiler of Cori (using Intel‚Äôs C compiler) was used to generate object files (.o files) on Cori. Those object files were copied to the local cluster. The native GROMACS was then built using the local mpicc, but with the (.o files) as input instead of the (.c files). The local mpicc linked these files with the local MPI implementation, and the native application was then launched in the traditional way. Figure 9 shows that GROMACS‚Äôs performance degrades by less than 1.8% post restart on the local cluster for the three different restart configurations (compared to the corresponding native runs). Also, note that the performance of GROMACS under MANA post restart closely tracks the performance of the native configuration. 4 DISCUSSION AND FUTURE WORK Next, we discuss both the limitations and some future implications of this work concerning dynamic load balancing. 4.1 Limitations While the split-process approach for checkpointing and process migration is quite flexible, it does include some limitations inherited by any approach based on transparent checkpointing. Naturally, when restarting on a different architecture, the CPU instruction set must be compatible. In particular, on the x86 architecture, the MPI application code must be compiled to the oldest x86 sub-architecture among those remote clusters where one might consider restarting a checkpoint image. (However, the MPI libraries themselves may be fully optimized for the local architecture, since restarting on a remote cluster implies using a new lower half.) Similarly, while MPI implies a standard API, any local extensions to MPI must be avoided. The application binary interface (ABI) used by the compiled MPI application must either be compatible or else a ‚Äúshim‚Äù layer of code must be inserted in the wrapper functions for calling from the upper half to the lower half. And of course, the use of a checkpoint coordinator implies coor- dinated checkpointing. If a single MPI rank crashes, MANA must restore the entire MPI computation from an earlier checkpoint. 4.2 Future Work MPI version 3 has added nonblocking collective communication calls (e.g., MPI_Igather). In future work, we propose to extend the two-phase algorithm for collective communication of Section 2.5 to the nonblocking case. The approach to be explored would be to employ a first phase that uses a nonblocking trivial barrier (MPI_Ibarrier), and to then convert the actual asynchronous col- lective call to a synchronous collective call (e.g., MPI_Gather to MPI_Igather) for the second phase. Nonblocking variations of col- lective communication calls are typically used as performance op- timizations in an MPI application. If an MPI rank reaches the col- lective communication early, then instead of blocking, it can con- tinue with an alternate compute task while occasionally testing (via MPI_Test/MPI_Wait) to see if the other ranks have all reached the barrier. In the two-phase analog, a wrapper around the nonblocking collective communication causes MPI_Ibarrier to be invoked. When the ranks have all reached the nonblocking trivial barrier and the MPI_Test/MPI_Wait calls of the original MPI application reports completion of the MPI_Ibarrier call of phase 1, then this implies that the ranks are all ready to enter the actual collective call of phase 2. A wrapper around MPI_Test/MPI_Wait can then invoke the actual collective call of phase 2. The split-process approach of MANA opens up some impor- tant new features in managing long-running MPI applications. An immediately obvious feature is the possibility of switching in the middle of a long run to a customized MPI implementation. Hence, one can dynamically substitute a customized MPI for performance analysis (e.g., using PMPI for profiling or tracing); or using a spe- cially compiled ‚Äúdebug‚Äù version of MPI to analyze a particular but occurring in the MPI library in the middle of a long run. This work also helps support many tools and proposals for opti- mizing MPI applications. For example, a trace analyzer is sometimes used to discover communication hotspots and opportunities for bet- ter load balancing. Such results are then fed back by re-configuring the binding of MPI ranks to specific hosts in order to better fit the underlying interconnect topology. MANA can enable new approaches to dynamically load balance across clusters and also to re-bind MPI ranks in the middle of a long run to create new configurations of rank-to-host bindings (new topology mappings). Currently, such bindings are chosen statically and used for the entire lifetime of the MPI application run. This added flexibility allows system managers to burst current long- running applications into the Cloud during periods of heavy usage or when the the MPI application enters a new phase for which a different rank-to-host binding is optimal. Finally, MANA can enable a new class of very long-running MPI applications ‚Äî ones which may outlive the lifespan of the original MPI Implementation, cluster, or even the network interconnect. Such temporally complex computations might be discarded as in- feasible today without the ability to migrate MPI implementations or clusters. 5 RELATED WORK Hursey et al. [22] developed a semi-network-agnostic checkpoint service for Open-MPI. It applied an ‚ÄúMPI Message‚Äù abstraction to a Chandy/Lamport algorithm [11], greatly reducing the complexity to support checkpoint/restart for many multiple network intercon- nects. However, it also highlighted the weakness of implementing transparent checkpointing within the MPI library, since porting to an additional MPI implementation would likely require as much software development as for the first MPI implementation. Addi- tionally, its dependence on BLCR imposed a large overhead cost, as it lacks support for SysV shared memory. Separate proxy processes for high- and low-level operations have been proposed both by CRUM (for CUDA) and McKernel (for the Linux kernel). CRUM [16] showed that by running a non-reentrant library in a separate process, one can work around the problem of a library ‚Äúpolluting‚Äù the address space of the application process ‚Äî i.e., creating and leaving side-effects in the application process‚Äôs address space. This decomposition of a single application process into two processes, however, forces the transfer of data between two processes via RPC, which can cause a large overhead. McKernel [17] runs a ‚Äúlightweight‚Äù kernel along with a full- fledged Linux kernel. The HPC application runs on the lightweight kernel, which implements time-critical system calls. The rest of the functionality is offloaded to a proxy process running on the Linux kernel. The proxy process is mapped in the address space of the main application, similar to MANA‚Äôs concept of a lower half, to min- imize the overhead of ‚Äúcall forwarding‚Äù (argument marshalling/un- marshalling). In general, a proxy process approach is problematic for MPI, since it can lead to additional jitter as the operating system tries to schedule the extra proxy process alongside the application pro- cess. The jitter harms performance since the MPI computation is constrained to complete no faster than its slowest MPI rank. Process-in-process [21] has in common with MANA that both approaches load multiple programs into a single address space. However, the goal of process-in-process was intra-node communi- cation optimization, and not checkpoint-restart. Process-in-process loads all MPI ranks co-located on the same node as separate threads within a single process, but in different logical ‚Äúnamespaces‚Äù, in the sense of the dlmopen namespaces in Linux. It would be diffi- cult to adapt process-in-process for use in checkpoint-restart since that approach implies a single ‚Äúld.so‚Äù run-time linker library that managed all of the MPI ranks. In particular, difficulties occur when restarting with fresh MPI libraries while ‚Äúld.so‚Äù retains pointers to destructor functions in the pre-checkpoint MPI libraries. In the special regime of application-specific checkpointing for bulk synchronous MPI applications, Sultana et al. [33] supported checkpointing by separately saving and restoring MPI state (MPI identifiers such as communicators, and so on). This is combined with application-specific code to save the application state. Thus, when a live process fails, it is restored using these two components, without the need restart the overall MPI job. SCR [32], and FTI [3] are other application-specific checkpoint- ing techniques. An application developer declares memory regions they‚Äôd like to checkpoint and checkpointing can only be done at specific points in the program determined by the application devel- oper. Combining these techniques with transparent checkpointing is outside the scope of this work, though it is an interesting avenue for further inquiry. In general, application-specific and transparent checkpointing each have their merits. Both application-specific and transparent checkpointing are used in practice. At the high end of HPC, application-specific checkpointing is preferred since the labor for supporting this is small compared to the labor already invested in supporting an extreme HPC application. At the low and medium end of HPC, developers prefer trans- parent checkpointing because the development effort for the soft- ware is more moderate, and the labor overhead of a specialized application-specific checkpointing solution would then be signif- icant. System architectures based on burst buffers (e.g., Cray‚Äôs DataWarp [19]) can be used to reduce the checkpointing overhead for both application-specific and transparent checkpointing. 6 CONCLUSION This work presents an MPI-Agnostic, Network-Agnostic transpar- ent checkpointing methodology for MPI (MANA), based on a split- process mechanism. The runtime overhead is typically less than 2%, even in spite of the overhead incurred by the current Linux ker- nel when the ‚ÄúFS‚Äù register is modified each time control passes between upper and lower half. Further, Section 3.3 shows that a commit (patch) to fix this by the Linux kernel developers is un- der review and that this commit reduces the runtime overhead of GROMACS from 2.1% to 0.6% using the patched kernel. Similar reductions to about 0.6% runtime overhead are expected in the general case. An additional major novelty is the demonstration of practical, efficient migration between clusters at different sites using differ- ent networks and different configurations of CPU cores per node. This was considered impractical in the past because a checkpoint image from one cluster will not be tuned for optimal performance on the second cluster. Section 3.6 demonstrates that this is now feasible, and that the migration of a GROMACS job with 8 MPI ranks experiences an average runtime overhead of less than 1.8% as compared to the native GROMACS application (without MANA) on the remote cluster. As before, even this overhead of 1.8% is likely to be reduced to about 0.6% in the future, based on the results of Section 3.3 with a patched Linux kernel.",1883
1798,Systems and Networking,Gene Cooperman,"March 15th, 2018",Transparently Checkpointing Software Test Benches to Improve Productivity of SoC Verification in an Emulation Environment,http://www.ccs.neu.edu/home/gene/papers/dvcon-us-18.pdf," ""Transparently Checkpointing Software Test Benches to Improve Productivity of SoC Verification in an Emulation Environment"", Ankit Garg, Suresh Krishnamurthy, Gene Cooperman, Rohan Garg, and Jeff Evans, <em>2018 Design and Verification Conference and Exhibition</em> (DVCON-US 2018)","Traditionally hardware emulation has been used in in-circuit emulation (ICE) mode where the design under test (DUT) executes inside the emulator and connected to the real target, which acts as a testbench. Over time, the software testbench-based emulation environments have become very popular, since the users can control its operation remotely from their desktops. This makes emulators an enterprise resource, accessible to a multitude of users spread across continents and multiple time zones. And since emulators are expensive resources, it is important to utilize them efficiently. Full checkpoint save/restore capability of emulation jobs helps the utilization by enabling flexible job scheduling, shortening of jobs by jumping ahead to interesting points for debug, carrying out what-if analysis, etc. Emulators have native save/restore capabilities for the model on the emulator. The software testbenches can be complex in multiple dimensions. For example, they may be using C/C++, SystemC, SystemVerilog, etc. They may be multi- threaded and based on multiple processes, they may be using IPC, and so on. It then becomes a challenge to save the states of such sophisticated software testbenches both transparently and through a uniform, reliable, mechanism. Since the objective is to solve the problem at an enterprise level, it is critical to find a uniform solution for a diverse set of software testbenches throughout the enterprise. The DMTCP (Distributed MultiThreaded Checkpointing) package supports such a uniform solution. This paper describes the integration of DMTCP with a virtual testbench-based emulation. This brings large benefits to a real life environment that includes multiple emulators within the larger set of enterprise resources. There are other, additional applications of full checkpoint save/restore for emulation jobs that become apparent only after having gained experience with its use in job management. For example, after having observed the behavior of an application prior to checkpoint, additional triggers can be inserted at the time of restore, to enhance debugging of an exception or other unusual behavior.s. II. BACKGROUND: CO-MODELING AND DMTCP A. Review of Co-Modeling Architecture Co-emulation, or (transaction-level) Co-Modeling, is the process of modeling cycle-accurate synthesizable hardware models (DUTs) running on an emulator, communicating with testbenches at transaction level via a high- speed link between the emulator and the host system. The reusable testbenches are interfaced to synthesizable transactors co-located with the DUT in the emulator. These ‚Äúaccelerated‚Äù transactors convert high-level transactions to signal-level stimuli to drive the DUT. During an emulation run, the hardware communicates with the software testbench using a high-speed link. For every DUT clock or for each time point in the model execution, communication may be required by one or more synthesizable transactors. In the general case, the DUT clocks will be suspended at times to complete all the communication requests for a given point in the model execution. So at any point of time, there could be inflight data in the link. Figure 1. Co-Modeling Architecture B. Review of DMTCP flow DMTCP is an open-source package that provides a capability for Checkpoint/Restart in applications involving multiple processes/threads distributed across multiple hosts and connected by socket connections. The package can be downloaded from: http://dmtcp.sourceforge.net It operates under Linux, with no modifications to the Linux kernel or to the user code, and it can be used by unprivileged users (no root privilege needed). One can later restart from a checkpoint, or even migrate the processes by moving the checkpoint files to another host prior to restarting. Figure 2 shows the typical flow of a user job under DMTCP. Figure 2. Typical flow of a user job under DMTCP A detailed description on DMTCP (Distributed MultiThreaded Checkpointing) internals can be found in [1]. DMTCP also provides a flexible plugin model that supports the ability to write an add-on library that can: support DMTCP event hooks; add custom wrappers around system calls; and add a custom distributed name service facility [2, 3]. III. MOTIVATING USE CASES Checkpoint-restore of emulation jobs opens a wide of range of applications, which will help users build a fault- tolerant emulation system, powerful debug mechanisms, and increase usage efficiency of critical resources like hardware emulators. This section describes different use cases for such capability in emulation. The following section, Section IV, then presents the Checkpoint/Restore Framework in detail. A. Skipping repeated initial sequences Designs may have an initialization phase that is always executed for each test. This may be a hardware reset phase or boot-up, which takes a great deal of time before an actual test can start. We can save much of the emulation runtime by taking a checkpoint right after this repeated initial sequence. New tests can then just restart immediately after this initial sequence, thus saving a great deal of regression time. Another application of this is to do what-if analysis after reaching an interesting point in the execution. In Figure 3, each test Test0, Test1, Test2 executes the same initial sequence, which takes C1 time. Figure 3. Job Progress with fixed initialization sequence The tests then follow their own unique paths, completing the test in different time intervals (T0, T1, and T2). This C1 time is saved if we checkpoint just after completion of the initial sequence and then restore from the checkpoint at the original state in each test. B. Better Job Management Policies One of the advantages of virtualization of test environments is the ability to use emulators remotely. This allows emulation to be moved to the data center, with jobs being managed by a workload management platform such as LSF. However, the non-pre-emptive nature of emulation jobs forbids pre-emptive scheduling policies. This prevents a high-priority job from acquiring the resources occupied by a currently executing low-priority job. For example, a currently running long job cannot be removed even though a short job has just arrived. The short job has to wait until the long job exits and frees up the resources. Hence, the non-pre-emptive nature of emulation jobs can easily lead to inefficient use of emulators. Consider the scenario depicted in Figure 4: Figure 4. Job Management Job1 occupies 4 slots on Emulator1 and Job2 occupies 2 slots on Emulator2. Further a high-priority request from Job3 arrives for 6 resources. As resources are fragmented, irrespective of its priority, Job3 has to wait for either of Job1 or Job2 to finish. The Checkpoint/Restore capability can remove this shortcoming and enable a pre-emptive scheduling policy. We could have checkpointed either of Job1 or Job2 and freed up the resources for Job3. Whenever resources become available, the checkpointed job can then be restarted using the DMTCP restart scripts. Further, this situation also leads to inefficient use of emulators due to resource fragmentation within each emulator. Using Checkpoint/Restore we could have migrated an interfering job to a different emulator, thereby making contiguous resources available for the new job. In Figure 5, the checkpoint of Job2 is taken first, and then Job2 is restarted on Emulator1. This frees up all 6 slots on Emulator2 for Job3. Job3 can now be allocated using contiguous resources on Emulator2. Figure 5. Resource free with Job Migration Another interesting example concerns the issue of ‚Äúfairness‚Äù for large-capacity jobs. In a distribution system dominated by high-priority, small-capacity jobs, a low-priority large-capacity job may never actually get a chance to run if the policy is to wait for required slots to become available. Further, a high-priority long job can lead to underutilization of emulation resources as freed slots cannot be allocated for other small jobs if they have to be pooled for a high-priority long job waiting in the queue. With checkpoint-restart, one can save all the small jobs at once, run the large job and then restart the small jobs. A long low-priority job might otherwise never get an opportunity to complete, if not for the use of checkpoint-restart. There are several such instances where checkpoint- restart can offer this kind of flexibility in an emulation job scheduling system. C. Debugging from past simulation time Debugging is an important requirement for verification engineers. Much time is spent in debugging functional issues in design as well as integration issues with software during validation of a full SoC. The ability to take a checkpoint of the full system can provide capabilities to start debugging just before an issue occurs, by restarting from the point of a previous checkpoint state. For example, one can take periodic checkpoints and when a problem is seen: start from the last checkpoint, run again and capture more debug information. This is a tremendous advantage when a debugging issue occurs only after a run of long duration. A large amount of time is saved, since one no longer needs to wait for the test to arrive at the point of interest. IV. CHECKPOINT/RESTORE FRAMEWORK In this section we describe the implementation of checkpoint-restore for emulation jobs. We address checkpoint and restore separately. Figure 6 shows the typical flow of an emulation job under DMTCP. Note that in Figure 2, the checkpoint was invoked by the user at an arbitrary point in time. However, in the emulation flow (Figure 6), the user invokes the checkpoint programmatically from within the user code, when the simulation reaches certain number of cycles. Figure 6. Typical flow of an emulation job under DMTCP. A. Checkpoint Checkpointing of emulation jobs involves both the emulator and the testbench on the workstation. One must save the simulation state for the design running on an emulator, while also employing binary-level checkpointing using DMTCP for the processes representing the testbench side and running on the workstation. As always, we have to make sure that the hardware side stops generating further transactions when a checkpoint is in progress. In addition, checkpointing requires that we make sure that there is no in-flight data inside the high-speed interface between the emulator and the testbench at the time of checkpointing. In the case that a checkpoint is taken without flushing the in-flight data, those transactions will be lost at the time of restoring from the checkpoint, thus resulting both in incorrect hardware state and incorrect state on the testbench side. Figure 7. Flowchart for Checkpoint Algorithm The following is the integrated algorithm for checkpointing of an emulation job. These steps are also depicted graphically in Figure 7. 1) A Checkpoint Request is received by the testbench either through an external utility such as dmtcp_command or through a user-exposed API, ScheduleCheckpoint, made by testbench itself. The request is sent to the emulator in order to freeze the running design. This will stop both the user design clocks and the simulation time itself. 2) Once a design is frozen, additional transactions from the hardware side will no longer be generated. At this point the data in flight inside the link is flushed until all of them have been processed and the emulator reaches a quiescent state. 3) When the emulator has reached a quiescent state, the system initiates the checkpoint of the emulator model by using the checkpoint technology native to the emulator. This will store the current design state to disk. 4) The system then disconnects from the emulator and makes sure that all emulator-related processes are terminated. This step will ensure that any external connections not running under DMTCP are removed from consideration. For example, there may be connections to a licensing server, to some waveform dump servers, and so on. This also reduces the overall checkpoint time by freeing up memory used by these external connections that the binary checkpointing procedure would otherwise have to save, as described in the next step. Further, checkpoints taken this way are independent of which specific emulator the session was running on, and this makes it easy to relocate saved emulation jobs to other emulators. 5) Next, the system initiates DMTCP-based checkpointing on the testbench side. This involves calling dmtcp_checkpoint, a part of the DMTCP API. Here, one writes an emulation-specific external plugin for DMTCP, which will specify which files must be checkpointed. The DMTCP plugin is specific to the emulator and testbench infrastructure, and must also specify the path to the checkpoint database, where DMTCP checkpoint image files are saved alongside the hardware database, as a consolidated database within the user specified path. . DMTCP also allows a user to have certain processes be explicitly excluded from checkpointing. This might be required for the case where processes have been spawned from an external library linked into the user testbench. Those processes are not required as part of a correct checkpoint state. And further, attempting to save such superfluous processes leads to other issues when restoring from a checkpoint if those processes were communicating with external processes that were not running under DMTCP. The details of DMTCP external plugins can be found in [2, 3]. 6) After the invocation of dmtcp_checkpoint returns, we can choose either to exit the current emulation or to resume the current run. 7) After resuming from a checkpoint, the following steps are taken: ‚óè Re-connect to same emulator and configure the same design again. ‚óè Restart the tool-specific processes and re-connect to servers from which they exited in step (4). This step is isolated to the emulation tool‚Äôs internal workings, and does not require the collaboration of DMTCP. ‚óè Perform a hardware design restore from the same checkpoint database and start the design clocks. ‚óè Note that after being restored from a checkpoint, the testbench side resumes in a correct state at the end of this procedure, and so nothing more is required on the testbench side. B. Restore/Restart The DMTCP package dumps a restart script at the time of checkpoint. This script takes care of restarting the entire testbench tree of processes. This script also takes care of restarting processes that were on remote machines. After restart, the system will ‚Äúwake up‚Äù in step (6) in the checkpoint sequence above, as if we have just returned from the call to dmtcp_checkpoint. So the remaining steps to restart are the same as those described in step (7) above. Figure 8. Flowchart for Restore The following is the algorithm for the restart/resume. These steps are also depicted graphically in Figure 8. 1) Use the restart script generated by DMTCP that relies on the checkpoint database (the checkpoint image files) in order to bring the whole testbench tree of processes up and running. 2) After DMTCP‚Äôs restore/restart, we return from the call to dmtcp_checkpoint. The next steps bring the HDL side up and fork any tool-specific processes. 3) The system then re-connects the emulator resource and downloads the design. 4) The system then restarts the tool-specific processes and re-connects to external servers such as license servers, waveform collection servers, etc. This step is completely isolated from the internal workings of the emulator tool. 5) The system then performs the hardware design restore using the same checkpoint database, and it starts the design clocks. This is the last step in successfully restoring the emulation. V. CASE STUDY: SKIPPING THE OS BOOT IN AN OEM COMPANY‚ÄôS SOC VALIDATION ENVIRONMENT For this case study, the SoC validation environment instantiates a SoC containing a CPU, Memory Subsystem, Switching Fabric, and peripherals. The SoC is modeled in a hybrid environment whereby part of the SoC is modeled on the workstation and part of the SoC is modeled in the emulator, and the Switching Fabric is the bridge between the models. Many of the SoC validation use cases require firstly booting an operating system (OS) in order to run the applications that are being validated. The boot of the OS takes on the order of hours to days. Often the applications that are being validated execute in a fraction of the time that it takes to boot the OS. This means that only a fraction of the emulation time was used to validate the application and the larger portion of the time is spent booting the OS in order to be able to run the application. Thus the overall boot time has an important impact not only on how many applications can be run per user per day, but also, from an emulation efficiency standpoint, how much emulation time is spent just getting the OS booted versus running the applications that are used to validate the SoC and/or the application. The ideal scenario would be to eliminate the time it takes to boot the OS. A solution close to the ideal scenario is to checkpoint the SoC validation environment after the boot of the OS. This OS boot can then be delivered as part of a checkpoint image that is bundled with the rest of the SoC validation environment. The checkpoint of the hardware can be taken by technology native to the emulator. The complexity is in the checkpointing of the part of the SoC validation environment that is executing on the workstation. There were two early attempts to checkpoint, before settling on DMTCP as the preferred solution. A first attempt at checkpointing, prior to the use of DMTCP, was to capture all of the stimulus from the hardware during the OS boot along with a checkpoint of the hardware, and then to restore the OS boot using the stimulus. This stimulus was replayed into the software test bench to re-establish the state of the software, and then finally restore the state of the emulator using the hardware checkpoint. This method worked, except it had two notable drawbacks: (1) Depending on how much stimulus needed to be captured, the size of the replay database could become quite large. (2) The time it took the software testbench to execute, controlled the time it took to perform the restoration of the software testbench. A second attempt at checkpointing prior to employing DMTCP was to leverage the Boost C++ libraries to make each of the software components of the SoC validation environment checkpoint-able. This method worked except that it had a major drawback in that each SoC validation software component had to be developed with checkpointing in mind and if there was just one component that didn¬πt support checkpointing or did the checkpointing incorrectly, the SoC validation environment was not checkpoint-able. Hence, the ideal solution would be to transparently checkpoint the software in the same way as we checkpoint the hardware. The DMTCP-based approach was able to overcome the limitations of these first two attempts by transparently checkpointing the software on the workstation, which includes the part of the SoC modeled on the workstation, the software testbench, and the emulation software. The checkpoint is taken without concern for how the software has been modeled and also without concern for the speed at which the software testbench executes. This resulted in making an ‚ÄúOS boot‚Äù checkpoint available to the users along with the SoC verification environment. This allows those users to restore the checkpoint in less than 5 minutes, and to then to run their applications for SoC validation in an environment after the OS boot. Now, users requiring this use case can focus their emulation time on running their application, and skipping the lengthy OS boot time. The DMTCP-based approach has accelerated the time to run an application by close to a factor of two. Additionally, it has freed up the emulation time that would have been spent in ‚ÄúOS boot‚Äù, thus saving many hours of emulation time. In addition, the DMTCP approach also saves the state of the emulation runtime software itself. This feature provides added value, as compared to the two earlier checkpointing approaches. The checkpoint-restore flow can now set up to address additional aspects of the emulation runtime environment, such as triggers, which are important for debugging in the case of an exception. This enables the designer to create an environment closer to a ‚Äúturnkey solution‚Äù, in which the end user no longer has to remember to load the trigger prior to starting the run of their application. First use case of DMTCP at an OEM company was on a regression suite consisting of 40 jobs. The 40 jobs had a similar profile in that they required around 1 hour to boot the OS and then 1 hour of execution of test content. DMTCP was used to create a checkpoint just after the boot of the OS. This checkpoint then becomes part of the collateral of that database. Any future user of that database and software configuration can restore the checkpoint rather than re-running the boot of the OS. The restoration of database using the checkpoint takes around 5 minutes. That is a time savings of 55 minutes per job for this regression. As a reminder, this environment is a hybrid environment and pending the configuration of whether the CPU is in software or RTL and also the type of OS can greatly impact the ""OS boot"" time from an hour to days. For this regression the 40 jobs were able to run in around 22 hours versus previously they would have taken 40 hour. Job throughput was increased close to 2x. This results not only in a substantial time savings but also a substantial cost savings. Figure 9. Regression Suite Emulation Time Comparison Figure 9 is highlighting the changes introduced by adding DMTCP into this use case; the following points are related to the numbers in the figure 9. 1) Checkpoint is created for OS boot as part of preparing the database for users. 2) Restoring OS boot from checkpoint saves 55 minutes for each job. 3) First job is completed after 1.1 hours with DMTCP versus 2 hours without DMTCP. 4) Full regression is completed after 22.9 hours with DMTCP versus 40 hours without DMTCP. During the integration of DMTCP with the emulation and SoC validation environment, we faced several challenges: (1) Very large read-only files were being saved as part of the checkpoint. This had an impact on both checkpoint/restore time as well as the memory footprint on disk. This was solved by having the DMTCP Emulation plugin detect and decide not to checkpoint such read-only files. The tool-specific file list was written into the DMTCP plugin to identify just those files that needed to be checkpointed. (2) Checkpoints were not portable to another site, due to some file paths that were preserved as part of the checkpoint. This was solved by using the existing file path virtualization plugin of DMTCP, allowing these paths to be changed at restore time. Limitations found when deploying DMTCP 1) Some use cases have a remote process connected via TCP on Windows machine. Additional work would be required to support this kind of use case both within the DMTCP community as well as in the testbench infrastructure. 2) Some use cases require changing the initial state of the environment which is part of the DMTCP checkpoint. For instance, if you had a SoC that had a programmable number of DIMMs and the number of DIMMs was changing per test you wouldn't be able to re-use a single checkpoint. DMTCP was found to be easy to integrate, and it required minimal changes to emulation environment. This has demonstrated the success of this approach toward OS-based use case validation during emulation. VI. FUTURE WORK We intend to work on developing preemptive capabilities for emulation jobs in a workload management system such as LSF. A case study in this environment is needed in order to discover the practical challenges thereof, and to help deploy this technology for more flexible job scheduling management. Finally, verification of a network switch presents an additional interesting case study for the future. In this scenario, a virtual machine is often required, so that simulated Ethernet traffic can be injected by the virtual machine into the environment for verification test coverage. This makes transparent checkpointing on the testbench side more difficult, since even though the virtual machine can be modified to inject Ethernet traffic, the virtual machine snapshot facility is difficult to modify, and so the state of the Ethernet traffic generator will not be checkpointed. On restore, some steps in the state diagram for Ethernet packets may be lost. As part of future work, it is proposed to use the ability of DMTCP to checkpoint a virtual machine from the outside. DMTCP has the ability to carry out a snapshot from the outside for the case of a QEMU virtual machine over KVM [4]. That same work [4] also presents DMTCP's ability to checkpoint a network of virtual machines. This latter case makes possible verification for end-to-end Ethernet test coverage between two virtual machines. VII. CONCLUSION This paper describes the approach to transparently checkpoint/restore emulation jobs and various key benefits it brings along with it. This integration was successfully tried in an OEM company‚Äôs SOC validation environment, which not only reduced total regression time but also increased Emulator efficiency. Emulation time is precious and any saving of this time directly affects one‚Äôs total verification cost. Experimental results have shown that this approach, when integrated with job management system, has increased the emulator utilization and has also increased the productivity of the verification engineers by providing them with a window to look back in time. The integration has also been successfully tried for a variety of software testbenches including C/C++/SystemC, and a SystemVerilog testbench running on a simulator. These testbenches can have multiple threads or multiple processes spread across different machines.",1884
1799,Systems and Networking,Gene Cooperman,"May 7th, 2014",Transparent Checkpoint-Restart over InfiniBand,http://www.ccs.neu.edu/home/gene/papers/hpdc14.pdf," ""Transparent Checkpoint-Restart over InfiniBand"", Jiajun Cao, Gregory Kerr, Kapil Arya and Gene Cooperman, ACM Symposium on High Performance Parallel and Distributed Computing (HPDC'14), pp. 13--24, ACM Press, 2014.","Transparently saving the state of the InÔ¨ÅniBand network as part of distributed checkpointing has been a long-standing challenge for researchers. The lack of a solution has forced typical MPI implementations to include custom checkpoint- restart services that ‚Äútear down‚Äù the network, checkpoint each node in isolation, and then re-connect the network again. This work presents the Ô¨Årst example of transpar- ent, system-initiated checkpoint-restart that directly sup- ports InÔ¨ÅniBand. The new approach simpliÔ¨Åes current prac- tice by avoiding the need for a privileged kernel module. The generality of this approach is demonstrated by applying it both to MPI and to Berkeley UPC (UniÔ¨Åed Parallel C), in its native mode (without MPI). Scalability is shown by check- pointing 2,048 MPI processes across 128 nodes (with 16 cores per node). The run-time overhead varies between 0.8% ands (Section 7) are presented. 2. BACKGROUND Section 2.1 reviews some concepts of InÔ¨ÅniBand, necessary for understanding the checkpointing approach described in Section 3. Section 2.2 describes the use of plugins in DMTCP. 2.1 InÔ¨ÅniBand Verbs API In order to understand the algorithm, we review some concepts from the Verbs API of InÔ¨ÅniBand. While there are several",1885
1800,Systems and Networking,Engin Kirda,"August 11th, 2016","UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware",https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_kharraz.pdf," A. Kharraz, S. Arshad, C. Mulliner, W. Robertson, E. Kirda. ""UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware"". In USENIX Security Symposium Austin, TX US, Aug 2016.","Although the concept of ransomware is not new (s In this paper we presented UNVEIL, a novel approach to detecting and analyzing ransomware. Our system is the first in the literature to specifically identify typical behavior of ransomware such as malicious encryption of files and locking of user desktops. These are behaviors that are difficult for ransomware to hide or change. The evaluation of UNVEIL shows that our approach was able to correctly detect 13,637 ransomware samples from multiple families in a real-world data feed with zero false positives. In fact, UNVEIL outperformed all ex- isting AV scanners and a modern industrial sandboxing technology in detecting both superficial and technically sophisticated ransomware attacks. Among our findings was also a new ransomware family that no security com- pany had previously detected before we submitted it to VirusTotal. 9",1886
1801,Systems and Networking,Alan Mislove,"May 24th, 2018",Privacy Risks with Facebook‚Äôs PII-based Targeting: Auditing a Data Broker‚Äôs Advertising Interface,https://mislove.org/publications/PII-Oakland.pdf," G. Venkatadri et al., ""Privacy Risks with Facebook's PII-Based Targeting: Auditing a Data Broker's Advertising Interface,"" 2018 IEEE Symposium on Security and Privacy (SP), San Francisco, CA, 2018, pp. 89-107.","‚ÄîSites like Facebook and Google now serve as de facto data brokers, aggregating data on users for the purpose of implementing powerful advertising platforms. Historically, these services allowed advertisers to select which users see their ads via targeting attributes. Recently, most advertising platforms have begun allowing advertisers to target users directly by uploading the personal information of the users who they wish to advertise to (e.g., their names, email addresses, phone numbers, etc.); these services are often known as custom audiences. Custom audiences effectively represent powerful linking mechanisms, allowing advertisers to leverage any PII (e.g., from customer data, public records, etc.) to target users. In this paper, we focus on Facebook‚Äôs custom audience implementation and demonstrate attacks that allow an adversary to exploit the interface to infer users‚Äô PII as well as to infer their activity. SpeciÔ¨Åcally, we show how the adversary can infer users‚Äô full phone numbers knowing just their email address, determine whether a particular user visited a website, and de-anonymize all the visitors to a website by inferring their phone numbers en masse. These attacks can be conducted without any interaction with the victim(s), cannot be detected by the victim(s), and do not require the adversary to spend money or actually place an ad. We propose a simple and effective Ô¨Åx to the attacks based on reworking the way Facebook de-duplicates uploaded information. Facebook‚Äôs security team acknowledged the vulnerability and has put into place a Ô¨Åx that is a variant of the Ô¨Åx we propose. Overall, our results indicate that advertising platforms need to carefully consider the privacy implications of their interfaces.The vast amounts of user data that social networking services have collected is now utilized by their advertising platforms to allow advertisers to target users via their PII. In this paper, we have shown how the inclusion of PII-based targeting opens up new privacy leaks in advertising platforms. By giving advertisers Ô¨Åne-grained control over the set of users targeted, and by providing them with coarse-grained statistics of audience sizes, the platforms open themselves to powerful attacks that can let an adversary learn private information about users. While we have proposed a solution to the attacks we uncovered, our work shows that platforms need to carefully audit their interfaces when introducing PII-based targeting.",1887
1802,Systems and Networking,Ji-Yong Shin,"March 5th, 2024",FusionFlow: Accelerating Data Preparation for Machine Learning with Hybrid CPU-GPU Processing,https://www.vldb.org/pvldb/vol17/p863-kim.pdf," Taeyoon Kim, Chanho Park, Mansur Mukimbekov, Heelim Hong, Minseok Kim, Ze Jin, Changdae Kim, Ji-Yong Shin, Myeongjae Jeon. (2023). FusionFlow: Accelerating Data Preparation for Machine Learning with Hybrid CPU-GPU Processing Proc. VLDB Endow., 17, 863-876. https://www.vldb.org/pvldb/vol17/p863-kim.pdf","Data augmentation enhances the accuracy of DL models by diversi- fying training samples through a sequence of data transformations. While recent advancements in data augmentation have demonstrated remarkable efficacy, they often rely on computationally expensive and dynamic algorithms. Unfortunately, current system optimiza- tions, primarily designed to leverage CPUs, cannot effectively sup- port these methods due to costs and limited resource availability. To address these issues, we introduce FusionFlow, a system that cooperatively utilizes both CPUs and GPUs to accelerate the data preprocessing stage of DL training that runs the data augmentation algorithm. FusionFlow orchestrates data preprocessing tasks across CPUs and GPUs while minimizing interference with GPU-based model training. In doing so, it effectively mitigates the risk of GPU memory overflow by managing memory allocations of the tasks within the GPU-wide free space. Furthermore, FusionFlow provides a dynamic scheduling strategy for tasks with varying computational demands and reallocates compute resources on the fly to enhance training throughput for both single and multi-GPU DL jobs. Our evaluations show that FusionFlow outperforms existing CPU-based methods by 16‚Äì285% in single-machine scenarios and, to achieve similar training speeds, requires 50‚Äì60% fewer CPUs compared to utilizing scalable compute resources from external servers. PVLDB Reference Format: Taeyoon Kim, ChanHo Park, Mansur Mukimbekov, Heelim Hong, Minseok Kim, Ze Jin, Changdae Kim, Ji-Yong Shin, and Myeongjae Jeon. FusionFlow: Accelerating Data Preprocessing for Machine Learning with CPU-GPU Cooperation. PVLDB, 17(4): 863 - 876, 2023. doi:10.14778/3636218.3636238 PVLDB Artifact Availability: The source code, data, and/or other artifacts have been made available at https://github.com/omnia-unist/FusionFlow. This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. Proceedings of the VLDB Endowment, Vol. 17, No. 4 ISSN 2150-8097. doi:10.14778/3636218.3636238 1We propose FusionFlow that speeds up the dynamic data augmen- tation algorithms on CPUs and GPUs. The key idea is exploiting intra-batch parallelism, which splits an input mini-batch into mul- tiple tiny-batches and augments the mini-batch in parallel on those compute resources. FusionFlow applies several optimizations to make GPU-offloading of tiny-batch tasks highly effective and per- forms CPU worker scaling to make CPU resource usage in data- parallel training more balanced. Experimental results confirm the effectiveness of FusionFlow.",1888
